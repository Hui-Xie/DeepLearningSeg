# Nov 30th, Monday, 2020
Grid search Lambda with unconstrained optimziaiton +ReLU on the validation data:
Summary:
1  at lambda=0 (which means not using soft separation) on validation data, muError = 2.38373947;
2  In the case of using perfect R from ground truth, lambda0=2.06, lambda1=3.99, muError=1.6399;
   Reflecction:
   A  The coefficient unary terms is in [0.000017, 3.492] with mean 0.4896; does this big lambda make sense in physical meaning?
   B  If lambda0= 0.004, lambda1=0.004 at predicted R case level, the muError = 2.24765 with the perfect R, improving 5.7% comparing with  no softSeparation;
   C  Previous binary search experiments didn't search so big lambda value.
3  In the case of using predicted R from another network, lambda0=0.004, lambda1=0.004, muError = 2.349234;
   Comparing with the No soft separation case, this muError improves 1.4%;
   Reflection:
   A when R is not accurate, improvement is not explict;
   B We need to further improve predict R; we need to rethink the architecture of predictR network to improve it;
   C A caveat: The accuracy of R is more difficult to achieve the same level with mu,as R involves 2 measured surfaces;

Grid search Lambda with unconstrained optimziaiton +ReLU:
sigma2Path = /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20201117A_SurfaceSubnet_NoReLU/testResult/validation/validation_simga2.npy
muPath = /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20201117A_SurfaceSubnet_NoReLU/testResult/validation/validation_mu.npy
rPath = /home/hxie1/data/OCT_Duke/numpy_slices/log/RiftSubnet/expDuke_20200902A_RiftSubnet/testResult/validation/validation_Rift.npy
gPath = /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20201117A_SurfaceSubnet_NoReLU/testResult/validation/validation_gt.npy
riftGTPath = /home/hxie1/data/OCT_Duke/numpy_slices/log/RiftSubnet/expDuke_20200902A_RiftSubnet/testResult/validation/validation_RiftGts.npy
the coefficient of unary terms(Q = 1.0/(sigma^2)):
Q/2 min = 0.000174444867298007
Q/2 mean = 0.48962265253067017
Q/2 max = 3.4920814037323
output Dir = /home/hxie1/data/OCT_Duke/numpy_slices/searchSoftLambda

at both min lambdas (=0), MuError= 2.383739471435547
===============================
Use predict R for grid-searching Lambda:

rSource = predictR
axis x: lambda0_min, lambda0_max, lambda0_step = 0, 4.0, 0.01
axis y: lambda1_min, lambda1_max, lambda1_step = 0, 4.0, 0.01
min error location with mu error = 2.356391668319702:
axis x: location: x= 1, lambda0 = 0.01
axis y: location: y= 1, lambda1 = 0.01

rSource = predictR
axis x: lambda0_min, lambda0_max, lambda0_step = 0, 0.5, 0.002
axis y: lambda1_min, lambda1_max, lambda1_step = 0, 0.5, 0.002
min error location with mu error = 2.3492398262023926: (Best)
axis x: location: x= 2, lambda0 = 0.004
axis y: location: y= 2, lambda1 = 0.004

rSource = predictR
axis x: lambda0_min, lambda0_max, lambda0_step = 0, 0.004, 2e-05
axis y: lambda1_min, lambda1_max, lambda1_step = 0, 0.004, 2e-05
min error location with mu error = 2.3492515087127686:
axis x: location: x= 199, lambda0 = 0.00398
axis y: location: y= 199, lambda1 = 0.00398

rSource = predictR
axis x: lambda0_min, lambda0_max, lambda0_step = 0, 4e-05, 2e-07
axis y: lambda1_min, lambda1_max, lambda1_step = 0, 4e-05, 2e-07
min error location with mu error = 2.3812191486358643:
axis x: location: x= 200, lambda0 = 3.9999999999999996e-05
axis y: location: y= 200, lambda1 = 3.9999999999999996e-05

rSource = predictR
axis x: lambda0_min, lambda0_max, lambda0_step = 0, 4e-07, 2e-09
axis y: lambda1_min, lambda1_max, lambda1_step = 0, 4e-07, 2e-09
min error location with mu error = 2.383711099624634:
axis x: location: x= 190, lambda0 = 3.8e-07
axis y: location: y= 198, lambda1 = 3.96e-07

==============================
Use perfect ground truth for grid-searching Lambda:

rSource = GTR
axis x: lambda0_min, lambda0_max, lambda0_step = 0, 4.0, 0.01
axis y: lambda1_min, lambda1_max, lambda1_step = 0, 4.0, 0.01
min error location with mu error = 1.6399389505386353:  (Best)
axis x: location: x= 206, lambda0 = 2.06
axis y: location: y= 399, lambda1 = 3.99

rSource = GTR
axis x: lambda0_min, lambda0_max, lambda0_step = 0, 0.5, 0.002
axis y: lambda1_min, lambda1_max, lambda1_step = 0, 0.5, 0.002
min error location with mu error = 1.695436954498291:
axis x: location: x= 249, lambda0 = 0.498
axis y: location: y= 249, lambda1 = 0.498

rSource = GTR
axis x: lambda0_min, lambda0_max, lambda0_step = 0, 0.004, 2e-05
axis y: lambda1_min, lambda1_max, lambda1_step = 0, 0.004, 2e-05
min error location with mu error = 2.247654676437378:
axis x: location: x= 199, lambda0 = 0.00398
axis y: location: y= 199, lambda1 = 0.00398

rSource = GTR
axis x: lambda0_min, lambda0_max, lambda0_step = 0, 4e-05, 2e-07
axis y: lambda1_min, lambda1_max, lambda1_step = 0, 4e-05, 2e-07
min error location with mu error = 2.3794524669647217:
axis x: location: x= 200, lambda0 = 3.9999999999999996e-05
axis y: location: y= 200, lambda1 = 3.9999999999999996e-05

rSource = GTR
axis x: lambda0_min, lambda0_max, lambda0_step = 0, 4e-07, 2e-09
axis y: lambda1_min, lambda1_max, lambda1_step = 0, 4e-07, 2e-09
min error location with mu error = 2.383693218231201:
axis x: location: x= 198, lambda0 = 3.96e-07
axis y: location: y= 198, lambda1 = 3.96e-07

=================================
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Nov 26th, 2020: Unary terms coefficient:
Q = 1/(sigma^2) on validation data:
Q/2 min = 0.000174444867298007
Q/2 mean = 0.48962265253067017
Q/2 max = 3.4920814037323

# Nov 25th, 2020  expDuke_20201117A_SurfaceSubnet_NoReLU Result
expDuke_20201117A_SurfaceSubnet_NoReLU finished:
1  trained 372 epochs in 7day 21hour 12min:
   (7*24*60+21*60+12)/372 = 30.5 min / epoch;
2  best validation error:
   at epoch 85: with learning rate 5.0e-3
   meanError: 2.207
                Error      Std
   surface 0:   0.9427     1.259
   surface 1:   2.371      2.588
   surface 2:   3.306      1.814
3  test on test data:
=======net running parameters=========
B,S,H,W = (3009, 3, 512, 361)
Test time: 204.82324028015137 seconds.
net.m_runParametersDict:
	validationLoss:40.726619720458984
	epoch:76
	errorMean:2.205378532409668
	learningRate: 5.0e-3

===============Formal Output Result ===========
patientIDList =[]
stdSurfaceError = tensor([3.0907, 1.1151, 1.5977], device='cuda:3')
muSurfaceError = tensor([1.2110, 1.9339, 2.9723], device='cuda:3')
stdError = 2.21911358833313
muError = 2.039097547531128
pixel number of violating surface-separation constraints: 67
slice number of violating surface-separation constraints: 5
slice list of violating surface-separation constraints:
	/home/hxie1/data/OCT_Duke/numpy_slices/test/AMD_1134_images_s29.npy
	/home/hxie1/data/OCT_Duke/numpy_slices/test/AMD_1257_images_s39.npy
	/home/hxie1/data/OCT_Duke/numpy_slices/test/AMD_1257_images_s41.npy
	/home/hxie1/data/OCT_Duke/numpy_slices/test/AMD_1257_images_s42.npy
	/home/hxie1/data/OCT_Duke/numpy_slices/test/AMD_1105_images_s44.npy
==================================================
test on Divided AMd and Control Group without ReLU:
python3.7 ./computeAMD_ControlAccuracy.py
Compute performance in AMD and Control group separately
predictDir= /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20201117A_SurfaceSubnet_NoReLU/testResult/xml
gtDir = /home/hxie1/data/OCT_Duke/numpy_slices/test
===============
GroupName: AMD
case number = 41
stdSurfaceError = tensor([3.6814, 1.1590, 1.7918])
muSurfaceError = tensor([1.4751, 2.0601, 3.3228])
HausdorffDistance in pixel = [[ 65. 123.  54.]]
HausdorffDistance in physical size (micrometer) = [[210.6  398.52 174.96]]
stdError = 2.5565528869628906
muError = 2.2859814167022705
===============
GroupName: Control
case number = 18
stdSurfaceError = tensor([0.3893, 0.9779, 0.4277])
muSurfaceError = tensor([0.6097, 1.6466, 2.1740])
HausdorffDistance in pixel = [[46. 13.  9.]]
HausdorffDistance in physical size (micrometer) = [[149.04  42.12  29.16]]
stdError = 0.9188244938850403
muError = 1.4767508506774902
===============
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
RiftSubnet For test data:
experimentName:expDuke_20200902A_RiftSubnet: for Rift prediction:
stdSurfaceError = tensor([2.7749, 2.5322], device='cuda:2')
muSurfaceError = tensor([3.4042, 8.4392], device='cuda:2')
stdError = 3.658905267715454
muError = 5.921670913696289

Lr = 1.0e-2
epoch = 42  for training.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Search best Lambda on validation data with unconstrained soft separation:
1  use riftNet: "/home/hxie1/Projects/DeepLearningSeg/OCTMultiSurfaces/SoftSepar3Unet/testConfig_Duke/expDuke_20200902A_RiftSubnet.yaml"
   and SurfaceNet Without ReLU:expDuke_20201117A_SurfaceSubnet_NoReLU
2  basic design:
   A use unconstrained softSeparation and ReLU at the last to estimate Lambda;
   B use unconstrained softSeparation optimal solution get S;
   C use validation data, without augmentation, output all its Q, mu, r:
     Q: Bx51x3x361
     mu:Bx51x3x361
     r: Bx51x2x361,
     g: Bx51x3x361,
     where B is the number of OCT volumes of validation data;
3  some subtasks:
   A generate Q,mu,r,g in validation data; -- done;
      surfaceResult: /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20201117A_SurfaceSubnet_NoReLU/testResult/validation
      riftResult: /home/hxie1/data/OCT_Duke/numpy_slices/log/RiftSubnet/expDuke_20200902A_RiftSubnet/testResult/validation
      And checked its order are consistent.
   B code the unconstrained optimal function;  --done
   C grid search lambda with generated Q,mu, r,g on validation data; -- on going. Monday it will have initial result.
     2 experiments parallel both on validation data:
     A  use predicted R;
     B  use ground truth R;
     1 search needs one second.
      lambda0_min, lambda0_max, lambda0_step = 0, 4.0, 0.01
      lambda1_min, lambda1_max, lambda1_step = 0, 4.0, 0.01,
      grid search totally needs 400*400 seconds = 44.4 hours. On Monday it will have initial result.

   D test expDuke_20201117A_SurfaceSubnet_NoReLU on test data;  --done, with average error 2.039 um.;
   E test searched fixed lambda fine tune on validation data with 2 experiments;   -- plan on Monday
      A  fixed Lambda + unconstrained soft separation optimization+ ReLU;
      B  fixed Lambda + IPM;
   F test searched fixed lambda final on test data with 2 experiments;             --plan on Wednesday
      A  fixed Lambda + unconstrained soft separation optimization + ReLU;
      B  fixed Lambda + IPM;

# Nov 19th, 2020
Exact slices with max hausdorff distance on Duke_AMD test data.

Summary:
1   These slices represent the worst error in the test data;
    Note: Hausdorff distance is a measurement relating to specific cases.
2   check error one by one:
    AMD_1198_images_s24_GT_Predict:  a rare disease case that surface 0 broken in the fovea region;
    AMD_1127_images_s23_GT_Predict:  surface 1 prediction error. By the way: the ground truth of surface 0 is not good;
    AMD_1198_images_s17_GT_Predict:  surface 2 prediction error;
    Control_1051_images_s16_GT_Predict: surface 0 signal is blurry, leading to prediction error;
    Control_1005_images_s24_GT_Predict: surface 1 prediction error;
    Control_1016_images_s08_GT_Predict: explicit ground truth error;
3   Surface 0 has maximum Hausdorff distance because the AMD_11198 case in the test data is a rare ILM broken patient;
4   Please refer to the attachments.

Search the worst cases: the slices with max hausdorff distance.
######################################################
Use softSeparation + fixed lambda network on Test data:
Compute performance in AMD and Control group separately
predictDir= /home/hxie1/data/OCT_Duke/numpy_slices/log/SoftSepar3Unet/expDuke_20201113A_FixLambda2Unet/testResult/xml
gtDir = /home/hxie1/data/OCT_Duke/numpy_slices/test
===============
GroupName: AMD
case number = 41
HausdorffDistance in pixel = [[50. 33. 31.]]
HausdorffDistance in physical size (micrometer) = [[162.   106.92 100.44]]
surface 0: the location of hausdorff at w=179 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SoftSepar3Unet/expDuke_20201113A_FixLambda2Unet/testResult/images/AMD_1198_images_s24_GT_Predict.png
surface 1: the location of hausdorff at w=126 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SoftSepar3Unet/expDuke_20201113A_FixLambda2Unet/testResult/images/AMD_1127_images_s23_GT_Predict.png
surface 2: the location of hausdorff at w=341 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SoftSepar3Unet/expDuke_20201113A_FixLambda2Unet/testResult/images/AMD_1198_images_s17_GT_Predict.png
===============
GroupName: Control
case number = 18
HausdorffDistance in pixel = [[28.  8.  8.]]
HausdorffDistance in physical size (micrometer) = [[90.72 25.92 25.92]]
surface 0: the location of hausdorff at w=71 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SoftSepar3Unet/expDuke_20201113A_FixLambda2Unet/testResult/images/Control_1051_images_s16_GT_Predict.png
surface 1: the location of hausdorff at w=171 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SoftSepar3Unet/expDuke_20201113A_FixLambda2Unet/testResult/images/Control_1005_images_s24_GT_Predict.png
surface 2: the location of hausdorff at w=132 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SoftSepar3Unet/expDuke_20201113A_FixLambda2Unet/testResult/images/Control_1016_images_s08_GT_Predict.png
===============
######################################################
Use Unet + ReLU network on Test data
python3.7 ./findMaxHausdorffPoint.py
Compute performance in AMD and Control group separately
predictDir= /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20200902A_SurfaceSubnet/testResult/xml
gtDir = /home/hxie1/data/OCT_Duke/numpy_slices/test
===============
GroupName: AMD
case number = 41
HausdorffDistance in pixel = [[50. 31. 44.]]
HausdorffDistance in physical size (micrometer) = [[162.   100.44 142.56]]
surface 0: the location of hausdorff at w=179 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20200902A_SurfaceSubnet/testResult/images/AMD_1198_images_s24_GT_Predict.png
surface 1: the location of hausdorff at w=360 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20200902A_SurfaceSubnet/testResult/images/AMD_1100_images_s48_GT_Predict.png
surface 2: the location of hausdorff at w=360 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20200902A_SurfaceSubnet/testResult/images/AMD_1100_images_s48_GT_Predict.png
===============
GroupName: Control
case number = 18
HausdorffDistance in pixel = [[33.  9.  8.]]
HausdorffDistance in physical size (micrometer) = [[106.92  29.16  25.92]]
surface 0: the location of hausdorff at w=48 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20200902A_SurfaceSubnet/testResult/images/Control_1051_images_s17_GT_Predict.png
surface 1: the location of hausdorff at w=171 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20200902A_SurfaceSubnet/testResult/images/Control_1005_images_s24_GT_Predict.png
surface 2: the location of hausdorff at w=132 of path: /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20200902A_SurfaceSubnet/testResult/images/Control_1016_images_s08_GT_Predict.png
===============
######################################################


# Nov 19th, 2020
Compute Hausdorff distance and segmentation error computation on AMD and Control test data separately.
Summary:
Compare pure Unet+ReLu and SoftSeparation Network:
1  In AMD test data, surface 2 improves about 30% of Hausdorff distance; while surface 0 didn't improve, and surface 1 worsen a little;
   We can use this surface 2 as an example for a demonstration;
2  In Control test data, surface 0 and surface 1 improve a little, while surface 3 didn't change.
   The reason behind it maybe is that control test data already has a high accuracy; (High accuracy improves small);
3  Hausdorff distance improves really depending on data.
4  In total result, SoftSeparation improves both Hausdorff distance, and mean accuracy;
5  Unet without ReLU is still in training. After its training, we may further compare it with SoftSeparation network;
   This comparison will be more explicit in our estimation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Compute performance in AMD and Control group separately in SoftSeparation Network + fixed Lambda
predictDir= /home/hxie1/data/OCT_Duke/numpy_slices/log/SoftSepar3Unet/expDuke_20201113A_FixLambda2Unet/testResult/xml
gtDir = /home/hxie1/data/OCT_Duke/numpy_slices/test
===============
GroupName: AMD
case number = 41
stdSurfaceError = tensor([2.9144, 1.0877, 1.8948])
muSurfaceError = tensor([1.3283, 1.9940, 3.2859])
HausdorffDistance in pixel = [[50. 33. 31.]]
HausdorffDistance in physical size (micrometer) = [[162.   106.92 100.44]]
stdError = 2.239591121673584
muError = 2.202744960784912
===============
GroupName: Control
case number = 18
stdSurfaceError = tensor([0.4251, 1.0081, 0.4460])
muSurfaceError = tensor([0.6201, 1.6549, 2.1552])
HausdorffDistance in pixel = [[28.  8.  8.]]
HausdorffDistance in physical size (micrometer) = [[90.72 25.92 25.92]]
stdError = 0.9295611381530762
muError = 1.4767508506774902
===============
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Compute performance in AMD and Control group separately in Unet + ReLU
predictDir= /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20200902A_SurfaceSubnet/testResult/xml
gtDir = /home/hxie1/data/OCT_Duke/numpy_slices/test
===============
GroupName: AMD
case number = 41
stdSurfaceError = tensor([2.9164, 1.0329, 2.0026])
muSurfaceError = tensor([1.3764, 1.9611, 3.3444])
HausdorffDistance in pixel = [[50. 31. 44.]]
HausdorffDistance in physical size (micrometer) = [[162.   100.44 142.56]]
stdError = 2.267122268676758
muError = 2.2273151874542236
===============
GroupName: Control
case number = 18
stdSurfaceError = tensor([0.4579, 1.1336, 0.4604])
muSurfaceError = tensor([0.6594, 1.7114, 2.1802])
HausdorffDistance in pixel = [[33.  9.  8.]]
HausdorffDistance in physical size (micrometer) = [[106.92  29.16  25.92]]
stdError = 0.9794862270355225
muError = 1.516985535621643
===============
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


# Nov 17th, 2020
Compute Accuracy separately in AMD and Control of Duke_AMD data:
Analysis:
1  Comparing ReLU constraints with SoftSepartion constraints, control group accuracy improves more with SoftSeparation;
2  Control group improves 0.04, while AMD group improves 0.02;
   So I have some suspicion that more disease data may will get better result.
3  Comparing our result with Leixin's result on the Table 1 of https://arxiv.org/pdf/2007.01217.pdf;
   our surface 3 corresponds with OBM, our surface 2 correpondis with IRPE. Our Control correspond its normal.
   Both our result in both control and AMD groups are better than Leixin's best result "W/".
   Leixin's used neighbor smooth constraints, while our method used soft separation constraints.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Compute performance in AMD and Control group separately in expDuke_20201113A_FixLambda2Unet Network:
predictDir= /home/hxie1/data/OCT_Duke/numpy_slices/log/SoftSepar3Unet/expDuke_20201113A_FixLambda2Unet/testResult/xml
gtDir = /home/hxie1/data/OCT_Duke/numpy_slices/test
===============
GroupName: AMD
case number = 41
stdSurfaceError = tensor([2.9144, 1.0877, 1.8948])
muSurfaceError = tensor([1.3283, 1.9940, 3.2859])
stdError = 2.239591121673584
muError = 2.202744960784912
===============
GroupName: Control
case number = 18
stdSurfaceError = tensor([0.4251, 1.0081, 0.4460])
muSurfaceError = tensor([0.6201, 1.6549, 2.1552])
stdError = 0.9295611381530762
muError = 1.4767508506774902
===============
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Compute performance in AMD and Control group separately in pure SurfaceSubnet with ReLU constraint without SoftSeparation:
predictDir= /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20200902A_SurfaceSubnet/testResult/xml
gtDir = /home/hxie1/data/OCT_Duke/numpy_slices/test
===============
GroupName: AMD
case number = 41
stdSurfaceError = tensor([2.9164, 1.0329, 2.0026])
muSurfaceError = tensor([1.3764, 1.9611, 3.3444])
stdError = 2.267122268676758
muError = 2.2273151874542236
===============
GroupName: Control
case number = 18
stdSurfaceError = tensor([0.4579, 1.1336, 0.4604])
muSurfaceError = tensor([0.6594, 1.7114, 2.1802])
stdError = 0.9794862270355225
muError = 1.516985535621643
===============
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

# Nov 17th, 2020
Meeting with professor:
1  we need to use JHU method to test Duke_AMD data;
2  make sure JHU method same with its paper, without using our gradient;
3  JHU's method has a Journel verson;

My think:
1  Leixin's method is single surface optimization, so its lambda only fit its single surface;
2  Our method is multi-surface paralllel optimization, so its final lambda is the balance of multi-surface;
3  we may need a special disease for show our method;
4  soft separation cost function does not consider the lambda for top and bottom surfaces.

# Nov 16th, 2020
Response to professor Wu:
 "I'd suggest you to calculate the segmentation accuracy for the normal and AMD subjects separately. I am still puzzling on the tiny \lambda."
 "We should compare to the model without any separation constraints. Also please compute the segmentation accuracy for the normal and AMD subjects separately.

1  OK.  I will write a script to divide normal and AMD case, and statistics its accuracy separately in test set;
2  "Compare model without any separation constraints" is a wonderful/insightful idea; Thank you,professor. ReLU is a hard constraint.
    OK. I need to retrain a network to test it;
3  I am totally not surprise this tiny lambda result:
   A. Grid searching lambda and network learning lambda both got same tiny lambda result, which should not be an occasional result;
   B. Grid Searching lambda on both Tongren and Duke_AMD data clearly demonstrated that muError is linear correlation with lambda; smaller lambda, smaller muError;
   C. Our theoretical analysis clearly demonstrated that adding lambda in cost function may improve error, may worse error; In total effect, lambda acts 0 effect.
      In other words, lambda may act as a positive or negative noise in different sample, therefore tiny lambda is network's natural choice;
      We also can explain that in proper data set, lambda may act a good effect; In other data set, lambda may act a negative effect;
   D. And we have used backward gradient, Cplex, manual computation 3 methods verifying that our IPM is correct;
   All there results from different dataset, from different methods, and from theory and experiments, all point to a tiny lambda.

# Nov 16th, 2020
Fine Tune Surface and Rift Subnet with fixed Lambda:
Exp config:  /home/sheen/projects/DeepLearningSeg/OCTMultiSurfaces/SoftSepar3Unet/testConfig_Duke/expDuke_20201113A_FixLambda2Unet.yaml
Result:
1   fine Tune training didn't improve accuracy in validation test; (when lambda is small, this is possible)
2   result with fixed lambda on test data:
    config file: /home/sheen/projects/DeepLearningSeg/OCTMultiSurfaces/SoftSepar3Unet/testConfig_Duke/expDuke_20201113A_FixLambda2Unet.yaml
    stdSurfaceError = tensor([2.4533, 1.0671, 1.6763], device='cuda:0')
    muSurfaceError = tensor([1.1122, 1.8906, 2.9410], device='cuda:0')
    stdError = 1.9619948863983154
    muError = 1.9812551736831665
    pixel number of violating surface-separation constraints: 0
3   compare with pure SurfaceSubnet result:
    test expDuke_20200902A_SurfaceSubnet.yaml experiment on test data:
    stdSurfaceError = tensor([2.4572, 1.0611, 1.7664], device='cuda:1')
    muSurfaceError = tensor([1.1576, 1.8849, 2.9892], device='cuda:1')
    stdError = 1.9898078441619873
    muError = 2.0106043815612793
4   use fixed small lambda, mu error improved 0.03 micrometer, while stdError improved 0.028 micrometer;

# Nov 13th, 2020
Professor ask 3 questions on initial grid search Lambda result on Duke_AMD data:
1) What is the method you used to get the error of 2.196 micrometer?
    2.196 is from pure surfaceSubent network with ReLU,without seperation rift as below.
    expDuke_20200902A_SurfaceSubnet.yaml experiment on validation data got:
    meanMuerror = 2.196 micrometer, stdError=2.171, mciepoch=74, learningRate=5e-3,
    surfaceMuError: surface0 = 1.017, surface1=2.45, surface2= 3.141

 2) Compared to your previous experiments, why this dataset takes such a long time?
    1 Duke_AMD data is very big, 12.7 times bigger than Tongren data;
    2 As Tongren data is small, I load all training and validation data in memory at beginning, and use them for each epoch without read disk again;
      As Duke_AMD data is too big, we can not load all training and validation data in memory at beginning,therefore each epoch needs to read each file from disk;
      And SATA harddisk reading speed in our GPU Server is about 1000 times slower than memory access speed.

3) What are the relative magnitudes of the two terms in the objective function?
   In my Aug 29 email report, I computed 1/(2sigma^2) for Tongren data like below. In other words, 1/(2sigma^2) is at 0.1 magnitude .
    1/(2sigma^2) in different OCT data at about 0.1 magnitude should not change too much, as it is surface error variance against same Guassian GT with same sigma =20 in training.
    While our grid search lambda is 2.9e-7, very small.
    Its relative magnitude of 2 terms in the object function is 300K times.
    Duke_AMD experiment is same with Tongren experiment, grid searched lambda is very small, which is consistant with leanring lambda result.
    This result also is consist with our theoretical analysis: Lambda can not improve mu (maybe better, maybe worse), so a smaller lambda is the choice of the grid search, and also the choice of learning lambda.


Attached 0829 email report:
# compare 1/(2*sigma2) and lambda, which represent the magnitude of unary terms and pairwise terms in the cost function of IPM:
reciprocalTwoSigma2.shape = torch.Size([5, 9, 512])
mean of reciprocalTwoSigma2 = [1.7199, 0.8725, 0.0993, 0.2319, 0.9011, 0.5338, 0.0335, 0.2529, 1.7592]
min of reciprocalTwoSigma2 = [0.0334, 0.0288, 0.0193, 0.0106, 0.0186, 0.0059, 0.0060, 0.0185, 0.0345]
max of reciprocalTwoSigma2 = [2.7259, 1.6216, 0.1681, 0.4646, 1.3337, 1.1049, 0.0949, 0.3692, 3.4337]



# Nov 13th, Friday, 2020
1  test expDuke_20200902A_SurfaceSubnet.yaml experiment on test data:
    stdSurfaceError = tensor([2.4572, 1.0611, 1.7664], device='cuda:1')
    muSurfaceError = tensor([1.1576, 1.8849, 2.9892], device='cuda:1')
    stdError = 1.9898078441619873
    muError = 2.0106043815612793

2  output visual prediction result;  Done.
   all visul images at : /home/hxie1/data/OCT_Duke/numpy_slices/log/SurfaceSubnet/expDuke_20200902A_SurfaceSubnet/testResult/images

3  using predicted R, and expDuke_20200902A_SurfaceSubnet.yaml to search a better lambda, from 1e-5 downward, on validation data:
   config file: /home/sheen/projects/DeepLearningSeg/OCTMultiSurfaces/SoftSepar3Unet/testConfig_Duke/expDuke_20201109A_SearchLambda2Unet.yaml
   lambda search initial value: 1.0e-5, step: 1.0e-8; It search 1000 points.
   Result: at the search iteration 971, it get its minimum error
   nSearch,meanError,      meanStd,            lambda_0,               lambda_1,               surfErr_0,      surfErr_1,              surfErr_2,      surfStd_0,          surfStd_1,          surfStd_2,
   971,2.166304588317871,2.102299451828003,2.900840172515018e-07,2.900840172515018e-07, 0.9951231479644775,2.3246231079101562,3.1791670322418213, 1.3870776891708374,2.5179460048675537,1.637975811958313,

   the relation curve of meanError and Lambda: /home/hxie1/data/OCT_Duke/numpy_slices/log/SearchLambda2Unet/expDuke_20201109A_SearchLambda2Unet/testResult/searchLambda_replaceRwithGT_0_gridSearch_1e-5downward.png
   Comparing with case without lambda on validation data:
              meanError improve from 2.196 micrometer to 2.1663 micrometer;
              meanStd   improve from 2.171 micorometer to 2.102 micrometer;
   And lambda_0 = 2.900840172515018e-07, and lambda_1= 2.900840172515018e-07, very small.

4  using fixed lambda to fine tune Rift+SurfaceNet network:
   It has launched training, but very slow. 40 min per epoch.




5  use fixed lambda + fineTune network to get result on test data;



# Nov 10th, Tuesday.
Professor Wu point out: The duke data is from JHU's paper, it is not AMD data.  I need to find this data, may redo experiment.

# Nov 9th, Monday, 2020
Analyze previous experiment data:
1  expDuke_20200902A_SurfaceSubnet.yaml experiment on validation data got:
   meanMuerror = 2.196 micrometer, stdError=2.171, mciepoch=74, learningRate=5e-3,
   surfaceMuError: surface0 = 1.017, surface1=2.45, surface2= 3.141

2  replace R with GT without smoothness, using expDuke_20200902A_SurfaceSubnet search Lambda on validaton data:
   nSearch	meanError	    meanStd	            lambda_0	        lambda_1	        surfErr_0	        surfErr_1	        surfErr_2	        surfStd_0	        surfStd_1	        surfStd_2
   99	2.16719126701355	2.09991383552551	9.9994576885365E-06	9.9994576885365E-06	0.996140241622925	2.31729507446289	3.18813920021057	1.39484310150146	2.49415946006775	1.6541827917099





# Sep 14th, Tuesday, 2020
Professor directed to use CPlex for lambda search to verify IPM again at convenient time.


# Sep 10th, Thursday, 2020
# Duke data grid search result:
Analysis:
1  Please refer to csv data and its relation between lambda and meanError;
2  Grid search uses un-smooth ground truth as r;
3  Duke data is 12.7 times bigger than Tongren data, and grid search is very time-consuming;
4  I searched 2 regions, each region needs about 16 hours with 3 GPUs;
   Region A: from 0.1 to 0.001, with grid step 0.001;
   Region B: from 0.001 to 1e-5, with grid step 1e-5;
5  Both searches show that it is basically a linear relation between meanError and lambda;
   Smaller lambda, better accuracy of IPM optimized surface location.
6  Recall the stationary condition formula like below of IPM cost function,
   it shows that the sum effect of mu and r uses lambda as weight to correct mu,
   mu and r occupy 50% weight respectively before multiplying lambda, and mu generally is far bigger than r.
   Therefore even perfect r from ground truth does not add benefit to correct mu,
   as this correcting process is dominated by mu/s self.


# Sep 4th, Friday, 2020
# on validation set with pixel resolution of 3.24 micrometer, at 11:30pm of Friday.
expDuke_20200902A_SurfaceSubnet: meanMuerror = 2.196 micrometer, epoch=74, learningRate=5e-3,
                                 surfaceMuError: surface0 = 1.017, surface1=2.45, surface2= 3.141
                                 Now valiation loss is increasing.

expDuke_20200902A_RiftSubnet:    meanSepartionerror = 3.881 micrometer, epoch=101, learningRate=1.25e-3,
                                 riftError: rift0 = 3.089, rift1=4.673
                                 Now validation loss is still decreasing.


# Sep 2nd, 2020
1 Duke data is training:
  A   data set statistics:
  training set: 266 volumes x 51 slices per volume, where 187 AMD + 79 control = 266 volumes;
  validation set: 59 volumes x 51 slice per volume, where 41 AMD + 18 control  =  59 volumes;
  test set:  59 volumes x 51 slice per volume, where 41 AMD + 18 control  =  59 volumes;
  B   Now SurfaceSubset and SeparationSubset are in training separately, very slow, about 33 min/epoch;
      Duke data is about 12.7 times of Tongren data in the slices number: (266+59)*51/(42*31) = 12.7;
  C   After 32 epochs, surfaceSubset got mean surface error 2.6 micrometer in resolution of 3.24 micrometer per pixel;
      After 28 epochs, separationSubst got mean separation error 4.3 micrometer;
      both networks are still in training;
  D   At the moment, surface 0 get 1.4 micrometer, surface 1 gets 2.8 micrometer, surface 2 gets 3.7 micrometer errors;
      It shows the surface0 is very easy, while surface2 is harder to segment, which is led by the difference of different surface information;

2 Grid search-lambda script is ready, waiting the Duke network finishing pretraining;
  An intuitive analysis from below A and B may predict that our further grid search may still get a very small lambda.
  A  learning lambda also gets very small lambda  of 1e-11 level;
  B  Binary search: when lambda =0.01, muError =13; when lambda=0.0001, muError = 2.07 for Tongren data;
  As search-lambda network needs 3 GPUs in which SurfaceSubset and SeparationSubset run 2 GPUs, current GPU resource is busy on Duke.
  We need to wait for Duke to finish training, and then launch grid search lambda.

Plan:
1 As Duke data training is very slow, I plan to launch ovarian cancer project tomorrow;
2 When Duke data training finish, I will come back to continue Duke data work;

