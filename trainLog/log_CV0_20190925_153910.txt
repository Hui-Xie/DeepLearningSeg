=============training from sratch============
Program ID: 23050

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy', '0', '3,2,1']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      
         

Discarded changes:                  

Experiment setting:
Input CT data: 51*171*171 ROI around primary cancer

Loss Function:  SoftMax

Data:   total 36 patients with 50-80% label, 6-fold cross validation, test 6, validation 6, and training 24.  
    script: python3.7 statisticsLabelFiles.py 
    Total 36 in /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
    0 has 48159408 elements, with a rate of  0.8970491562903105 
    1 has 5527068 elements, with a rate of  0.10295084370968957

Training strategy: 

          

Program starting Time: 2019-09-25 15:39:10.197031
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190925_153910

Info: this is the 0th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 6

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190925_153910.
6-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 24 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Total 24 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
0 has 32252453 elements, with a rate of  0.9011334530506342 
1 has 3538531 elements, with a rate of  0.0988665469493658 
loss weight = tensor([1.0000, 9.1146])
Network has total 32,972,258 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		21.6635		0.15530		375536.7188		0.00000		229466.4688		0.00000
5	1.0000e-02		7.7190		0.51027		62.4843		0.34761		219.9770		0.21094
10	1.0000e-02		7.0128		0.46419		9.7595		0.51492		14.5726		0.36076
15	1.0000e-02		5.8794		0.48972		7.6127		0.53017		9.7608		0.39680
20	1.0000e-02		5.8483		0.53880		4.6719		0.64950		5.1567		0.51987
25	1.0000e-02		4.9560		0.55260		6.2038		0.68617		4.1901		0.60147
30	1.0000e-02		5.7224		0.57548		6.9808		0.58704		7.3440		0.45888
35	1.0000e-02		4.8966		0.56874		5.7937		0.60803		6.0852		0.49452
40	1.0000e-02		6.7046		0.43666		5.0046		0.66608		9.5058		0.48450
45	1.0000e-02		5.3824		0.55541		5.6182		0.59886		7.6807		0.45553
50	1.0000e-02		4.7841		0.56103		4.7112		0.64783		5.6668		0.50333
55	1.0000e-02		6.5573		0.55345		10.4741		0.55581		6.2540		0.53513
60	1.0000e-02		5.5016		0.52691		5.5065		0.59953		6.4780		0.47612
65	1.0000e-02		6.9915		0.54334		6.9200		0.58145		5.8145		0.50193
70	1.0000e-02		5.1328		0.54167		7.3724		0.61368		5.2592		0.54453
75	1.0000e-03		5.2410		0.53711		5.4439		0.60955		6.1628		0.46957
80	1.0000e-03		5.0752		0.55742		6.2136		0.65893		4.4640		0.58222
85	1.0000e-03		3.8791		0.59765		5.7351		0.66752		4.3586		0.58635
90	1.0000e-03		3.7603		0.57972		5.3143		0.66573		4.2354		0.57558
95	1.0000e-03		4.2081		0.58025		5.0848		0.67316		4.1008		0.58908
100	1.0000e-03		3.8733		0.62326		5.4719		0.65946		4.3641		0.58156
105	1.0000e-03		3.9724		0.60629		5.5195		0.66998		4.0174		0.61120
110	1.0000e-03		3.8092		0.63268		4.9163		0.66573		4.0870		0.58705
115	1.0000e-03		3.6467		0.60840		5.3122		0.66207		4.0627		0.59277
120	1.0000e-03		3.8425		0.61403		4.9622		0.66207		4.1631		0.58547
125	1.0000e-03		4.2760		0.61102		4.9037		0.67444		3.9563		0.60738
130	1.0000e-04		3.6596		0.60089		5.2667		0.67210		3.9168		0.61044
135	1.0000e-04		3.3140		0.61308		5.1118		0.66770		3.9321		0.59787
140	1.0000e-04		4.0330		0.61267		5.1427		0.66283		4.1514		0.58354
145	1.0000e-04		3.8041		0.59521		5.1969		0.66763		3.8942		0.60159
150	1.0000e-04		3.5123		0.61398		5.1797		0.66813		3.8758		0.60502
155	1.0000e-04		3.5397		0.59147		5.1903		0.66888		4.0238		0.60107
160	1.0000e-04		3.5276		0.59726		5.0083		0.66383		4.1233		0.58913
165	1.0000e-04		3.3713		0.62546		4.9756		0.66548		4.0322		0.59340
170	1.0000e-04		3.4427		0.61122		5.1351		0.66506		3.9864		0.59294
175	1.0000e-04		4.0334		0.61363		5.1952		0.66893		3.8866		0.60838
180	1.0000e-04		3.9332		0.59736		5.1549		0.66157		4.1440		0.58539
185	1.0000e-05		3.9294		0.61193		5.1357		0.66697		4.1417		0.59406
