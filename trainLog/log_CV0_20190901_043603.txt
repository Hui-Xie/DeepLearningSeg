=============training from sratch============
Program ID: 23009

Program command: 
 ['TrainResNeXtVNet.py', '/home/hxie1/temp_netParameters/OvarianCancer/ResNeXtVNet', '1', '/home/hxie1/data/OvarianCancerCT/pixelSize223withLabel/numpy', '/home/hxie1/data/OvarianCancerCT/pixelSize223withLabel/numpyLabel', '0', '3,2,1']

Major program changes: 
     1  a V model with ResNeXt block: use z convolution, and then xy convolution, to implement 3D convolution.
     2  at ground truth, only check the segmented slices, about 3 slices per patient;
     3  the input is whole 3D volume, instead of ROI around a segmented slice;
     4  support input data augmentation: affine in xy plane, and translation in z direction;
     5  input Size: 231*251*251 with label, instead of previous SkyWatch Model of 29*140*140;
     6  treat all 1,2,3 labels as 1, in other words, do not differentiate primary, metastase, and nymph node;
     7  initializaiton LR is 0.1; considering zero padding and the bigger risk cost of missing cancer, adjust loss positive weight;  
    

Discarded changes:                  

Experiment setting:
Input CT data: maximum size 231*251*251 (zyx) of 3D numpy array with spacing size(3*2*2)

Loss Function:  BCELogitLoss

Data:   total 143 patients with weak annotaton label, 5-fold cross validation, test 29, validation 29, and training 85.  

Training strategy: 

          

Program starting Time: 2019-09-01 04:36:03.708808
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/ResNeXtVNet/20190901_043603

Info: this is the 0th fold leave for test in the 5-fold cross-validation.

Info: batchSize = 12

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/ResNeXtVNet/20190901_043603.
5-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 85 image files.

validation dataset: total 29 image files.

test dataset: total 29 image files.
Network has total 26,372,379 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-01		12655003.6172	0.03304		4461440.2083	0.02300		5638809.5833	0.03527
5	1.0000e-01		2130962.8018	0.07130		5068430.8333	0.00353		7963002.0417	0.00508
10	1.0000e-01		1902770.6836	0.08510		2707821.8333	0.06844		3552955.3125	0.08108
15	1.0000e-01		1893468.5469	0.09960		2949840.0833	0.07727		3865164.2083	0.08834
20	1.0000e-01		2145701.2344	0.09310		4253942.6667	0.04947		4522614.1667	0.06470
25	1.0000e-01		1765016.9131	0.08015		2329059.8750	0.09121		2747634.9375	0.11312
30	1.0000e-01		1711269.2549	0.09415		6995422.1667	0.01893		8591696.2917	0.03227
35	1.0000e-01		1623416.5781	0.10710		7447336.8333	0.07257		10591558.4167	0.06797
40	1.0000e-01		1496310.7891	0.09675		3653490.3333	0.06135		4017015.9583	0.08230
45	1.0000e-01		1525436.3091	0.11123		2763706.5417	0.12274		3598838.9583	0.14116
50	1.0000e-02		1531042.2773	0.11887		1547506.0833	0.11674		1914261.1875	0.13429
55	1.0000e-02		1340392.1797	0.12948		1478602.2917	0.13310		1903655.9375	0.13034
60	1.0000e-02		1221878.0410	0.12790		1449500.2917	0.13961		1884512.8125	0.13585
65	1.0000e-02		1383640.2134	0.13125		1440246.1875	0.13187		1907138.2500	0.13607
70	1.0000e-02		1217042.2900	0.12912		1582514.3333	0.11074		1953613.7917	0.13643
75	1.0000e-02		1211719.7207	0.13451		1458209.0000	0.13172		1923543.8333	0.13641
80	1.0000e-02		1260954.2559	0.13615		1423616.4792	0.12741		1810220.9792	0.13512
85	1.0000e-02		1227578.7324	0.13290		1458722.9167	0.13060		1846190.0833	0.13070
90	1.0000e-02		1239639.1475	0.12888		1490062.2917	0.12478		1904495.7708	0.14020
95	1.0000e-02		1186616.3457	0.14190		1486023.7083	0.12816		1845596.0833	0.13980
100	1.0000e-02		1249083.0938	0.12159		1661178.5208	0.11015		2020926.3333	0.12691
105	1.0000e-02		1231484.5645	0.12308		1469624.8125	0.12302		1896396.1875	0.12854
110	1.0000e-02		1212353.4414	0.12751		1458587.8125	0.13260		1863009.3021	0.14164
115	1.0000e-02		1234589.5586	0.12896		1537384.2917	0.11393		1779890.2917	0.13911
120	1.0000e-02		1310886.9141	0.13041		1392530.0208	0.14270		1836678.3750	0.14041
125	1.0000e-02		1249885.1250	0.13061		1570433.8750	0.12305		1997431.3542	0.13613
130	1.0000e-02		1165222.6211	0.12837		1475462.2708	0.13002		1864913.3125	0.13846
135	1.0000e-02		1199729.9902	0.13801		1502362.6667	0.12302		1850634.6667	0.13856
140	1.0000e-02		1023001.3179	0.14030		1438326.8958	0.13366		1890064.7917	0.13644
145	1.0000e-02		1207957.0879	0.15104		1466573.5833	0.13017		1921572.1042	0.13828
150	1.0000e-03		1331466.4043	0.13212		1427210.3750	0.13558		1852519.7812	0.13931
155	1.0000e-03		1223652.9805	0.13275		1421418.8125	0.13711		1874540.6458	0.13903
160	1.0000e-03		1073453.7725	0.13833		1434915.9583	0.13751		1894720.1667	0.14203
165	1.0000e-03		1006817.6543	0.15582		1416744.0417	0.13384		1833880.4167	0.13772
170	1.0000e-03		1122283.7656	0.13805		1407844.4375	0.13683		1829759.9375	0.13865
175	1.0000e-03		1164645.0469	0.15150		1427664.5000	0.13363		1843549.7812	0.14267
180	1.0000e-03		1057383.0078	0.15779		1432909.5417	0.13384		1887559.1042	0.14034
185	1.0000e-03		1013364.9043	0.14963		1438529.1042	0.13491		1879028.2500	0.14291
190	1.0000e-03		1219720.6006	0.13994		1420330.1250	0.13645		1827401.7917	0.14039
195	1.0000e-03		1073086.4619	0.13995		1480059.1667	0.13474		1922063.9375	0.14416
200	1.0000e-03		1195794.2285	0.14139		1430293.8750	0.13562		1857973.9062	0.14163
205	1.0000e-03		1205488.6290	0.15656		1406832.3542	0.14068		1836560.6354	0.13964
210	1.0000e-03		1121552.7324	0.15129		1449459.6875	0.13249		1834922.3021	0.14668
215	1.0000e-03		1169206.5820	0.15415		1429286.2500	0.13338		1754307.5938	0.14348
220	1.0000e-03		1184675.2109	0.13606		1405845.7708	0.13351		1717482.7188	0.14371
225	1.0000e-03		1060648.3232	0.13912		1424826.4167	0.13579		1811079.9062	0.14349
230	1.0000e-03		1140710.0500	0.14450		1400146.5417	0.13285		1799538.5104	0.14061
235	1.0000e-03		1064967.4255	0.15285		1406041.2500	0.13589		1800298.0625	0.13847
240	1.0000e-03		1030897.1172	0.14181		1439168.6042	0.13311		1848985.6354	0.14469
245	1.0000e-03		1031114.9941	0.15025		1398305.1458	0.13922		1793276.4479	0.14249
250	1.0000e-03		1120139.0820	0.13880		1364831.0000	0.14647		1844260.6042	0.14138
255	1.0000e-03		1101221.0728	0.15326		1359954.5208	0.14290		1832522.5312	0.13912
260	1.0000e-03		1031640.9600	0.15319		1386604.7083	0.14244		1794695.9688	0.13787
265	1.0000e-03		1091835.4297	0.15801		1434380.4792	0.13375		1803066.4167	0.14264
270	1.0000e-03		1109163.8340	0.16046		1452803.4167	0.13473		1900601.8125	0.14664
275	1.0000e-03		1117501.4917	0.14012		1444636.8333	0.13535		1834918.7812	0.14396
280	1.0000e-03		1078647.1055	0.13653		1391895.1250	0.13744		1759284.0417	0.13932
285	1.0000e-03		1108977.3359	0.13838		1480543.4583	0.13217		1849308.0208	0.14807
290	1.0000e-03		1059739.3867	0.14712		1394535.8958	0.13507		1717949.6354	0.14260
295	1.0000e-03		1027077.0342	0.14091		1452018.6458	0.13001		1817391.6875	0.14676
300	1.0000e-04		1025013.5195	0.16263		1455525.7917	0.13999		1862073.5000	0.14909
305	1.0000e-04		1120029.4766	0.14237		1377312.0625	0.13970		1707877.3125	0.14315
310	1.0000e-04		1019581.8535	0.16290		1410455.0208	0.14179		1918930.1771	0.14556
315	1.0000e-04		1060642.3418	0.14909		1430067.3542	0.14472		1905493.3854	0.14756
320	1.0000e-04		1161961.9875	0.14966		1394627.5000	0.13945		1768921.0312	0.14366
325	1.0000e-04		1107977.5024	0.14464		1397578.3125	0.13993		1824283.0625	0.14465
330	1.0000e-04		1058232.1992	0.15947		1382641.4583	0.14103		1739731.5833	0.14355
335	1.0000e-04		1040362.7793	0.15884		1417987.7917	0.13771		1761243.3958	0.14563
340	1.0000e-04		1068258.8884	0.16832		1383263.0000	0.14050		1781678.7083	0.14288
345	1.0000e-04		1021803.5195	0.14083		1395276.7083	0.14096		1810262.8125	0.14495
350	1.0000e-04		1076717.4268	0.14139		1415939.5208	0.14206		1849762.8854	0.14643
355	1.0000e-04		1051996.7573	0.14458		1397573.4583	0.14034		1841518.4792	0.14459
360	1.0000e-04		1061641.9062	0.15498		1366613.6458	0.14055		1777487.1146	0.14124
