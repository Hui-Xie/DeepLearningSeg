=============training from sratch============
Program ID: 4636

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/labels_npy', '0', '3', '1']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      Sep 30th, 2019
      1   With size-reduced ROI of size 51*149*149;
      2   reduce the translation of data augmentation;
      3   reduce all data into 35 patients, excluding a very blur patient.
      Oct 5th, 2019
      1   use uniform physical size 147mm*147mm*147mm, input pixel size: 49*147*147 with spacing size 3mm*1mm*1mm;
      2   change V model with inputsize 49*147*147
      Oct 6th, 2019
      1   add filter number to 48 at the first layer. 
      Oct 7th, 2019
      1   restore to 32 of number of filters in the first layer;
      2   add bottom number of filters to 1024, and keep down sample and add filter number together. 
      Oct 8th, 2019
      1   discard the cancer with size exceeding 147mm*147mm*147mm; Now remains 29 patients data; 
      Oct 9th, 2019
      1   In the first layer of V model, remove the residual link; 
           with the residula link at first layer: Tr dice:54%, Validation Dice 27%, Test Dice 56%;  Not good.
      2   the final output layer, change into 1*1*1 convolution, instead of 3*3*3 convolution;
      3   add labelConsistencyLoss, it use 64 dimension feature extracted from 2 ends of V model:
           It gets stable Training Dice 61%, validation Dice 27%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      Oct 11th, 2019
      1   use feature tensor just from the output end of V model. It is 32 dimensions.
          It gets stable Training Dice 61%, validation Dice 23%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      2   windows size for consistency loss changes to 3;
      Oct 12th, 2019
      1   change image window level to 100/50; relaunch training;
      2   change consistencyLoss to use ground truth for comparing diff of feature vector;
       
      

          
         

Discarded changes:                  
          

Program starting Time: 2019-10-12 18:08:15.968822
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191012_180815

Info: this is the 0th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 1

Info: useConsistencyLoss = True and searchWindowSize= 3

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191012_180815.
6-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 19 image files.

validation dataset: total 5 image files.

test dataset: total 5 image files.
Total 19 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/labels_npy
0 has 18433812 elements, with a rate of  0.9162854777808447 
1 has 1684167 elements, with a rate of  0.08371452221915532 
loss weight = tensor([ 1.0000, 10.9454])
Network has total 113,191,074 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		5.6529		0.04014		2.2965		0.04098		3.5943		0.11905
5	1.0000e-02		3.5298		0.31243		5.3705		0.07790		3.4404		0.26585
10	1.0000e-02		2.5338		0.40348		2.5431		0.17844		1.6196		0.39336
15	1.0000e-02		2.9813		0.37337		2.9010		0.16006		2.7977		0.31894
20	1.0000e-02		2.6451		0.34747		1.5237		0.16347		5.6196		0.44371
25	1.0000e-02		2.0256		0.44384		2.2440		0.17645		2.5338		0.35263
30	1.0000e-02		1.9474		0.36151		5.8055		0.11770		4.6056		0.33061
35	1.0000e-02		2.2578		0.41763		1.9557		0.19192		1.9570		0.43546
40	1.0000e-02		1.7078		0.45633		1.1772		0.24031		1.6377		0.42615
45	1.0000e-02		1.8377		0.46328		1.9750		0.17204		1.6290		0.45811
50	1.0000e-02		2.0106		0.41271		1.3558		0.27385		1.8288		0.43433
55	1.0000e-02		1.7637		0.41677		1.9439		0.17719		2.5515		0.34535
60	1.0000e-02		2.2632		0.39311		2.3456		0.19116		2.4446		0.38931
65	1.0000e-02		1.7408		0.44607		2.9743		0.18212		1.7328		0.53802
70	1.0000e-02		2.1100		0.43908		9.6875		0.08838		6.5167		0.31436
75	1.0000e-02		1.4000		0.44594		6.1434		0.12007		5.2470		0.37055
80	1.0000e-02		1.5103		0.51150		4.2784		0.15859		2.6518		0.42142
85	1.0000e-02		1.3793		0.49252		7.6228		0.11899		5.6547		0.36408
90	1.0000e-02		1.2279		0.50809		3.5529		0.17396		3.5464		0.36352
95	1.0000e-03		0.8422		0.57922		3.1312		0.20109		3.7471		0.32761
100	1.0000e-03		0.7532		0.61725		3.9072		0.17409		3.5340		0.34567
105	1.0000e-03		0.8935		0.58689		3.6883		0.18455		4.5577		0.30876
110	1.0000e-03		0.6979		0.63116		3.0094		0.19092		3.1514		0.36137
115	1.0000e-03		0.7941		0.63292		2.3064		0.19296		2.5042		0.37378
120	1.0000e-03		0.8611		0.60739		4.0113		0.18909		5.1117		0.30842
125	1.0000e-03		0.7336		0.61783		3.3495		0.18319		3.3982		0.35778
130	1.0000e-03		0.7788		0.62101		3.1498		0.17864		3.1680		0.35425
135	1.0000e-03		0.8028		0.62539		3.3765		0.17310		3.3251		0.36249
140	1.0000e-03		0.7538		0.65283		1.9862		0.17370		2.7627		0.36741
145	1.0000e-03		0.5662		0.68723		3.7951		0.18054		5.1399		0.31757
150	1.0000e-04		0.5763		0.67595		2.8247		0.18111		3.9784		0.34007
155	1.0000e-04		0.5490		0.68088		4.4328		0.15958		4.4440		0.33535
160	1.0000e-04		0.6594		0.64727		3.6242		0.15615		8.5395		0.29593
165	1.0000e-04		0.6287		0.67462		2.9609		0.17559		5.2835		0.31872
170	1.0000e-04		0.5608		0.67197		3.2434		0.16581		3.1783		0.36903
175	1.0000e-04		0.7178		0.65191		2.6416		0.17409		5.0515		0.33049
180	1.0000e-04		0.7833		0.65426		2.7938		0.20137		3.9350		0.34364
185	1.0000e-04		0.5236		0.68750		2.7106		0.16769		3.2262		0.36502
190	1.0000e-04		0.6272		0.67804		2.5452		0.17143		5.3091		0.31917
195	1.0000e-04		0.5815		0.68077		3.0974		0.19682		4.2329		0.33821
200	1.0000e-04		0.5844		0.68165		2.9119		0.16165		3.9192		0.33995
205	1.0000e-05		0.6195		0.67338		2.8287		0.18957		4.1837		0.33416
210	1.0000e-05		0.6007		0.65187		2.8935		0.20185		4.4442		0.32937
215	1.0000e-05		0.4814		0.70723		2.9129		0.18968		4.5668		0.32542
220	1.0000e-05		0.6267		0.68651		2.8665		0.17163		6.7490		0.30731
225	1.0000e-05		0.5760		0.71645		1.9662		0.16604		3.3180		0.35170
230	1.0000e-05		0.6088		0.69224		2.7115		0.18534		3.5505		0.34941
235	1.0000e-05		0.5717		0.68085		2.5289		0.17700		3.6235		0.34560
240	1.0000e-05		0.6324		0.68833		2.2137		0.16810		3.9047		0.34549
245	1.0000e-05		0.7470		0.65558		2.7740		0.16608		3.6444		0.35303
250	1.0000e-05		0.5942		0.67330		3.1080		0.19359		4.4255		0.33176
255	1.0000e-05		0.4769		0.72530		2.7028		0.18752		5.5259		0.31743
260	1.0000e-06		0.6788		0.66239		2.9328		0.18105		3.2058		0.36668
265	1.0000e-06		0.6367		0.67569		2.4161		0.19690		3.4036		0.35501
270	1.0000e-06		0.6145		0.67101		2.3651		0.17891		2.7569		0.37487
275	1.0000e-06		0.5816		0.69298		2.7519		0.17072		5.5356		0.31767
280	1.0000e-06		0.5293		0.70702		2.6033		0.18833		4.9208		0.32609
285	1.0000e-06		0.6710		0.67927		2.6649		0.18542		4.4234		0.33436
290	1.0000e-06		0.5101		0.68914		1.9892		0.18455		4.4123		0.33675
295	1.0000e-06		0.6142		0.68485		2.4600		0.17975		3.2110		0.36198
300	1.0000e-06		0.5330		0.71876		3.5017		0.15742		4.7332		0.32322
305	1.0000e-06		0.5238		0.70260		2.5980		0.17595		3.0867		0.36557
310	1.0000e-06		0.6459		0.66458		2.1383		0.16627		3.0067		0.36958
315	1.0000e-07		0.5760		0.67388		2.3428		0.17561		4.9077		0.33432
320	1.0000e-07		0.6973		0.68242		2.5942		0.21122		3.6583		0.34738
325	1.0000e-07		0.7298		0.67684		2.6050		0.18450		3.2953		0.35642
330	1.0000e-07		0.6591		0.67879		2.1157		0.18439		5.0319		0.33584
335	1.0000e-07		0.5335		0.68095		2.8497		0.18980		3.7058		0.34664
340	1.0000e-07		1.0885		0.64909		2.9637		0.17963		6.3754		0.31244
345	1.0000e-07		0.6198		0.67496		2.8786		0.18863		4.6235		0.32604
350	1.0000e-07		0.6102		0.68790		2.6725		0.17554		7.2643		0.30525
355	1.0000e-07		0.5652		0.67154		3.0716		0.18816		4.5753		0.33360
360	1.0000e-07		0.5990		0.70345		2.2018		0.17930		6.7193		0.31713
365	1.0000e-07		0.5595		0.68652		2.4806		0.18294		3.5550		0.34849
370	1.0000e-08		0.6021		0.68895		2.6847		0.16826		7.6603		0.30690
375	1.0000e-08		0.6607		0.69604		2.3987		0.16794		3.0207		0.36397
380	1.0000e-08		0.5827		0.66978		2.4101		0.19519		3.5910		0.34471
385	1.0000e-08		0.5378		0.70545		3.0504		0.18440		3.3986		0.36230
390	1.0000e-08		0.5951		0.64641		2.6270		0.15825		2.5950		0.39516
395	1.0000e-08		0.5044		0.68170		2.9115		0.20251		4.4620		0.33023
400	1.0000e-08		0.5591		0.66174		2.6425		0.16475		2.6043		0.39332
405	1.0000e-08		0.6506		0.67924		2.4828		0.18451		2.8254		0.37657
410	1.0000e-08		0.5407		0.68311		2.0144		0.17795		3.1609		0.35773
415	1.0000e-08		0.6300		0.68038		2.2711		0.17694		5.8877		0.32062
420	1.0000e-08		0.7142		0.67062		3.5981		0.18478		5.4099		0.31769
425	1.0000e-08		0.6809		0.66882		2.8107		0.19957		3.6161		0.35239
430	1.0000e-08		0.6883		0.65162		2.3116		0.19155		2.9662		0.37422
435	1.0000e-08		0.5692		0.68596		2.6227		0.16125		3.7270		0.34778
440	1.0000e-08		0.6266		0.65484		2.1746		0.19765		4.5911		0.32939
445	1.0000e-08		0.5207		0.65620		3.0590		0.18632		3.1732		0.37450
450	1.0000e-08		0.7146		0.67966		2.5457		0.17629		6.0304		0.31742
455	1.0000e-08		0.6055		0.69556		2.7974		0.16835		3.4635		0.35588
460	1.0000e-08		0.5348		0.66388		2.5685		0.16885		3.4197		0.35674
465	1.0000e-08		0.4854		0.70256		2.7505		0.19747		4.2735		0.33560
470	1.0000e-08		0.5213		0.72220		2.7181		0.18146		4.7517		0.32783
475	1.0000e-08		0.6520		0.69549		2.6160		0.16904		4.8621		0.32741
480	1.0000e-08		0.5031		0.68863		2.9129		0.21702		5.1455		0.32519
485	1.0000e-08		0.6394		0.65145		2.8791		0.19515		4.4943		0.33246
490	1.0000e-08		0.7208		0.71636		2.4465		0.15740		3.4936		0.35244
495	1.0000e-08		0.5860		0.65192		2.6262		0.16510		2.7124		0.38373
500	1.0000e-08		0.5603		0.70268		2.1765		0.19135		3.1847		0.35665
505	1.0000e-08		0.7614		0.68908		2.1632		0.17644		3.8353		0.35012
510	1.0000e-08		0.5776		0.69251		2.5334		0.18561		3.5478		0.35062
515	1.0000e-08		0.5548		0.69706		2.0661		0.17620		3.9772		0.34328
520	1.0000e-08		0.5108		0.67346		2.8106		0.18653		3.2149		0.36515
525	1.0000e-08		0.7071		0.66373		2.2783		0.17961		4.7560		0.33008
530	1.0000e-08		0.5943		0.65055		2.6136		0.21039		3.5186		0.35184
535	1.0000e-08		0.5538		0.69399		2.9300		0.16330		3.8358		0.34214
540	1.0000e-08		0.5332		0.71058		2.0772		0.17408		5.2032		0.33211
545	1.0000e-08		0.5824		0.67748		2.6420		0.17735		4.2906		0.33604
550	1.0000e-08		0.5295		0.69259		3.0795		0.18517		4.1951		0.33518
555	1.0000e-08		0.5585		0.70853		2.5650		0.15288		2.4607		0.39560
560	1.0000e-08		0.6061		0.66742		2.7881		0.17430		4.0868		0.33753
565	1.0000e-08		0.6526		0.65679		2.4118		0.18066		4.5020		0.33587
570	1.0000e-08		0.9011		0.63691		2.1990		0.16350		4.4997		0.34049
575	1.0000e-08		0.6225		0.70935		2.9214		0.16542		5.8085		0.31497
580	1.0000e-08		0.6670		0.68156		2.3959		0.18353		3.4034		0.35241
585	1.0000e-08		0.6412		0.69420		2.2831		0.17970		5.0417		0.32359
590	1.0000e-08		0.5905		0.70158		2.3188		0.16801		4.2856		0.33775
595	1.0000e-08		0.5267		0.71788		2.9625		0.18306		4.0784		0.33870
600	1.0000e-08		0.6246		0.68963		2.6656		0.20306		4.2476		0.33628
605	1.0000e-08		0.5734		0.68057		2.9060		0.16941		3.3007		0.36325
610	1.0000e-08		0.5389		0.69125		3.2711		0.16759		3.9122		0.34299
615	1.0000e-08		0.8613		0.69442		2.5782		0.17856		4.8547		0.33379
620	1.0000e-08		0.7055		0.64827		2.8759		0.18762		3.1204		0.37055
625	1.0000e-08		0.5521		0.66250		2.4507		0.18279		4.0445		0.33914
630	1.0000e-08		0.6394		0.67299		3.5105		0.16038		3.6717		0.35704
635	1.0000e-08		0.6643		0.68290		2.5829		0.18465		5.0576		0.32227
640	1.0000e-08		0.5644		0.68150		2.5537		0.16134		4.0881		0.33946
645	1.0000e-08		0.7225		0.68067		2.3673		0.15702		3.4433		0.34853
650	1.0000e-08		0.7034		0.69916		2.7581		0.18750		3.0388		0.37308
655	1.0000e-08		0.5345		0.69706		2.0738		0.17091		3.4715		0.35123
660	1.0000e-08		0.5505		0.69963		2.7626		0.18666		5.1622		0.31906
665	1.0000e-08		0.6703		0.69726		2.8226		0.18109		4.3871		0.33172
670	1.0000e-08		0.5378		0.70967		3.4053		0.19739		6.0397		0.30685
675	1.0000e-08		0.6270		0.67356		2.9294		0.19828		3.8850		0.34235
680	1.0000e-08		0.6957		0.66495		2.7228		0.17429		6.0371		0.32270
685	1.0000e-08		0.5734		0.69403		1.8116		0.18013		4.9152		0.33737
690	1.0000e-08		0.5664		0.70792		2.7434		0.17578		3.6804		0.34656
695	1.0000e-08		0.6460		0.66477		2.3306		0.17746		3.0080		0.36935
700	1.0000e-08		0.5483		0.70653		2.6139		0.18639		3.9439		0.33980
705	1.0000e-08		0.6302		0.66848		2.8235		0.16919		4.9593		0.32171
710	1.0000e-08		0.6340		0.67745		2.4564		0.19422		5.0298		0.32412
715	1.0000e-08		0.5045		0.67669		2.7889		0.16682		3.6873		0.34292
720	1.0000e-08		0.5518		0.66954		2.7602		0.19328		3.5600		0.35205
725	1.0000e-08		0.5604		0.66191		2.4257		0.21237		3.0031		0.36828
730	1.0000e-08		0.7423		0.69010		3.1432		0.16971		3.5151		0.35515
735	1.0000e-08		0.5024		0.69778		2.8017		0.21108		5.3649		0.32279
740	1.0000e-08		0.6167		0.71551		2.8409		0.16212		3.9404		0.33687
745	1.0000e-08		0.6266		0.68797		2.9553		0.17137		4.5100		0.33101
750	1.0000e-08		0.5280		0.64399		3.1420		0.19637		4.2438		0.33846
755	1.0000e-08		0.6532		0.66664		2.7424		0.16925		7.0263		0.31362
760	1.0000e-08		0.6591		0.66304		2.2486		0.16811		4.6354		0.33191
765	1.0000e-08		0.7037		0.67079		2.5481		0.17435		2.9264		0.37433
770	1.0000e-08		0.5903		0.67518		2.9268		0.19136		5.6945		0.32509
775	1.0000e-08		0.6353		0.70036		1.9392		0.18242		3.7182		0.34494
780	1.0000e-08		0.5517		0.73097		2.5534		0.17123		4.1871		0.33515
785	1.0000e-08		0.5794		0.66609		2.3485		0.19051		3.5121		0.34309
790	1.0000e-08		0.5521		0.67942		2.3267		0.16518		2.4155		0.39150
795	1.0000e-08		0.5823		0.68036		2.4546		0.17423		3.6760		0.34511
800	1.0000e-08		0.8687		0.65779		2.2450		0.15731		2.7720		0.36959
805	1.0000e-08		0.7549		0.66505		2.5941		0.17100		4.0952		0.33696
810	1.0000e-08		0.9773		0.62326		2.4821		0.17352		4.2150		0.33477
815	1.0000e-08		0.6571		0.65424		2.6271		0.18377		3.3642		0.35443
820	1.0000e-08		0.6421		0.69317		2.2854		0.18001		4.3280		0.34392
825	1.0000e-08		0.5060		0.69269		2.6151		0.21729		5.3225		0.32507
830	1.0000e-08		0.5213		0.68975		2.3343		0.18642		3.2914		0.35356
835	1.0000e-08		0.7155		0.67263		2.3771		0.15698		3.1194		0.36024
840	1.0000e-08		0.5032		0.69621		3.2996		0.18892		5.1680		0.31782
845	1.0000e-08		0.6304		0.65866		2.1206		0.17809		5.2472		0.33846
850	1.0000e-08		0.5540		0.67395		2.6332		0.18305		3.4592		0.35512
855	1.0000e-08		0.6450		0.69359		2.1691		0.16929		3.9395		0.34243
860	1.0000e-08		0.7206		0.67822		2.9124		0.16379		4.7406		0.32741
865	1.0000e-08		0.5906		0.70275		2.0108		0.16672		3.1883		0.36116
870	1.0000e-08		0.5299		0.66720		3.1463		0.16829		3.1188		0.37914
875	1.0000e-08		0.7376		0.65682		2.5012		0.21852		3.7308		0.35075
880	1.0000e-08		0.5919		0.68088		2.4693		0.18378		3.9963		0.33794
885	1.0000e-08		0.6704		0.66701		2.9342		0.18124		4.5766		0.32932
890	1.0000e-08		0.6042		0.68540		2.1591		0.17011		3.9365		0.34427
895	1.0000e-08		0.5739		0.69621		2.2578		0.19018		3.1936		0.35651
900	1.0000e-08		0.7117		0.66779		2.1563		0.18392		3.3950		0.35221
905	1.0000e-08		0.6298		0.68861		2.6067		0.17918		4.9353		0.32348
910	1.0000e-08		0.6833		0.67574		2.2437		0.16401		3.2757		0.35640
915	1.0000e-08		0.6030		0.69710		4.2578		0.17927		6.7656		0.29881
920	1.0000e-08		0.5116		0.65820		2.8842		0.19137		3.4194		0.35800
925	1.0000e-08		0.4812		0.68644		2.6428		0.19066		4.2737		0.33461
930	1.0000e-08		0.6508		0.67572		2.9840		0.13624		3.7925		0.34692
935	1.0000e-08		0.7168		0.64868		2.2815		0.18682		3.6106		0.35186
940	1.0000e-08		0.7270		0.70456		2.6566		0.16326		3.0294		0.36556
945	1.0000e-08		0.5639		0.67849		2.4091		0.17376		4.7693		0.33149
