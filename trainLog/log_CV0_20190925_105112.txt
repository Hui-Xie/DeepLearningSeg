=============training from sratch============
Program ID: 3382

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy', '0', '3,2,1']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      
         

Discarded changes:                  

Experiment setting:
Input CT data: 51*171*171 ROI around primary cancer

Loss Function:  SoftMax

Data:   total 36 patients with 50-80% label, 6-fold cross validation, test 6, validation 6, and training 24.  
    script: python3.7 statisticsLabelFiles.py 
    Total 36 in /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
    0 has 48159408 elements, with a rate of  0.8970491562903105 
    1 has 5527068 elements, with a rate of  0.10295084370968957

Training strategy: 

          

Program starting Time: 2019-09-25 10:51:12.110069
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190925_105112

Info: this is the 0th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 6

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190925_105112.
6-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 24 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Total 24 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
0 has 32252453 elements, with a rate of  0.9011334530506342 
1 has 3538531 elements, with a rate of  0.0988665469493658 
loss weight = tensor([1.0000, 9.1146])
Network has total 32,972,258 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		-15056.8120		0.03334		-177410912.0000		0.00000		-195529568.0000		0.00000
5	1.0000e-02		-394944.0703		0.00000		-189638.4062		0.00000		-289162.5000		0.00000
10	1.0000e-02		-1351902.2656		0.00000		-1078223.3750		0.00000		-1015949.8750		0.00000
15	1.0000e-02		-3099972.1875		0.00000		-1547062.0000		0.00000		-1699677.1250		0.00000
20	1.0000e-02		-4985816.1250		0.00000		-3381468.7500		0.00000		-3669312.0000		0.00000
25	1.0000e-02		-8021388.0000		0.00000		-4222937.0000		0.00000		-4872525.0000		0.00000
30	1.0000e-02		-11837175.7500		0.00000		-6648151.5000		0.00000		-7485324.5000		0.00000
35	1.0000e-02		-14549431.5000		0.00000		-9276463.0000		0.00000		-10174694.0000		0.00000
40	1.0000e-02		-20556764.5000		0.00000		-13114755.0000		0.00000		-15219062.0000		0.00000
45	1.0000e-02		-27347463.5000		0.00000		-16577667.0000		0.00000		-18201776.0000		0.00000
50	1.0000e-03		-31321669.5000		0.00000		-23914332.0000		0.00000		-26530044.0000		0.00000
55	1.0000e-03		-35449062.5000		0.00000		-21196352.0000		0.00000		-22793148.0000		0.00000
60	1.0000e-03		-33735234.5000		0.00000		-20784284.0000		0.00000		-21562142.0000		0.00000
65	1.0000e-03		-35577964.0000		0.00159		-22412412.0000		0.00000		-23251812.0000		0.00000
70	1.0000e-03		-33426048.0000		0.00001		-22202116.0000		0.00000		-22824764.0000		0.00054
75	1.0000e-03		-35997566.0000		0.01838		-23853124.0000		0.00000		-24597674.0000		0.06483
80	1.0000e-03		-35680155.0000		0.01857		-24041036.0000		0.00001		-25405592.0000		0.07461
85	1.0000e-03		-38207807.0000		0.01037		-22812376.0000		0.00003		-23675524.0000		0.05027
90	1.0000e-03		-37840206.0000		0.00019		-25083506.0000		0.00001		-26336372.0000		0.05731
95	1.0000e-03		-40457677.0000		0.05211		-23019010.0000		0.00309		-24848148.0000		0.07685
100	1.0000e-04		-40296236.0000		0.02718		-22175352.0000		0.00348		-23712484.0000		0.05378
105	1.0000e-04		-37693262.5000		0.06428		-24817434.0000		0.00613		-26360240.0000		0.09794
110	1.0000e-04		-40751907.0000		0.02749		-25846520.0000		0.00667		-27481480.0000		0.11348
115	1.0000e-04		-39831378.0000		0.04348		-24235872.0000		0.03368		-25747896.0000		0.11165
120	1.0000e-04		-43353491.0000		0.04518		-24605192.0000		0.01494		-26408228.0000		0.12681
125	1.0000e-04		-40954508.5000		0.05165		-25179510.0000		0.00751		-26753272.0000		0.10737
130	1.0000e-04		-41915489.0000		0.05734		-24596424.0000		0.01377		-26118372.0000		0.10578
135	1.0000e-04		-42546719.0000		0.04692		-23733696.0000		0.02338		-25660236.0000		0.10272
140	1.0000e-04		-37834318.5000		0.05504		-23946124.0000		0.02004		-25274038.0000		0.12298
145	1.0000e-04		-39973603.0000		0.06737		-24575992.0000		0.01746		-26431888.0000		0.12748
150	1.0000e-04		-41037349.0000		0.03689		-25084776.0000		0.01107		-26879644.0000		0.12428
155	1.0000e-04		-38043665.0000		0.04351		-25239946.0000		0.01239		-26932532.0000		0.11835
160	1.0000e-04		-42783930.0000		0.04586		-24669792.0000		0.03173		-26109262.0000		0.12223
165	1.0000e-04		-37825792.0000		0.07368		-25406412.0000		0.02989		-26869064.0000		0.11223
170	1.0000e-04		-40176127.0000		0.03531		-24885320.0000		0.03609		-26603530.0000		0.13021
175	1.0000e-04		-42952894.0000		0.04297		-24851760.0000		0.03493		-26633052.0000		0.13317
180	1.0000e-04		-44148782.0000		0.05756		-24370288.0000		0.01546		-26063576.0000		0.12657
185	1.0000e-04		-40840644.0000		0.03425		-24250400.0000		0.01879		-25878112.0000		0.11637
190	1.0000e-04		-39044832.0000		0.04353		-25517906.0000		0.03167		-27080640.0000		0.12925
195	1.0000e-04		-42161079.0000		0.08102		-22853098.0000		0.02866		-24428482.0000		0.11792
200	1.0000e-05		-42662919.0000		0.07557		-23207668.0000		0.04009		-25493748.0000		0.12456
205	1.0000e-05		-40382362.0000		0.06970		-26889332.0000		0.03661		-28635296.0000		0.10830
210	1.0000e-05		-38803482.0000		0.02323		-26204584.0000		0.03642		-27965632.0000		0.11328
215	1.0000e-05		-41259649.0000		0.08222		-24995976.0000		0.01967		-26879548.0000		0.13000
220	1.0000e-05		-39600853.0000		0.06748		-24572536.0000		0.02782		-26195772.0000		0.12836
225	1.0000e-05		-39983575.0000		0.04962		-23682540.0000		0.02011		-25666422.0000		0.11431
230	1.0000e-05		-43460008.0000		0.03904		-23904164.0000		0.04325		-26182512.0000		0.11875
235	1.0000e-05		-43293766.0000		0.05897		-24856458.0000		0.02963		-26494872.0000		0.13124
240	1.0000e-05		-44287788.0000		0.05117		-24213664.0000		0.03939		-26313430.0000		0.12483
245	1.0000e-05		-40991717.0000		0.03300		-24746108.0000		0.02799		-26284702.0000		0.12728
250	1.0000e-05		-41156340.0000		0.07378		-24243524.0000		0.05079		-25568312.0000		0.13116
255	1.0000e-05		-44068266.0000		0.05851		-23654166.0000		0.04028		-25657406.0000		0.12284
260	1.0000e-05		-41581800.0000		0.01134		-24427848.0000		0.02465		-26135196.0000		0.12495
265	1.0000e-05		-46483035.0000		0.02784		-26590732.0000		0.02322		-28300404.0000		0.12000
270	1.0000e-05		-40027090.0000		0.05947		-25576744.0000		0.04475		-27146084.0000		0.13580
275	1.0000e-05		-42222135.0000		0.01355		-25809368.0000		0.04101		-27603868.0000		0.13535
280	1.0000e-05		-45164766.0000		0.04963		-25033132.0000		0.03181		-26948552.0000		0.13108
285	1.0000e-05		-41775067.0000		0.03469		-22362260.0000		0.05555		-24741552.0000		0.09536
290	1.0000e-05		-39956127.0000		0.04274		-25558982.0000		0.02943		-27162072.0000		0.12437
