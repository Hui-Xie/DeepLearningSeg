=============training from sratch============
Program ID: 3555

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy', '2', '3,2,1']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      Sep 30th, 2019
      1   With size-reduced ROI of size 51*149*149;
      2   reduce the translation of data augmentation;
      3   reduce all data into 35 patients, excluding a very blur patient.
      
         

Discarded changes:                  

Experiment setting:
Input CT data: 51*171*171 ROI around primary cancer

Loss Function:  SoftMax

Data:   total 36 patients with 50-80% label, 6-fold cross validation, test 6, validation 6, and training 24.  
    script: python3.7 statisticsLabelFiles.py 
    Total 36 in /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
    0 has 48159408 elements, with a rate of  0.8970491562903105 
    1 has 5527068 elements, with a rate of  0.10295084370968957

Training strategy: 

          

Program starting Time: 2019-10-01 09:24:00.335447
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191001_092400

Info: this is the 2th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 6

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191001_092400.
6-fold cross validation: the 2th fold is for test, the 3th fold is for validation, remaining folds are for training.

training dataset: total 23 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Total 23 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy
0 has 20366782 elements, with a rate of  0.7820812354058996 
1 has 5674991 elements, with a rate of  0.21791876459410042 
loss weight = tensor([1.0000, 3.5889])
Network has total 73,047,746 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		33.1324		0.08230		23322.9688		0.00000		24328.5117		0.00000
5	1.0000e-02		8.2340		0.53900		54.4068		0.68027		79.0696		0.52682
10	1.0000e-02		5.7261		0.68125		9.3199		0.66833		7.4346		0.60505
15	1.0000e-02		5.5748		0.67083		5.2613		0.76722		4.3953		0.70373
20	1.0000e-02		5.5969		0.67929		5.1028		0.75052		4.9033		0.68809
25	1.0000e-02		5.0112		0.67167		8.0756		0.76650		4.7266		0.72836
30	1.0000e-02		5.4396		0.68035		6.6465		0.71630		5.7706		0.66441
35	1.0000e-02		4.6700		0.70604		5.8884		0.76822		4.1902		0.73066
40	1.0000e-02		5.0691		0.70335		5.8985		0.76818		4.1183		0.73637
45	1.0000e-02		4.2992		0.71347		6.3995		0.74898		5.9543		0.69333
50	1.0000e-02		4.9390		0.71043		4.7291		0.77461		4.7842		0.70590
55	1.0000e-02		4.9240		0.70984		5.7379		0.74089		5.7470		0.67551
60	1.0000e-02		5.2785		0.71453		6.4852		0.74145		7.4800		0.66061
65	1.0000e-02		5.4770		0.68176		5.8168		0.76520		4.4216		0.72327
70	1.0000e-02		4.7238		0.69557		4.3725		0.77886		4.5913		0.72023
75	1.0000e-02		4.0934		0.72992		5.7493		0.76623		5.2802		0.69716
80	1.0000e-02		4.3491		0.70991		8.6538		0.68972		7.9235		0.63779
85	1.0000e-02		4.5075		0.72917		4.0293		0.78093		3.9805		0.74027
90	1.0000e-02		4.5985		0.72745		5.4907		0.79521		4.7779		0.72153
95	1.0000e-02		4.5676		0.67700		4.3097		0.79831		5.2194		0.67430
100	1.0000e-02		4.0617		0.72639		4.5517		0.79023		3.7126		0.74878
105	1.0000e-02		3.5842		0.74907		6.1657		0.80648		3.9638		0.76672
110	1.0000e-02		3.8666		0.72882		4.5025		0.75650		4.1712		0.72991
115	1.0000e-02		4.7200		0.74345		5.4440		0.80642		4.1068		0.74907
120	1.0000e-02		3.7863		0.73941		4.1063		0.79383		4.0641		0.73105
125	1.0000e-02		3.7220		0.74613		4.6343		0.77538		3.6809		0.76529
130	1.0000e-02		3.6772		0.77403		4.9494		0.79225		3.2630		0.79147
135	1.0000e-02		4.0135		0.73291		8.2195		0.69238		4.1443		0.77030
140	1.0000e-03		3.0154		0.76953		7.8351		0.73254		3.7142		0.77146
145	1.0000e-03		3.9679		0.75347		4.4274		0.78356		3.1652		0.76186
150	1.0000e-03		3.4950		0.76457		5.0478		0.77987		3.0698		0.77733
155	1.0000e-03		3.0615		0.75879		4.7178		0.79242		3.1928		0.76856
160	1.0000e-03		3.1813		0.77094		4.5004		0.79472		3.0253		0.77304
165	1.0000e-03		3.5373		0.76273		5.0208		0.78314		2.9476		0.78088
170	1.0000e-03		2.5580		0.79575		4.8568		0.79841		3.4477		0.76746
175	1.0000e-03		2.5609		0.77148		4.5049		0.78450		3.0914		0.77033
180	1.0000e-03		3.0210		0.77495		4.6690		0.79306		3.0830		0.77543
185	1.0000e-03		2.9965		0.78026		5.8026		0.78786		2.8121		0.79233
190	1.0000e-03		2.9939		0.78376		5.1054		0.78710		2.9040		0.78173
195	1.0000e-04		3.3117		0.78068		7.6775		0.74932		3.1022		0.79315
200	1.0000e-04		3.1998		0.77605		5.7755		0.78519		2.9236		0.78710
205	1.0000e-04		3.0158		0.78303		5.2341		0.79580		2.9415		0.78193
210	1.0000e-04		2.4553		0.79192		6.5383		0.77047		3.0373		0.79002
215	1.0000e-04		2.9769		0.79225		5.7754		0.77767		2.9218		0.78395
220	1.0000e-04		3.1621		0.78115		9.1061		0.72484		3.2202		0.78771
225	1.0000e-04		2.6219		0.78996		8.2261		0.74495		2.8077		0.79815
230	1.0000e-04		3.0000		0.77319		4.5300		0.79637		3.0365		0.77161
235	1.0000e-04		2.7313		0.77788		5.5910		0.77462		2.9366		0.78341
240	1.0000e-04		3.7654		0.77650		4.9171		0.79023		2.9111		0.78382
245	1.0000e-04		2.6690		0.78052		6.1942		0.76944		2.8141		0.79311
250	1.0000e-05		2.9665		0.77890		5.5719		0.78175		2.9561		0.78660
255	1.0000e-05		2.3493		0.78779		9.1548		0.72751		3.2080		0.79301
260	1.0000e-05		2.9703		0.79768		6.9647		0.76457		3.0690		0.79093
265	1.0000e-05		2.7576		0.79437		5.7416		0.77875		2.7595		0.78985
270	1.0000e-05		2.6172		0.79969		4.7199		0.79901		2.8906		0.78297
275	1.0000e-05		2.8569		0.77752		6.7711		0.76123		2.7705		0.79305
280	1.0000e-05		2.4917		0.78516		5.1019		0.79557		2.9174		0.78906
285	1.0000e-05		2.6847		0.77937		6.1947		0.76993		2.9643		0.79001
290	1.0000e-05		2.5656		0.78588		6.5170		0.76592		2.6862		0.79338
295	1.0000e-05		2.6517		0.79609		6.1237		0.78008		2.7652		0.79760
300	1.0000e-05		2.9542		0.78327		4.8287		0.79711		2.9189		0.77713
305	1.0000e-06		2.4917		0.76820		4.5710		0.79831		3.0154		0.77253
310	1.0000e-06		2.6986		0.79318		5.3519		0.79067		2.8505		0.78979
315	1.0000e-06		3.0900		0.76818		5.2037		0.78648		2.9398		0.78299
320	1.0000e-06		2.7506		0.79631		4.9360		0.79298		2.8922		0.78329
325	1.0000e-06		2.6387		0.79033		5.6984		0.78464		2.7556		0.79227
330	1.0000e-06		2.9062		0.77894		5.3749		0.78478		3.0496		0.78736
335	1.0000e-06		2.7817		0.78843		6.9405		0.75676		2.9295		0.79153
340	1.0000e-06		2.3760		0.79607		4.6521		0.79617		2.9185		0.77793
345	1.0000e-06		2.5698		0.79722		4.5555		0.80408		2.9577		0.77812
350	1.0000e-06		2.9757		0.78076		5.1688		0.79467		2.9198		0.79106
355	1.0000e-06		2.2400		0.78268		4.9466		0.79512		2.8349		0.78745
360	1.0000e-07		3.0144		0.78467		6.0281		0.77423		2.9049		0.79112
365	1.0000e-07		2.8765		0.78706		5.6020		0.78241		2.9267		0.78819
370	1.0000e-07		2.8596		0.79877		6.2841		0.77097		2.7440		0.78866
375	1.0000e-07		2.5538		0.78254		7.1570		0.75907		2.9567		0.79021
380	1.0000e-07		2.8435		0.77650		5.5547		0.77952		2.9502		0.77549
385	1.0000e-07		2.9678		0.77326		6.2285		0.77514		2.8945		0.78415
390	1.0000e-07		2.5226		0.79755		5.1097		0.78992		3.0480		0.77908
395	1.0000e-07		3.3393		0.76886		4.6555		0.80727		2.9335		0.78343
400	1.0000e-07		2.8655		0.79958		4.8061		0.79852		2.9558		0.77754
405	1.0000e-07		2.3077		0.80421		4.8627		0.79170		2.8436		0.78298
410	1.0000e-07		2.7405		0.79510		5.5271		0.79042		2.7864		0.78921
415	1.0000e-08		2.5700		0.78286		4.7133		0.79389		2.9020		0.77583
420	1.0000e-08		2.7458		0.77941		5.5421		0.78777		2.7373		0.79091
425	1.0000e-08		2.7660		0.79847		5.4709		0.78017		2.7793		0.78747
430	1.0000e-08		2.8044		0.79923		4.8386		0.79216		2.8827		0.78002
435	1.0000e-08		3.1585		0.78052		5.2565		0.78582		2.8585		0.78308
440	1.0000e-08		2.7555		0.77158		4.8105		0.79735		2.9510		0.78295
445	1.0000e-08		2.6062		0.78963		6.4704		0.77148		2.9279		0.79428
450	1.0000e-08		2.9423		0.78730		4.8949		0.79695		2.8232		0.78288
455	1.0000e-08		3.3015		0.78764		4.9884		0.79903		2.8689		0.78436
460	1.0000e-08		2.7522		0.77703		7.1293		0.75481		2.6871		0.79611
465	1.0000e-08		3.7135		0.78157		5.1276		0.79578		3.0201		0.78713
470	1.0000e-08		3.1786		0.78846		5.2854		0.78958		2.8091		0.78606
475	1.0000e-08		2.7766		0.78423		4.9230		0.79275		2.8595		0.77949
480	1.0000e-08		3.0191		0.79494		8.1519		0.73825		2.8673		0.79875
485	1.0000e-08		2.9813		0.78405		6.2715		0.76998		2.7117		0.79275
490	1.0000e-08		3.4770		0.78212		4.8768		0.79798		2.9194		0.78602
495	1.0000e-08		2.8397		0.78348		4.6602		0.79425		2.8710		0.78202
500	1.0000e-08		2.4348		0.80218		5.6094		0.78287		2.9758		0.78772
505	1.0000e-08		2.7592		0.78505		4.7604		0.79336		2.9478		0.77491
510	1.0000e-08		2.7880		0.77229		5.8815		0.78157		2.8299		0.78823
515	1.0000e-08		3.0645		0.78690		5.8644		0.78683		2.8374		0.78582
520	1.0000e-08		2.5002		0.78656		4.8078		0.79837		3.0030		0.77572
525	1.0000e-08		2.6559		0.79622		6.2715		0.76962		2.9830		0.79069
530	1.0000e-08		3.4404		0.79020		4.8022		0.79173		2.9966		0.78310
535	1.0000e-08		3.6563		0.79123		5.2656		0.77874		2.8436		0.78350
540	1.0000e-08		2.8468		0.79229		4.2956		0.80422		3.0387		0.77565
545	1.0000e-08		3.0492		0.77882		6.2498		0.77160		2.7021		0.79198
550	1.0000e-08		2.7552		0.77967		6.0667		0.77695		2.7718		0.78821
555	1.0000e-08		3.0096		0.79296		4.4372		0.79667		2.9973		0.77731
560	1.0000e-08		3.1656		0.78055		6.5830		0.76531		2.6237		0.80161
565	1.0000e-08		2.7920		0.79813		8.6807		0.73483		3.2572		0.79416
570	1.0000e-08		3.2292		0.79272		5.1096		0.79122		3.0500		0.78489
575	1.0000e-08		3.1418		0.77222		4.9525		0.79506		2.7917		0.78503
580	1.0000e-08		2.7982		0.77974		8.2201		0.73818		2.9346		0.79754
585	1.0000e-08		2.4831		0.78819		6.7364		0.76067		2.7205		0.79665
590	1.0000e-08		2.7463		0.79062		5.1187		0.79001		2.8228		0.78625
595	1.0000e-08		3.5276		0.77029		6.7693		0.76266		2.8778		0.79204
600	1.0000e-08		3.5176		0.77408		5.1100		0.79359		2.8939		0.78613
605	1.0000e-08		3.1748		0.78979		5.4806		0.78621		2.9525		0.78832
610	1.0000e-08		2.6183		0.79192		4.8547		0.79982		2.9316		0.78262
615	1.0000e-08		2.9550		0.78842		5.1544		0.78913		2.9209		0.78757
620	1.0000e-08		2.8484		0.79332		5.6211		0.77812		2.7935		0.78777
625	1.0000e-08		3.0125		0.78976		7.3912		0.75493		2.8156		0.79508
630	1.0000e-08		3.6597		0.78732		6.1194		0.77011		2.8173		0.79234
635	1.0000e-08		2.7155		0.78711		5.4501		0.78303		2.7919		0.78698
640	1.0000e-08		3.1098		0.78083		4.5955		0.80051		2.9104		0.78414
645	1.0000e-08		2.8871		0.79449		6.2259		0.77906		2.9989		0.79329
650	1.0000e-08		3.4528		0.78996		5.3323		0.78412		2.8616		0.78589
655	1.0000e-08		3.0615		0.78399		4.5414		0.79591		2.9456		0.77490
660	1.0000e-08		3.4060		0.79101		6.2487		0.77634		2.7262		0.79849
665	1.0000e-08		2.8409		0.79898		5.0734		0.78614		2.9025		0.78353
670	1.0000e-08		2.9859		0.77867		8.3690		0.74284		2.8963		0.79687
675	1.0000e-08		2.6815		0.77183		6.3069		0.77161		2.6378		0.79858
680	1.0000e-08		3.0685		0.77883		6.7478		0.76720		2.8983		0.79492
685	1.0000e-08		3.2371		0.78405		5.9259		0.78354		2.9249		0.79160
690	1.0000e-08		2.9686		0.77466		5.0956		0.79306		2.9032		0.78451
695	1.0000e-08		3.1657		0.78604		6.2896		0.77276		2.8792		0.78832
