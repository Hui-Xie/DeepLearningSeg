=============training from sratch============
Program ID: 9633

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy', '0', '3,2,1']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Spe 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      
         

Discarded changes:                  

Experiment setting:
Input CT data: 51*171*171 ROI around primary cancer

Loss Function:  SoftMax

Data:   total 36 patients with 50-80% label, 6-fold cross validation, test 6, validation 6, and training 24.  
    script: python3.7 statisticsLabelFiles.py 
    Total 36 in /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
    0 has 48159408 elements, with a rate of  0.8970491562903105 
    1 has 5527068 elements, with a rate of  0.10295084370968957

Training strategy: 

          

Program starting Time: 2019-09-24 12:51:21.024351
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190924_125121

Info: this is the 0th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 6

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190924_125121.
6-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 24 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Total 24 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
0 has 32252453 elements, with a rate of  0.9011334530506342 
1 has 3538531 elements, with a rate of  0.0988665469493658 
loss weight = tensor([1.0000, 9.1146])
Network has total 32,972,258 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-01		31.1276		0.08707		91752304.0000		0.00000		72309392.0000		0.00000
5	1.0000e-01		2.4276		0.22287		1.8598		0.30313		1.7672		0.25041
10	1.0000e-01		1.9452		0.20097		1.8183		0.30133		1.7402		0.24604
15	1.0000e-01		1.7590		0.23423		1.5900		0.30219		1.6657		0.23912
20	1.0000e-01		1.6771		0.42295		1.2634		0.40401		1.4153		0.31563
25	1.0000e-01		1.1909		0.50236		1.3081		0.60870		1.3026		0.52180
30	1.0000e-01		1.0802		0.51644		1.9077		0.53293		2.0236		0.38693
35	1.0000e-01		1.1193		0.51826		1.2035		0.61123		1.0825		0.53329
40	1.0000e-01		0.9411		0.55178		2.0972		0.29342		2.0705		0.17098
45	1.0000e-01		0.8642		0.51211		0.9350		0.58922		0.9342		0.50864
50	1.0000e-01		0.9368		0.48600		0.8540		0.55288		0.9487		0.45960
55	1.0000e-01		1.0431		0.47626		1224.9155		0.00000		1082.7463		0.00000
60	1.0000e-01		0.9343		0.49568		1.7151		0.36692		2.0113		0.30109
65	1.0000e-01		0.8381		0.53959		7.6017		0.00000		6.2938		0.00000
70	1.0000e-01		0.8335		0.50499		2.1020		0.51055		1.7292		0.53176
75	1.0000e-01		0.8726		0.54394		6.9696		0.00000		5.5697		0.00000
80	1.0000e-01		0.8674		0.53830		0.9999		0.59397		0.9405		0.50598
85	1.0000e-01		0.7945		0.54247		1.2149		0.59349		1.1197		0.52029
90	1.0000e-01		0.8736		0.55480		2.9061		0.21539		2.5524		0.27863
95	1.0000e-01		0.7955		0.51517		9.0600		0.32124		16.7176		0.16820
100	1.0000e-01		0.8974		0.52786		0.8962		0.62183		0.8609		0.55078
105	1.0000e-01		0.9591		0.58754		2.9760		0.35360		2.1790		0.42246
110	1.0000e-01		0.8518		0.58247		1.1786		0.51779		1.6566		0.37950
115	1.0000e-01		0.9773		0.56025		3841.3931		0.00000		3592.4504		0.00000
120	1.0000e-01		1.0773		0.54749		2.7843		0.36034		2.6307		0.33711
125	1.0000e-01		0.9247		0.56461		1.4555		0.62612		1.3316		0.54052
130	1.0000e-01		1.0518		0.56107		4072.3047		0.00000		3626.0229		0.00000
135	1.0000e-01		1.1677		0.54907		10090.8125		0.00000		8916.0420		0.00000
140	1.0000e-01		1.0461		0.58195		2772.0127		0.00000		2579.9565		0.00000
145	1.0000e-01		0.9614		0.59111		6.5439		0.00000		5.8069		0.00000
150	1.0000e-01		0.9674		0.60213		13.3913		0.00000		11.7889		0.00000
155	1.0000e-01		0.9671		0.61872		180.9853		0.00042		184.9391		0.00210
160	1.0000e-01		1.0291		0.64399		2595.9917		0.00000		2289.1750		0.00000
165	1.0000e-01		1.0658		0.55105		2063.7739		0.00000		1907.1221		0.00000
170	1.0000e-01		0.8798		0.61835		3.5800		0.23014		2.6859		0.27522
175	1.0000e-01		0.9145		0.62436		25.4946		0.00000		35.6912		0.00000
180	1.0000e-01		0.9813		0.65644		3.1533		0.29088		2.6621		0.30244
185	1.0000e-01		1.0104		0.61716		36.1278		0.00000		52.7516		0.00000
190	1.0000e-01		1.0652		0.64073		1.4137		0.60571		1.8503		0.47960
195	1.0000e-01		1.0042		0.62352		972.6484		0.00000		912.4093		0.00000
200	1.0000e-02		0.8334		0.61559		1.5263		0.62992		1.7008		0.56515
205	1.0000e-02		0.8049		0.65351		1.8451		0.58966		2.6287		0.51841
210	1.0000e-02		0.7647		0.65215		1.1099		0.65983		1.1123		0.58049
215	1.0000e-02		0.7449		0.67290		1.5481		0.60531		1.8620		0.50944
220	1.0000e-02		0.8292		0.62636		1.4876		0.63209		1.0454		0.72089
225	1.0000e-02		0.8051		0.63649		2.6630		0.21938		2.0475		0.24070
230	1.0000e-02		0.6204		0.65875		1.0424		0.69876		0.7178		0.69879
235	1.0000e-02		0.7107		0.66662		1.0703		0.67603		0.9900		0.60758
240	1.0000e-02		0.7012		0.65808		2.8437		0.50606		4.4292		0.36284
245	1.0000e-02		0.6682		0.66306		2.1616		0.56593		2.7099		0.47833
250	1.0000e-02		0.6561		0.61546		1.2030		0.65276		1.2730		0.57603
255	1.0000e-02		0.7927		0.64855		1.6501		0.61264		2.0410		0.51864
260	1.0000e-02		0.7120		0.62870		1.4003		0.64253		1.6222		0.55261
265	1.0000e-02		0.7170		0.66550		1.0203		0.69174		0.8286		0.72857
270	1.0000e-02		0.6481		0.66541		1.4191		0.64462		1.5684		0.56293
275	1.0000e-02		0.6383		0.66342		3.6738		0.45323		4.7104		0.36941
280	1.0000e-02		0.7622		0.66111		3.0286		0.53169		4.0519		0.42838
285	1.0000e-02		0.7686		0.65993		1.0302		0.68286		0.8457		0.64867
290	1.0000e-02		0.6796		0.66422		1.6210		0.51542		1.6875		0.49259
295	1.0000e-02		0.6780		0.67551		0.7716		0.71773		0.8582		0.69248
300	1.0000e-02		0.6191		0.65743		2.9914		0.55721		4.2084		0.44308
305	1.0000e-02		0.4201		0.70296		1.5535		0.64204		1.4368		0.57836
310	1.0000e-02		0.5883		0.68827		0.9799		0.68577		0.7919		0.65456
315	1.0000e-02		0.6147		0.69477		0.9345		0.67614		0.9864		0.67845
320	1.0000e-02		0.5417		0.69236		0.8422		0.69607		0.7530		0.66817
325	1.0000e-02		0.5527		0.66988		1.2058		0.60179		0.8924		0.65840
330	1.0000e-02		0.5349		0.67470		1.0913		0.60760		0.8736		0.66703
335	1.0000e-02		0.4420		0.70442		1.6221		0.64329		1.6613		0.57512
340	1.0000e-02		0.4791		0.68690		0.7579		0.69442		0.5313		0.69785
345	1.0000e-02		0.4695		0.69691		0.9828		0.62530		0.8528		0.64593
350	1.0000e-02		0.4630		0.69714		1.3878		0.50848		1.2626		0.55739
355	1.0000e-02		0.5669		0.65870		2.4696		0.16045		2.0368		0.14393
360	1.0000e-02		0.4369		0.65215		1.4248		0.39284		1.3965		0.36161
365	1.0000e-02		0.4022		0.68726		1.3536		0.65474		1.0781		0.62260
370	1.0000e-02		0.3714		0.67705		2.5819		0.60005		3.1234		0.50998
375	1.0000e-02		0.3850		0.70084		0.6588		0.64872		0.6964		0.63538
380	1.0000e-02		0.5251		0.67485		0.8763		0.57252		1.2265		0.54664
385	1.0000e-02		0.4701		0.65657		0.5617		0.68907		0.4245		0.69026
390	1.0000e-02		0.3157		0.65697		1.1533		0.67040		0.9993		0.63171
395	1.0000e-02		0.3388		0.67621		2.8043		0.58034		3.4712		0.48989
400	1.0000e-03		0.1770		0.72375		1.5189		0.65956		1.5979		0.60151
405	1.0000e-03		0.3527		0.69135		0.5066		0.68273		0.2304		0.72603
410	1.0000e-03		0.1273		0.67714		0.5106		0.64839		0.2357		0.69792
415	1.0000e-03		0.1534		0.69863		0.4198		0.67741		0.2114		0.71610
420	1.0000e-03		0.2827		0.67995		0.4486		0.64383		0.2935		0.65845
425	1.0000e-03		0.1997		0.69672		0.3212		0.68737		0.2087		0.70058
430	1.0000e-03		0.1893		0.68960		0.4882		0.60256		0.3244		0.60591
435	1.0000e-03		0.0747		0.68690		0.4282		0.63042		0.2466		0.62770
440	1.0000e-03		0.0838		0.71079		0.4055		0.68613		0.1166		0.72457
445	1.0000e-03		0.0944		0.69059		0.4480		0.68132		0.1529		0.71517
