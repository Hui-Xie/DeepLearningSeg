=============training from sratch============
Program ID: 23693

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy', '0', '3,2,1']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      Sep 30th, 2019
      1   With size-reduced ROI of size 51*149*149;
      2   reduce the translation of data augmentation;
      3   reduce all data into 35 patients, excluding a very blur patient.
      
         

Discarded changes:                  

Experiment setting:
Input CT data: 51*171*171 ROI around primary cancer

Loss Function:  SoftMax

Data:   total 36 patients with 50-80% label, 6-fold cross validation, test 6, validation 6, and training 24.  
    script: python3.7 statisticsLabelFiles.py 
    Total 36 in /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
    0 has 48159408 elements, with a rate of  0.8970491562903105 
    1 has 5527068 elements, with a rate of  0.10295084370968957

Training strategy: 

          

Program starting Time: 2019-09-30 12:43:06.958927
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190930_124306

Info: this is the 0th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 6

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190930_124306.
program re-initializes all input files list, which will lead previous all K_fold cross validation invalid.
6-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 23 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Total 23 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy
0 has 20483196 elements, with a rate of  0.786551514752855 
1 has 5558577 elements, with a rate of  0.21344848524714505 
loss weight = tensor([1.0000, 3.6850])
Network has total 73,047,746 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		29.8776		0.18939		5700.4971		0.00000		2719.8948		0.00000
5	1.0000e-02		6.9066		0.60991		9.9393		0.59085		9.8877		0.53572
10	1.0000e-02		5.9259		0.65910		11.4485		0.73227		9.0259		0.70291
15	1.0000e-02		4.5820		0.68013		3.8882		0.77840		5.2487		0.70651
20	1.0000e-02		5.7073		0.64690		4.1125		0.75925		5.2559		0.69336
25	1.0000e-02		5.8250		0.67366		4.2474		0.76400		5.3987		0.68822
30	1.0000e-02		4.5686		0.70163		4.4526		0.77138		5.4036		0.68029
35	1.0000e-02		5.0694		0.69565		5.6282		0.76713		5.4424		0.71914
40	1.0000e-02		4.0485		0.72614		3.3722		0.81091		4.9304		0.71811
45	1.0000e-02		4.4987		0.70297		3.7273		0.79413		4.9654		0.71364
50	1.0000e-02		5.2193		0.74675		3.7806		0.80607		4.8507		0.71464
55	1.0000e-02		5.6665		0.70685		3.3355		0.83091		4.9443		0.73133
60	1.0000e-02		3.6324		0.74660		4.1067		0.78732		4.9397		0.72777
