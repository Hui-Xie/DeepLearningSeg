=============training from sratch============
Program ID: 10794

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy', '0', '3,2,1']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
         

Discarded changes:                  

Experiment setting:
Input CT data: 51*171*171 ROI around primary cancer

Loss Function:  SoftMax

Data:   total 36 patients with 50-80% label, 6-fold cross validation, test 6, validation 6, and training 24.  
    script: python3.7 statisticsLabelFiles.py 
    Total 36 in /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
    0 has 48159408 elements, with a rate of  0.8970491562903105 
    1 has 5527068 elements, with a rate of  0.10295084370968957

Training strategy: 

          

Program starting Time: 2019-09-18 14:38:34.185160
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190918_143834

Info: this is the 0th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 6

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190918_143834.
6-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 24 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Total 24 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
0 has 32252453 elements, with a rate of  0.9011334530506342 
1 has 3538531 elements, with a rate of  0.0988665469493658 
loss weight = tensor([1.0000, 9.1146])
Network has total 32,972,258 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-01		12.3436		0.05911		48671.9609		0.00000		30357.3672		0.00000
5	1.0000e-01		0.6180		0.26338		0.7050		0.09769		0.7144		0.00158
10	1.0000e-01		0.4708		0.40974		0.4628		0.48429		0.4745		0.36304
15	1.0000e-01		0.3756		0.48028		0.3396		0.57641		0.3339		0.46765
20	1.0000e-01		0.3482		0.44373		0.4388		0.64202		0.3660		0.58249
25	1.0000e-01		0.3441		0.51468		0.5150		0.63105		0.4069		0.58397
30	1.0000e-01		0.3434		0.51659		0.6773		0.39389		0.5636		0.52459
35	1.0000e-01		0.3788		0.51916		0.3398		0.64258		0.2819		0.56070
40	1.0000e-01		0.3676		0.49947		0.3250		0.61118		0.2943		0.51660
45	1.0000e-01		0.3412		0.48054		0.6318		0.57047		0.5707		0.55346
50	1.0000e-01		0.3432		0.47165		0.5214		0.67397		0.4689		0.55294
55	1.0000e-01		0.3559		0.46428		1.0131		0.05865		0.8863		0.06188
60	1.0000e-01		0.3428		0.50317		0.5128		0.63814		0.4695		0.59135
65	1.0000e-01		0.3095		0.52975		0.7423		0.28697		0.6820		0.32276
70	1.0000e-01		0.3633		0.49393		0.4121		0.68133		0.3460		0.62934
75	1.0000e-01		0.3186		0.52972		0.3184		0.66143		0.2792		0.56162
80	1.0000e-01		0.3019		0.49637		0.3167		0.69726		0.3549		0.54079
85	1.0000e-01		0.2793		0.52513		0.3137		0.54854		0.3926		0.38544
90	1.0000e-01		0.3338		0.46193		0.3187		0.63318		0.2820		0.50400
95	1.0000e-01		0.3501		0.53207		0.7223		0.26167		0.7938		0.26309
100	1.0000e-01		0.3129		0.52539		0.7733		0.17883		0.6357		0.24982
105	1.0000e-01		0.3059		0.51286		0.5764		0.56757		0.5871		0.48036
110	1.0000e-01		0.2849		0.55500		1.0895		0.00200		1.0135		0.00000
115	1.0000e-01		0.2764		0.52438		0.4513		0.59299		0.2711		0.54039
120	1.0000e-01		0.3263		0.49290		0.3055		0.61427		0.2835		0.48184
125	1.0000e-01		0.2725		0.52686		0.4031		0.64708		0.3360		0.59043
130	1.0000e-01		0.3055		0.58467		0.2501		0.63205		0.2970		0.49565
135	1.0000e-01		0.2435		0.52667		0.4129		0.45066		0.5363		0.33900
140	1.0000e-01		0.2804		0.53569		0.2579		0.59093		0.2935		0.48416
145	1.0000e-01		0.2982		0.56771		0.3832		0.69943		0.4638		0.53406
150	1.0000e-01		0.2557		0.52874		0.8179		0.34196		0.9066		0.24471
155	1.0000e-01		0.2855		0.51408		0.2576		0.66528		0.2765		0.56195
160	1.0000e-01		0.3067		0.52882		0.3888		0.68407		0.4868		0.50601
165	1.0000e-01		0.2771		0.51688		0.4998		0.36444		0.5542		0.31729
170	1.0000e-01		0.2461		0.50013		0.2905		0.53381		0.3333		0.40653
175	1.0000e-01		0.2905		0.56232		1.7936		0.03365		1.7481		0.00048
180	1.0000e-01		0.2442		0.54997		1.9932		0.05355		2.1564		0.00000
185	1.0000e-01		0.2904		0.53642		1.4822		0.23194		1.8931		0.00305
190	1.0000e-01		0.2957		0.51013		0.2416		0.59042		0.3459		0.44816
195	1.0000e-01		0.2534		0.57390		0.3194		0.65974		0.2775		0.56449
200	1.0000e-02		0.2871		0.54105		0.3223		0.60454		0.2796		0.50400
205	1.0000e-02		0.2492		0.59726		0.2678		0.64077		0.2545		0.53135
210	1.0000e-02		0.2466		0.55702		0.2612		0.61979		0.2760		0.49095
215	1.0000e-02		0.2481		0.55583		0.2416		0.65218		0.2446		0.54271
220	1.0000e-02		0.2258		0.54776		0.2618		0.66518		0.2283		0.56289
225	1.0000e-02		0.2569		0.57727		0.2499		0.67170		0.2283		0.56414
230	1.0000e-02		0.2315		0.57856		0.2634		0.67481		0.2302		0.56774
235	1.0000e-02		0.2258		0.54880		0.2366		0.67114		0.2298		0.57370
240	1.0000e-02		0.2206		0.53306		0.2242		0.65708		0.2423		0.54879
245	1.0000e-02		0.2363		0.57821		0.2292		0.66084		0.2450		0.53250
250	1.0000e-02		0.2233		0.58184		0.2367		0.66995		0.2354		0.55774
255	1.0000e-02		0.2142		0.51980		0.2468		0.64834		0.2381		0.54662
260	1.0000e-02		0.2281		0.53808		0.2498		0.58692		0.2985		0.46264
265	1.0000e-02		0.2297		0.54884		0.2433		0.61464		0.2628		0.50081
270	1.0000e-02		0.2349		0.58000		0.2425		0.64907		0.2496		0.52837
275	1.0000e-02		0.2197		0.59199		0.2590		0.65574		0.2443		0.54915
280	1.0000e-02		0.2178		0.56757		0.2234		0.65755		0.2353		0.55503
285	1.0000e-02		0.2084		0.57985		0.2417		0.64195		0.2557		0.52076
290	1.0000e-02		0.2551		0.57984		0.2286		0.63789		0.2517		0.52190
295	1.0000e-02		0.2256		0.59733		0.2628		0.67373		0.2311		0.58481
300	1.0000e-02		0.2319		0.56837		0.2459		0.60962		0.2648		0.50110
305	1.0000e-02		0.2240		0.58415		0.2119		0.64211		0.2472		0.52486
310	1.0000e-02		0.2087		0.60814		0.2403		0.66205		0.2332		0.57394
315	1.0000e-02		0.2230		0.58641		0.2262		0.66203		0.2318		0.57491
320	1.0000e-02		0.2330		0.57633		0.1943		0.68796		0.2163		0.58010
325	1.0000e-02		0.2792		0.55350		0.2301		0.65490		0.2437		0.55639
330	1.0000e-02		0.2308		0.59928		0.2516		0.67372		0.2322		0.57891
335	1.0000e-02		0.2255		0.57522		0.2503		0.65917		0.2463		0.56470
340	1.0000e-02		0.2187		0.59036		0.2498		0.66117		0.2463		0.56049
345	1.0000e-02		0.2366		0.60254		0.2386		0.66328		0.2364		0.56928
350	1.0000e-02		0.2112		0.59128		0.2586		0.67147		0.2354		0.58878
355	1.0000e-02		0.2022		0.59385		0.2210		0.65452		0.2379		0.55659
360	1.0000e-02		0.2158		0.57768		0.2243		0.64821		0.2363		0.54240
365	1.0000e-02		0.2004		0.57462		0.2404		0.66161		0.2290		0.56777
370	1.0000e-02		0.2092		0.59810		0.2501		0.67476		0.2134		0.59787
375	1.0000e-02		0.1979		0.60014		0.2197		0.66248		0.2269		0.56514
380	1.0000e-02		0.2073		0.59362		0.2304		0.65459		0.2319		0.56399
385	1.0000e-02		0.2086		0.60214		0.2465		0.65309		0.2325		0.56725
390	1.0000e-02		0.1909		0.58605		0.2417		0.62961		0.2438		0.53972
395	1.0000e-02		0.2222		0.57227		0.2176		0.64662		0.2381		0.54316
400	1.0000e-03		0.2043		0.62491		0.2120		0.67236		0.2287		0.57231
405	1.0000e-03		0.2078		0.59811		0.2173		0.66554		0.2356		0.56473
410	1.0000e-03		0.2274		0.61914		0.2229		0.65761		0.2363		0.55918
415	1.0000e-03		0.1926		0.60972		0.2197		0.67048		0.2208		0.58097
420	1.0000e-03		0.1816		0.62694		0.2217		0.66664		0.2201		0.58255
425	1.0000e-03		0.2169		0.59865		0.2301		0.65159		0.2400		0.55885
430	1.0000e-03		0.2000		0.60859		0.2225		0.64995		0.2392		0.55403
435	1.0000e-03		0.2015		0.61025		0.2234		0.65223		0.2314		0.55731
440	1.0000e-03		0.2156		0.58163		0.2203		0.65423		0.2293		0.55731
445	1.0000e-03		0.2386		0.57387		0.2334		0.65114		0.2248		0.56691
450	1.0000e-03		0.2000		0.63543		0.2192		0.67487		0.2255		0.58491
455	1.0000e-03		0.2159		0.62091		0.2280		0.65230		0.2355		0.56077
460	1.0000e-03		0.1966		0.61128		0.2160		0.66812		0.2227		0.57145
465	1.0000e-03		0.2037		0.57711		0.2178		0.67704		0.2097		0.59637
470	1.0000e-03		0.2091		0.60505		0.2293		0.66189		0.2215		0.57510
475	1.0000e-03		0.1993		0.59431		0.2140		0.68167		0.2168		0.59521
480	1.0000e-03		0.1981		0.61517		0.2182		0.66778		0.2297		0.57658
485	1.0000e-03		0.1822		0.59827		0.2205		0.65722		0.2309		0.56706
490	1.0000e-03		0.2242		0.63334		0.2141		0.66122		0.2237		0.56684
495	1.0000e-03		0.1920		0.55437		0.2182		0.63089		0.2368		0.53677
500	1.0000e-03		0.1851		0.59533		0.2202		0.65795		0.2303		0.55790
505	1.0000e-03		0.1948		0.63078		0.2197		0.65828		0.2217		0.57426
510	1.0000e-03		0.2045		0.60098		0.2142		0.66442		0.2256		0.57034
515	1.0000e-03		0.2095		0.59390		0.2129		0.66512		0.2131		0.59018
520	1.0000e-03		0.1929		0.61752		0.2125		0.66503		0.2210		0.57376
525	1.0000e-03		0.1938		0.62424		0.2096		0.67197		0.2163		0.58486
530	1.0000e-03		0.1881		0.61967		0.2140		0.65270		0.2259		0.56387
535	1.0000e-03		0.1902		0.58472		0.2190		0.64532		0.2395		0.54461
540	1.0000e-03		0.1944		0.62884		0.2180		0.67939		0.2190		0.59116
