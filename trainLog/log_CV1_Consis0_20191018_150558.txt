=============training from sratch============
Program ID: 17584

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy', '1', '2', '0']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      Sep 30th, 2019
      1   With size-reduced ROI of size 51*149*149;
      2   reduce the translation of data augmentation;
      3   reduce all data into 35 patients, excluding a very blur patient.
      Oct 5th, 2019
      1   use uniform physical size 147mm*147mm*147mm, input pixel size: 49*147*147 with spacing size 3mm*1mm*1mm;
      2   change V model with inputsize 49*147*147
      Oct 6th, 2019
      1   add filter number to 48 at the first layer. 
      Oct 7th, 2019
      1   restore to 32 of number of filters in the first layer;
      2   add bottom number of filters to 1024, and keep down sample and add filter number together. 
      Oct 8th, 2019
      1   discard the cancer with size exceeding 147mm*147mm*147mm; Now remains 29 patients data; 
      Oct 9th, 2019
      1   In the first layer of V model, remove the residual link; 
           with the residula link at first layer: Tr dice:54%, Validation Dice 27%, Test Dice 56%;  Not good.
      2   the final output layer, change into 1*1*1 convolution, instead of 3*3*3 convolution;
      3   add labelConsistencyLoss, it use 64 dimension feature extracted from 2 ends of V model:
           It gets stable Training Dice 61%, validation Dice 27%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      Oct 11th, 2019
      1   use feature tensor just from the output end of V model. It is 32 dimensions.
          It gets stable Training Dice 61%, validation Dice 23%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      2   windows size for consistency loss changes to 3;
      Oct 12th, 2019
      1   change image window level to 100/50; relaunch training;
      2   change consistencyLoss to use ground truth for comparing diff of feature vector;
      Oct 13th, 2019
      1    use conistencyLoss3: ((G1-G2)-(P1-P2))**2 as loss.
      
      Oct 18th, 2019
      1   use 48 filters at the first layer with inputsize 49*147*147 with scaled ROI.
       
      
       
      

          
         

Discarded changes:                  
          

Program starting Time: 2019-10-18 15:05:58.869915
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191018_150558

Info: this is the 1th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 1

Info: useConsistencyLoss = False and searchWindowSize= 0

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191018_150558.
6-fold cross validation: the 1th fold is for test, the 2th fold is for validation, remaining folds are for training.

training dataset: total 23 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Total 23 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy
0 has 19065790 elements, with a rate of  0.7828818409037314 
1 has 5287553 elements, with a rate of  0.21711815909626864 
loss weight = tensor([1.0000, 3.6058])
Network has total 254,652,146 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		4.3261		0.29518		8.4396		0.00017		4.7678		0.00004
5	1.0000e-02		2.3069		0.62363		1.7304		0.70123		1.9021		0.72386
10	1.0000e-02		2.1485		0.62740		1.5104		0.71766		1.3469		0.79137
15	1.0000e-02		2.8222		0.59231		1.9828		0.71437		1.9251		0.77784
20	1.0000e-02		2.0304		0.63856		1.6429		0.73088		1.6842		0.77517
25	1.0000e-02		1.9644		0.61019		1.6348		0.72146		1.6365		0.79248
30	1.0000e-02		1.8764		0.66143		1.4799		0.72041		1.5174		0.76273
35	1.0000e-02		1.7995		0.65717		4.1666		0.45393		2.2172		0.68842
40	1.0000e-02		1.9466		0.65720		1.9219		0.65847		1.6400		0.77263
45	1.0000e-02		1.6199		0.69487		2.2820		0.58757		1.4833		0.78508
50	1.0000e-02		1.8885		0.65278		2.5232		0.59393		1.4514		0.75505
55	1.0000e-02		1.6733		0.69755		2.1937		0.62497		1.8049		0.73962
60	1.0000e-02		1.7530		0.68575		2.7458		0.55662		1.3925		0.78220
65	1.0000e-02		1.5315		0.71201		2.0347		0.64875		1.2697		0.80658
70	1.0000e-02		1.8088		0.70097		2.6021		0.58203		2.3113		0.70147
75	1.0000e-02		1.5914		0.71124		2.5550		0.61160		2.8353		0.58861
80	1.0000e-02		1.3686		0.74043		1.6407		0.70708		1.3609		0.78133
85	1.0000e-03		1.4402		0.72776		1.5907		0.70185		1.4430		0.75453
90	1.0000e-03		1.2123		0.74699		1.2646		0.75720		1.2327		0.78942
95	1.0000e-03		1.0852		0.77385		1.3003		0.75931		1.2121		0.80366
100	1.0000e-03		0.9746		0.77700		1.4590		0.72885		1.2958		0.78782
105	1.0000e-03		1.2678		0.77003		1.9235		0.67631		1.3523		0.78465
110	1.0000e-03		0.9619		0.77828		2.5859		0.63483		1.7103		0.74572
115	1.0000e-03		0.9726		0.78454		2.5107		0.65449		1.8473		0.74385
120	1.0000e-03		1.0132		0.78739		2.1436		0.68404		1.5390		0.76697
125	1.0000e-03		0.9275		0.78075		1.4474		0.72806		1.1846		0.79410
130	1.0000e-03		1.0514		0.76996		1.2475		0.74407		1.1822		0.79048
135	1.0000e-03		0.8791		0.78926		1.1833		0.75700		1.2550		0.78101
140	1.0000e-03		0.9064		0.79125		1.3472		0.73742		1.2609		0.78578
145	1.0000e-03		0.8628		0.78803		1.7456		0.69486		1.5881		0.75795
150	1.0000e-03		0.8827		0.79494		1.2756		0.75326		1.2302		0.78816
155	1.0000e-03		0.9957		0.79888		1.7039		0.71488		1.5250		0.75406
160	1.0000e-03		0.8626		0.79855		1.4874		0.73118		1.2483		0.78909
165	1.0000e-03		0.8013		0.80933		1.4782		0.72354		1.3053		0.78575
170	1.0000e-03		0.7639		0.80306		1.4694		0.73055		1.4026		0.78527
175	1.0000e-03		0.6783		0.82778		1.5831		0.72566		1.2176		0.79201
180	1.0000e-03		0.9980		0.80024		1.7157		0.70249		1.3409		0.78415
185	1.0000e-03		0.7661		0.82360		1.2696		0.74948		1.2169		0.79624
190	1.0000e-04		0.7655		0.81545		1.3203		0.75078		1.4588		0.77367
195	1.0000e-04		0.5840		0.83655		1.1465		0.76905		1.3028		0.79025
200	1.0000e-04		0.7270		0.83228		1.1751		0.77813		1.3804		0.78645
205	1.0000e-04		0.6618		0.83106		1.2949		0.74833		1.4276		0.77951
210	1.0000e-04		0.7842		0.83448		1.2717		0.75901		1.3188		0.79213
215	1.0000e-04		0.6763		0.82994		1.4793		0.72992		1.4404		0.77444
220	1.0000e-04		0.6148		0.81807		1.5973		0.71714		1.5516		0.77257
225	1.0000e-04		0.7037		0.81647		1.4583		0.73117		1.4850		0.77931
230	1.0000e-04		0.6039		0.84013		1.1780		0.76677		1.4949		0.77455
235	1.0000e-04		0.5474		0.83837		1.1452		0.77054		1.4611		0.78103
240	1.0000e-04		0.6151		0.84440		1.3489		0.73990		1.4465		0.77606
245	1.0000e-04		0.5968		0.83285		1.2570		0.75904		1.4886		0.77862
250	1.0000e-04		0.5769		0.82915		1.3335		0.74674		1.7140		0.76030
255	1.0000e-04		0.5351		0.85921		1.1901		0.76511		1.4499		0.78278
260	1.0000e-04		0.5789		0.84790		1.2855		0.75189		1.3536		0.79141
265	1.0000e-04		0.6283		0.84858		1.4285		0.73495		1.6489		0.76723
270	1.0000e-04		0.5778		0.84149		2.1271		0.68200		1.7504		0.76473
275	1.0000e-04		0.5150		0.84749		1.1594		0.76236		1.6390		0.76489
280	1.0000e-04		0.6109		0.82841		1.4428		0.72626		1.6654		0.75716
285	1.0000e-04		0.5966		0.83765		1.3530		0.75066		1.6662		0.76373
290	1.0000e-05		0.5673		0.83086		1.5307		0.72370		1.6927		0.75854
295	1.0000e-05		0.6485		0.84080		1.3467		0.74675		1.8338		0.75734
300	1.0000e-05		0.6592		0.81020		1.8297		0.70034		1.6461		0.76258
305	1.0000e-05		0.7820		0.83906		1.3560		0.74514		1.6527		0.76291
310	1.0000e-05		0.5917		0.83752		1.4022		0.73670		1.7305		0.76270
315	1.0000e-05		0.6215		0.84698		1.2457		0.75685		1.6479		0.76717
320	1.0000e-05		0.5035		0.85714		1.2823		0.75691		1.7022		0.76002
325	1.0000e-05		0.6368		0.83971		1.6222		0.71787		1.7447		0.75670
330	1.0000e-05		0.5625		0.83822		2.1597		0.67754		1.7405		0.75907
335	1.0000e-05		0.5253		0.83768		1.3286		0.75315		1.7967		0.76211
340	1.0000e-05		0.6082		0.84904		1.3096		0.75331		1.6979		0.76698
345	1.0000e-06		0.6470		0.85300		1.2820		0.75891		1.6454		0.76534
350	1.0000e-06		0.7746		0.82192		1.2873		0.75584		1.7614		0.76363
355	1.0000e-06		0.4697		0.85625		1.4562		0.73339		1.7428		0.76207
360	1.0000e-06		0.4736		0.85219		1.2936		0.75379		1.7077		0.76523
365	1.0000e-06		0.6041		0.82350		1.1768		0.77274		1.7691		0.76330
370	1.0000e-06		0.6445		0.82890		1.3321		0.74721		1.6849		0.76687
375	1.0000e-06		0.5116		0.85796		1.2218		0.77215		1.6923		0.76796
380	1.0000e-06		0.5293		0.84972		1.2844		0.75677		1.8369		0.75555
385	1.0000e-06		0.6158		0.84368		1.1899		0.76824		1.6643		0.77059
390	1.0000e-06		0.5261		0.85983		1.2735		0.77805		1.7741		0.75533
395	1.0000e-06		0.6326		0.83605		1.3038		0.75317		1.6968		0.76691
400	1.0000e-07		0.4762		0.83086		1.3097		0.74983		1.8170		0.76241
405	1.0000e-07		0.5348		0.86447		1.2128		0.76902		1.7413		0.75808
410	1.0000e-07		0.5429		0.84067		1.2592		0.75209		1.7998		0.75875
415	1.0000e-07		0.7067		0.82573		1.3898		0.73925		1.6712		0.76596
420	1.0000e-07		0.5472		0.84233		1.4074		0.73898		1.7279		0.75966
425	1.0000e-07		0.7050		0.83846		1.4138		0.73465		1.7822		0.76002
430	1.0000e-07		0.4692		0.84568		1.2588		0.75887		1.7687		0.76107
435	1.0000e-07		0.6465		0.82827		2.0531		0.68686		1.7567		0.75759
440	1.0000e-07		0.5416		0.83082		2.1235		0.68338		1.6054		0.76861
445	1.0000e-07		0.6986		0.82790		1.2500		0.75548		1.6925		0.76670
450	1.0000e-07		0.5360		0.85514		1.1552		0.77189		1.6671		0.76443
455	1.0000e-08		0.6976		0.82171		1.4728		0.73091		1.7150		0.76048
460	1.0000e-08		0.6362		0.84264		1.2739		0.75686		1.6515		0.76947
465	1.0000e-08		0.6264		0.83797		1.2616		0.76884		1.9044		0.74899
470	1.0000e-08		0.5347		0.85699		1.2553		0.76020		1.7137		0.76379
475	1.0000e-08		0.5695		0.83532		1.6313		0.71931		1.9351		0.74561
480	1.0000e-08		0.6441		0.84119		1.2095		0.77144		1.8536		0.75008
485	1.0000e-08		0.5116		0.85834		1.1766		0.77237		1.6923		0.76806
490	1.0000e-08		0.5864		0.84072		1.2243		0.76911		1.7421		0.76497
495	1.0000e-08		0.6563		0.83890		1.4878		0.73206		1.6854		0.76143
500	1.0000e-08		0.6371		0.83610		1.6509		0.71554		1.7818		0.75208
505	1.0000e-08		0.7297		0.84316		1.2191		0.77117		1.7133		0.76192
510	1.0000e-08		0.7287		0.83381		2.1766		0.67850		1.7320		0.76093
515	1.0000e-08		0.5962		0.84617		1.2448		0.76435		1.7072		0.77158
520	1.0000e-08		0.4911		0.85578		1.2474		0.75940		1.7068		0.76803
525	1.0000e-08		0.5847		0.84451		1.3193		0.74594		1.7435		0.76342
530	1.0000e-08		0.5733		0.84825		1.3217		0.75181		1.7017		0.76754
535	1.0000e-08		0.4997		0.83914		1.3261		0.74759		1.6446		0.76519
540	1.0000e-08		0.5042		0.83275		1.9217		0.69435		1.7791		0.75759
545	1.0000e-08		0.5341		0.84831		1.1973		0.76734		1.7168		0.76889
550	1.0000e-08		0.6639		0.82475		1.6298		0.71048		1.6931		0.75968
555	1.0000e-08		0.6150		0.84890		1.2359		0.76884		1.8301		0.75704
560	1.0000e-08		0.5888		0.84142		1.4266		0.73967		1.7474		0.76215
565	1.0000e-08		0.6296		0.83600		1.2408		0.75908		1.7401		0.76084
570	1.0000e-08		0.5892		0.84938		1.2626		0.75636		1.7919		0.75463
575	1.0000e-08		0.5606		0.84501		1.3174		0.75254		1.7418		0.76194
580	1.0000e-08		0.5080		0.86109		1.2482		0.76961		1.7473		0.75919
585	1.0000e-08		0.5612		0.84831		1.5426		0.72246		1.8305		0.75434
590	1.0000e-08		0.7216		0.84506		1.3309		0.74498		1.5731		0.77161
595	1.0000e-08		0.5076		0.86339		1.3404		0.75016		1.6961		0.76535
600	1.0000e-08		0.4728		0.84968		1.4620		0.73517		1.7713		0.76172
605	1.0000e-08		0.5464		0.85956		1.4184		0.73524		1.6124		0.76613
610	1.0000e-08		0.4652		0.86887		1.1967		0.77436		1.7793		0.76179
615	1.0000e-08		0.4843		0.85808		1.2140		0.76300		1.7804		0.76066
620	1.0000e-08		0.8701		0.82998		1.6284		0.71890		1.7771		0.75217
625	1.0000e-08		0.4817		0.85981		1.4915		0.72939		1.7049		0.76543
630	1.0000e-08		0.4839		0.84206		1.2154		0.76641		1.8344		0.76115
635	1.0000e-08		0.5117		0.84957		1.2077		0.76701		1.8338		0.75531
640	1.0000e-08		0.5110		0.85511		1.1950		0.77327		1.6731		0.76790
645	1.0000e-08		0.5800		0.84598		1.2972		0.75340		1.7643		0.75889
650	1.0000e-08		0.4998		0.84637		1.4017		0.73985		1.7092		0.76217
655	1.0000e-08		0.5234		0.84753		1.2070		0.76966		1.8432		0.75820
660	1.0000e-08		0.6029		0.82601		1.3460		0.74709		1.8861		0.75411
665	1.0000e-08		0.5221		0.84675		1.3209		0.75341		1.8378		0.76056
670	1.0000e-08		0.5449		0.86789		1.2863		0.74885		1.5174		0.77637
675	1.0000e-08		0.6269		0.83495		1.4387		0.73552		1.6592		0.76464
680	1.0000e-08		0.5015		0.84264		1.4335		0.73022		1.6587		0.76683
685	1.0000e-08		0.5354		0.85749		1.2802		0.75312		1.5785		0.76977
690	1.0000e-08		0.5221		0.85351		1.2706		0.76066		1.6591		0.76770
695	1.0000e-08		0.4888		0.84080		1.4606		0.73448		1.8039		0.76173
700	1.0000e-08		0.5423		0.85617		1.2919		0.75561		1.7378		0.76091
705	1.0000e-08		0.6261		0.84333		1.2697		0.75563		1.6811		0.76205
710	1.0000e-08		0.5835		0.84262		1.2092		0.77345		1.8354		0.75175
715	1.0000e-08		0.5346		0.84626		1.3224		0.74731		1.8109		0.75999
720	1.0000e-08		0.5106		0.85766		1.2269		0.76399		1.6200		0.77143
725	1.0000e-08		0.4986		0.85390		1.3028		0.76911		1.6723		0.76274
730	1.0000e-08		0.5560		0.84506		1.3808		0.73836		1.6878		0.76093
735	1.0000e-08		0.6242		0.83537		1.5230		0.72645		1.7333		0.75899
740	1.0000e-08		0.4746		0.87525		1.1980		0.77965		2.0282		0.72837
745	1.0000e-08		0.5172		0.86183		1.2656		0.77098		1.7962		0.75809
750	1.0000e-08		0.4646		0.86635		1.2080		0.76533		1.6820		0.76399
755	1.0000e-08		0.6052		0.82906		1.6598		0.71777		1.6300		0.77019
760	1.0000e-08		0.5169		0.85378		1.2429		0.77607		1.8831		0.74522
765	1.0000e-08		0.5772		0.83740		1.3024		0.75392		1.9044		0.75803
770	1.0000e-08		0.5591		0.82813		1.3805		0.73503		1.7691		0.75916
775	1.0000e-08		0.5881		0.84012		1.1935		0.76914		1.7066		0.76621
780	1.0000e-08		0.5132		0.85122		1.2446		0.77582		1.8331		0.75620
785	1.0000e-08		0.5476		0.84135		1.2251		0.76225		1.8957		0.75928
790	1.0000e-08		0.5787		0.85113		1.1915		0.76888		1.6143		0.77133
795	1.0000e-08		0.6713		0.82895		1.3377		0.74667		1.6967		0.76631
800	1.0000e-08		0.4979		0.85814		1.3428		0.74850		1.8060		0.75817
805	1.0000e-08		0.5745		0.84680		1.2585		0.75384		1.6802		0.76279
810	1.0000e-08		0.6122		0.84411		1.2792		0.75340		1.7754		0.76009
815	1.0000e-08		0.5831		0.85314		1.1956		0.76745		1.7816		0.76354
820	1.0000e-08		0.5246		0.84557		1.5242		0.72757		1.7296		0.75999
825	1.0000e-08		0.5798		0.84195		1.2436		0.76157		1.6070		0.76967
830	1.0000e-08		0.5990		0.84542		1.2448		0.75815		1.7377		0.75805
835	1.0000e-08		0.5005		0.85458		1.2261		0.76587		1.6431		0.76750
840	1.0000e-08		0.5620		0.86394		1.1416		0.77579		1.7759		0.75660
845	1.0000e-08		0.5444		0.84739		1.3513		0.74550		1.7297		0.76724
850	1.0000e-08		0.5893		0.83305		1.4534		0.74093		1.8321		0.75799
855	1.0000e-08		0.5635		0.84462		1.3214		0.75360		1.5692		0.77390
860	1.0000e-08		0.5149		0.84532		1.2934		0.75303		1.6102		0.77190
865	1.0000e-08		0.6223		0.84205		1.3154		0.74926		1.6712		0.76705
870	1.0000e-08		0.5593		0.84841		1.2882		0.76021		1.6720		0.76423
875	1.0000e-08		0.5721		0.83897		1.2767		0.75475		1.9123		0.75664
880	1.0000e-08		0.6786		0.82680		1.2810		0.75524		1.7605		0.76427
885	1.0000e-08		0.4719		0.85668		1.9289		0.69029		1.7844		0.75653
890	1.0000e-08		0.5164		0.83887		2.1102		0.67865		1.6649		0.76517
895	1.0000e-08		0.5005		0.84828		1.2480		0.75911		1.6808		0.76957
900	1.0000e-08		0.4866		0.86524		1.3134		0.75275		1.7098		0.76257
905	1.0000e-08		0.8574		0.83800		1.2383		0.76834		1.7825		0.75625
910	1.0000e-08		0.5672		0.82969		1.2196		0.75853		1.8886		0.75619
915	1.0000e-08		0.6776		0.84513		1.8495		0.69620		1.6818		0.76490
920	1.0000e-08		0.5360		0.83829		1.2423		0.76049		1.9001		0.75100
925	1.0000e-08		0.6224		0.84118		1.3638		0.74201		1.6961		0.76305
930	1.0000e-08		0.5487		0.85023		1.4818		0.72945		1.6475		0.76266
935	1.0000e-08		0.5285		0.85770		1.1880		0.76176		1.7209		0.76505
940	1.0000e-08		0.6753		0.84913		1.3264		0.75091		1.5449		0.77476
945	1.0000e-08		0.5533		0.84914		1.4461		0.73409		1.5892		0.76803
950	1.0000e-08		0.5093		0.85016		1.3497		0.74203		1.6934		0.76490
955	1.0000e-08		0.5077		0.85216		1.1671		0.77413		1.7687		0.75923
960	1.0000e-08		0.4940		0.84601		1.3349		0.74565		1.8534		0.75801
965	1.0000e-08		0.5632		0.85674		1.2022		0.76439		1.6455		0.76931
970	1.0000e-08		0.6665		0.84419		1.2359		0.76653		1.6896		0.76775
975	1.0000e-08		0.5352		0.86011		1.2240		0.76180		1.7045		0.76733
980	1.0000e-08		0.5342		0.84576		1.5305		0.72492		1.7721		0.75439
985	1.0000e-08		0.6200		0.83033		1.3328		0.75071		1.6591		0.76849
990	1.0000e-08		0.4968		0.84871		1.2417		0.75484		1.7266		0.76672
995	1.0000e-08		0.6628		0.84003		1.2876		0.74984		1.5613		0.77072
1000	1.0000e-08		0.5629		0.85388		1.1993		0.76983		1.6900		0.76413
1005	1.0000e-08		0.6057		0.83964		1.3258		0.74748		1.6644		0.76187
1010	1.0000e-08		0.5605		0.84057		1.3013		0.75321		1.7601		0.76271
1015	1.0000e-08		0.5119		0.85761		1.3207		0.76430		1.7812		0.76092
1020	1.0000e-08		0.5125		0.84705		1.4104		0.73982		1.7113		0.76345
1025	1.0000e-08		0.5127		0.83843		1.2267		0.75967		1.7906		0.75694
1030	1.0000e-08		0.6089		0.85490		1.4104		0.74169		1.7414		0.75939
1035	1.0000e-08		0.5052		0.85082		1.4746		0.72982		1.6860		0.76477
1040	1.0000e-08		0.5838		0.85611		1.2158		0.76219		1.6556		0.76347
1045	1.0000e-08		0.5751		0.84280		1.3057		0.75263		1.6357		0.77107
1050	1.0000e-08		0.6106		0.82600		1.4743		0.72912		1.7146		0.75796
1055	1.0000e-08		0.5530		0.84590		1.2018		0.77128		1.8255		0.75596
1060	1.0000e-08		0.5655		0.85808		1.2557		0.75703		1.6097		0.77039
1065	1.0000e-08		0.6134		0.84020		1.4449		0.73765		1.7816		0.75917
1070	1.0000e-08		0.5419		0.83872		1.2495		0.75265		1.6020		0.77032
1075	1.0000e-08		0.5858		0.83969		1.6768		0.71456		1.7059		0.75862
1080	1.0000e-08		0.5577		0.84153		1.3195		0.75069		1.7403		0.76263
1085	1.0000e-08		0.5773		0.86562		1.2387		0.77637		1.7834		0.75621
1090	1.0000e-08		0.4701		0.83073		1.5964		0.71533		1.8623		0.75189
1095	1.0000e-08		0.5120		0.84258		2.3267		0.66192		1.8760		0.74696
1100	1.0000e-08		0.5483		0.84970		1.3659		0.74293		1.8342		0.75697
1105	1.0000e-08		0.5337		0.83713		1.2514		0.75865		1.7208		0.76488
1110	1.0000e-08		0.7308		0.82161		1.3711		0.74608		1.7866		0.75881
1115	1.0000e-08		0.5323		0.85072		1.3132		0.75219		1.7124		0.76747
1120	1.0000e-08		0.6213		0.83874		1.3345		0.74682		1.7414		0.76418
