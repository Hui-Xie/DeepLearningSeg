Program ID 16491

Program command: 
 ['/home/hxie1/Projects/OvarianCancer/TrainSegV.py', '/home/hxie1/temp_netParameters/OvarianCancer/Label0_1', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainImages', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels', '2D', '0,1']

Major program changes: ConvResidual use BatchNorm-reLU-Conv structure; 
                       ConsDense also use BatchNorm-reLU-Conv structure.
                       Add ConvSegDecreaseChannels
                       and each block has 5 layers, 
                       Residual connect to each Conv, 
                       skip at least 2 layers.
                       output layer use conv with 3*3 fiter instead of 1*1 filter. 
                       use boundary loss with weight 0 at beginning, and pretrain CE loss. 
                       special convInput Module
                       convOutput moudel uses 1*1 conv to tranparent gradident 
                       ConvOutput use residual module.
                       Use Dense Net in the Building Block
                       add ConvBlock to wrapp the ConvResidual and ConvDense
                       first layer filter = 96, reducing from 128 of previous experiment
                       the nLayers in block is 4, increase from 2 of previous experiment
                       add Bn-Relu-Conv module with paparamter
                       use Conv-ReLu-Bn order (CBR)
                       use Mixup and DenseNet
                       
            

Program starting Time: 2019-05-10 16:04:15.923509
Info: program uses mixeup with alpha=0.4.
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/Label0_1

Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels has 164 segmented slices for remained labels [0, 1].
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/testLabels has 31 segmented slices for remained labels [0, 1].
Info: program uses 2D input.
TrainData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

TestData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

Network trains from scratch.
Network has total 115864034 parameters.
Info: network dropout rate = 0.3
Infor: Cross Entropy Weight: [1.0260619741432382, 39.37007874015748]

====================Net Architecture===========================
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 96, 281, 281]             960
       BatchNorm2d-2         [-1, 96, 281, 281]             192
              ReLU-3         [-1, 96, 281, 281]               0
    BN_ReLU_Conv2d-4         [-1, 96, 281, 281]               0
            Conv2d-5         [-1, 96, 281, 281]           9,312
       BatchNorm2d-6         [-1, 96, 281, 281]             192
              ReLU-7         [-1, 96, 281, 281]               0
    BN_ReLU_Conv2d-8         [-1, 96, 281, 281]               0
            Conv2d-9         [-1, 24, 281, 281]          20,760
      BatchNorm2d-10         [-1, 24, 281, 281]              48
             ReLU-11         [-1, 24, 281, 281]               0
   BN_ReLU_Conv2d-12         [-1, 24, 281, 281]               0
           Conv2d-13         [-1, 96, 281, 281]          11,616
      BatchNorm2d-14         [-1, 96, 281, 281]             192
             ReLU-15         [-1, 96, 281, 281]               0
   BN_ReLU_Conv2d-16         [-1, 96, 281, 281]               0
           Conv2d-17         [-1, 24, 281, 281]          20,760
      BatchNorm2d-18         [-1, 24, 281, 281]              48
             ReLU-19         [-1, 24, 281, 281]               0
   BN_ReLU_Conv2d-20         [-1, 24, 281, 281]               0
           Conv2d-21         [-1, 96, 281, 281]          13,920
      BatchNorm2d-22         [-1, 96, 281, 281]             192
             ReLU-23         [-1, 96, 281, 281]               0
   BN_ReLU_Conv2d-24         [-1, 96, 281, 281]               0
           Conv2d-25         [-1, 24, 281, 281]          20,760
      BatchNorm2d-26         [-1, 24, 281, 281]              48
             ReLU-27         [-1, 24, 281, 281]               0
   BN_ReLU_Conv2d-28         [-1, 24, 281, 281]               0
           Conv2d-29         [-1, 96, 281, 281]          16,224
      BatchNorm2d-30         [-1, 96, 281, 281]             192
             ReLU-31         [-1, 96, 281, 281]               0
   BN_ReLU_Conv2d-32         [-1, 96, 281, 281]               0
           Conv2d-33         [-1, 24, 281, 281]          20,760
      BatchNorm2d-34         [-1, 24, 281, 281]              48
             ReLU-35         [-1, 24, 281, 281]               0
   BN_ReLU_Conv2d-36         [-1, 24, 281, 281]               0
           Conv2d-37         [-1, 96, 281, 281]          18,528
      BatchNorm2d-38         [-1, 96, 281, 281]             192
             ReLU-39         [-1, 96, 281, 281]               0
   BN_ReLU_Conv2d-40         [-1, 96, 281, 281]               0
        ConvDense-41         [-1, 96, 281, 281]               0
ConvBuildingBlock-42         [-1, 96, 281, 281]               0
        ConvInput-43         [-1, 96, 281, 281]               0
           Conv2d-44         [-1, 96, 139, 139]         230,496
      BatchNorm2d-45         [-1, 96, 139, 139]             192
             ReLU-46         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-47         [-1, 96, 139, 139]               0
           Conv2d-48         [-1, 96, 139, 139]           9,312
      BatchNorm2d-49         [-1, 96, 139, 139]             192
             ReLU-50         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-51         [-1, 96, 139, 139]               0
           Conv2d-52         [-1, 24, 139, 139]          20,760
      BatchNorm2d-53         [-1, 24, 139, 139]              48
             ReLU-54         [-1, 24, 139, 139]               0
   BN_ReLU_Conv2d-55         [-1, 24, 139, 139]               0
           Conv2d-56         [-1, 96, 139, 139]          11,616
      BatchNorm2d-57         [-1, 96, 139, 139]             192
             ReLU-58         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-59         [-1, 96, 139, 139]               0
           Conv2d-60         [-1, 24, 139, 139]          20,760
      BatchNorm2d-61         [-1, 24, 139, 139]              48
             ReLU-62         [-1, 24, 139, 139]               0
   BN_ReLU_Conv2d-63         [-1, 24, 139, 139]               0
           Conv2d-64         [-1, 96, 139, 139]          13,920
      BatchNorm2d-65         [-1, 96, 139, 139]             192
             ReLU-66         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-67         [-1, 96, 139, 139]               0
           Conv2d-68         [-1, 24, 139, 139]          20,760
      BatchNorm2d-69         [-1, 24, 139, 139]              48
             ReLU-70         [-1, 24, 139, 139]               0
   BN_ReLU_Conv2d-71         [-1, 24, 139, 139]               0
           Conv2d-72         [-1, 96, 139, 139]          16,224
      BatchNorm2d-73         [-1, 96, 139, 139]             192
             ReLU-74         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-75         [-1, 96, 139, 139]               0
           Conv2d-76         [-1, 24, 139, 139]          20,760
      BatchNorm2d-77         [-1, 24, 139, 139]              48
             ReLU-78         [-1, 24, 139, 139]               0
   BN_ReLU_Conv2d-79         [-1, 24, 139, 139]               0
           Conv2d-80         [-1, 96, 139, 139]          18,528
      BatchNorm2d-81         [-1, 96, 139, 139]             192
             ReLU-82         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-83         [-1, 96, 139, 139]               0
        ConvDense-84         [-1, 96, 139, 139]               0
ConvBuildingBlock-85         [-1, 96, 139, 139]               0
         Down2dBB-86         [-1, 96, 139, 139]               0
        Dropout2d-87         [-1, 96, 139, 139]               0
           Conv2d-88          [-1, 192, 69, 69]         166,080
      BatchNorm2d-89          [-1, 192, 69, 69]             384
             ReLU-90          [-1, 192, 69, 69]               0
   BN_ReLU_Conv2d-91          [-1, 192, 69, 69]               0
           Conv2d-92          [-1, 192, 69, 69]          37,056
      BatchNorm2d-93          [-1, 192, 69, 69]             384
             ReLU-94          [-1, 192, 69, 69]               0
   BN_ReLU_Conv2d-95          [-1, 192, 69, 69]               0
           Conv2d-96           [-1, 48, 69, 69]          82,992
      BatchNorm2d-97           [-1, 48, 69, 69]              96
             ReLU-98           [-1, 48, 69, 69]               0
   BN_ReLU_Conv2d-99           [-1, 48, 69, 69]               0
          Conv2d-100          [-1, 192, 69, 69]          46,272
     BatchNorm2d-101          [-1, 192, 69, 69]             384
            ReLU-102          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-103          [-1, 192, 69, 69]               0
          Conv2d-104           [-1, 48, 69, 69]          82,992
     BatchNorm2d-105           [-1, 48, 69, 69]              96
            ReLU-106           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-107           [-1, 48, 69, 69]               0
          Conv2d-108          [-1, 192, 69, 69]          55,488
     BatchNorm2d-109          [-1, 192, 69, 69]             384
            ReLU-110          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-111          [-1, 192, 69, 69]               0
          Conv2d-112           [-1, 48, 69, 69]          82,992
     BatchNorm2d-113           [-1, 48, 69, 69]              96
            ReLU-114           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-115           [-1, 48, 69, 69]               0
          Conv2d-116          [-1, 192, 69, 69]          64,704
     BatchNorm2d-117          [-1, 192, 69, 69]             384
            ReLU-118          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-119          [-1, 192, 69, 69]               0
          Conv2d-120           [-1, 48, 69, 69]          82,992
     BatchNorm2d-121           [-1, 48, 69, 69]              96
            ReLU-122           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-123           [-1, 48, 69, 69]               0
          Conv2d-124          [-1, 192, 69, 69]          73,920
     BatchNorm2d-125          [-1, 192, 69, 69]             384
            ReLU-126          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-127          [-1, 192, 69, 69]               0
       ConvDense-128          [-1, 192, 69, 69]               0
ConvBuildingBlock-129          [-1, 192, 69, 69]               0
        Down2dBB-130          [-1, 192, 69, 69]               0
       Dropout2d-131          [-1, 192, 69, 69]               0
          Conv2d-132          [-1, 384, 33, 33]       1,843,584
     BatchNorm2d-133          [-1, 384, 33, 33]             768
            ReLU-134          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-135          [-1, 384, 33, 33]               0
          Conv2d-136          [-1, 384, 33, 33]         147,840
     BatchNorm2d-137          [-1, 384, 33, 33]             768
            ReLU-138          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-139          [-1, 384, 33, 33]               0
          Conv2d-140           [-1, 96, 33, 33]         331,872
     BatchNorm2d-141           [-1, 96, 33, 33]             192
            ReLU-142           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-143           [-1, 96, 33, 33]               0
          Conv2d-144          [-1, 384, 33, 33]         184,704
     BatchNorm2d-145          [-1, 384, 33, 33]             768
            ReLU-146          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-147          [-1, 384, 33, 33]               0
          Conv2d-148           [-1, 96, 33, 33]         331,872
     BatchNorm2d-149           [-1, 96, 33, 33]             192
            ReLU-150           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-151           [-1, 96, 33, 33]               0
          Conv2d-152          [-1, 384, 33, 33]         221,568
     BatchNorm2d-153          [-1, 384, 33, 33]             768
            ReLU-154          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-155          [-1, 384, 33, 33]               0
          Conv2d-156           [-1, 96, 33, 33]         331,872
     BatchNorm2d-157           [-1, 96, 33, 33]             192
            ReLU-158           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-159           [-1, 96, 33, 33]               0
          Conv2d-160          [-1, 384, 33, 33]         258,432
     BatchNorm2d-161          [-1, 384, 33, 33]             768
            ReLU-162          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-163          [-1, 384, 33, 33]               0
          Conv2d-164           [-1, 96, 33, 33]         331,872
     BatchNorm2d-165           [-1, 96, 33, 33]             192
            ReLU-166           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-167           [-1, 96, 33, 33]               0
          Conv2d-168          [-1, 384, 33, 33]         295,296
     BatchNorm2d-169          [-1, 384, 33, 33]             768
            ReLU-170          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-171          [-1, 384, 33, 33]               0
       ConvDense-172          [-1, 384, 33, 33]               0
ConvBuildingBlock-173          [-1, 384, 33, 33]               0
        Down2dBB-174          [-1, 384, 33, 33]               0
       Dropout2d-175          [-1, 384, 33, 33]               0
          Conv2d-176          [-1, 768, 15, 15]       7,373,568
     BatchNorm2d-177          [-1, 768, 15, 15]           1,536
            ReLU-178          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-179          [-1, 768, 15, 15]               0
          Conv2d-180          [-1, 768, 15, 15]         590,592
     BatchNorm2d-181          [-1, 768, 15, 15]           1,536
            ReLU-182          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-183          [-1, 768, 15, 15]               0
          Conv2d-184          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-185          [-1, 192, 15, 15]             384
            ReLU-186          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-187          [-1, 192, 15, 15]               0
          Conv2d-188          [-1, 768, 15, 15]         738,048
     BatchNorm2d-189          [-1, 768, 15, 15]           1,536
            ReLU-190          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-191          [-1, 768, 15, 15]               0
          Conv2d-192          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-193          [-1, 192, 15, 15]             384
            ReLU-194          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-195          [-1, 192, 15, 15]               0
          Conv2d-196          [-1, 768, 15, 15]         885,504
     BatchNorm2d-197          [-1, 768, 15, 15]           1,536
            ReLU-198          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-199          [-1, 768, 15, 15]               0
          Conv2d-200          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-201          [-1, 192, 15, 15]             384
            ReLU-202          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-203          [-1, 192, 15, 15]               0
          Conv2d-204          [-1, 768, 15, 15]       1,032,960
     BatchNorm2d-205          [-1, 768, 15, 15]           1,536
            ReLU-206          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-207          [-1, 768, 15, 15]               0
          Conv2d-208          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-209          [-1, 192, 15, 15]             384
            ReLU-210          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-211          [-1, 192, 15, 15]               0
          Conv2d-212          [-1, 768, 15, 15]       1,180,416
     BatchNorm2d-213          [-1, 768, 15, 15]           1,536
            ReLU-214          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-215          [-1, 768, 15, 15]               0
       ConvDense-216          [-1, 768, 15, 15]               0
ConvBuildingBlock-217          [-1, 768, 15, 15]               0
        Down2dBB-218          [-1, 768, 15, 15]               0
       Dropout2d-219          [-1, 768, 15, 15]               0
          Conv2d-220           [-1, 1536, 7, 7]      10,618,368
     BatchNorm2d-221           [-1, 1536, 7, 7]           3,072
            ReLU-222           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-223           [-1, 1536, 7, 7]               0
          Conv2d-224           [-1, 1536, 7, 7]       2,360,832
     BatchNorm2d-225           [-1, 1536, 7, 7]           3,072
            ReLU-226           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-227           [-1, 1536, 7, 7]               0
          Conv2d-228            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-229            [-1, 384, 7, 7]             768
            ReLU-230            [-1, 384, 7, 7]               0
  BN_ReLU_Conv2d-231            [-1, 384, 7, 7]               0
          Conv2d-232           [-1, 1536, 7, 7]       2,950,656
     BatchNorm2d-233           [-1, 1536, 7, 7]           3,072
            ReLU-234           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-235           [-1, 1536, 7, 7]               0
          Conv2d-236            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-237            [-1, 384, 7, 7]             768
            ReLU-238            [-1, 384, 7, 7]               0
  BN_ReLU_Conv2d-239            [-1, 384, 7, 7]               0
          Conv2d-240           [-1, 1536, 7, 7]       3,540,480
     BatchNorm2d-241           [-1, 1536, 7, 7]           3,072
            ReLU-242           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-243           [-1, 1536, 7, 7]               0
          Conv2d-244            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-245            [-1, 384, 7, 7]             768
            ReLU-246            [-1, 384, 7, 7]               0
  BN_ReLU_Conv2d-247            [-1, 384, 7, 7]               0
          Conv2d-248           [-1, 1536, 7, 7]       4,130,304
     BatchNorm2d-249           [-1, 1536, 7, 7]           3,072
            ReLU-250           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-251           [-1, 1536, 7, 7]               0
          Conv2d-252            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-253            [-1, 384, 7, 7]             768
            ReLU-254            [-1, 384, 7, 7]               0
  BN_ReLU_Conv2d-255            [-1, 384, 7, 7]               0
          Conv2d-256           [-1, 1536, 7, 7]       4,720,128
     BatchNorm2d-257           [-1, 1536, 7, 7]           3,072
            ReLU-258           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-259           [-1, 1536, 7, 7]               0
       ConvDense-260           [-1, 1536, 7, 7]               0
ConvBuildingBlock-261           [-1, 1536, 7, 7]               0
        Down2dBB-262           [-1, 1536, 7, 7]               0
       Dropout2d-263           [-1, 1536, 7, 7]               0
 ConvTranspose2d-264          [-1, 768, 15, 15]      10,617,600
     BatchNorm2d-265          [-1, 768, 15, 15]           1,536
            ReLU-266          [-1, 768, 15, 15]               0
 BN_ReLU_ConvT2d-267          [-1, 768, 15, 15]               0
          Conv2d-268          [-1, 768, 15, 15]         590,592
     BatchNorm2d-269          [-1, 768, 15, 15]           1,536
            ReLU-270          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-271          [-1, 768, 15, 15]               0
          Conv2d-272          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-273          [-1, 192, 15, 15]             384
            ReLU-274          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-275          [-1, 192, 15, 15]               0
          Conv2d-276          [-1, 768, 15, 15]         738,048
     BatchNorm2d-277          [-1, 768, 15, 15]           1,536
            ReLU-278          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-279          [-1, 768, 15, 15]               0
          Conv2d-280          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-281          [-1, 192, 15, 15]             384
            ReLU-282          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-283          [-1, 192, 15, 15]               0
          Conv2d-284          [-1, 768, 15, 15]         885,504
     BatchNorm2d-285          [-1, 768, 15, 15]           1,536
            ReLU-286          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-287          [-1, 768, 15, 15]               0
          Conv2d-288          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-289          [-1, 192, 15, 15]             384
            ReLU-290          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-291          [-1, 192, 15, 15]               0
          Conv2d-292          [-1, 768, 15, 15]       1,032,960
     BatchNorm2d-293          [-1, 768, 15, 15]           1,536
            ReLU-294          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-295          [-1, 768, 15, 15]               0
          Conv2d-296          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-297          [-1, 192, 15, 15]             384
            ReLU-298          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-299          [-1, 192, 15, 15]               0
          Conv2d-300          [-1, 768, 15, 15]       1,180,416
     BatchNorm2d-301          [-1, 768, 15, 15]           1,536
            ReLU-302          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-303          [-1, 768, 15, 15]               0
       ConvDense-304          [-1, 768, 15, 15]               0
ConvBuildingBlock-305          [-1, 768, 15, 15]               0
          Up2dBB-306          [-1, 768, 15, 15]               0
       Dropout2d-307          [-1, 768, 15, 15]               0
 ConvTranspose2d-308          [-1, 384, 33, 33]      14,745,984
     BatchNorm2d-309          [-1, 384, 33, 33]             768
            ReLU-310          [-1, 384, 33, 33]               0
 BN_ReLU_ConvT2d-311          [-1, 384, 33, 33]               0
          Conv2d-312          [-1, 384, 33, 33]         147,840
     BatchNorm2d-313          [-1, 384, 33, 33]             768
            ReLU-314          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-315          [-1, 384, 33, 33]               0
          Conv2d-316           [-1, 96, 33, 33]         331,872
     BatchNorm2d-317           [-1, 96, 33, 33]             192
            ReLU-318           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-319           [-1, 96, 33, 33]               0
          Conv2d-320          [-1, 384, 33, 33]         184,704
     BatchNorm2d-321          [-1, 384, 33, 33]             768
            ReLU-322          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-323          [-1, 384, 33, 33]               0
          Conv2d-324           [-1, 96, 33, 33]         331,872
     BatchNorm2d-325           [-1, 96, 33, 33]             192
            ReLU-326           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-327           [-1, 96, 33, 33]               0
          Conv2d-328          [-1, 384, 33, 33]         221,568
     BatchNorm2d-329          [-1, 384, 33, 33]             768
            ReLU-330          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-331          [-1, 384, 33, 33]               0
          Conv2d-332           [-1, 96, 33, 33]         331,872
     BatchNorm2d-333           [-1, 96, 33, 33]             192
            ReLU-334           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-335           [-1, 96, 33, 33]               0
          Conv2d-336          [-1, 384, 33, 33]         258,432
     BatchNorm2d-337          [-1, 384, 33, 33]             768
            ReLU-338          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-339          [-1, 384, 33, 33]               0
          Conv2d-340           [-1, 96, 33, 33]         331,872
     BatchNorm2d-341           [-1, 96, 33, 33]             192
            ReLU-342           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-343           [-1, 96, 33, 33]               0
          Conv2d-344          [-1, 384, 33, 33]         295,296
     BatchNorm2d-345          [-1, 384, 33, 33]             768
            ReLU-346          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-347          [-1, 384, 33, 33]               0
       ConvDense-348          [-1, 384, 33, 33]               0
ConvBuildingBlock-349          [-1, 384, 33, 33]               0
          Up2dBB-350          [-1, 384, 33, 33]               0
       Dropout2d-351          [-1, 384, 33, 33]               0
 ConvTranspose2d-352          [-1, 192, 69, 69]       3,686,592
     BatchNorm2d-353          [-1, 192, 69, 69]             384
            ReLU-354          [-1, 192, 69, 69]               0
 BN_ReLU_ConvT2d-355          [-1, 192, 69, 69]               0
          Conv2d-356          [-1, 192, 69, 69]          37,056
     BatchNorm2d-357          [-1, 192, 69, 69]             384
            ReLU-358          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-359          [-1, 192, 69, 69]               0
          Conv2d-360           [-1, 48, 69, 69]          82,992
     BatchNorm2d-361           [-1, 48, 69, 69]              96
            ReLU-362           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-363           [-1, 48, 69, 69]               0
          Conv2d-364          [-1, 192, 69, 69]          46,272
     BatchNorm2d-365          [-1, 192, 69, 69]             384
            ReLU-366          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-367          [-1, 192, 69, 69]               0
          Conv2d-368           [-1, 48, 69, 69]          82,992
     BatchNorm2d-369           [-1, 48, 69, 69]              96
            ReLU-370           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-371           [-1, 48, 69, 69]               0
          Conv2d-372          [-1, 192, 69, 69]          55,488
     BatchNorm2d-373          [-1, 192, 69, 69]             384
            ReLU-374          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-375          [-1, 192, 69, 69]               0
          Conv2d-376           [-1, 48, 69, 69]          82,992
     BatchNorm2d-377           [-1, 48, 69, 69]              96
            ReLU-378           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-379           [-1, 48, 69, 69]               0
          Conv2d-380          [-1, 192, 69, 69]          64,704
     BatchNorm2d-381          [-1, 192, 69, 69]             384
            ReLU-382          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-383          [-1, 192, 69, 69]               0
          Conv2d-384           [-1, 48, 69, 69]          82,992
     BatchNorm2d-385           [-1, 48, 69, 69]              96
            ReLU-386           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-387           [-1, 48, 69, 69]               0
          Conv2d-388          [-1, 192, 69, 69]          73,920
     BatchNorm2d-389          [-1, 192, 69, 69]             384
            ReLU-390          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-391          [-1, 192, 69, 69]               0
       ConvDense-392          [-1, 192, 69, 69]               0
ConvBuildingBlock-393          [-1, 192, 69, 69]               0
          Up2dBB-394          [-1, 192, 69, 69]               0
       Dropout2d-395          [-1, 192, 69, 69]               0
 ConvTranspose2d-396         [-1, 96, 139, 139]         331,872
     BatchNorm2d-397         [-1, 96, 139, 139]             192
            ReLU-398         [-1, 96, 139, 139]               0
 BN_ReLU_ConvT2d-399         [-1, 96, 139, 139]               0
          Conv2d-400         [-1, 96, 139, 139]           9,312
     BatchNorm2d-401         [-1, 96, 139, 139]             192
            ReLU-402         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-403         [-1, 96, 139, 139]               0
          Conv2d-404         [-1, 24, 139, 139]          20,760
     BatchNorm2d-405         [-1, 24, 139, 139]              48
            ReLU-406         [-1, 24, 139, 139]               0
  BN_ReLU_Conv2d-407         [-1, 24, 139, 139]               0
          Conv2d-408         [-1, 96, 139, 139]          11,616
     BatchNorm2d-409         [-1, 96, 139, 139]             192
            ReLU-410         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-411         [-1, 96, 139, 139]               0
          Conv2d-412         [-1, 24, 139, 139]          20,760
     BatchNorm2d-413         [-1, 24, 139, 139]              48
            ReLU-414         [-1, 24, 139, 139]               0
  BN_ReLU_Conv2d-415         [-1, 24, 139, 139]               0
          Conv2d-416         [-1, 96, 139, 139]          13,920
     BatchNorm2d-417         [-1, 96, 139, 139]             192
            ReLU-418         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-419         [-1, 96, 139, 139]               0
          Conv2d-420         [-1, 24, 139, 139]          20,760
     BatchNorm2d-421         [-1, 24, 139, 139]              48
            ReLU-422         [-1, 24, 139, 139]               0
  BN_ReLU_Conv2d-423         [-1, 24, 139, 139]               0
          Conv2d-424         [-1, 96, 139, 139]          16,224
     BatchNorm2d-425         [-1, 96, 139, 139]             192
            ReLU-426         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-427         [-1, 96, 139, 139]               0
          Conv2d-428         [-1, 24, 139, 139]          20,760
     BatchNorm2d-429         [-1, 24, 139, 139]              48
            ReLU-430         [-1, 24, 139, 139]               0
  BN_ReLU_Conv2d-431         [-1, 24, 139, 139]               0
          Conv2d-432         [-1, 96, 139, 139]          18,528
     BatchNorm2d-433         [-1, 96, 139, 139]             192
            ReLU-434         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-435         [-1, 96, 139, 139]               0
       ConvDense-436         [-1, 96, 139, 139]               0
ConvBuildingBlock-437         [-1, 96, 139, 139]               0
          Up2dBB-438         [-1, 96, 139, 139]               0
       Dropout2d-439         [-1, 96, 139, 139]               0
 ConvTranspose2d-440         [-1, 96, 281, 281]         460,896
     BatchNorm2d-441         [-1, 96, 281, 281]             192
            ReLU-442         [-1, 96, 281, 281]               0
 BN_ReLU_ConvT2d-443         [-1, 96, 281, 281]               0
          Conv2d-444         [-1, 96, 281, 281]           9,312
     BatchNorm2d-445         [-1, 96, 281, 281]             192
            ReLU-446         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-447         [-1, 96, 281, 281]               0
          Conv2d-448         [-1, 24, 281, 281]          20,760
     BatchNorm2d-449         [-1, 24, 281, 281]              48
            ReLU-450         [-1, 24, 281, 281]               0
  BN_ReLU_Conv2d-451         [-1, 24, 281, 281]               0
          Conv2d-452         [-1, 96, 281, 281]          11,616
     BatchNorm2d-453         [-1, 96, 281, 281]             192
            ReLU-454         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-455         [-1, 96, 281, 281]               0
          Conv2d-456         [-1, 24, 281, 281]          20,760
     BatchNorm2d-457         [-1, 24, 281, 281]              48
            ReLU-458         [-1, 24, 281, 281]               0
  BN_ReLU_Conv2d-459         [-1, 24, 281, 281]               0
          Conv2d-460         [-1, 96, 281, 281]          13,920
     BatchNorm2d-461         [-1, 96, 281, 281]             192
            ReLU-462         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-463         [-1, 96, 281, 281]               0
          Conv2d-464         [-1, 24, 281, 281]          20,760
     BatchNorm2d-465         [-1, 24, 281, 281]              48
            ReLU-466         [-1, 24, 281, 281]               0
  BN_ReLU_Conv2d-467         [-1, 24, 281, 281]               0
          Conv2d-468         [-1, 96, 281, 281]          16,224
     BatchNorm2d-469         [-1, 96, 281, 281]             192
            ReLU-470         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-471         [-1, 96, 281, 281]               0
          Conv2d-472         [-1, 24, 281, 281]          20,760
     BatchNorm2d-473         [-1, 24, 281, 281]              48
            ReLU-474         [-1, 24, 281, 281]               0
  BN_ReLU_Conv2d-475         [-1, 24, 281, 281]               0
          Conv2d-476         [-1, 96, 281, 281]          18,528
     BatchNorm2d-477         [-1, 96, 281, 281]             192
            ReLU-478         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-479         [-1, 96, 281, 281]               0
       ConvDense-480         [-1, 96, 281, 281]               0
ConvBuildingBlock-481         [-1, 96, 281, 281]               0
          Up2dBB-482         [-1, 96, 281, 281]               0
       Dropout2d-483         [-1, 96, 281, 281]               0
          Conv2d-484        [-1, 192, 281, 281]          37,056
     BatchNorm2d-485        [-1, 192, 281, 281]             384
            ReLU-486        [-1, 192, 281, 281]               0
  BN_ReLU_Conv2d-487        [-1, 192, 281, 281]               0
          Conv2d-488         [-1, 48, 281, 281]          82,992
     BatchNorm2d-489         [-1, 48, 281, 281]              96
            ReLU-490         [-1, 48, 281, 281]               0
  BN_ReLU_Conv2d-491         [-1, 48, 281, 281]               0
          Conv2d-492        [-1, 192, 281, 281]          46,272
     BatchNorm2d-493        [-1, 192, 281, 281]             384
            ReLU-494        [-1, 192, 281, 281]               0
  BN_ReLU_Conv2d-495        [-1, 192, 281, 281]               0
          Conv2d-496         [-1, 48, 281, 281]          82,992
     BatchNorm2d-497         [-1, 48, 281, 281]              96
            ReLU-498         [-1, 48, 281, 281]               0
  BN_ReLU_Conv2d-499         [-1, 48, 281, 281]               0
          Conv2d-500        [-1, 192, 281, 281]          55,488
     BatchNorm2d-501        [-1, 192, 281, 281]             384
            ReLU-502        [-1, 192, 281, 281]               0
  BN_ReLU_Conv2d-503        [-1, 192, 281, 281]               0
          Conv2d-504         [-1, 48, 281, 281]          82,992
     BatchNorm2d-505         [-1, 48, 281, 281]              96
            ReLU-506         [-1, 48, 281, 281]               0
  BN_ReLU_Conv2d-507         [-1, 48, 281, 281]               0
          Conv2d-508        [-1, 192, 281, 281]          64,704
     BatchNorm2d-509        [-1, 192, 281, 281]             384
            ReLU-510        [-1, 192, 281, 281]               0
  BN_ReLU_Conv2d-511        [-1, 192, 281, 281]               0
          Conv2d-512         [-1, 48, 281, 281]          82,992
     BatchNorm2d-513         [-1, 48, 281, 281]              96
            ReLU-514         [-1, 48, 281, 281]               0
  BN_ReLU_Conv2d-515         [-1, 48, 281, 281]               0
          Conv2d-516        [-1, 192, 281, 281]          73,920
     BatchNorm2d-517        [-1, 192, 281, 281]             384
            ReLU-518        [-1, 192, 281, 281]               0
  BN_ReLU_Conv2d-519        [-1, 192, 281, 281]               0
       ConvDense-520        [-1, 192, 281, 281]               0
ConvBuildingBlock-521        [-1, 192, 281, 281]               0
          Conv2d-522          [-1, 2, 281, 281]             386
      ConvOutput-523          [-1, 2, 281, 281]               0
================================================================
Total params: 115,863,650
Trainable params: 115,863,650
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.30
Forward/backward pass size (MB): 8312.13
Params size (MB): 441.98
Estimated Total Size (MB): 8754.42
----------------------------------------------------------------
===================End of Net Architecture =====================

Info: program will use 4 GPUs.
Loss Functions List: FocalCELoss with weight of 1; 	BoundaryLoss with weight of 0; 
Hints: Test Dice_0 is the dice coeff for all non-zero labels
Hints: Test Dice_1 is for primary cancer(green), test Dice_2 is for metastasis(yellow), and test Dice_3 is for invaded lymph node(brown).
Hints: Test TPR_0 is the TPR for all non-zero labels
Hints: Test TPR_1 is for primary cancer(green), TPR_2 is for metastasis(yellow), and TPR_3 is for invaded lymph node(brown).

Epoch 	 TrainingLoss 	 TestLoss 	Dice_0	Dice_1	TPR_0	TPR_1
0 	 0.1067 	 0.1177 	0.171	0.171	1.000	1.000
1 	 0.0854 	 0.0722 	0.299	0.299	0.993	0.993
2 	 0.0748 	 0.0690 	0.440	0.440	0.909	0.909
3 	 0.0686 	 0.0590 	0.401	0.401	0.961	0.961
4 	 0.0648 	 0.0418 	0.483	0.483	0.971	0.971
5 	 0.0621 	 0.0468 	0.479	0.479	0.945	0.945
6 	 0.0628 	 0.0523 	0.422	0.422	0.966	0.966
7 	 0.0670 	 0.0556 	0.506	0.506	0.959	0.959
8 	 0.0648 	 0.0446 	0.453	0.453	0.985	0.985
9 	 0.0623 	 0.0418 	0.548	0.548	0.967	0.967
10 	 0.0587 	 0.0843 	0.575	0.575	0.868	0.868
11 	 0.0625 	 0.2404 	0.506	0.506	0.803	0.803
12 	 0.0680 	 0.0481 	0.507	0.507	0.961	0.961
13 	 0.0611 	 0.0445 	0.489	0.489	0.981	0.981
14 	 0.0601 	 0.0440 	0.550	0.550	0.973	0.973
15 	 0.0528 	 0.0338 	0.525	0.525	0.985	0.985
16 	 0.0527 	 0.0368 	0.479	0.479	0.991	0.991
17 	 0.0561 	 0.0458 	0.527	0.527	0.954	0.954
18 	 0.0534 	 0.0406 	0.588	0.588	0.965	0.965
19 	 0.0549 	 0.0535 	0.450	0.450	0.966	0.966
20 	 0.0592 	 0.0439 	0.546	0.546	0.987	0.987
21 	 0.0533 	 0.0408 	0.469	0.469	0.995	0.995
22 	 0.0554 	 0.0565 	0.552	0.552	0.949	0.949
23 	 0.0580 	 0.0494 	0.550	0.550	0.945	0.945
24 	 0.0617 	 0.0537 	0.610	0.610	0.968	0.968
25 	 0.0565 	 0.0382 	0.541	0.541	0.985	0.985
26 	 0.0523 	 0.0358 	0.554	0.554	0.986	0.986
27 	 0.0538 	 0.0361 	0.486	0.486	0.997	0.997
28 	 0.0533 	 0.0333 	0.529	0.529	0.990	0.990
29 	 0.0452 	 0.0299 	0.564	0.564	0.993	0.993
30 	 0.0504 	 0.0958 	0.603	0.603	0.862	0.862
31 	 0.0505 	 0.0501 	0.611	0.611	0.946	0.946
32 	 0.0537 	 0.0333 	0.615	0.615	0.971	0.971
33 	 0.0528 	 0.0378 	0.586	0.586	0.973	0.973
34 	 0.0573 	 0.0655 	0.582	0.582	0.880	0.880
35 	 0.0530 	 0.0295 	0.550	0.550	0.995	0.995
36 	 0.0543 	 0.0351 	0.511	0.511	0.996	0.996
37 	 0.0539 	 0.0449 	0.623	0.623	0.914	0.914
38 	 0.0438 	 0.0295 	0.580	0.580	0.988	0.988
39 	 0.0457 	 0.0672 	0.630	0.630	0.923	0.923
40 	 0.0502 	 0.1906 	0.621	0.621	0.645	0.645
41 	 0.0445 	 0.0311 	0.520	0.520	0.997	0.997
42 	 0.0567 	 0.0548 	0.591	0.591	0.914	0.914
43 	 0.0526 	 0.0424 	0.644	0.644	0.943	0.943
44 	 0.0538 	 0.0291 	0.565	0.565	0.993	0.993
45 	 0.0460 	 0.0309 	0.602	0.602	0.977	0.977
46 	 0.0465 	 0.0334 	0.464	0.464	0.999	0.999
47 	 0.0489 	 0.0419 	0.611	0.611	0.973	0.973
48 	 0.0531 	 0.0298 	0.546	0.546	0.994	0.994
49 	 0.0491 	 0.0599 	0.644	0.644	0.861	0.861
50 	 0.0485 	 0.0385 	0.599	0.599	0.968	0.968
51 	 0.0438 	 0.0295 	0.581	0.581	0.986	0.986
52 	 0.0505 	 0.0394 	0.642	0.642	0.974	0.974
53 	 0.0508 	 0.0311 	0.518	0.518	0.997	0.997
54 	 0.0454 	 0.0369 	0.653	0.653	0.952	0.952
55 	 0.0370 	 0.0383 	0.665	0.665	0.936	0.936
56 	 0.0551 	 0.0310 	0.505	0.505	0.995	0.995
57 	 0.0511 	 0.0396 	0.519	0.519	0.978	0.978
58 	 0.0488 	 0.0352 	0.505	0.505	0.996	0.996
59 	 0.0485 	 0.0316 	0.588	0.588	0.979	0.979
60 	 0.0438 	 0.0305 	0.576	0.576	0.984	0.984
61 	 0.0466 	 0.0291 	0.623	0.623	0.984	0.984
62 	 0.0487 	 0.0286 	0.534	0.534	0.997	0.997
63 	 0.0446 	 0.0287 	0.579	0.579	0.988	0.988
64 	 0.0448 	 0.1509 	0.648	0.648	0.788	0.788
65 	 0.0464 	 0.0295 	0.568	0.568	0.992	0.992
66 	 0.0459 	 0.0299 	0.613	0.613	0.986	0.986
67 	 0.0416 	 0.0296 	0.586	0.586	0.993	0.993
68 	 0.0504 	 0.0344 	0.512	0.512	0.996	0.996
69 	 0.0497 	 0.0476 	0.647	0.647	0.949	0.949
70 	 0.0446 	 0.0350 	0.609	0.609	0.976	0.976
71 	 0.0442 	 0.0473 	0.677	0.677	0.919	0.919
72 	 0.0519 	 0.0390 	0.536	0.536	0.966	0.966
73 	 0.0456 	 0.0410 	0.664	0.664	0.938	0.938
74 	 0.0451 	 0.0272 	0.586	0.586	0.992	0.992
75 	 0.0394 	 0.0363 	0.632	0.632	0.977	0.977
76 	 0.0483 	 0.0500 	0.591	0.591	0.935	0.935
77 	 0.0465 	 0.0390 	0.614	0.614	0.984	0.984
78 	 0.0447 	 0.0279 	0.563	0.563	0.994	0.994
79 	 0.0446 	 0.0380 	0.539	0.539	0.982	0.982
80 	 0.0443 	 0.0512 	0.663	0.663	0.917	0.917
81 	 0.0482 	 0.0386 	0.641	0.641	0.960	0.960
82 	 0.0501 	 0.0325 	0.574	0.574	0.989	0.989
83 	 0.0460 	 0.0318 	0.646	0.646	0.963	0.963
84 	 0.0502 	 0.0324 	0.588	0.588	0.979	0.979
85 	 0.0452 	 0.0290 	0.532	0.532	0.997	0.997
86 	 0.0500 	 0.0341 	0.589	0.589	0.990	0.990
87 	 0.0466 	 0.0286 	0.561	0.561	0.996	0.996
88 	 0.0545 	 0.0524 	0.626	0.626	0.935	0.935
89 	 0.0442 	 0.0272 	0.630	0.630	0.985	0.985
90 	 0.0441 	 0.0323 	0.620	0.620	0.976	0.976
91 	 0.0490 	 0.0287 	0.573	0.573	0.991	0.991
92 	 0.0443 	 0.0278 	0.561	0.561	0.995	0.995
93 	 0.0446 	 0.0277 	0.580	0.580	0.991	0.991
94 	 0.0436 	 0.0280 	0.556	0.556	0.992	0.992
95 	 0.0429 	 0.0330 	0.611	0.611	0.976	0.976
96 	 0.0427 	 0.0349 	0.660	0.660	0.974	0.974
97 	 0.0474 	 0.0287 	0.550	0.550	0.995	0.995
98 	 0.0512 	 0.0343 	0.574	0.574	0.973	0.973
99 	 0.0404 	 0.0490 	0.667	0.667	0.945	0.945
100 	 0.0431 	 0.0268 	0.580	0.580	0.986	0.986
101 	 0.0439 	 0.0322 	0.608	0.608	0.979	0.979
102 	 0.0454 	 0.0401 	0.630	0.630	0.957	0.957
103 	 0.0471 	 0.0339 	0.653	0.653	0.958	0.958
104 	 0.0473 	 0.0272 	0.585	0.585	0.989	0.989
105 	 0.0480 	 0.0303 	0.516	0.516	0.998	0.998
106 	 0.0439 	 0.0287 	0.576	0.576	0.983	0.983
107 	 0.0471 	 0.0296 	0.512	0.512	0.998	0.998
108 	 0.0436 	 0.0479 	0.680	0.680	0.945	0.945
109 	 0.0404 	 0.0335 	0.634	0.634	0.977	0.977
110 	 0.0350 	 0.0281 	0.598	0.598	0.976	0.976
111 	 0.0482 	 0.0326 	0.628	0.628	0.976	0.976
112 	 0.0458 	 0.0307 	0.645	0.645	0.975	0.975
113 	 0.0380 	 0.0301 	0.576	0.576	0.988	0.988
114 	 0.0437 	 0.0276 	0.573	0.573	0.992	0.992
115 	 0.0351 	 0.0261 	0.551	0.551	0.994	0.994
116 	 0.0471 	 0.0309 	0.536	0.536	0.997	0.997
117 	 0.0408 	 0.0380 	0.664	0.664	0.947	0.947
118 	 0.0359 	 0.0245 	0.572	0.572	0.995	0.995
119 	 0.0419 	 0.0298 	0.615	0.615	0.977	0.977
120 	 0.0426 	 0.0276 	0.619	0.619	0.979	0.979
121 	 0.0337 	 0.0267 	0.619	0.619	0.984	0.984
122 	 0.0392 	 0.0248 	0.550	0.550	0.996	0.996
123 	 0.0383 	 0.0291 	0.568	0.568	0.981	0.981
124 	 0.0397 	 0.0247 	0.617	0.617	0.983	0.983
125 	 0.0445 	 0.0285 	0.567	0.567	0.991	0.991
126 	 0.0399 	 0.0344 	0.679	0.679	0.970	0.970
127 	 0.0392 	 0.0254 	0.567	0.567	0.992	0.992
128 	 0.0433 	 0.0263 	0.577	0.577	0.991	0.991
129 	 0.0394 	 0.0295 	0.645	0.645	0.968	0.968
130 	 0.0398 	 0.0249 	0.572	0.572	0.994	0.994
131 	 0.0386 	 0.0254 	0.595	0.595	0.987	0.987
132 	 0.0395 	 0.0279 	0.656	0.656	0.975	0.975
133 	 0.0438 	 0.0303 	0.602	0.602	0.974	0.974
134 	 0.0405 	 0.0307 	0.659	0.659	0.975	0.975
135 	 0.0434 	 0.0250 	0.597	0.597	0.991	0.991
136 	 0.0433 	 0.0310 	0.642	0.642	0.983	0.983
137 	 0.0408 	 0.0256 	0.621	0.621	0.980	0.980
138 	 0.0387 	 0.0235 	0.616	0.616	0.991	0.991
139 	 0.0427 	 0.0294 	0.619	0.619	0.970	0.970
140 	 0.0351 	 0.0239 	0.553	0.553	0.997	0.997
141 	 0.0458 	 0.0297 	0.473	0.473	1.000	1.000
142 	 0.0420 	 0.0274 	0.582	0.582	0.987	0.987
143 	 0.0415 	 0.0758 	0.671	0.671	0.798	0.798
144 	 0.0418 	 0.0857 	0.696	0.696	0.905	0.905
145 	 0.0386 	 0.0269 	0.596	0.596	0.988	0.988
146 	 0.0366 	 0.0252 	0.572	0.572	0.992	0.992
147 	 0.0447 	 0.0259 	0.538	0.538	0.996	0.996
148 	 0.0431 	 0.0252 	0.612	0.612	0.984	0.984
149 	 0.0336 	 0.0239 	0.606	0.606	0.989	0.989
150 	 0.0414 	 0.0316 	0.623	0.623	0.979	0.979
151 	 0.0386 	 0.0267 	0.612	0.612	0.979	0.979
152 	 0.0394 	 0.0269 	0.634	0.634	0.986	0.986
153 	 0.0347 	 0.0275 	0.667	0.667	0.967	0.967
154 	 0.0391 	 0.0259 	0.654	0.654	0.981	0.981
155 	 0.0408 	 0.0267 	0.516	0.516	0.997	0.997
156 	 0.0377 	 0.0276 	0.644	0.644	0.975	0.975
157 	 0.0374 	 0.0302 	0.653	0.653	0.970	0.970
158 	 0.0363 	 0.0236 	0.568	0.568	0.995	0.995
159 	 0.0388 	 0.0489 	0.639	0.639	0.950	0.950
160 	 0.0411 	 0.0237 	0.588	0.588	0.994	0.994
161 	 0.0369 	 0.0405 	0.528	0.528	0.975	0.975
162 	 0.0369 	 0.0303 	0.676	0.676	0.967	0.967
163 	 0.0332 	 0.0316 	0.698	0.698	0.961	0.961
164 	 0.0422 	 0.0236 	0.596	0.596	0.992	0.992
165 	 0.0379 	 0.0271 	0.624	0.624	0.984	0.984
166 	 0.0402 	 0.0306 	0.633	0.633	0.973	0.973
167 	 0.0385 	 0.0254 	0.536	0.536	0.997	0.997
168 	 0.0354 	 0.0238 	0.584	0.584	0.983	0.983
169 	 0.0325 	 0.0222 	0.608	0.608	0.994	0.994
170 	 0.0342 	 0.0241 	0.603	0.603	0.984	0.984
171 	 0.0436 	 0.0255 	0.552	0.552	0.992	0.992
172 	 0.0404 	 0.0248 	0.562	0.562	0.995	0.995
173 	 0.0397 	 0.0253 	0.501	0.501	0.999	0.999
174 	 0.0353 	 0.0237 	0.597	0.597	0.990	0.990
175 	 0.0351 	 0.0384 	0.680	0.680	0.956	0.956
176 	 0.0396 	 0.0244 	0.529	0.529	0.992	0.992
177 	 0.0400 	 0.0254 	0.545	0.545	0.992	0.992
178 	 0.0369 	 0.0261 	0.557	0.557	0.989	0.989
179 	 0.0348 	 0.0266 	0.607	0.607	0.981	0.981
180 	 0.0337 	 0.0263 	0.628	0.628	0.982	0.982
181 	 0.0375 	 0.0236 	0.597	0.597	0.988	0.988
182 	 0.0308 	 0.0265 	0.637	0.637	0.979	0.979
183 	 0.0341 	 0.0231 	0.554	0.554	0.995	0.995
184 	 0.0346 	 0.0208 	0.593	0.593	0.994	0.994
185 	 0.0373 	 0.0220 	0.597	0.597	0.986	0.986
186 	 0.0338 	 0.0227 	0.594	0.594	0.990	0.990
187 	 0.0319 	 0.0236 	0.610	0.610	0.985	0.985
188 	 0.0407 	 0.0245 	0.584	0.584	0.983	0.983
189 	 0.0443 	 0.0275 	0.597	0.597	0.988	0.988
190 	 0.0350 	 0.0304 	0.689	0.689	0.950	0.950
191 	 0.0345 	 0.1593 	0.661	0.661	0.771	0.771
192 	 0.0365 	 0.0262 	0.636	0.636	0.980	0.980
193 	 0.0407 	 0.0268 	0.663	0.663	0.979	0.979
194 	 0.0346 	 0.0237 	0.635	0.635	0.977	0.977
195 	 0.0333 	 0.0216 	0.595	0.595	0.995	0.995
196 	 0.0362 	 0.0243 	0.507	0.507	0.999	0.999
197 	 0.0383 	 0.0260 	0.630	0.630	0.975	0.975
198 	 0.0331 	 0.0242 	0.641	0.641	0.980	0.980
199 	 0.0327 	 0.0238 	0.686	0.686	0.965	0.965
200 	 0.0387 	 0.0255 	0.479	0.479	1.000	1.000
201 	 0.0357 	 0.0249 	0.623	0.623	0.975	0.975
202 	 0.0337 	 0.0379 	0.704	0.704	0.944	0.944
203 	 0.0374 	 0.0245 	0.519	0.519	1.000	1.000
204 	 0.0365 	 0.0245 	0.583	0.583	0.997	0.997
205 	 0.0414 	 0.0353 	0.643	0.643	0.966	0.966
206 	 0.0319 	 0.0312 	0.649	0.649	0.964	0.964
207 	 0.0363 	 0.0296 	0.693	0.693	0.962	0.962
208 	 0.0354 	 0.0205 	0.559	0.559	0.994	0.994
209 	 0.0342 	 0.0189 	0.589	0.589	0.994	0.994
210 	 0.0368 	 0.0237 	0.593	0.593	0.994	0.994
211 	 0.0324 	 0.0205 	0.611	0.611	0.991	0.991
212 	 0.0319 	 0.0276 	0.675	0.675	0.965	0.965
213 	 0.0350 	 0.0254 	0.644	0.644	0.983	0.983
214 	 0.0323 	 0.0219 	0.605	0.605	0.986	0.986
215 	 0.0335 	 0.0285 	0.551	0.551	0.989	0.989
216 	 0.0342 	 0.0251 	0.649	0.649	0.966	0.966
217 	 0.0326 	 0.0239 	0.591	0.591	0.986	0.986
218 	 0.0374 	 0.0233 	0.594	0.594	0.992	0.992
219 	 0.0357 	 0.0217 	0.604	0.604	0.990	0.990
220 	 0.0313 	 0.0213 	0.567	0.567	0.994	0.994
221 	 0.0315 	 0.0223 	0.593	0.593	0.983	0.983
222 	 0.0326 	 0.0266 	0.628	0.628	0.966	0.966
223 	 0.0383 	 0.0205 	0.584	0.584	0.995	0.995
224 	 0.0390 	 0.0249 	0.581	0.581	0.986	0.986
225 	 0.0426 	 0.0358 	0.645	0.645	0.949	0.949
226 	 0.0352 	 0.0233 	0.679	0.679	0.972	0.972
227 	 0.0293 	 0.0277 	0.695	0.695	0.957	0.957
228 	 0.0298 	 0.0226 	0.668	0.668	0.971	0.971
229 	 0.0293 	 0.0232 	0.626	0.626	0.979	0.979
230 	 0.0361 	 0.0269 	0.634	0.634	0.980	0.980
231 	 0.0351 	 0.0236 	0.630	0.630	0.976	0.976
232 	 0.0357 	 0.0191 	0.591	0.591	0.991	0.991
233 	 0.0305 	 0.0203 	0.601	0.601	0.994	0.994
234 	 0.0299 	 0.0204 	0.584	0.584	0.985	0.985
235 	 0.0325 	 0.0277 	0.686	0.686	0.962	0.962
236 	 0.0296 	 0.0207 	0.648	0.648	0.986	0.986
237 	 0.0343 	 0.0193 	0.563	0.563	0.995	0.995
238 	 0.0293 	 0.0218 	0.682	0.682	0.968	0.968
239 	 0.0307 	 0.0280 	0.665	0.665	0.973	0.973
240 	 0.0321 	 0.0204 	0.515	0.515	0.999	0.999
241 	 0.0334 	 0.0275 	0.583	0.583	0.981	0.981
242 	 0.0291 	 0.0239 	0.682	0.682	0.979	0.979
243 	 0.0302 	 0.0194 	0.628	0.628	0.985	0.985
244 	 0.0320 	 0.0208 	0.620	0.620	0.988	0.988
245 	 0.0282 	 0.0240 	0.608	0.608	0.983	0.983
246 	 0.0263 	 0.0227 	0.639	0.639	0.974	0.974
247 	 0.0292 	 0.0210 	0.644	0.644	0.985	0.985
248 	 0.0285 	 0.0204 	0.652	0.652	0.985	0.985
249 	 0.0277 	 0.0202 	0.592	0.592	0.989	0.989
250 	 0.0237 	 0.0211 	0.671	0.671	0.971	0.971
251 	 0.0303 	 0.0289 	0.635	0.635	0.963	0.963
252 	 0.0273 	 0.0282 	0.675	0.675	0.958	0.958
253 	 0.0312 	 0.0219 	0.660	0.660	0.973	0.973
254 	 0.0315 	 0.0233 	0.628	0.628	0.976	0.976
255 	 0.0273 	 0.0187 	0.616	0.616	0.986	0.986
256 	 0.0310 	 0.0322 	0.625	0.625	0.964	0.964
257 	 0.0288 	 0.0304 	0.652	0.652	0.951	0.951
258 	 0.0270 	 0.0269 	0.646	0.646	0.968	0.968
259 	 0.0321 	 0.0569 	0.575	0.575	0.909	0.909
260 	 0.0319 	 0.0521 	0.572	0.572	0.908	0.908
261 	 0.0304 	 0.0230 	0.598	0.598	0.983	0.983
262 	 0.0274 	 0.0185 	0.591	0.591	0.987	0.987
263 	 0.0281 	 0.0181 	0.651	0.651	0.981	0.981
264 	 0.0270 	 0.0206 	0.654	0.654	0.977	0.977
265 	 0.0275 	 0.0191 	0.656	0.656	0.975	0.975
266 	 0.0248 	 0.1752 	0.650	0.650	0.726	0.726
267 	 0.0292 	 0.0171 	0.614	0.614	0.991	0.991
268 	 0.0275 	 0.0204 	0.620	0.620	0.989	0.989
269 	 0.0277 	 0.0213 	0.627	0.627	0.985	0.985
270 	 0.0285 	 0.0190 	0.625	0.625	0.985	0.985
271 	 0.0259 	 0.0433 	0.662	0.662	0.935	0.935
272 	 0.0306 	 0.0182 	0.640	0.640	0.974	0.974
273 	 0.0317 	 0.0192 	0.571	0.571	0.994	0.994
274 	 0.0256 	 0.0179 	0.633	0.633	0.987	0.987
275 	 0.0278 	 0.0176 	0.604	0.604	0.988	0.988
276 	 0.0280 	 0.0176 	0.624	0.624	0.987	0.987
277 	 0.0253 	 0.0166 	0.622	0.622	0.982	0.982
278 	 0.0311 	 0.0176 	0.614	0.614	0.988	0.988
279 	 0.0246 	 0.0179 	0.648	0.648	0.976	0.976
280 	 0.0266 	 0.0191 	0.616	0.616	0.982	0.982
281 	 0.0313 	 0.0261 	0.668	0.668	0.953	0.953
282 	 0.0257 	 0.0404 	0.624	0.624	0.930	0.930
283 	 0.0304 	 0.0202 	0.637	0.637	0.987	0.987
284 	 0.0241 	 0.0171 	0.573	0.573	0.996	0.996
285 	 0.0261 	 0.0166 	0.601	0.601	0.989	0.989
286 	 0.0264 	 0.0188 	0.642	0.642	0.978	0.978
287 	 0.0273 	 0.0171 	0.567	0.567	0.990	0.990
288 	 0.0251 	 0.0168 	0.637	0.637	0.984	0.984
289 	 0.0265 	 0.0174 	0.655	0.655	0.981	0.981
290 	 0.0272 	 0.0195 	0.658	0.658	0.983	0.983
291 	 0.0265 	 0.0178 	0.606	0.606	0.986	0.986
292 	 0.0269 	 0.0172 	0.638	0.638	0.984	0.984
293 	 0.0274 	 0.0278 	0.670	0.670	0.945	0.945
294 	 0.0278 	 0.0208 	0.632	0.632	0.965	0.965
295 	 0.0256 	 0.0181 	0.634	0.634	0.993	0.993
296 	 0.0252 	 0.0174 	0.585	0.585	0.993	0.993
297 	 0.0222 	 0.0192 	0.644	0.644	0.975	0.975
298 	 0.0261 	 0.0198 	0.615	0.615	0.980	0.980
299 	 0.0284 	 0.0192 	0.663	0.663	0.977	0.977
300 	 0.0266 	 0.0194 	0.628	0.628	0.984	0.984
301 	 0.0280 	 0.0181 	0.603	0.603	0.981	0.981
302 	 0.0309 	 0.0248 	0.564	0.564	0.991	0.991
303 	 0.0281 	 0.0243 	0.720	0.720	0.950	0.950
304 	 0.0234 	 0.0246 	0.707	0.707	0.956	0.956
305 	 0.0284 	 0.0169 	0.594	0.594	0.992	0.992
306 	 0.0258 	 0.0192 	0.680	0.680	0.963	0.963
307 	 0.0252 	 0.0162 	0.661	0.661	0.989	0.989
308 	 0.0274 	 0.0253 	0.684	0.684	0.958	0.958
309 	 0.0254 	 0.0171 	0.634	0.634	0.987	0.987
310 	 0.0312 	 0.0198 	0.595	0.595	0.986	0.986
311 	 0.0265 	 0.0168 	0.567	0.567	0.997	0.997
312 	 0.0253 	 0.0177 	0.664	0.664	0.974	0.974
313 	 0.0234 	 0.0176 	0.636	0.636	0.983	0.983
314 	 0.0285 	 0.0178 	0.597	0.597	0.997	0.997
315 	 0.0283 	 0.0206 	0.634	0.634	0.965	0.965
316 	 0.0274 	 0.0172 	0.624	0.624	0.987	0.987
317 	 0.0268 	 0.0175 	0.630	0.630	0.979	0.979
318 	 0.0218 	 0.0174 	0.628	0.628	0.985	0.985
319 	 0.0235 	 0.0361 	0.724	0.724	0.927	0.927
320 	 0.0282 	 0.0234 	0.646	0.646	0.973	0.973
321 	 0.0291 	 0.0166 	0.616	0.616	0.983	0.983
322 	 0.0239 	 0.0195 	0.653	0.653	0.978	0.978
323 	 0.0243 	 0.0211 	0.655	0.655	0.970	0.970
324 	 0.0249 	 0.0166 	0.606	0.606	0.985	0.985
325 	 0.0249 	 0.0167 	0.609	0.609	0.986	0.986
326 	 0.0230 	 0.0169 	0.640	0.640	0.982	0.982
327 	 0.0214 	 0.0162 	0.639	0.639	0.981	0.981
328 	 0.0231 	 0.0157 	0.626	0.626	0.984	0.984
329 	 0.0250 	 0.0160 	0.644	0.644	0.981	0.981
330 	 0.0229 	 0.0267 	0.648	0.648	0.952	0.952
331 	 0.0238 	 0.0221 	0.647	0.647	0.967	0.967
332 	 0.0261 	 0.0176 	0.655	0.655	0.971	0.971
333 	 0.0270 	 0.0225 	0.638	0.638	0.976	0.976
334 	 0.0288 	 0.0162 	0.601	0.601	0.991	0.991
335 	 0.0252 	 0.0173 	0.589	0.589	0.992	0.992
336 	 0.0241 	 0.0178 	0.636	0.636	0.976	0.976
337 	 0.0252 	 0.0164 	0.617	0.617	0.983	0.983
338 	 0.0245 	 0.0209 	0.650	0.650	0.973	0.973
339 	 0.0192 	 0.0279 	0.724	0.724	0.928	0.928
340 	 0.0258 	 0.0274 	0.635	0.635	0.952	0.952
341 	 0.0235 	 0.0230 	0.660	0.660	0.967	0.967
342 	 0.0241 	 0.0262 	0.625	0.625	0.954	0.954
343 	 0.0201 	 0.0255 	0.639	0.639	0.948	0.948
344 	 0.0224 	 0.0421 	0.568	0.568	0.931	0.931
345 	 0.0220 	 0.0252 	0.614	0.614	0.968	0.968
346 	 0.0209 	 0.0611 	0.578	0.578	0.924	0.924
347 	 0.0193 	 0.0321 	0.625	0.625	0.944	0.944
348 	 0.0222 	 0.0509 	0.604	0.604	0.939	0.939
349 	 0.0279 	 0.1075 	0.491	0.491	0.891	0.891
350 	 0.0237 	 0.0833 	0.563	0.563	0.889	0.889
351 	 0.0231 	 0.0182 	0.655	0.655	0.964	0.964
352 	 0.0227 	 0.0180 	0.618	0.618	0.993	0.993
353 	 0.0244 	 0.0203 	0.677	0.677	0.959	0.959
354 	 0.0253 	 0.0190 	0.653	0.653	0.975	0.975
355 	 0.0227 	 0.0160 	0.614	0.614	0.978	0.978
356 	 0.0247 	 0.0146 	0.627	0.627	0.987	0.987
357 	 0.0211 	 0.0159 	0.594	0.594	0.991	0.991
358 	 0.0227 	 0.0164 	0.587	0.587	0.992	0.992
359 	 0.0241 	 0.0199 	0.664	0.664	0.968	0.968
360 	 0.0216 	 0.0182 	0.658	0.658	0.976	0.976
361 	 0.0218 	 0.0167 	0.670	0.670	0.967	0.967
362 	 0.0240 	 0.0170 	0.665	0.665	0.969	0.969
363 	 0.0191 	 0.0156 	0.618	0.618	0.990	0.990
364 	 0.0204 	 0.0178 	0.670	0.670	0.974	0.974
365 	 0.0206 	 0.0178 	0.667	0.667	0.970	0.970
366 	 0.0206 	 0.0157 	0.590	0.590	0.987	0.987
367 	 0.0218 	 0.0147 	0.551	0.551	0.997	0.997
368 	 0.0203 	 0.0146 	0.612	0.612	0.989	0.989
369 	 0.0208 	 0.0151 	0.617	0.617	0.986	0.986
370 	 0.0175 	 0.0140 	0.640	0.640	0.982	0.982
371 	 0.0191 	 0.0134 	0.635	0.635	0.987	0.987
372 	 0.0203 	 0.0129 	0.619	0.619	0.996	0.996
373 	 0.0204 	 0.0191 	0.651	0.651	0.967	0.967
374 	 0.0212 	 0.0145 	0.593	0.593	0.995	0.995
375 	 0.0187 	 0.0177 	0.633	0.633	0.974	0.974
376 	 0.0208 	 0.0191 	0.650	0.650	0.963	0.963
377 	 0.0201 	 0.0180 	0.642	0.642	0.974	0.974
378 	 0.0198 	 0.0176 	0.580	0.580	0.988	0.988
379 	 0.0206 	 0.0169 	0.618	0.618	0.975	0.975
380 	 0.0200 	 0.0175 	0.666	0.666	0.966	0.966
381 	 0.0185 	 0.0152 	0.592	0.592	0.986	0.986
382 	 0.0229 	 0.0253 	0.635	0.635	0.950	0.950
383 	 0.0180 	 0.0137 	0.682	0.682	0.974	0.974
384 	 0.0219 	 0.0165 	0.645	0.645	0.975	0.975
385 	 0.0191 	 0.0167 	0.675	0.675	0.970	0.970
386 	 0.0197 	 0.0143 	0.642	0.642	0.991	0.991
387 	 0.0192 	 0.0174 	0.678	0.678	0.963	0.963
388 	 0.0225 	 0.0181 	0.642	0.642	0.978	0.978
389 	 0.0252 	 0.0157 	0.621	0.621	0.992	0.992
390 	 0.0221 	 0.0250 	0.670	0.670	0.936	0.936
391 	 0.0159 	 0.0193 	0.685	0.685	0.955	0.955
392 	 0.0175 	 0.0127 	0.631	0.631	0.991	0.991
393 	 0.0191 	 0.0156 	0.669	0.669	0.972	0.972
394 	 0.0153 	 0.0170 	0.681	0.681	0.970	0.970
395 	 0.0195 	 0.0249 	0.639	0.639	0.951	0.951
396 	 0.0191 	 0.0157 	0.655	0.655	0.967	0.967
397 	 0.0161 	 0.0134 	0.656	0.656	0.982	0.982
398 	 0.0166 	 0.0146 	0.678	0.678	0.964	0.964
399 	 0.0182 	 0.0147 	0.633	0.633	0.981	0.981
400 	 0.0174 	 0.0128 	0.659	0.659	0.978	0.978
401 	 0.0210 	 0.0152 	0.604	0.604	0.989	0.989
402 	 0.0176 	 0.0130 	0.611	0.611	0.990	0.990
403 	 0.0184 	 0.0155 	0.661	0.661	0.964	0.964
404 	 0.0166 	 0.0161 	0.644	0.644	0.968	0.968
405 	 0.0152 	 0.0181 	0.715	0.715	0.949	0.949
406 	 0.0197 	 0.0139 	0.668	0.668	0.975	0.975
407 	 0.0203 	 0.0156 	0.671	0.671	0.958	0.958
408 	 0.0217 	 0.0131 	0.655	0.655	0.972	0.972
409 	 0.0192 	 0.0168 	0.637	0.637	0.972	0.972
410 	 0.0207 	 0.0348 	0.623	0.623	0.923	0.923
411 	 0.0176 	 0.0308 	0.641	0.641	0.929	0.929
412 	 0.0212 	 0.0190 	0.646	0.646	0.963	0.963
413 	 0.0198 	 0.0129 	0.609	0.609	0.987	0.987
414 	 0.0169 	 0.0233 	0.665	0.665	0.960	0.960
415 	 0.0157 	 0.0327 	0.645	0.645	0.929	0.929
416 	 0.0169 	 0.0108 	0.687	0.687	0.980	0.980
417 	 0.0172 	 0.0117 	0.616	0.616	0.987	0.987
418 	 0.0152 	 0.0140 	0.663	0.663	0.975	0.975
419 	 0.0170 	 0.0150 	0.659	0.659	0.975	0.975
420 	 0.0153 	 0.0132 	0.665	0.665	0.977	0.977
421 	 0.0154 	 0.0406 	0.643	0.643	0.918	0.918
422 	 0.0173 	 0.0485 	0.641	0.641	0.918	0.918
423 	 0.0170 	 0.0296 	0.647	0.647	0.934	0.934
424 	 0.0188 	 0.0313 	0.667	0.667	0.941	0.941
425 	 0.0157 	 0.0488 	0.637	0.637	0.928	0.928
426 	 0.0165 	 0.0161 	0.681	0.681	0.948	0.948
427 	 0.0151 	 0.0205 	0.675	0.675	0.944	0.944
428 	 0.0159 	 0.0133 	0.690	0.690	0.976	0.976
429 	 0.0205 	 0.0238 	0.614	0.614	0.953	0.953
430 	 0.0154 	 0.0191 	0.687	0.687	0.937	0.937
431 	 0.0155 	 0.0135 	0.642	0.642	0.971	0.971
432 	 0.0193 	 0.0175 	0.613	0.613	0.955	0.955
433 	 0.0192 	 0.0101 	0.572	0.572	0.993	0.993
434 	 0.0162 	 0.0103 	0.639	0.639	0.980	0.980
435 	 0.0173 	 0.0118 	0.651	0.651	0.980	0.980
436 	 0.0165 	 0.0147 	0.664	0.664	0.965	0.965
437 	 0.0176 	 0.0122 	0.666	0.666	0.974	0.974
438 	 0.0162 	 0.0156 	0.640	0.640	0.956	0.956
439 	 0.0175 	 0.0142 	0.667	0.667	0.968	0.968
440 	 0.0167 	 0.0102 	0.610	0.610	0.992	0.992
441 	 0.0114 	 0.0093 	0.704	0.704	0.980	0.980
442 	 0.0150 	 0.0136 	0.659	0.659	0.968	0.968
443 	 0.0166 	 0.0126 	0.645	0.645	0.986	0.986
444 	 0.0158 	 0.0268 	0.564	0.564	0.955	0.955
445 	 0.0161 	 0.0160 	0.681	0.681	0.952	0.952
446 	 0.0188 	 0.0146 	0.662	0.662	0.965	0.965
447 	 0.0152 	 0.0174 	0.670	0.670	0.959	0.959
448 	 0.0184 	 0.0171 	0.664	0.664	0.963	0.963
449 	 0.0154 	 0.0264 	0.652	0.652	0.947	0.947
450 	 0.0158 	 0.0235 	0.639	0.639	0.953	0.953
451 	 0.0138 	 0.0157 	0.624	0.624	0.965	0.965
452 	 0.0158 	 0.0228 	0.667	0.667	0.940	0.940
453 	 0.0139 	 0.0099 	0.690	0.690	0.977	0.977
454 	 0.0161 	 0.0106 	0.631	0.631	0.984	0.984
455 	 0.0145 	 0.0121 	0.684	0.684	0.968	0.968
456 	 0.0150 	 0.0119 	0.690	0.690	0.959	0.959
457 	 0.0146 	 0.0123 	0.668	0.668	0.972	0.972
458 	 0.0136 	 0.0364 	0.628	0.628	0.936	0.936
459 	 0.0143 	 0.0579 	0.653	0.653	0.891	0.891
460 	 0.0178 	 0.0288 	0.646	0.646	0.926	0.926
461 	 0.0142 	 0.0213 	0.687	0.687	0.953	0.953
462 	 0.0148 	 0.0095 	0.695	0.695	0.968	0.968
463 	 0.0118 	 0.0105 	0.656	0.656	0.969	0.969
464 	 0.0157 	 0.0118 	0.690	0.690	0.953	0.953
465 	 0.0136 	 0.0104 	0.632	0.632	0.980	0.980
466 	 0.0137 	 0.0110 	0.625	0.625	0.977	0.977
467 	 0.0122 	 0.0115 	0.689	0.689	0.967	0.967
468 	 0.0108 	 0.0128 	0.695	0.695	0.949	0.949
469 	 0.0140 	 0.0123 	0.613	0.613	0.990	0.990
470 	 0.0128 	 0.0139 	0.677	0.677	0.958	0.958
471 	 0.0129 	 0.0213 	0.676	0.676	0.934	0.934
472 	 0.0126 	 0.0196 	0.650	0.650	0.953	0.953
473 	 0.0120 	 0.0249 	0.672	0.672	0.935	0.935
474 	 0.0141 	 0.0256 	0.667	0.667	0.930	0.930
475 	 0.0120 	 0.0211 	0.715	0.715	0.927	0.927
476 	 0.0132 	 0.0308 	0.682	0.682	0.907	0.907
477 	 0.0129 	 0.0178 	0.684	0.684	0.935	0.935
478 	 0.0118 	 0.0188 	0.695	0.695	0.941	0.941
479 	 0.0121 	 0.0128 	0.691	0.691	0.963	0.963
480 	 0.0123 	 0.0137 	0.671	0.671	0.961	0.961
481 	 0.0111 	 0.0285 	0.680	0.680	0.925	0.925
482 	 0.0123 	 0.0220 	0.675	0.675	0.941	0.941
483 	 0.0118 	 0.0284 	0.671	0.671	0.930	0.930
484 	 0.0123 	 0.0229 	0.643	0.643	0.948	0.948
485 	 0.0096 	 0.0338 	0.679	0.679	0.915	0.915
486 	 0.0138 	 0.0269 	0.651	0.651	0.939	0.939
487 	 0.0107 	 0.0369 	0.679	0.679	0.905	0.905
488 	 0.0111 	 0.0366 	0.648	0.648	0.929	0.929
489 	 0.0113 	 0.0115 	0.661	0.661	0.964	0.964
490 	 0.0090 	 0.0087 	0.683	0.683	0.973	0.973
491 	 0.0128 	 0.0104 	0.682	0.682	0.963	0.963
492 	 0.0108 	 0.0089 	0.669	0.669	0.970	0.970
493 	 0.0111 	 0.0078 	0.647	0.647	0.976	0.976
494 	 0.0120 	 0.0069 	0.621	0.621	0.993	0.993
495 	 0.0099 	 0.0075 	0.690	0.690	0.971	0.971
496 	 0.0100 	 0.0083 	0.697	0.697	0.955	0.955
497 	 0.0116 	 0.0076 	0.671	0.671	0.973	0.973
498 	 0.0091 	 0.0105 	0.709	0.709	0.949	0.949
499 	 0.0129 	 0.0103 	0.672	0.672	0.960	0.960
500 	 0.0106 	 0.0127 	0.700	0.700	0.934	0.934
501 	 0.0095 	 0.0145 	0.682	0.682	0.941	0.941
502 	 0.0099 	 0.0097 	0.710	0.710	0.958	0.958
503 	 0.0121 	 0.0123 	0.668	0.668	0.954	0.954
504 	 0.0098 	 0.0118 	0.661	0.661	0.955	0.955
505 	 0.0098 	 0.0148 	0.678	0.678	0.937	0.937
506 	 0.0092 	 0.0162 	0.679	0.679	0.934	0.934
507 	 0.0089 	 0.0116 	0.685	0.685	0.959	0.959
