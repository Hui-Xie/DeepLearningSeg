Program ID 11121

Program command: 
 ['/home/hxie1/Projects/OvarianCancer/TrainSegV.py', '/home/hxie1/temp_netParameters/OvarianCancer/Label0_1', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainImages', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels', '2D', '0,1']

Major program changes: ConvResidual use BatchNorm-reLU-Conv structure; 
                       ConsDense also use BatchNorm-reLU-Conv structure.
                       Add ConvSegDecreaseChannels
                       and each block has 5 layers, 
                       Residual connect to each Conv, 
                       skip at least 2 layers.
                       output layer use conv with 3*3 fiter instead of 1*1 filter. 
                       use boundary loss with weight 0 at beginning, and pretrain CE loss. 
                       special convInput Module
                       convOutput moudel uses 1*1 conv to tranparent gradident 
                       ConvOutput use residual module.
                       Use Dense Net in the Building Block
                       add ConvBlock to wrapp the ConvResidual and ConvDense
            

Program starting Time: 2019-05-09 10:27:30.136422
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/Label0_1

Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels has 164 segmented slices for remained labels [0, 1].
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/testLabels has 31 segmented slices for remained labels [0, 1].
Info: program uses 2D input.
TrainData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

TestData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

Network trains from scratch.
Network has total 343919234 parameters.
Info: network dropout rate = 0.3
Infor: Cross Entropy Weight: [1.0260619741432382, 39.37007874015748]

====================Net Architecture===========================
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1        [-1, 128, 281, 281]           1,280
       BatchNorm2d-2        [-1, 128, 281, 281]             256
              ReLU-3        [-1, 128, 281, 281]               0
            Conv2d-4        [-1, 128, 281, 281]         147,584
       BatchNorm2d-5        [-1, 128, 281, 281]             256
              ReLU-6        [-1, 128, 281, 281]               0
            Conv2d-7        [-1, 128, 281, 281]         147,584
       BatchNorm2d-8        [-1, 128, 281, 281]             256
              ReLU-9        [-1, 128, 281, 281]               0
           Conv2d-10        [-1, 128, 281, 281]         147,584
      BatchNorm2d-11        [-1, 128, 281, 281]             256
             ReLU-12        [-1, 128, 281, 281]               0
           Conv2d-13        [-1, 128, 281, 281]         147,584
     ConvResidual-14        [-1, 128, 281, 281]               0
        ConvBlock-15        [-1, 128, 281, 281]               0
        ConvInput-16        [-1, 128, 281, 281]               0
      BatchNorm2d-17        [-1, 128, 281, 281]             256
           Conv2d-18        [-1, 128, 139, 139]         409,728
      BatchNorm2d-19        [-1, 128, 139, 139]             256
             ReLU-20        [-1, 128, 139, 139]               0
           Conv2d-21        [-1, 128, 139, 139]         147,584
      BatchNorm2d-22        [-1, 128, 139, 139]             256
             ReLU-23        [-1, 128, 139, 139]               0
           Conv2d-24        [-1, 128, 139, 139]         147,584
      BatchNorm2d-25        [-1, 128, 139, 139]             256
             ReLU-26        [-1, 128, 139, 139]               0
           Conv2d-27        [-1, 128, 139, 139]         147,584
      BatchNorm2d-28        [-1, 128, 139, 139]             256
             ReLU-29        [-1, 128, 139, 139]               0
           Conv2d-30        [-1, 128, 139, 139]         147,584
     ConvResidual-31        [-1, 128, 139, 139]               0
        ConvBlock-32        [-1, 128, 139, 139]               0
         Down2dBB-33        [-1, 128, 139, 139]               0
        Dropout2d-34        [-1, 128, 139, 139]               0
      BatchNorm2d-35        [-1, 128, 139, 139]             256
           Conv2d-36          [-1, 256, 69, 69]         295,168
      BatchNorm2d-37          [-1, 256, 69, 69]             512
             ReLU-38          [-1, 256, 69, 69]               0
           Conv2d-39          [-1, 256, 69, 69]         590,080
      BatchNorm2d-40          [-1, 256, 69, 69]             512
             ReLU-41          [-1, 256, 69, 69]               0
           Conv2d-42          [-1, 256, 69, 69]         590,080
      BatchNorm2d-43          [-1, 256, 69, 69]             512
             ReLU-44          [-1, 256, 69, 69]               0
           Conv2d-45          [-1, 256, 69, 69]         590,080
      BatchNorm2d-46          [-1, 256, 69, 69]             512
             ReLU-47          [-1, 256, 69, 69]               0
           Conv2d-48          [-1, 256, 69, 69]         590,080
     ConvResidual-49          [-1, 256, 69, 69]               0
        ConvBlock-50          [-1, 256, 69, 69]               0
         Down2dBB-51          [-1, 256, 69, 69]               0
        Dropout2d-52          [-1, 256, 69, 69]               0
      BatchNorm2d-53          [-1, 256, 69, 69]             512
           Conv2d-54          [-1, 512, 33, 33]       3,277,312
      BatchNorm2d-55          [-1, 512, 33, 33]           1,024
             ReLU-56          [-1, 512, 33, 33]               0
           Conv2d-57          [-1, 512, 33, 33]       2,359,808
      BatchNorm2d-58          [-1, 512, 33, 33]           1,024
             ReLU-59          [-1, 512, 33, 33]               0
           Conv2d-60          [-1, 512, 33, 33]       2,359,808
      BatchNorm2d-61          [-1, 512, 33, 33]           1,024
             ReLU-62          [-1, 512, 33, 33]               0
           Conv2d-63          [-1, 512, 33, 33]       2,359,808
      BatchNorm2d-64          [-1, 512, 33, 33]           1,024
             ReLU-65          [-1, 512, 33, 33]               0
           Conv2d-66          [-1, 512, 33, 33]       2,359,808
     ConvResidual-67          [-1, 512, 33, 33]               0
        ConvBlock-68          [-1, 512, 33, 33]               0
         Down2dBB-69          [-1, 512, 33, 33]               0
        Dropout2d-70          [-1, 512, 33, 33]               0
      BatchNorm2d-71          [-1, 512, 33, 33]           1,024
           Conv2d-72         [-1, 1024, 15, 15]      13,108,224
      BatchNorm2d-73         [-1, 1024, 15, 15]           2,048
             ReLU-74         [-1, 1024, 15, 15]               0
           Conv2d-75         [-1, 1024, 15, 15]       9,438,208
      BatchNorm2d-76         [-1, 1024, 15, 15]           2,048
             ReLU-77         [-1, 1024, 15, 15]               0
           Conv2d-78         [-1, 1024, 15, 15]       9,438,208
      BatchNorm2d-79         [-1, 1024, 15, 15]           2,048
             ReLU-80         [-1, 1024, 15, 15]               0
           Conv2d-81         [-1, 1024, 15, 15]       9,438,208
      BatchNorm2d-82         [-1, 1024, 15, 15]           2,048
             ReLU-83         [-1, 1024, 15, 15]               0
           Conv2d-84         [-1, 1024, 15, 15]       9,438,208
     ConvResidual-85         [-1, 1024, 15, 15]               0
        ConvBlock-86         [-1, 1024, 15, 15]               0
         Down2dBB-87         [-1, 1024, 15, 15]               0
        Dropout2d-88         [-1, 1024, 15, 15]               0
      BatchNorm2d-89         [-1, 1024, 15, 15]           2,048
           Conv2d-90           [-1, 2048, 7, 7]      18,876,416
      BatchNorm2d-91           [-1, 2048, 7, 7]           4,096
             ReLU-92           [-1, 2048, 7, 7]               0
           Conv2d-93           [-1, 2048, 7, 7]      37,750,784
      BatchNorm2d-94           [-1, 2048, 7, 7]           4,096
             ReLU-95           [-1, 2048, 7, 7]               0
           Conv2d-96           [-1, 2048, 7, 7]      37,750,784
      BatchNorm2d-97           [-1, 2048, 7, 7]           4,096
             ReLU-98           [-1, 2048, 7, 7]               0
           Conv2d-99           [-1, 2048, 7, 7]      37,750,784
     BatchNorm2d-100           [-1, 2048, 7, 7]           4,096
            ReLU-101           [-1, 2048, 7, 7]               0
          Conv2d-102           [-1, 2048, 7, 7]      37,750,784
    ConvResidual-103           [-1, 2048, 7, 7]               0
       ConvBlock-104           [-1, 2048, 7, 7]               0
        Down2dBB-105           [-1, 2048, 7, 7]               0
       Dropout2d-106           [-1, 2048, 7, 7]               0
     BatchNorm2d-107           [-1, 2048, 7, 7]           4,096
 ConvTranspose2d-108         [-1, 1024, 15, 15]      18,875,392
     BatchNorm2d-109         [-1, 1024, 15, 15]           2,048
            ReLU-110         [-1, 1024, 15, 15]               0
          Conv2d-111         [-1, 1024, 15, 15]       9,438,208
     BatchNorm2d-112         [-1, 1024, 15, 15]           2,048
            ReLU-113         [-1, 1024, 15, 15]               0
          Conv2d-114         [-1, 1024, 15, 15]       9,438,208
     BatchNorm2d-115         [-1, 1024, 15, 15]           2,048
            ReLU-116         [-1, 1024, 15, 15]               0
          Conv2d-117         [-1, 1024, 15, 15]       9,438,208
     BatchNorm2d-118         [-1, 1024, 15, 15]           2,048
            ReLU-119         [-1, 1024, 15, 15]               0
          Conv2d-120         [-1, 1024, 15, 15]       9,438,208
    ConvResidual-121         [-1, 1024, 15, 15]               0
       ConvBlock-122         [-1, 1024, 15, 15]               0
          Up2dBB-123         [-1, 1024, 15, 15]               0
       Dropout2d-124         [-1, 1024, 15, 15]               0
     BatchNorm2d-125         [-1, 2048, 15, 15]           4,096
 ConvTranspose2d-126          [-1, 512, 33, 33]      26,214,912
     BatchNorm2d-127          [-1, 512, 33, 33]           1,024
            ReLU-128          [-1, 512, 33, 33]               0
          Conv2d-129          [-1, 512, 33, 33]       2,359,808
     BatchNorm2d-130          [-1, 512, 33, 33]           1,024
            ReLU-131          [-1, 512, 33, 33]               0
          Conv2d-132          [-1, 512, 33, 33]       2,359,808
     BatchNorm2d-133          [-1, 512, 33, 33]           1,024
            ReLU-134          [-1, 512, 33, 33]               0
          Conv2d-135          [-1, 512, 33, 33]       2,359,808
     BatchNorm2d-136          [-1, 512, 33, 33]           1,024
            ReLU-137          [-1, 512, 33, 33]               0
          Conv2d-138          [-1, 512, 33, 33]       2,359,808
    ConvResidual-139          [-1, 512, 33, 33]               0
       ConvBlock-140          [-1, 512, 33, 33]               0
          Up2dBB-141          [-1, 512, 33, 33]               0
       Dropout2d-142          [-1, 512, 33, 33]               0
     BatchNorm2d-143         [-1, 1024, 33, 33]           2,048
 ConvTranspose2d-144          [-1, 256, 69, 69]       6,553,856
     BatchNorm2d-145          [-1, 256, 69, 69]             512
            ReLU-146          [-1, 256, 69, 69]               0
          Conv2d-147          [-1, 256, 69, 69]         590,080
     BatchNorm2d-148          [-1, 256, 69, 69]             512
            ReLU-149          [-1, 256, 69, 69]               0
          Conv2d-150          [-1, 256, 69, 69]         590,080
     BatchNorm2d-151          [-1, 256, 69, 69]             512
            ReLU-152          [-1, 256, 69, 69]               0
          Conv2d-153          [-1, 256, 69, 69]         590,080
     BatchNorm2d-154          [-1, 256, 69, 69]             512
            ReLU-155          [-1, 256, 69, 69]               0
          Conv2d-156          [-1, 256, 69, 69]         590,080
    ConvResidual-157          [-1, 256, 69, 69]               0
       ConvBlock-158          [-1, 256, 69, 69]               0
          Up2dBB-159          [-1, 256, 69, 69]               0
       Dropout2d-160          [-1, 256, 69, 69]               0
     BatchNorm2d-161          [-1, 512, 69, 69]           1,024
 ConvTranspose2d-162        [-1, 128, 139, 139]         589,952
     BatchNorm2d-163        [-1, 128, 139, 139]             256
            ReLU-164        [-1, 128, 139, 139]               0
          Conv2d-165        [-1, 128, 139, 139]         147,584
     BatchNorm2d-166        [-1, 128, 139, 139]             256
            ReLU-167        [-1, 128, 139, 139]               0
          Conv2d-168        [-1, 128, 139, 139]         147,584
     BatchNorm2d-169        [-1, 128, 139, 139]             256
            ReLU-170        [-1, 128, 139, 139]               0
          Conv2d-171        [-1, 128, 139, 139]         147,584
     BatchNorm2d-172        [-1, 128, 139, 139]             256
            ReLU-173        [-1, 128, 139, 139]               0
          Conv2d-174        [-1, 128, 139, 139]         147,584
    ConvResidual-175        [-1, 128, 139, 139]               0
       ConvBlock-176        [-1, 128, 139, 139]               0
          Up2dBB-177        [-1, 128, 139, 139]               0
       Dropout2d-178        [-1, 128, 139, 139]               0
     BatchNorm2d-179        [-1, 256, 139, 139]             512
 ConvTranspose2d-180        [-1, 128, 281, 281]         819,328
     BatchNorm2d-181        [-1, 128, 281, 281]             256
            ReLU-182        [-1, 128, 281, 281]               0
          Conv2d-183        [-1, 128, 281, 281]         147,584
     BatchNorm2d-184        [-1, 128, 281, 281]             256
            ReLU-185        [-1, 128, 281, 281]               0
          Conv2d-186        [-1, 128, 281, 281]         147,584
     BatchNorm2d-187        [-1, 128, 281, 281]             256
            ReLU-188        [-1, 128, 281, 281]               0
          Conv2d-189        [-1, 128, 281, 281]         147,584
     BatchNorm2d-190        [-1, 128, 281, 281]             256
            ReLU-191        [-1, 128, 281, 281]               0
          Conv2d-192        [-1, 128, 281, 281]         147,584
    ConvResidual-193        [-1, 128, 281, 281]               0
       ConvBlock-194        [-1, 128, 281, 281]               0
          Up2dBB-195        [-1, 128, 281, 281]               0
       Dropout2d-196        [-1, 128, 281, 281]               0
     BatchNorm2d-197        [-1, 256, 281, 281]             512
            ReLU-198        [-1, 256, 281, 281]               0
          Conv2d-199        [-1, 256, 281, 281]         590,080
     BatchNorm2d-200        [-1, 256, 281, 281]             512
            ReLU-201        [-1, 256, 281, 281]               0
          Conv2d-202        [-1, 256, 281, 281]         590,080
     BatchNorm2d-203        [-1, 256, 281, 281]             512
            ReLU-204        [-1, 256, 281, 281]               0
          Conv2d-205        [-1, 256, 281, 281]         590,080
     BatchNorm2d-206        [-1, 256, 281, 281]             512
            ReLU-207        [-1, 256, 281, 281]               0
          Conv2d-208        [-1, 256, 281, 281]         590,080
    ConvResidual-209        [-1, 256, 281, 281]               0
       ConvBlock-210        [-1, 256, 281, 281]               0
     BatchNorm2d-211        [-1, 256, 281, 281]             512
          Conv2d-212          [-1, 2, 281, 281]             514
      ConvOutput-213          [-1, 2, 281, 281]               0
================================================================
Total params: 343,919,234
Trainable params: 343,919,234
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.30
Forward/backward pass size (MB): 6215.87
Params size (MB): 1311.95
Estimated Total Size (MB): 7528.11
----------------------------------------------------------------
===================End of Net Architecture =====================

Info: program will use 4 GPUs.
Loss Functions List: FocalCELoss with weight of 1; 	BoundaryLoss with weight of 0; 
Hints: Test Dice_0 is the dice coeff for all non-zero labels
Hints: Test Dice_1 is for primary cancer(green), test Dice_2 is for metastasis(yellow), and test Dice_3 is for invaded lymph node(brown).
Hints: Test TPR_0 is the TPR for all non-zero labels
Hints: Test TPR_1 is for primary cancer(green), TPR_2 is for metastasis(yellow), and TPR_3 is for invaded lymph node(brown).

Epoch 	 TrainingLoss 	 TestLoss 	Dice_0	Dice_1	TPR_0	TPR_1
0 	 0.1231 	 0.0826 	0.297	0.297	0.992	0.992
1 	 0.0874 	 0.1473 	0.332	0.332	0.908	0.908
2 	 0.0791 	 0.0717 	0.363	0.363	0.933	0.933
3 	 0.0762 	 0.0677 	0.373	0.373	0.934	0.934
4 	 0.0671 	 0.1525 	0.281	0.281	1.000	1.000
5 	 0.0595 	 0.0884 	0.539	0.539	0.671	0.671
