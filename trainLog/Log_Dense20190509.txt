Program ID 25077

Program command: 
 ['/home/hxie1/Projects/OvarianCancer/TrainSegV.py', '/home/hxie1/temp_netParameters/OvarianCancer/Label0_1', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainImages', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels', '2D', '0,1']

Major program changes: ConvResidual use BatchNorm-reLU-Conv structure; 
                       ConsDense also use BatchNorm-reLU-Conv structure.
                       Add ConvSegDecreaseChannels
                       and each block has 5 layers, 
                       Residual connect to each Conv, 
                       skip at least 2 layers.
                       output layer use conv with 3*3 fiter instead of 1*1 filter. 
                       use boundary loss with weight 0 at beginning, and pretrain CE loss. 
                       special convInput Module
                       convOutput moudel uses 1*1 conv to tranparent gradident 
                       ConvOutput use residual module.
                       Use Dense Net in the Building Block
                       add ConvBlock to wrapp the ConvResidual and ConvDense
            

Program starting Time: 2019-05-09 12:13:27.308353
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/Label0_1

Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels has 164 segmented slices for remained labels [0, 1].
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/testLabels has 31 segmented slices for remained labels [0, 1].
Info: program uses 2D input.
TrainData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

TestData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

Network trains from scratch.
Network has total 184698754 parameters.
Info: network dropout rate = 0.3
Infor: Cross Entropy Weight: [1.0260619741432382, 39.37007874015748]

====================Net Architecture===========================
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1        [-1, 128, 281, 281]           1,280
       BatchNorm2d-2        [-1, 128, 281, 281]             256
              ReLU-3        [-1, 128, 281, 281]               0
            Conv2d-4        [-1, 128, 281, 281]          16,512
       BatchNorm2d-5        [-1, 128, 281, 281]             256
              ReLU-6        [-1, 128, 281, 281]               0
            Conv2d-7         [-1, 64, 281, 281]          73,792
       BatchNorm2d-8        [-1, 192, 281, 281]             384
              ReLU-9        [-1, 192, 281, 281]               0
           Conv2d-10        [-1, 128, 281, 281]          24,704
      BatchNorm2d-11        [-1, 128, 281, 281]             256
             ReLU-12        [-1, 128, 281, 281]               0
           Conv2d-13         [-1, 64, 281, 281]          73,792
      BatchNorm2d-14        [-1, 256, 281, 281]             512
             ReLU-15        [-1, 256, 281, 281]               0
           Conv2d-16        [-1, 128, 281, 281]          32,896
        ConvDense-17        [-1, 128, 281, 281]               0
        ConvBlock-18        [-1, 128, 281, 281]               0
        ConvInput-19        [-1, 128, 281, 281]               0
      BatchNorm2d-20        [-1, 128, 281, 281]             256
           Conv2d-21        [-1, 128, 139, 139]         409,728
      BatchNorm2d-22        [-1, 128, 139, 139]             256
             ReLU-23        [-1, 128, 139, 139]               0
           Conv2d-24        [-1, 128, 139, 139]          16,512
      BatchNorm2d-25        [-1, 128, 139, 139]             256
             ReLU-26        [-1, 128, 139, 139]               0
           Conv2d-27         [-1, 64, 139, 139]          73,792
      BatchNorm2d-28        [-1, 192, 139, 139]             384
             ReLU-29        [-1, 192, 139, 139]               0
           Conv2d-30        [-1, 128, 139, 139]          24,704
      BatchNorm2d-31        [-1, 128, 139, 139]             256
             ReLU-32        [-1, 128, 139, 139]               0
           Conv2d-33         [-1, 64, 139, 139]          73,792
      BatchNorm2d-34        [-1, 256, 139, 139]             512
             ReLU-35        [-1, 256, 139, 139]               0
           Conv2d-36        [-1, 128, 139, 139]          32,896
        ConvDense-37        [-1, 128, 139, 139]               0
        ConvBlock-38        [-1, 128, 139, 139]               0
         Down2dBB-39        [-1, 128, 139, 139]               0
        Dropout2d-40        [-1, 128, 139, 139]               0
      BatchNorm2d-41        [-1, 128, 139, 139]             256
           Conv2d-42          [-1, 256, 69, 69]         295,168
      BatchNorm2d-43          [-1, 256, 69, 69]             512
             ReLU-44          [-1, 256, 69, 69]               0
           Conv2d-45          [-1, 256, 69, 69]          65,792
      BatchNorm2d-46          [-1, 256, 69, 69]             512
             ReLU-47          [-1, 256, 69, 69]               0
           Conv2d-48          [-1, 128, 69, 69]         295,040
      BatchNorm2d-49          [-1, 384, 69, 69]             768
             ReLU-50          [-1, 384, 69, 69]               0
           Conv2d-51          [-1, 256, 69, 69]          98,560
      BatchNorm2d-52          [-1, 256, 69, 69]             512
             ReLU-53          [-1, 256, 69, 69]               0
           Conv2d-54          [-1, 128, 69, 69]         295,040
      BatchNorm2d-55          [-1, 512, 69, 69]           1,024
             ReLU-56          [-1, 512, 69, 69]               0
           Conv2d-57          [-1, 256, 69, 69]         131,328
        ConvDense-58          [-1, 256, 69, 69]               0
        ConvBlock-59          [-1, 256, 69, 69]               0
         Down2dBB-60          [-1, 256, 69, 69]               0
        Dropout2d-61          [-1, 256, 69, 69]               0
      BatchNorm2d-62          [-1, 256, 69, 69]             512
           Conv2d-63          [-1, 512, 33, 33]       3,277,312
      BatchNorm2d-64          [-1, 512, 33, 33]           1,024
             ReLU-65          [-1, 512, 33, 33]               0
           Conv2d-66          [-1, 512, 33, 33]         262,656
      BatchNorm2d-67          [-1, 512, 33, 33]           1,024
             ReLU-68          [-1, 512, 33, 33]               0
           Conv2d-69          [-1, 256, 33, 33]       1,179,904
      BatchNorm2d-70          [-1, 768, 33, 33]           1,536
             ReLU-71          [-1, 768, 33, 33]               0
           Conv2d-72          [-1, 512, 33, 33]         393,728
      BatchNorm2d-73          [-1, 512, 33, 33]           1,024
             ReLU-74          [-1, 512, 33, 33]               0
           Conv2d-75          [-1, 256, 33, 33]       1,179,904
      BatchNorm2d-76         [-1, 1024, 33, 33]           2,048
             ReLU-77         [-1, 1024, 33, 33]               0
           Conv2d-78          [-1, 512, 33, 33]         524,800
        ConvDense-79          [-1, 512, 33, 33]               0
        ConvBlock-80          [-1, 512, 33, 33]               0
         Down2dBB-81          [-1, 512, 33, 33]               0
        Dropout2d-82          [-1, 512, 33, 33]               0
      BatchNorm2d-83          [-1, 512, 33, 33]           1,024
           Conv2d-84         [-1, 1024, 15, 15]      13,108,224
      BatchNorm2d-85         [-1, 1024, 15, 15]           2,048
             ReLU-86         [-1, 1024, 15, 15]               0
           Conv2d-87         [-1, 1024, 15, 15]       1,049,600
      BatchNorm2d-88         [-1, 1024, 15, 15]           2,048
             ReLU-89         [-1, 1024, 15, 15]               0
           Conv2d-90          [-1, 512, 15, 15]       4,719,104
      BatchNorm2d-91         [-1, 1536, 15, 15]           3,072
             ReLU-92         [-1, 1536, 15, 15]               0
           Conv2d-93         [-1, 1024, 15, 15]       1,573,888
      BatchNorm2d-94         [-1, 1024, 15, 15]           2,048
             ReLU-95         [-1, 1024, 15, 15]               0
           Conv2d-96          [-1, 512, 15, 15]       4,719,104
      BatchNorm2d-97         [-1, 2048, 15, 15]           4,096
             ReLU-98         [-1, 2048, 15, 15]               0
           Conv2d-99         [-1, 1024, 15, 15]       2,098,176
       ConvDense-100         [-1, 1024, 15, 15]               0
       ConvBlock-101         [-1, 1024, 15, 15]               0
        Down2dBB-102         [-1, 1024, 15, 15]               0
       Dropout2d-103         [-1, 1024, 15, 15]               0
     BatchNorm2d-104         [-1, 1024, 15, 15]           2,048
          Conv2d-105           [-1, 2048, 7, 7]      18,876,416
     BatchNorm2d-106           [-1, 2048, 7, 7]           4,096
            ReLU-107           [-1, 2048, 7, 7]               0
          Conv2d-108           [-1, 2048, 7, 7]       4,196,352
     BatchNorm2d-109           [-1, 2048, 7, 7]           4,096
            ReLU-110           [-1, 2048, 7, 7]               0
          Conv2d-111           [-1, 1024, 7, 7]      18,875,392
     BatchNorm2d-112           [-1, 3072, 7, 7]           6,144
            ReLU-113           [-1, 3072, 7, 7]               0
          Conv2d-114           [-1, 2048, 7, 7]       6,293,504
     BatchNorm2d-115           [-1, 2048, 7, 7]           4,096
            ReLU-116           [-1, 2048, 7, 7]               0
          Conv2d-117           [-1, 1024, 7, 7]      18,875,392
     BatchNorm2d-118           [-1, 4096, 7, 7]           8,192
            ReLU-119           [-1, 4096, 7, 7]               0
          Conv2d-120           [-1, 2048, 7, 7]       8,390,656
       ConvDense-121           [-1, 2048, 7, 7]               0
       ConvBlock-122           [-1, 2048, 7, 7]               0
        Down2dBB-123           [-1, 2048, 7, 7]               0
       Dropout2d-124           [-1, 2048, 7, 7]               0
     BatchNorm2d-125           [-1, 2048, 7, 7]           4,096
 ConvTranspose2d-126         [-1, 1024, 15, 15]      18,875,392
     BatchNorm2d-127         [-1, 1024, 15, 15]           2,048
            ReLU-128         [-1, 1024, 15, 15]               0
          Conv2d-129         [-1, 1024, 15, 15]       1,049,600
     BatchNorm2d-130         [-1, 1024, 15, 15]           2,048
            ReLU-131         [-1, 1024, 15, 15]               0
          Conv2d-132          [-1, 512, 15, 15]       4,719,104
     BatchNorm2d-133         [-1, 1536, 15, 15]           3,072
            ReLU-134         [-1, 1536, 15, 15]               0
          Conv2d-135         [-1, 1024, 15, 15]       1,573,888
     BatchNorm2d-136         [-1, 1024, 15, 15]           2,048
            ReLU-137         [-1, 1024, 15, 15]               0
          Conv2d-138          [-1, 512, 15, 15]       4,719,104
     BatchNorm2d-139         [-1, 2048, 15, 15]           4,096
            ReLU-140         [-1, 2048, 15, 15]               0
          Conv2d-141         [-1, 1024, 15, 15]       2,098,176
       ConvDense-142         [-1, 1024, 15, 15]               0
       ConvBlock-143         [-1, 1024, 15, 15]               0
          Up2dBB-144         [-1, 1024, 15, 15]               0
       Dropout2d-145         [-1, 1024, 15, 15]               0
     BatchNorm2d-146         [-1, 2048, 15, 15]           4,096
 ConvTranspose2d-147          [-1, 512, 33, 33]      26,214,912
     BatchNorm2d-148          [-1, 512, 33, 33]           1,024
            ReLU-149          [-1, 512, 33, 33]               0
          Conv2d-150          [-1, 512, 33, 33]         262,656
     BatchNorm2d-151          [-1, 512, 33, 33]           1,024
            ReLU-152          [-1, 512, 33, 33]               0
          Conv2d-153          [-1, 256, 33, 33]       1,179,904
     BatchNorm2d-154          [-1, 768, 33, 33]           1,536
            ReLU-155          [-1, 768, 33, 33]               0
          Conv2d-156          [-1, 512, 33, 33]         393,728
     BatchNorm2d-157          [-1, 512, 33, 33]           1,024
            ReLU-158          [-1, 512, 33, 33]               0
          Conv2d-159          [-1, 256, 33, 33]       1,179,904
     BatchNorm2d-160         [-1, 1024, 33, 33]           2,048
            ReLU-161         [-1, 1024, 33, 33]               0
          Conv2d-162          [-1, 512, 33, 33]         524,800
       ConvDense-163          [-1, 512, 33, 33]               0
       ConvBlock-164          [-1, 512, 33, 33]               0
          Up2dBB-165          [-1, 512, 33, 33]               0
       Dropout2d-166          [-1, 512, 33, 33]               0
     BatchNorm2d-167         [-1, 1024, 33, 33]           2,048
 ConvTranspose2d-168          [-1, 256, 69, 69]       6,553,856
     BatchNorm2d-169          [-1, 256, 69, 69]             512
            ReLU-170          [-1, 256, 69, 69]               0
          Conv2d-171          [-1, 256, 69, 69]          65,792
     BatchNorm2d-172          [-1, 256, 69, 69]             512
            ReLU-173          [-1, 256, 69, 69]               0
          Conv2d-174          [-1, 128, 69, 69]         295,040
     BatchNorm2d-175          [-1, 384, 69, 69]             768
            ReLU-176          [-1, 384, 69, 69]               0
          Conv2d-177          [-1, 256, 69, 69]          98,560
     BatchNorm2d-178          [-1, 256, 69, 69]             512
            ReLU-179          [-1, 256, 69, 69]               0
          Conv2d-180          [-1, 128, 69, 69]         295,040
     BatchNorm2d-181          [-1, 512, 69, 69]           1,024
            ReLU-182          [-1, 512, 69, 69]               0
          Conv2d-183          [-1, 256, 69, 69]         131,328
       ConvDense-184          [-1, 256, 69, 69]               0
       ConvBlock-185          [-1, 256, 69, 69]               0
          Up2dBB-186          [-1, 256, 69, 69]               0
       Dropout2d-187          [-1, 256, 69, 69]               0
     BatchNorm2d-188          [-1, 512, 69, 69]           1,024
 ConvTranspose2d-189        [-1, 128, 139, 139]         589,952
     BatchNorm2d-190        [-1, 128, 139, 139]             256
            ReLU-191        [-1, 128, 139, 139]               0
          Conv2d-192        [-1, 128, 139, 139]          16,512
     BatchNorm2d-193        [-1, 128, 139, 139]             256
            ReLU-194        [-1, 128, 139, 139]               0
          Conv2d-195         [-1, 64, 139, 139]          73,792
     BatchNorm2d-196        [-1, 192, 139, 139]             384
            ReLU-197        [-1, 192, 139, 139]               0
          Conv2d-198        [-1, 128, 139, 139]          24,704
     BatchNorm2d-199        [-1, 128, 139, 139]             256
            ReLU-200        [-1, 128, 139, 139]               0
          Conv2d-201         [-1, 64, 139, 139]          73,792
     BatchNorm2d-202        [-1, 256, 139, 139]             512
            ReLU-203        [-1, 256, 139, 139]               0
          Conv2d-204        [-1, 128, 139, 139]          32,896
       ConvDense-205        [-1, 128, 139, 139]               0
       ConvBlock-206        [-1, 128, 139, 139]               0
          Up2dBB-207        [-1, 128, 139, 139]               0
       Dropout2d-208        [-1, 128, 139, 139]               0
     BatchNorm2d-209        [-1, 256, 139, 139]             512
 ConvTranspose2d-210        [-1, 128, 281, 281]         819,328
     BatchNorm2d-211        [-1, 128, 281, 281]             256
            ReLU-212        [-1, 128, 281, 281]               0
          Conv2d-213        [-1, 128, 281, 281]          16,512
     BatchNorm2d-214        [-1, 128, 281, 281]             256
            ReLU-215        [-1, 128, 281, 281]               0
          Conv2d-216         [-1, 64, 281, 281]          73,792
     BatchNorm2d-217        [-1, 192, 281, 281]             384
            ReLU-218        [-1, 192, 281, 281]               0
          Conv2d-219        [-1, 128, 281, 281]          24,704
     BatchNorm2d-220        [-1, 128, 281, 281]             256
            ReLU-221        [-1, 128, 281, 281]               0
          Conv2d-222         [-1, 64, 281, 281]          73,792
     BatchNorm2d-223        [-1, 256, 281, 281]             512
            ReLU-224        [-1, 256, 281, 281]               0
          Conv2d-225        [-1, 128, 281, 281]          32,896
       ConvDense-226        [-1, 128, 281, 281]               0
       ConvBlock-227        [-1, 128, 281, 281]               0
          Up2dBB-228        [-1, 128, 281, 281]               0
       Dropout2d-229        [-1, 128, 281, 281]               0
     BatchNorm2d-230        [-1, 256, 281, 281]             512
            ReLU-231        [-1, 256, 281, 281]               0
          Conv2d-232        [-1, 256, 281, 281]          65,792
     BatchNorm2d-233        [-1, 256, 281, 281]             512
            ReLU-234        [-1, 256, 281, 281]               0
          Conv2d-235        [-1, 128, 281, 281]         295,040
     BatchNorm2d-236        [-1, 384, 281, 281]             768
            ReLU-237        [-1, 384, 281, 281]               0
          Conv2d-238        [-1, 256, 281, 281]          98,560
     BatchNorm2d-239        [-1, 256, 281, 281]             512
            ReLU-240        [-1, 256, 281, 281]               0
          Conv2d-241        [-1, 128, 281, 281]         295,040
     BatchNorm2d-242        [-1, 512, 281, 281]           1,024
            ReLU-243        [-1, 512, 281, 281]               0
          Conv2d-244        [-1, 256, 281, 281]         131,328
       ConvDense-245        [-1, 256, 281, 281]               0
       ConvBlock-246        [-1, 256, 281, 281]               0
     BatchNorm2d-247        [-1, 256, 281, 281]             512
          Conv2d-248          [-1, 2, 281, 281]             514
      ConvOutput-249          [-1, 2, 281, 281]               0
================================================================
Total params: 184,698,754
Trainable params: 184,698,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.30
Forward/backward pass size (MB): 8103.69
Params size (MB): 704.57
Estimated Total Size (MB): 8808.56
----------------------------------------------------------------
===================End of Net Architecture =====================

Info: program will use 4 GPUs.
Loss Functions List: FocalCELoss with weight of 1; 	BoundaryLoss with weight of 0; 
Hints: Test Dice_0 is the dice coeff for all non-zero labels
Hints: Test Dice_1 is for primary cancer(green), test Dice_2 is for metastasis(yellow), and test Dice_3 is for invaded lymph node(brown).
Hints: Test TPR_0 is the TPR for all non-zero labels
Hints: Test TPR_1 is for primary cancer(green), TPR_2 is for metastasis(yellow), and TPR_3 is for invaded lymph node(brown).

Epoch 	 TrainingLoss 	 TestLoss 	Dice_0	Dice_1	TPR_0	TPR_1
0 	 0.0970 	 0.1185 	0.217	0.217	1.000	1.000
1 	 0.0713 	 0.0958 	0.291	0.291	0.996	0.996
2 	 0.0649 	 0.2128 	0.312	0.312	0.331	0.331
3 	 0.0592 	 0.0974 	0.587	0.587	0.737	0.737
4 	 0.0528 	 0.0688 	0.568	0.568	0.891	0.891
