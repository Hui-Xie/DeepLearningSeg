Program ID 3954

Program command: 
 ['/home/hxie1/Projects/OvarianCancer/TrainSegV.py', '/home/hxie1/temp_netParameters/OvarianCancer/Label0_1', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainImages', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels', '2D', '0,1']

Major program changes: 
                       Restore May 1st 11:51 nework which got test dice 78% for primary
                       ConvDense uses Conv-Bn-ReLU order (CBR)
                       useSkip2Conv = 3 
                       output layer use 1*1 filter. 
                       use boundary loss with weight 0 at beginning, and pretrain CE loss. 
                       special convInput Module    
                       first layer filter = 96
                       use Mixup
                       Boundary Loss supports multi-class, and weight
                       Only  0,1 two classes clasfication for primary
                       Encoder do not use dropout, Decoder use dropout.
                       
                       
            

Program starting Time: 2019-05-17 11:36:32.119988
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/Label0_1

Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Info: program does not output training dice.
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels has 164 segmented slices for remained labels [0, 1].
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/testLabels has 31 segmented slices for remained labels [0, 1].
Info: program uses 2D input.
TrainData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

TestData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

Info: program uses Mixup with alpha=0.4, and mixupProb = 0.5.
Network trains from scratch.
Network has total 337066946 parameters.
Info: network dropout rate = 0.3
Infor: Cross Entropy Weight: [1.0260619741432382, 39.37007874015748]

====================Net Architecture===========================
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 96, 281, 281]             960
       BatchNorm2d-2         [-1, 96, 281, 281]             192
              ReLU-3         [-1, 96, 281, 281]               0
    BN_ReLU_Conv2d-4         [-1, 96, 281, 281]               0
            Conv2d-5         [-1, 96, 281, 281]          83,040
       BatchNorm2d-6         [-1, 96, 281, 281]             192
              ReLU-7         [-1, 96, 281, 281]               0
    BN_ReLU_Conv2d-8         [-1, 96, 281, 281]               0
            Conv2d-9         [-1, 96, 281, 281]          83,040
      BatchNorm2d-10         [-1, 96, 281, 281]             192
             ReLU-11         [-1, 96, 281, 281]               0
   BN_ReLU_Conv2d-12         [-1, 96, 281, 281]               0
       Skip2Convs-13         [-1, 96, 281, 281]               0
ConvBuildingBlock-14         [-1, 96, 281, 281]               0
        ConvInput-15         [-1, 96, 281, 281]               0
           Conv2d-16         [-1, 96, 139, 139]         230,496
      BatchNorm2d-17         [-1, 96, 139, 139]             192
             ReLU-18         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-19         [-1, 96, 139, 139]               0
           Conv2d-20         [-1, 96, 139, 139]          83,040
      BatchNorm2d-21         [-1, 96, 139, 139]             192
             ReLU-22         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-23         [-1, 96, 139, 139]               0
           Conv2d-24         [-1, 96, 139, 139]          83,040
      BatchNorm2d-25         [-1, 96, 139, 139]             192
             ReLU-26         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-27         [-1, 96, 139, 139]               0
           Conv2d-28         [-1, 96, 139, 139]          83,040
      BatchNorm2d-29         [-1, 96, 139, 139]             192
             ReLU-30         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-31         [-1, 96, 139, 139]               0
       Skip2Convs-32         [-1, 96, 139, 139]               0
ConvBuildingBlock-33         [-1, 96, 139, 139]               0
         Down2dBB-34         [-1, 96, 139, 139]               0
           Conv2d-35          [-1, 192, 69, 69]         166,080
      BatchNorm2d-36          [-1, 192, 69, 69]             384
             ReLU-37          [-1, 192, 69, 69]               0
   BN_ReLU_Conv2d-38          [-1, 192, 69, 69]               0
           Conv2d-39          [-1, 192, 69, 69]         331,968
      BatchNorm2d-40          [-1, 192, 69, 69]             384
             ReLU-41          [-1, 192, 69, 69]               0
   BN_ReLU_Conv2d-42          [-1, 192, 69, 69]               0
           Conv2d-43          [-1, 192, 69, 69]         331,968
      BatchNorm2d-44          [-1, 192, 69, 69]             384
             ReLU-45          [-1, 192, 69, 69]               0
   BN_ReLU_Conv2d-46          [-1, 192, 69, 69]               0
           Conv2d-47          [-1, 192, 69, 69]         331,968
      BatchNorm2d-48          [-1, 192, 69, 69]             384
             ReLU-49          [-1, 192, 69, 69]               0
   BN_ReLU_Conv2d-50          [-1, 192, 69, 69]               0
       Skip2Convs-51          [-1, 192, 69, 69]               0
ConvBuildingBlock-52          [-1, 192, 69, 69]               0
         Down2dBB-53          [-1, 192, 69, 69]               0
           Conv2d-54          [-1, 384, 33, 33]       1,843,584
      BatchNorm2d-55          [-1, 384, 33, 33]             768
             ReLU-56          [-1, 384, 33, 33]               0
   BN_ReLU_Conv2d-57          [-1, 384, 33, 33]               0
           Conv2d-58          [-1, 384, 33, 33]       1,327,488
      BatchNorm2d-59          [-1, 384, 33, 33]             768
             ReLU-60          [-1, 384, 33, 33]               0
   BN_ReLU_Conv2d-61          [-1, 384, 33, 33]               0
           Conv2d-62          [-1, 384, 33, 33]       1,327,488
      BatchNorm2d-63          [-1, 384, 33, 33]             768
             ReLU-64          [-1, 384, 33, 33]               0
   BN_ReLU_Conv2d-65          [-1, 384, 33, 33]               0
           Conv2d-66          [-1, 384, 33, 33]       1,327,488
      BatchNorm2d-67          [-1, 384, 33, 33]             768
             ReLU-68          [-1, 384, 33, 33]               0
   BN_ReLU_Conv2d-69          [-1, 384, 33, 33]               0
       Skip2Convs-70          [-1, 384, 33, 33]               0
ConvBuildingBlock-71          [-1, 384, 33, 33]               0
         Down2dBB-72          [-1, 384, 33, 33]               0
           Conv2d-73          [-1, 768, 15, 15]       7,373,568
      BatchNorm2d-74          [-1, 768, 15, 15]           1,536
             ReLU-75          [-1, 768, 15, 15]               0
   BN_ReLU_Conv2d-76          [-1, 768, 15, 15]               0
           Conv2d-77          [-1, 768, 15, 15]       5,309,184
      BatchNorm2d-78          [-1, 768, 15, 15]           1,536
             ReLU-79          [-1, 768, 15, 15]               0
   BN_ReLU_Conv2d-80          [-1, 768, 15, 15]               0
           Conv2d-81          [-1, 768, 15, 15]       5,309,184
      BatchNorm2d-82          [-1, 768, 15, 15]           1,536
             ReLU-83          [-1, 768, 15, 15]               0
   BN_ReLU_Conv2d-84          [-1, 768, 15, 15]               0
           Conv2d-85          [-1, 768, 15, 15]       5,309,184
      BatchNorm2d-86          [-1, 768, 15, 15]           1,536
             ReLU-87          [-1, 768, 15, 15]               0
   BN_ReLU_Conv2d-88          [-1, 768, 15, 15]               0
       Skip2Convs-89          [-1, 768, 15, 15]               0
ConvBuildingBlock-90          [-1, 768, 15, 15]               0
         Down2dBB-91          [-1, 768, 15, 15]               0
           Conv2d-92           [-1, 1536, 7, 7]      10,618,368
      BatchNorm2d-93           [-1, 1536, 7, 7]           3,072
             ReLU-94           [-1, 1536, 7, 7]               0
   BN_ReLU_Conv2d-95           [-1, 1536, 7, 7]               0
           Conv2d-96           [-1, 1536, 7, 7]      21,235,200
      BatchNorm2d-97           [-1, 1536, 7, 7]           3,072
             ReLU-98           [-1, 1536, 7, 7]               0
   BN_ReLU_Conv2d-99           [-1, 1536, 7, 7]               0
          Conv2d-100           [-1, 1536, 7, 7]      21,235,200
     BatchNorm2d-101           [-1, 1536, 7, 7]           3,072
            ReLU-102           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-103           [-1, 1536, 7, 7]               0
          Conv2d-104           [-1, 1536, 7, 7]      21,235,200
     BatchNorm2d-105           [-1, 1536, 7, 7]           3,072
            ReLU-106           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-107           [-1, 1536, 7, 7]               0
      Skip2Convs-108           [-1, 1536, 7, 7]               0
ConvBuildingBlock-109           [-1, 1536, 7, 7]               0
        Down2dBB-110           [-1, 1536, 7, 7]               0
          Conv2d-111           [-1, 1536, 3, 3]      21,235,200
     BatchNorm2d-112           [-1, 1536, 3, 3]           3,072
            ReLU-113           [-1, 1536, 3, 3]               0
  BN_ReLU_Conv2d-114           [-1, 1536, 3, 3]               0
          Conv2d-115           [-1, 1536, 3, 3]      21,235,200
     BatchNorm2d-116           [-1, 1536, 3, 3]           3,072
            ReLU-117           [-1, 1536, 3, 3]               0
  BN_ReLU_Conv2d-118           [-1, 1536, 3, 3]               0
          Conv2d-119           [-1, 1536, 3, 3]      21,235,200
     BatchNorm2d-120           [-1, 1536, 3, 3]           3,072
            ReLU-121           [-1, 1536, 3, 3]               0
  BN_ReLU_Conv2d-122           [-1, 1536, 3, 3]               0
          Conv2d-123           [-1, 1536, 3, 3]      21,235,200
     BatchNorm2d-124           [-1, 1536, 3, 3]           3,072
            ReLU-125           [-1, 1536, 3, 3]               0
  BN_ReLU_Conv2d-126           [-1, 1536, 3, 3]               0
      Skip2Convs-127           [-1, 1536, 3, 3]               0
ConvBuildingBlock-128           [-1, 1536, 3, 3]               0
        Down2dBB-129           [-1, 1536, 3, 3]               0
 ConvTranspose2d-130           [-1, 1536, 7, 7]      21,235,200
     BatchNorm2d-131           [-1, 1536, 7, 7]           3,072
            ReLU-132           [-1, 1536, 7, 7]               0
 BN_ReLU_ConvT2d-133           [-1, 1536, 7, 7]               0
          Conv2d-134           [-1, 1536, 7, 7]      21,235,200
     BatchNorm2d-135           [-1, 1536, 7, 7]           3,072
            ReLU-136           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-137           [-1, 1536, 7, 7]               0
          Conv2d-138           [-1, 1536, 7, 7]      21,235,200
     BatchNorm2d-139           [-1, 1536, 7, 7]           3,072
            ReLU-140           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-141           [-1, 1536, 7, 7]               0
          Conv2d-142           [-1, 1536, 7, 7]      21,235,200
     BatchNorm2d-143           [-1, 1536, 7, 7]           3,072
            ReLU-144           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-145           [-1, 1536, 7, 7]               0
      Skip2Convs-146           [-1, 1536, 7, 7]               0
ConvBuildingBlock-147           [-1, 1536, 7, 7]               0
          Up2dBB-148           [-1, 1536, 7, 7]               0
       Dropout2d-149           [-1, 1536, 7, 7]               0
 ConvTranspose2d-150          [-1, 768, 15, 15]      21,234,432
     BatchNorm2d-151          [-1, 768, 15, 15]           1,536
            ReLU-152          [-1, 768, 15, 15]               0
 BN_ReLU_ConvT2d-153          [-1, 768, 15, 15]               0
          Conv2d-154          [-1, 768, 15, 15]       5,309,184
     BatchNorm2d-155          [-1, 768, 15, 15]           1,536
            ReLU-156          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-157          [-1, 768, 15, 15]               0
          Conv2d-158          [-1, 768, 15, 15]       5,309,184
     BatchNorm2d-159          [-1, 768, 15, 15]           1,536
            ReLU-160          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-161          [-1, 768, 15, 15]               0
          Conv2d-162          [-1, 768, 15, 15]       5,309,184
     BatchNorm2d-163          [-1, 768, 15, 15]           1,536
            ReLU-164          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-165          [-1, 768, 15, 15]               0
      Skip2Convs-166          [-1, 768, 15, 15]               0
ConvBuildingBlock-167          [-1, 768, 15, 15]               0
          Up2dBB-168          [-1, 768, 15, 15]               0
       Dropout2d-169          [-1, 768, 15, 15]               0
 ConvTranspose2d-170          [-1, 384, 33, 33]      14,745,984
     BatchNorm2d-171          [-1, 384, 33, 33]             768
            ReLU-172          [-1, 384, 33, 33]               0
 BN_ReLU_ConvT2d-173          [-1, 384, 33, 33]               0
          Conv2d-174          [-1, 384, 33, 33]       1,327,488
     BatchNorm2d-175          [-1, 384, 33, 33]             768
            ReLU-176          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-177          [-1, 384, 33, 33]               0
          Conv2d-178          [-1, 384, 33, 33]       1,327,488
     BatchNorm2d-179          [-1, 384, 33, 33]             768
            ReLU-180          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-181          [-1, 384, 33, 33]               0
          Conv2d-182          [-1, 384, 33, 33]       1,327,488
     BatchNorm2d-183          [-1, 384, 33, 33]             768
            ReLU-184          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-185          [-1, 384, 33, 33]               0
      Skip2Convs-186          [-1, 384, 33, 33]               0
ConvBuildingBlock-187          [-1, 384, 33, 33]               0
          Up2dBB-188          [-1, 384, 33, 33]               0
       Dropout2d-189          [-1, 384, 33, 33]               0
 ConvTranspose2d-190          [-1, 192, 69, 69]       3,686,592
     BatchNorm2d-191          [-1, 192, 69, 69]             384
            ReLU-192          [-1, 192, 69, 69]               0
 BN_ReLU_ConvT2d-193          [-1, 192, 69, 69]               0
          Conv2d-194          [-1, 192, 69, 69]         331,968
     BatchNorm2d-195          [-1, 192, 69, 69]             384
            ReLU-196          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-197          [-1, 192, 69, 69]               0
          Conv2d-198          [-1, 192, 69, 69]         331,968
     BatchNorm2d-199          [-1, 192, 69, 69]             384
            ReLU-200          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-201          [-1, 192, 69, 69]               0
          Conv2d-202          [-1, 192, 69, 69]         331,968
     BatchNorm2d-203          [-1, 192, 69, 69]             384
            ReLU-204          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-205          [-1, 192, 69, 69]               0
      Skip2Convs-206          [-1, 192, 69, 69]               0
ConvBuildingBlock-207          [-1, 192, 69, 69]               0
          Up2dBB-208          [-1, 192, 69, 69]               0
       Dropout2d-209          [-1, 192, 69, 69]               0
 ConvTranspose2d-210         [-1, 96, 139, 139]         331,872
     BatchNorm2d-211         [-1, 96, 139, 139]             192
            ReLU-212         [-1, 96, 139, 139]               0
 BN_ReLU_ConvT2d-213         [-1, 96, 139, 139]               0
          Conv2d-214         [-1, 96, 139, 139]          83,040
     BatchNorm2d-215         [-1, 96, 139, 139]             192
            ReLU-216         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-217         [-1, 96, 139, 139]               0
          Conv2d-218         [-1, 96, 139, 139]          83,040
     BatchNorm2d-219         [-1, 96, 139, 139]             192
            ReLU-220         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-221         [-1, 96, 139, 139]               0
          Conv2d-222         [-1, 96, 139, 139]          83,040
     BatchNorm2d-223         [-1, 96, 139, 139]             192
            ReLU-224         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-225         [-1, 96, 139, 139]               0
      Skip2Convs-226         [-1, 96, 139, 139]               0
ConvBuildingBlock-227         [-1, 96, 139, 139]               0
          Up2dBB-228         [-1, 96, 139, 139]               0
       Dropout2d-229         [-1, 96, 139, 139]               0
 ConvTranspose2d-230         [-1, 96, 281, 281]         460,896
     BatchNorm2d-231         [-1, 96, 281, 281]             192
            ReLU-232         [-1, 96, 281, 281]               0
 BN_ReLU_ConvT2d-233         [-1, 96, 281, 281]               0
          Conv2d-234         [-1, 96, 281, 281]          83,040
     BatchNorm2d-235         [-1, 96, 281, 281]             192
            ReLU-236         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-237         [-1, 96, 281, 281]               0
          Conv2d-238         [-1, 96, 281, 281]          83,040
     BatchNorm2d-239         [-1, 96, 281, 281]             192
            ReLU-240         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-241         [-1, 96, 281, 281]               0
          Conv2d-242         [-1, 96, 281, 281]          83,040
     BatchNorm2d-243         [-1, 96, 281, 281]             192
            ReLU-244         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-245         [-1, 96, 281, 281]               0
      Skip2Convs-246         [-1, 96, 281, 281]               0
ConvBuildingBlock-247         [-1, 96, 281, 281]               0
          Up2dBB-248         [-1, 96, 281, 281]               0
       Dropout2d-249         [-1, 96, 281, 281]               0
          Conv2d-250          [-1, 2, 281, 281]             386
================================================================
Total params: 337,066,946
Trainable params: 337,066,946
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.30
Forward/backward pass size (MB): 3049.48
Params size (MB): 1285.81
Estimated Total Size (MB): 4335.59
----------------------------------------------------------------
===================End of Net Architecture =====================

Info: program will use 4 GPUs.
Loss Functions List: FocalCELoss with weight of 1; 	BoundaryLoss with weight of 0; 
Hints: Test Dice_0 is the dice coeff for all non-zero labels
Hints: Test Dice_1 is for primary cancer(green), 	
 test Dice_2 is for metastasis(yellow), 	
 and test Dice_3 is for invaded lymph node(brown).
Hints: Test TPR_0 is the TPR for all non-zero labels
Hints: Test TPR_1 is for primary cancer(green), 	
 TPR_2 is for metastasis(yellow), 	
 and TPR_3 is for invaded lymph node(brown).

Epoch	TrLoss	Dice0	Dice1	TPR_0	TPR_1	TsLoss	Dice0	Dice1	TPR_0	TPR_1
0	0.1059	0.000	0.000	0.000	0.000	0.0882	0.275	0.275	0.997	0.997
1	0.0746	0.000	0.000	0.000	0.000	0.0677	0.310	0.310	0.991	0.991
2	0.0621	0.000	0.000	0.000	0.000	0.0564	0.443	0.443	0.959	0.959
3	0.0672	0.000	0.000	0.000	0.000	0.0960	0.319	0.319	1.000	1.000
4	0.0556	0.000	0.000	0.000	0.000	0.0593	0.419	0.419	0.994	0.994
5	0.0560	0.000	0.000	0.000	0.000	0.0617	0.395	0.395	0.989	0.989
6	0.0593	0.000	0.000	0.000	0.000	0.0612	0.553	0.553	0.936	0.936
7	0.0578	0.000	0.000	0.000	0.000	0.0435	0.564	0.564	0.964	0.964
8	0.0583	0.000	0.000	0.000	0.000	0.0362	0.570	0.570	0.982	0.982
9	0.0578	0.000	0.000	0.000	0.000	0.0517	0.486	0.486	0.968	0.968
10	0.0533	0.000	0.000	0.000	0.000	0.0360	0.543	0.543	0.982	0.982
11	0.0593	0.000	0.000	0.000	0.000	0.0415	0.564	0.564	0.982	0.982
12	0.0529	0.000	0.000	0.000	0.000	0.0454	0.422	0.422	0.997	0.997
13	0.0475	0.000	0.000	0.000	0.000	0.0387	0.472	0.472	0.985	0.985
14	0.0548	0.000	0.000	0.000	0.000	0.0383	0.489	0.489	0.989	0.989
15	0.0514	0.000	0.000	0.000	0.000	0.0399	0.467	0.467	0.991	0.991
16	0.0494	0.000	0.000	0.000	0.000	0.0443	0.541	0.541	0.967	0.967
17	0.0497	0.000	0.000	0.000	0.000	0.0409	0.617	0.617	0.964	0.964
18	0.0525	0.000	0.000	0.000	0.000	0.0510	0.579	0.579	0.957	0.957
19	0.0482	0.000	0.000	0.000	0.000	0.0406	0.477	0.477	0.988	0.988
20	0.0529	0.000	0.000	0.000	0.000	0.0388	0.514	0.514	0.984	0.984
21	0.0451	0.000	0.000	0.000	0.000	0.0370	0.555	0.555	0.975	0.975
22	0.0492	0.000	0.000	0.000	0.000	0.0380	0.510	0.510	0.983	0.983
23	0.0503	0.000	0.000	0.000	0.000	0.0346	0.563	0.563	0.979	0.979
24	0.0497	0.000	0.000	0.000	0.000	0.0354	0.551	0.551	0.981	0.981
25	0.0511	0.000	0.000	0.000	0.000	0.0373	0.606	0.606	0.969	0.969
26	0.0553	0.000	0.000	0.000	0.000	0.0709	0.328	0.328	0.998	0.998
27	0.0537	0.000	0.000	0.000	0.000	0.0422	0.441	0.441	0.987	0.987
28	0.0592	0.000	0.000	0.000	0.000	0.0384	0.476	0.476	0.995	0.995
29	0.0511	0.000	0.000	0.000	0.000	0.0334	0.562	0.562	0.986	0.986
30	0.0528	0.000	0.000	0.000	0.000	0.0390	0.469	0.469	0.987	0.987
31	0.0472	0.000	0.000	0.000	0.000	0.0343	0.600	0.600	0.982	0.982
32	0.0563	0.000	0.000	0.000	0.000	0.0407	0.522	0.522	0.981	0.981
33	0.0511	0.000	0.000	0.000	0.000	0.0363	0.462	0.462	0.995	0.995
34	0.0395	0.000	0.000	0.000	0.000	0.0379	0.613	0.613	0.963	0.963
35	0.0430	0.000	0.000	0.000	0.000	0.0367	0.523	0.523	0.985	0.985
36	0.0534	0.000	0.000	0.000	0.000	0.0432	0.389	0.389	0.998	0.998
37	0.0490	0.000	0.000	0.000	0.000	0.0467	0.640	0.640	0.948	0.948
38	0.0541	0.000	0.000	0.000	0.000	0.0360	0.561	0.561	0.973	0.973
