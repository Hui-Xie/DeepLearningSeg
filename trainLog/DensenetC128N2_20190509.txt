Program ID 25077

Program command: 
 ['/home/hxie1/Projects/OvarianCancer/TrainSegV.py', '/home/hxie1/temp_netParameters/OvarianCancer/Label0_1', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainImages', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels', '2D', '0,1']

Major program changes: ConvResidual use BatchNorm-reLU-Conv structure; 
                       ConsDense also use BatchNorm-reLU-Conv structure.
                       Add ConvSegDecreaseChannels
                       and each block has 5 layers, 
                       Residual connect to each Conv, 
                       skip at least 2 layers.
                       output layer use conv with 3*3 fiter instead of 1*1 filter. 
                       use boundary loss with weight 0 at beginning, and pretrain CE loss. 
                       special convInput Module
                       convOutput moudel uses 1*1 conv to tranparent gradident 
                       ConvOutput use residual module.
                       Use Dense Net in the Building Block
                       add ConvBlock to wrapp the ConvResidual and ConvDense
            

Program starting Time: 2019-05-09 12:13:27.308353
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/Label0_1

Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels has 164 segmented slices for remained labels [0, 1].
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/testLabels has 31 segmented slices for remained labels [0, 1].
Info: program uses 2D input.
TrainData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

TestData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

Network trains from scratch.
Network has total 184698754 parameters.
Info: network dropout rate = 0.3
Infor: Cross Entropy Weight: [1.0260619741432382, 39.37007874015748]

====================Net Architecture===========================
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1        [-1, 128, 281, 281]           1,280
       BatchNorm2d-2        [-1, 128, 281, 281]             256
              ReLU-3        [-1, 128, 281, 281]               0
            Conv2d-4        [-1, 128, 281, 281]          16,512
       BatchNorm2d-5        [-1, 128, 281, 281]             256
              ReLU-6        [-1, 128, 281, 281]               0
            Conv2d-7         [-1, 64, 281, 281]          73,792
       BatchNorm2d-8        [-1, 192, 281, 281]             384
              ReLU-9        [-1, 192, 281, 281]               0
           Conv2d-10        [-1, 128, 281, 281]          24,704
      BatchNorm2d-11        [-1, 128, 281, 281]             256
             ReLU-12        [-1, 128, 281, 281]               0
           Conv2d-13         [-1, 64, 281, 281]          73,792
      BatchNorm2d-14        [-1, 256, 281, 281]             512
             ReLU-15        [-1, 256, 281, 281]               0
           Conv2d-16        [-1, 128, 281, 281]          32,896
        ConvDense-17        [-1, 128, 281, 281]               0
        ConvBlock-18        [-1, 128, 281, 281]               0
        ConvInput-19        [-1, 128, 281, 281]               0
      BatchNorm2d-20        [-1, 128, 281, 281]             256
           Conv2d-21        [-1, 128, 139, 139]         409,728
      BatchNorm2d-22        [-1, 128, 139, 139]             256
             ReLU-23        [-1, 128, 139, 139]               0
           Conv2d-24        [-1, 128, 139, 139]          16,512
      BatchNorm2d-25        [-1, 128, 139, 139]             256
             ReLU-26        [-1, 128, 139, 139]               0
           Conv2d-27         [-1, 64, 139, 139]          73,792
      BatchNorm2d-28        [-1, 192, 139, 139]             384
             ReLU-29        [-1, 192, 139, 139]               0
           Conv2d-30        [-1, 128, 139, 139]          24,704
      BatchNorm2d-31        [-1, 128, 139, 139]             256
             ReLU-32        [-1, 128, 139, 139]               0
           Conv2d-33         [-1, 64, 139, 139]          73,792
      BatchNorm2d-34        [-1, 256, 139, 139]             512
             ReLU-35        [-1, 256, 139, 139]               0
           Conv2d-36        [-1, 128, 139, 139]          32,896
        ConvDense-37        [-1, 128, 139, 139]               0
        ConvBlock-38        [-1, 128, 139, 139]               0
         Down2dBB-39        [-1, 128, 139, 139]               0
        Dropout2d-40        [-1, 128, 139, 139]               0
      BatchNorm2d-41        [-1, 128, 139, 139]             256
           Conv2d-42          [-1, 256, 69, 69]         295,168
      BatchNorm2d-43          [-1, 256, 69, 69]             512
             ReLU-44          [-1, 256, 69, 69]               0
           Conv2d-45          [-1, 256, 69, 69]          65,792
      BatchNorm2d-46          [-1, 256, 69, 69]             512
             ReLU-47          [-1, 256, 69, 69]               0
           Conv2d-48          [-1, 128, 69, 69]         295,040
      BatchNorm2d-49          [-1, 384, 69, 69]             768
             ReLU-50          [-1, 384, 69, 69]               0
           Conv2d-51          [-1, 256, 69, 69]          98,560
      BatchNorm2d-52          [-1, 256, 69, 69]             512
             ReLU-53          [-1, 256, 69, 69]               0
           Conv2d-54          [-1, 128, 69, 69]         295,040
      BatchNorm2d-55          [-1, 512, 69, 69]           1,024
             ReLU-56          [-1, 512, 69, 69]               0
           Conv2d-57          [-1, 256, 69, 69]         131,328
        ConvDense-58          [-1, 256, 69, 69]               0
        ConvBlock-59          [-1, 256, 69, 69]               0
         Down2dBB-60          [-1, 256, 69, 69]               0
        Dropout2d-61          [-1, 256, 69, 69]               0
      BatchNorm2d-62          [-1, 256, 69, 69]             512
           Conv2d-63          [-1, 512, 33, 33]       3,277,312
      BatchNorm2d-64          [-1, 512, 33, 33]           1,024
             ReLU-65          [-1, 512, 33, 33]               0
           Conv2d-66          [-1, 512, 33, 33]         262,656
      BatchNorm2d-67          [-1, 512, 33, 33]           1,024
             ReLU-68          [-1, 512, 33, 33]               0
           Conv2d-69          [-1, 256, 33, 33]       1,179,904
      BatchNorm2d-70          [-1, 768, 33, 33]           1,536
             ReLU-71          [-1, 768, 33, 33]               0
           Conv2d-72          [-1, 512, 33, 33]         393,728
      BatchNorm2d-73          [-1, 512, 33, 33]           1,024
             ReLU-74          [-1, 512, 33, 33]               0
           Conv2d-75          [-1, 256, 33, 33]       1,179,904
      BatchNorm2d-76         [-1, 1024, 33, 33]           2,048
             ReLU-77         [-1, 1024, 33, 33]               0
           Conv2d-78          [-1, 512, 33, 33]         524,800
        ConvDense-79          [-1, 512, 33, 33]               0
        ConvBlock-80          [-1, 512, 33, 33]               0
         Down2dBB-81          [-1, 512, 33, 33]               0
        Dropout2d-82          [-1, 512, 33, 33]               0
      BatchNorm2d-83          [-1, 512, 33, 33]           1,024
           Conv2d-84         [-1, 1024, 15, 15]      13,108,224
      BatchNorm2d-85         [-1, 1024, 15, 15]           2,048
             ReLU-86         [-1, 1024, 15, 15]               0
           Conv2d-87         [-1, 1024, 15, 15]       1,049,600
      BatchNorm2d-88         [-1, 1024, 15, 15]           2,048
             ReLU-89         [-1, 1024, 15, 15]               0
           Conv2d-90          [-1, 512, 15, 15]       4,719,104
      BatchNorm2d-91         [-1, 1536, 15, 15]           3,072
             ReLU-92         [-1, 1536, 15, 15]               0
           Conv2d-93         [-1, 1024, 15, 15]       1,573,888
      BatchNorm2d-94         [-1, 1024, 15, 15]           2,048
             ReLU-95         [-1, 1024, 15, 15]               0
           Conv2d-96          [-1, 512, 15, 15]       4,719,104
      BatchNorm2d-97         [-1, 2048, 15, 15]           4,096
             ReLU-98         [-1, 2048, 15, 15]               0
           Conv2d-99         [-1, 1024, 15, 15]       2,098,176
       ConvDense-100         [-1, 1024, 15, 15]               0
       ConvBlock-101         [-1, 1024, 15, 15]               0
        Down2dBB-102         [-1, 1024, 15, 15]               0
       Dropout2d-103         [-1, 1024, 15, 15]               0
     BatchNorm2d-104         [-1, 1024, 15, 15]           2,048
          Conv2d-105           [-1, 2048, 7, 7]      18,876,416
     BatchNorm2d-106           [-1, 2048, 7, 7]           4,096
            ReLU-107           [-1, 2048, 7, 7]               0
          Conv2d-108           [-1, 2048, 7, 7]       4,196,352
     BatchNorm2d-109           [-1, 2048, 7, 7]           4,096
            ReLU-110           [-1, 2048, 7, 7]               0
          Conv2d-111           [-1, 1024, 7, 7]      18,875,392
     BatchNorm2d-112           [-1, 3072, 7, 7]           6,144
            ReLU-113           [-1, 3072, 7, 7]               0
          Conv2d-114           [-1, 2048, 7, 7]       6,293,504
     BatchNorm2d-115           [-1, 2048, 7, 7]           4,096
            ReLU-116           [-1, 2048, 7, 7]               0
          Conv2d-117           [-1, 1024, 7, 7]      18,875,392
     BatchNorm2d-118           [-1, 4096, 7, 7]           8,192
            ReLU-119           [-1, 4096, 7, 7]               0
          Conv2d-120           [-1, 2048, 7, 7]       8,390,656
       ConvDense-121           [-1, 2048, 7, 7]               0
       ConvBlock-122           [-1, 2048, 7, 7]               0
        Down2dBB-123           [-1, 2048, 7, 7]               0
       Dropout2d-124           [-1, 2048, 7, 7]               0
     BatchNorm2d-125           [-1, 2048, 7, 7]           4,096
 ConvTranspose2d-126         [-1, 1024, 15, 15]      18,875,392
     BatchNorm2d-127         [-1, 1024, 15, 15]           2,048
            ReLU-128         [-1, 1024, 15, 15]               0
          Conv2d-129         [-1, 1024, 15, 15]       1,049,600
     BatchNorm2d-130         [-1, 1024, 15, 15]           2,048
            ReLU-131         [-1, 1024, 15, 15]               0
          Conv2d-132          [-1, 512, 15, 15]       4,719,104
     BatchNorm2d-133         [-1, 1536, 15, 15]           3,072
            ReLU-134         [-1, 1536, 15, 15]               0
          Conv2d-135         [-1, 1024, 15, 15]       1,573,888
     BatchNorm2d-136         [-1, 1024, 15, 15]           2,048
            ReLU-137         [-1, 1024, 15, 15]               0
          Conv2d-138          [-1, 512, 15, 15]       4,719,104
     BatchNorm2d-139         [-1, 2048, 15, 15]           4,096
            ReLU-140         [-1, 2048, 15, 15]               0
          Conv2d-141         [-1, 1024, 15, 15]       2,098,176
       ConvDense-142         [-1, 1024, 15, 15]               0
       ConvBlock-143         [-1, 1024, 15, 15]               0
          Up2dBB-144         [-1, 1024, 15, 15]               0
       Dropout2d-145         [-1, 1024, 15, 15]               0
     BatchNorm2d-146         [-1, 2048, 15, 15]           4,096
 ConvTranspose2d-147          [-1, 512, 33, 33]      26,214,912
     BatchNorm2d-148          [-1, 512, 33, 33]           1,024
            ReLU-149          [-1, 512, 33, 33]               0
          Conv2d-150          [-1, 512, 33, 33]         262,656
     BatchNorm2d-151          [-1, 512, 33, 33]           1,024
            ReLU-152          [-1, 512, 33, 33]               0
          Conv2d-153          [-1, 256, 33, 33]       1,179,904
     BatchNorm2d-154          [-1, 768, 33, 33]           1,536
            ReLU-155          [-1, 768, 33, 33]               0
          Conv2d-156          [-1, 512, 33, 33]         393,728
     BatchNorm2d-157          [-1, 512, 33, 33]           1,024
            ReLU-158          [-1, 512, 33, 33]               0
          Conv2d-159          [-1, 256, 33, 33]       1,179,904
     BatchNorm2d-160         [-1, 1024, 33, 33]           2,048
            ReLU-161         [-1, 1024, 33, 33]               0
          Conv2d-162          [-1, 512, 33, 33]         524,800
       ConvDense-163          [-1, 512, 33, 33]               0
       ConvBlock-164          [-1, 512, 33, 33]               0
          Up2dBB-165          [-1, 512, 33, 33]               0
       Dropout2d-166          [-1, 512, 33, 33]               0
     BatchNorm2d-167         [-1, 1024, 33, 33]           2,048
 ConvTranspose2d-168          [-1, 256, 69, 69]       6,553,856
     BatchNorm2d-169          [-1, 256, 69, 69]             512
            ReLU-170          [-1, 256, 69, 69]               0
          Conv2d-171          [-1, 256, 69, 69]          65,792
     BatchNorm2d-172          [-1, 256, 69, 69]             512
            ReLU-173          [-1, 256, 69, 69]               0
          Conv2d-174          [-1, 128, 69, 69]         295,040
     BatchNorm2d-175          [-1, 384, 69, 69]             768
            ReLU-176          [-1, 384, 69, 69]               0
          Conv2d-177          [-1, 256, 69, 69]          98,560
     BatchNorm2d-178          [-1, 256, 69, 69]             512
            ReLU-179          [-1, 256, 69, 69]               0
          Conv2d-180          [-1, 128, 69, 69]         295,040
     BatchNorm2d-181          [-1, 512, 69, 69]           1,024
            ReLU-182          [-1, 512, 69, 69]               0
          Conv2d-183          [-1, 256, 69, 69]         131,328
       ConvDense-184          [-1, 256, 69, 69]               0
       ConvBlock-185          [-1, 256, 69, 69]               0
          Up2dBB-186          [-1, 256, 69, 69]               0
       Dropout2d-187          [-1, 256, 69, 69]               0
     BatchNorm2d-188          [-1, 512, 69, 69]           1,024
 ConvTranspose2d-189        [-1, 128, 139, 139]         589,952
     BatchNorm2d-190        [-1, 128, 139, 139]             256
            ReLU-191        [-1, 128, 139, 139]               0
          Conv2d-192        [-1, 128, 139, 139]          16,512
     BatchNorm2d-193        [-1, 128, 139, 139]             256
            ReLU-194        [-1, 128, 139, 139]               0
          Conv2d-195         [-1, 64, 139, 139]          73,792
     BatchNorm2d-196        [-1, 192, 139, 139]             384
            ReLU-197        [-1, 192, 139, 139]               0
          Conv2d-198        [-1, 128, 139, 139]          24,704
     BatchNorm2d-199        [-1, 128, 139, 139]             256
            ReLU-200        [-1, 128, 139, 139]               0
          Conv2d-201         [-1, 64, 139, 139]          73,792
     BatchNorm2d-202        [-1, 256, 139, 139]             512
            ReLU-203        [-1, 256, 139, 139]               0
          Conv2d-204        [-1, 128, 139, 139]          32,896
       ConvDense-205        [-1, 128, 139, 139]               0
       ConvBlock-206        [-1, 128, 139, 139]               0
          Up2dBB-207        [-1, 128, 139, 139]               0
       Dropout2d-208        [-1, 128, 139, 139]               0
     BatchNorm2d-209        [-1, 256, 139, 139]             512
 ConvTranspose2d-210        [-1, 128, 281, 281]         819,328
     BatchNorm2d-211        [-1, 128, 281, 281]             256
            ReLU-212        [-1, 128, 281, 281]               0
          Conv2d-213        [-1, 128, 281, 281]          16,512
     BatchNorm2d-214        [-1, 128, 281, 281]             256
            ReLU-215        [-1, 128, 281, 281]               0
          Conv2d-216         [-1, 64, 281, 281]          73,792
     BatchNorm2d-217        [-1, 192, 281, 281]             384
            ReLU-218        [-1, 192, 281, 281]               0
          Conv2d-219        [-1, 128, 281, 281]          24,704
     BatchNorm2d-220        [-1, 128, 281, 281]             256
            ReLU-221        [-1, 128, 281, 281]               0
          Conv2d-222         [-1, 64, 281, 281]          73,792
     BatchNorm2d-223        [-1, 256, 281, 281]             512
            ReLU-224        [-1, 256, 281, 281]               0
          Conv2d-225        [-1, 128, 281, 281]          32,896
       ConvDense-226        [-1, 128, 281, 281]               0
       ConvBlock-227        [-1, 128, 281, 281]               0
          Up2dBB-228        [-1, 128, 281, 281]               0
       Dropout2d-229        [-1, 128, 281, 281]               0
     BatchNorm2d-230        [-1, 256, 281, 281]             512
            ReLU-231        [-1, 256, 281, 281]               0
          Conv2d-232        [-1, 256, 281, 281]          65,792
     BatchNorm2d-233        [-1, 256, 281, 281]             512
            ReLU-234        [-1, 256, 281, 281]               0
          Conv2d-235        [-1, 128, 281, 281]         295,040
     BatchNorm2d-236        [-1, 384, 281, 281]             768
            ReLU-237        [-1, 384, 281, 281]               0
          Conv2d-238        [-1, 256, 281, 281]          98,560
     BatchNorm2d-239        [-1, 256, 281, 281]             512
            ReLU-240        [-1, 256, 281, 281]               0
          Conv2d-241        [-1, 128, 281, 281]         295,040
     BatchNorm2d-242        [-1, 512, 281, 281]           1,024
            ReLU-243        [-1, 512, 281, 281]               0
          Conv2d-244        [-1, 256, 281, 281]         131,328
       ConvDense-245        [-1, 256, 281, 281]               0
       ConvBlock-246        [-1, 256, 281, 281]               0
     BatchNorm2d-247        [-1, 256, 281, 281]             512
          Conv2d-248          [-1, 2, 281, 281]             514
      ConvOutput-249          [-1, 2, 281, 281]               0
================================================================
Total params: 184,698,754
Trainable params: 184,698,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.30
Forward/backward pass size (MB): 8103.69
Params size (MB): 704.57
Estimated Total Size (MB): 8808.56
----------------------------------------------------------------
===================End of Net Architecture =====================

Info: program will use 4 GPUs.
Loss Functions List: FocalCELoss with weight of 1; 	BoundaryLoss with weight of 0; 
Hints: Test Dice_0 is the dice coeff for all non-zero labels
Hints: Test Dice_1 is for primary cancer(green), test Dice_2 is for metastasis(yellow), and test Dice_3 is for invaded lymph node(brown).
Hints: Test TPR_0 is the TPR for all non-zero labels
Hints: Test TPR_1 is for primary cancer(green), TPR_2 is for metastasis(yellow), and TPR_3 is for invaded lymph node(brown).

Epoch 	 TrainingLoss 	 TestLoss 	Dice_0	Dice_1	TPR_0	TPR_1
0 	 0.0970 	 0.1185 	0.217	0.217	1.000	1.000
1 	 0.0713 	 0.0958 	0.291	0.291	0.996	0.996
2 	 0.0649 	 0.2128 	0.312	0.312	0.331	0.331
3 	 0.0592 	 0.0974 	0.587	0.587	0.737	0.737
4 	 0.0528 	 0.0688 	0.568	0.568	0.891	0.891
5 	 0.0645 	 0.0595 	0.467	0.467	0.943	0.943
6 	 0.0477 	 0.0438 	0.529	0.529	0.974	0.974
7 	 0.0522 	 0.1171 	0.500	0.500	0.926	0.926
8 	 0.0468 	 0.1619 	0.545	0.545	0.788	0.788
9 	 0.0458 	 0.0836 	0.575	0.575	0.896	0.896
10 	 0.0440 	 0.0544 	0.545	0.545	0.944	0.944
11 	 0.0425 	 0.0421 	0.511	0.511	0.980	0.980
12 	 0.0431 	 0.0448 	0.560	0.560	0.973	0.973
13 	 0.0422 	 0.0399 	0.559	0.559	0.972	0.972
14 	 0.0384 	 0.0389 	0.616	0.616	0.959	0.959
15 	 0.0396 	 0.0299 	0.542	0.542	0.992	0.992
16 	 0.0564 	 0.2572 	0.508	0.508	0.828	0.828
17 	 0.0505 	 0.1482 	0.534	0.534	0.921	0.921
18 	 0.0475 	 0.0941 	0.565	0.565	0.931	0.931
19 	 0.0444 	 0.0559 	0.531	0.531	0.969	0.969
20 	 0.0453 	 0.0541 	0.534	0.534	0.960	0.960
21 	 0.0392 	 0.0538 	0.600	0.600	0.935	0.935
22 	 0.0378 	 0.0362 	0.582	0.582	0.961	0.961
23 	 0.0377 	 0.0593 	0.521	0.521	0.948	0.948
24 	 0.0358 	 0.0476 	0.589	0.589	0.955	0.955
25 	 0.0457 	 0.1787 	0.513	0.513	0.912	0.912
26 	 0.0452 	 0.0485 	0.502	0.502	0.980	0.980
27 	 0.0399 	 0.0443 	0.531	0.531	0.976	0.976
28 	 0.0463 	 0.0634 	0.568	0.568	0.934	0.934
29 	 0.0427 	 0.0405 	0.589	0.589	0.973	0.973
30 	 0.0372 	 0.0445 	0.524	0.524	0.973	0.973
31 	 0.0364 	 0.0371 	0.582	0.582	0.974	0.974
32 	 0.0347 	 0.0447 	0.611	0.611	0.952	0.952
33 	 0.0352 	 0.0662 	0.576	0.576	0.942	0.942
34 	 0.0397 	 0.0337 	0.588	0.588	0.979	0.979
35 	 0.0349 	 0.0588 	0.576	0.576	0.953	0.953
36 	 0.0332 	 0.0556 	0.586	0.586	0.949	0.949
37 	 0.0345 	 0.0932 	0.581	0.581	0.953	0.953
38 	 0.0318 	 0.0616 	0.618	0.618	0.934	0.934
39 	 0.0352 	 0.0466 	0.601	0.601	0.968	0.968
40 	 0.0319 	 0.0701 	0.680	0.680	0.913	0.913
41 	 0.0349 	 0.0638 	0.610	0.610	0.942	0.942
42 	 0.0324 	 0.0715 	0.624	0.624	0.961	0.961
43 	 0.0299 	 0.0452 	0.609	0.609	0.971	0.971
44 	 0.0333 	 0.0369 	0.571	0.571	0.976	0.976
45 	 0.0367 	 0.0432 	0.513	0.513	0.976	0.976
46 	 0.0315 	 0.0417 	0.561	0.561	0.988	0.988
47 	 0.0287 	 0.0420 	0.601	0.601	0.970	0.970
48 	 0.0299 	 0.0338 	0.627	0.627	0.981	0.981
49 	 0.0295 	 0.0426 	0.621	0.621	0.968	0.968
50 	 0.0287 	 0.0362 	0.610	0.610	0.980	0.980
51 	 0.0267 	 0.0331 	0.647	0.647	0.974	0.974
52 	 0.0298 	 0.0564 	0.593	0.593	0.965	0.965
53 	 0.0277 	 0.0508 	0.611	0.611	0.960	0.960
54 	 0.0274 	 0.0533 	0.606	0.606	0.965	0.965
55 	 0.0289 	 0.0468 	0.630	0.630	0.971	0.971
56 	 0.0289 	 0.0484 	0.650	0.650	0.963	0.963
57 	 0.0281 	 0.0520 	0.642	0.642	0.955	0.955
58 	 0.0279 	 0.0537 	0.618	0.618	0.967	0.967
59 	 0.0294 	 0.0668 	0.587	0.587	0.952	0.952
60 	 0.0277 	 0.0594 	0.609	0.609	0.949	0.949
