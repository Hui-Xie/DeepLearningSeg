Program ID of SkyWatcher Network training:20579

Program command: 
 ['TrainSkyWatcher.py', '/home/hxie1/temp_netParameters/OvarianCancer/SkyWatcher', '/home/hxie1/data/OvarianCancerCT/Extract_ps2_2_5/images_npy', '/home/hxie1/data/OvarianCancerCT/Extract_ps2_2_5/labels_npy', '/home/hxie1/data/OvarianCancerCT/patientResponseDict.json']

Major program changes: 
                      along deeper layer, increase filter number.
                      10 fold cross validation, 0 fold for test.
                      data partition with patient ID, instead of VOI.
                      in image3dResponseDataMgr, random Crop ROI in the fly.
                      erase normalization layers  in the fully connected layers.
                      Crop ROI around the mass center in each labeled slice. 
                      use reSampleForSameDistribution in training set, but keep original ditribution in the test set
                      First implement 1000 epochs in the segmentation path, and then freeze the encoder and decoder, only train the ResponseBranch.  
                      epoch < 1000, the loss is pure segmentation loss;
                      epoch >= 1000, the loss is pure response loss with reinitialized learning rate 1e-3.
                      add FC layer width = 980.
                      Add dropout at Fully connected layer with dropout rate of 50%. 
                                                    
 
Discarded changes:                      
                      training response branch per 5 epoch after epoch 100, while continuing train the segmenation branch.
                      which means that before epoch 100, the accuray data is a mess.
                      Add L2 norm regularization in Adam optimizer with weight 5e-4.      
                      

Experiment setting for Image3d ROI to response:
Input CT data: 29*140*140  3D CT raw image ROI with spacing size(5*2*2)
segmentation label: 23*127*127 with spacing size(5*2*2) segmentation label with value (0,1,2) which erases lymph node label

This is a multi-task learning. 

Predictive Model: 1,  first 3-layer dense conv block with channel size 128.
                  2,  and 3 dense conv DownBB blocks,  each of which includes a stride 2 conv and 3-layers dense conv block; 
                  3,  and 3 fully connected layers  changes the tensor into size 2*1;
                  4,  final a softmax for binary classification;
                  Total network learning parameters are 8 million.
                  Network architecture is referred at https://github.com/Hui-Xie/OvarianCancer/blob/master/SkyWatcherModel.py

response Loss Function:   focus loss  with weight [3.3, 1.4] for [0,1] class separately, as [0,1] uneven distribution.
segmentation loss function: focus loss  with weight [1.0416883685076772, 39.37007874015748, 68.39945280437757] for label (0, 1, 2)

Data:   training data has 113 patients, and valdiation data has 27 patients with training/test rate 80/20.
        We randomize all data, and then assign same distrubtion of treat reponse 0,1 into to training and test data set.
        

Training strategy:  50% probability of data are mixed up with beta distribution with alpha =0.4, to feed into network for training. 
                    No other data augmentation, and no dropout.  

                    Learning Scheduler:  Reduce learning rate on  plateau, and learning rate patience is 30 epochs.                                

            

Program starting Time: 2019-07-02 11:35:37.738403
Info: this is the 0th fold leave for test in the 10-fold cross-validation.

Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SkyWatcher

Now program get 169 input files.
Infor: In all data of 169 files, respone 0 has 51 files,
	  and response 1 has 118 files, where positive response rate = 0.6982248520710059 in full data
Infor: Validation Set has 16 files,and Training Set has 153 files
Infor: Validataion set has 11 1's, and positive response rate = 0.6875
Infor: trainning set has 107 1's, and positive response rate = 0.6993464052287581
Infor: the drop_last data in the dataMgr may lead the number of validation set and training set less than above number.
Infor: program is in multi samples running model.
TrainTestData Input:  batchSize=9, depth=29, height=140, width=140

Info: the size of bottle neck in the net = (512, 1, 7, 7)

Info: program uses Mixup with alpha=0.4, and mixupProb = 0.5.
Network trains from scratch.
Network has total 23,396,593 parameters.
Infor: Segmentation Cross Entropy Weight: [1.0416883685076772, 39.37007874015748, 68.39945280437757] for label (0, 1, 2)
Info: program will use 3 GPUs.
Loss Functions List: FocalCELoss with weight of 1; 	FocalCELoss with weight of 1; 
when epoch < 1000, only train segmentation, which means response accuracy are meaningless at these epoch.
when epoch >= 1000, only training response branch, which means segmentation accuracy should keep unchange.
Hints: Test Dice_0 is the dice coeff for all non-zero labels
Hints: Test Dice_1 is for primary cancer(green), 	
 test Dice_2 is for metastasis(yellow), 	
 and test Dice_3 is for invaded lymph node(brown).
Hints: Test TPR_0 is the TPR for all non-zero labels
Hints: Test TPR_1 is for primary cancer(green), 	
 TPR_2 is for metastasis(yellow), 	
 and TPR_3 is for invaded lymph node(brown).

Dice is based on all 2D segmented slices in the volume from weak annotation, not real 3D dice.

Hints: Optimal_Result = Yes = 1,  Optimal_Result = No = 0 

Epoch	TrLoss	Dice0	Dice1	Dice2	TPR_0	TPR_1	TPR_2	Accura	TPR_r	TNR_r		TsLoss	Dice0	Dice1	Dice2	TPR_0	TPR_1	TPR_2	Accura	TPR_r	TNR_r
0	1.2020	0.079	0.109	0.000	0.998	0.996	0.000	0.4533	0.5047	0.4019		2.2555	0.103	0.168	0.000	0.999	0.998	0.000	0.3750	0.3636	0.4000
5	0.4651	0.085	0.080	0.063	0.848	0.264	0.828	0.4439	0.4673	0.4206		0.6762	0.119	0.090	0.060	0.933	0.302	0.688	0.6250	0.7273	0.4000
10	0.3776	0.183	0.242	0.130	0.887	0.583	0.722	0.5140	0.6355	0.3925		0.5744	0.235	0.109	0.184	0.948	0.280	0.953	0.6875	0.8182	0.4000
15	0.3282	0.177	0.273	0.134	0.893	0.585	0.817	0.4252	0.4486	0.4019		0.5564	0.247	0.229	0.160	0.924	0.333	0.965	0.4375	0.5455	0.2000
20	0.3129	0.199	0.303	0.142	0.890	0.740	0.668	0.4486	0.4673	0.4299		1.3304	0.285	0.373	0.233	0.971	0.686	0.816	0.3750	0.2727	0.6000
25	0.2786	0.188	0.314	0.135	0.875	0.692	0.749	0.4486	0.5234	0.3738		0.5250	0.290	0.390	0.178	0.970	0.851	0.695	0.5000	0.4545	0.6000
30	0.2446	0.215	0.333	0.143	0.906	0.780	0.734	0.5467	0.6262	0.4673		0.4048	0.256	0.431	0.159	0.981	0.944	0.821	0.6250	0.5455	0.8000
35	0.2514	0.216	0.341	0.154	0.909	0.731	0.773	0.5140	0.5607	0.4673		0.4448	0.334	0.476	0.283	0.746	0.572	0.643	0.5625	0.6364	0.4000
40	0.2375	0.215	0.318	0.165	0.895	0.751	0.758	0.4206	0.4112	0.4299		0.4784	0.262	0.405	0.224	0.913	0.693	0.779	0.3750	0.2727	0.6000
45	0.2220	0.193	0.339	0.146	0.905	0.824	0.785	0.5047	0.4486	0.5607		0.5398	0.349	0.329	0.203	0.866	0.450	0.834	0.5000	0.2727	1.0000
50	0.2411	0.210	0.313	0.158	0.909	0.778	0.747	0.5187	0.5234	0.5140		1.0573	0.321	0.183	0.286	0.671	0.290	0.684	0.3750	0.0909	1.0000
55	0.2119	0.228	0.343	0.164	0.891	0.642	0.792	0.5140	0.4206	0.6075		0.5614	0.298	0.391	0.170	0.852	0.599	0.783	0.3125	0.0909	0.8000
60	0.1988	0.224	0.341	0.174	0.877	0.864	0.723	0.5000	0.5421	0.4579		0.4542	0.283	0.396	0.197	0.846	0.557	0.905	0.1875	0.0000	0.6000
65	0.2180	0.221	0.342	0.172	0.916	0.852	0.750	0.5280	0.5047	0.5514		0.4409	0.269	0.390	0.156	0.975	0.844	0.977	0.4375	0.1818	1.0000
70	0.2274	0.215	0.348	0.171	0.900	0.845	0.753	0.5234	0.4860	0.5607		0.4481	0.249	0.352	0.207	0.900	0.628	0.917	0.3125	0.1818	0.6000
75	0.1869	0.243	0.395	0.160	0.877	0.809	0.748	0.5093	0.4206	0.5981		0.4820	0.287	0.484	0.202	0.942	0.770	0.897	0.3750	0.0909	1.0000
80	0.1879	0.219	0.345	0.167	0.914	0.829	0.806	0.5467	0.4486	0.6449		0.5884	0.282	0.435	0.212	0.933	0.808	0.814	0.3750	0.0909	1.0000
85	0.1880	0.225	0.362	0.167	0.899	0.821	0.780	0.5093	0.3925	0.6262		0.3972	0.317	0.457	0.198	0.888	0.779	0.842	0.1875	0.0000	0.6000
90	0.1589	0.247	0.412	0.186	0.890	0.843	0.808	0.4252	0.3178	0.5327		0.4624	0.296	0.416	0.177	0.927	0.654	0.875	0.3125	0.0000	1.0000
95	0.1684	0.231	0.396	0.173	0.909	0.877	0.798	0.5234	0.4206	0.6262		0.5624	0.295	0.407	0.280	0.899	0.850	0.728	0.3125	0.0000	1.0000
100	0.1728	0.227	0.367	0.178	0.899	0.858	0.771	0.5421	0.4206	0.6636		0.6804	0.294	0.300	0.214	0.897	0.624	0.851	0.3125	0.0000	1.0000
105	0.1519	0.232	0.376	0.181	0.910	0.846	0.816	0.4486	0.3458	0.5514		0.5885	0.253	0.322	0.224	0.846	0.759	0.705	0.3750	0.0909	1.0000
110	0.1427	0.244	0.380	0.191	0.930	0.907	0.849	0.4953	0.3178	0.6729		0.5523	0.309	0.475	0.219	0.939	0.766	0.821	0.3125	0.0000	1.0000
115	0.1349	0.243	0.399	0.175	0.930	0.860	0.874	0.4766	0.4019	0.5514		0.6976	0.364	0.461	0.290	0.927	0.864	0.838	0.2500	0.0000	0.8000
120	0.1472	0.242	0.394	0.181	0.924	0.871	0.848	0.5140	0.4579	0.5701		0.6387	0.376	0.475	0.296	0.851	0.686	0.834	0.3750	0.1818	0.8000
125	0.1398	0.241	0.391	0.182	0.918	0.849	0.856	0.4673	0.3364	0.5981		0.5738	0.361	0.457	0.269	0.924	0.743	0.797	0.4375	0.1818	1.0000
130	0.1521	0.230	0.353	0.185	0.900	0.891	0.811	0.5047	0.4019	0.6075		0.5312	0.318	0.430	0.295	0.849	0.839	0.825	0.3125	0.0000	1.0000
135	0.1347	0.245	0.401	0.186	0.917	0.902	0.831	0.5467	0.4579	0.6355		0.6400	0.340	0.300	0.253	0.868	0.505	0.859	0.3125	0.0000	1.0000
140	0.1311	0.246	0.384	0.178	0.904	0.880	0.831	0.4953	0.3738	0.6168		0.4711	0.279	0.369	0.218	0.933	0.753	0.953	0.3125	0.0000	1.0000
145	0.1427	0.266	0.370	0.197	0.892	0.859	0.811	0.5327	0.4766	0.5888		0.4963	0.302	0.420	0.202	0.909	0.753	0.830	0.3750	0.1818	0.8000
150	0.1289	0.220	0.361	0.168	0.912	0.856	0.863	0.4860	0.4019	0.5701		0.5836	0.273	0.387	0.228	0.919	0.755	0.876	0.3750	0.0909	1.0000
155	0.1680	0.251	0.367	0.165	0.892	0.883	0.757	0.4626	0.4112	0.5140		0.4452	0.312	0.425	0.176	0.915	0.822	0.812	0.3750	0.0909	1.0000
160	0.1160	0.267	0.373	0.207	0.897	0.871	0.819	0.4439	0.3832	0.5047		0.5446	0.326	0.413	0.257	0.895	0.754	0.739	0.3125	0.0000	1.0000
165	0.1183	0.259	0.381	0.184	0.904	0.852	0.831	0.4860	0.4112	0.5607		0.4811	0.337	0.409	0.283	0.933	0.756	0.947	0.3125	0.1818	0.6000
170	0.1099	0.268	0.416	0.207	0.899	0.910	0.832	0.5093	0.3832	0.6355		0.4237	0.356	0.463	0.277	0.926	0.779	0.870	0.3750	0.1818	0.8000
175	0.1178	0.256	0.390	0.198	0.897	0.858	0.863	0.4907	0.4019	0.5794		0.5446	0.322	0.437	0.224	0.885	0.810	0.944	0.1875	0.0000	0.6000
180	0.1054	0.274	0.403	0.206	0.900	0.840	0.862	0.4953	0.3925	0.5981		0.9413	0.320	0.246	0.278	0.854	0.487	0.762	0.2500	0.0000	0.8000
185	0.1017	0.280	0.412	0.214	0.904	0.887	0.851	0.4907	0.3645	0.6168		0.5301	0.334	0.426	0.259	0.879	0.817	0.763	0.3125	0.0000	1.0000
190	0.1152	0.263	0.388	0.203	0.890	0.876	0.827	0.5374	0.4112	0.6636		0.4604	0.332	0.412	0.245	0.971	0.868	0.834	0.3125	0.0909	0.8000
195	0.1027	0.264	0.413	0.193	0.901	0.862	0.854	0.4860	0.3925	0.5794		0.5634	0.389	0.436	0.311	0.876	0.735	0.841	0.3125	0.0000	1.0000
200	0.1025	0.257	0.373	0.202	0.921	0.889	0.865	0.5093	0.3925	0.6262		0.5241	0.358	0.464	0.261	0.845	0.686	0.791	0.1875	0.0909	0.4000
205	0.1002	0.259	0.392	0.196	0.942	0.916	0.899	0.5187	0.4860	0.5514		0.4289	0.332	0.490	0.193	0.952	0.810	0.919	0.3750	0.0909	1.0000
210	0.1055	0.271	0.424	0.205	0.907	0.905	0.856	0.5093	0.4206	0.5981		0.4035	0.318	0.417	0.251	0.967	0.782	0.950	0.5000	0.2727	1.0000
215	0.1056	0.286	0.397	0.218	0.882	0.894	0.798	0.4720	0.4112	0.5327		0.5173	0.326	0.438	0.239	0.930	0.820	0.841	0.3750	0.0909	1.0000
220	0.0876	0.279	0.400	0.226	0.916	0.898	0.876	0.4720	0.4112	0.5327		0.3316	0.320	0.423	0.281	0.918	0.852	0.796	0.3750	0.2727	0.6000
225	0.0947	0.278	0.409	0.202	0.941	0.940	0.874	0.4720	0.3364	0.6075		0.3381	0.321	0.502	0.237	0.909	0.822	0.852	0.5000	0.3636	0.8000
230	0.0856	0.272	0.404	0.216	0.904	0.873	0.874	0.5234	0.4486	0.5981		0.4995	0.333	0.380	0.235	0.941	0.605	0.950	0.4375	0.1818	1.0000
235	0.1004	0.251	0.365	0.189	0.930	0.845	0.870	0.4626	0.4019	0.5234		0.4289	0.334	0.443	0.245	0.865	0.797	0.817	0.3750	0.0909	1.0000
240	0.1073	0.262	0.410	0.202	0.908	0.850	0.856	0.4626	0.3738	0.5514		0.4107	0.276	0.447	0.179	0.966	0.842	0.933	0.5625	0.3636	1.0000
245	0.0938	0.287	0.388	0.235	0.910	0.886	0.870	0.5047	0.4299	0.5794		0.3770	0.347	0.402	0.220	0.944	0.725	0.904	0.5625	0.3636	1.0000
250	0.0952	0.285	0.422	0.201	0.894	0.862	0.838	0.5000	0.3925	0.6075		0.3859	0.400	0.478	0.327	0.910	0.848	0.858	0.3750	0.0909	1.0000
255	0.0871	0.277	0.422	0.215	0.887	0.896	0.833	0.5047	0.4019	0.6075		0.4469	0.383	0.466	0.242	0.872	0.743	0.859	0.3750	0.1818	0.8000
260	0.0827	0.274	0.408	0.208	0.895	0.882	0.853	0.4579	0.4953	0.4206		0.5555	0.346	0.372	0.231	0.936	0.701	0.933	0.3750	0.0909	1.0000
265	0.0699	0.285	0.407	0.220	0.904	0.918	0.865	0.4626	0.3738	0.5514		0.4389	0.354	0.403	0.288	0.894	0.828	0.837	0.3125	0.0000	1.0000
270	0.0805	0.256	0.399	0.200	0.948	0.925	0.914	0.5000	0.4206	0.5794		0.4451	0.340	0.428	0.250	0.927	0.865	0.777	0.3750	0.1818	0.8000
275	0.0910	0.280	0.414	0.216	0.933	0.903	0.891	0.4813	0.4486	0.5140		0.5515	0.401	0.449	0.358	0.889	0.788	0.921	0.3125	0.0909	0.8000
280	0.0834	0.289	0.422	0.216	0.916	0.876	0.857	0.4860	0.4393	0.5327		0.3884	0.366	0.437	0.284	0.956	0.943	0.834	0.4375	0.1818	1.0000
285	0.0850	0.271	0.423	0.207	0.936	0.933	0.910	0.4860	0.3458	0.6262		0.4654	0.291	0.362	0.219	0.880	0.722	0.887	0.3125	0.0000	1.0000
290	0.0732	0.293	0.417	0.224	0.934	0.923	0.878	0.4813	0.3551	0.6075		0.6998	0.340	0.427	0.226	0.954	0.825	0.977	0.3125	0.0909	0.8000
295	0.0873	0.285	0.447	0.203	0.939	0.907	0.891	0.4860	0.4673	0.5047		0.4789	0.365	0.463	0.254	0.934	0.701	0.893	0.4375	0.1818	1.0000
300	0.0991	0.272	0.391	0.206	0.918	0.878	0.872	0.4907	0.3925	0.5888		0.4662	0.356	0.459	0.302	0.902	0.831	0.899	0.3750	0.0909	1.0000
305	0.0809	0.290	0.423	0.217	0.928	0.921	0.886	0.5047	0.3832	0.6262		0.7655	0.297	0.317	0.213	0.884	0.628	0.984	0.3125	0.0000	1.0000
310	0.0762	0.288	0.401	0.232	0.919	0.910	0.867	0.4860	0.3738	0.5981		0.6305	0.370	0.365	0.286	0.860	0.635	0.858	0.5000	0.2727	1.0000
315	0.0854	0.287	0.412	0.214	0.924	0.918	0.862	0.5280	0.4299	0.6262		0.4295	0.346	0.430	0.317	0.868	0.736	0.934	0.3750	0.0909	1.0000
320	0.0650	0.311	0.450	0.247	0.928	0.923	0.889	0.4813	0.3645	0.5981		0.6014	0.369	0.446	0.279	0.911	0.744	0.971	0.3125	0.0909	0.8000
325	0.1030	0.263	0.400	0.201	0.920	0.896	0.851	0.4626	0.3925	0.5327		0.5520	0.370	0.398	0.270	0.966	0.738	0.936	0.5000	0.2727	1.0000
330	0.0655	0.304	0.419	0.242	0.909	0.925	0.864	0.5000	0.4673	0.5327		0.4741	0.307	0.489	0.170	0.914	0.744	0.936	0.2500	0.0000	0.8000
335	0.0784	0.305	0.445	0.238	0.933	0.915	0.896	0.5234	0.3832	0.6636		0.4342	0.359	0.502	0.229	0.924	0.739	0.860	0.2500	0.0000	0.8000
340	0.0716	0.280	0.406	0.218	0.955	0.943	0.885	0.4860	0.4019	0.5701		0.4642	0.361	0.488	0.219	0.926	0.854	0.867	0.2500	0.0909	0.6000
345	0.0715	0.290	0.414	0.225	0.937	0.917	0.903	0.4813	0.4299	0.5327		0.4629	0.346	0.408	0.258	0.928	0.808	0.879	0.3750	0.1818	0.8000
350	0.0777	0.276	0.418	0.202	0.942	0.950	0.899	0.5748	0.5701	0.5794		0.5153	0.368	0.418	0.292	0.860	0.747	0.956	0.2500	0.0000	0.8000
355	0.0654	0.308	0.432	0.237	0.918	0.911	0.881	0.5140	0.4019	0.6262		0.6682	0.393	0.376	0.341	0.823	0.627	0.785	0.5000	0.2727	1.0000
360	0.0616	0.311	0.433	0.244	0.911	0.910	0.861	0.5280	0.4486	0.6075		0.5652	0.377	0.417	0.236	0.896	0.782	0.954	0.4375	0.1818	1.0000
365	0.0732	0.292	0.418	0.226	0.926	0.881	0.895	0.4953	0.4019	0.5888		0.4813	0.342	0.412	0.284	0.937	0.881	0.834	0.3125	0.0000	1.0000
370	0.0743	0.298	0.409	0.235	0.940	0.921	0.896	0.5234	0.4112	0.6355		0.4057	0.367	0.435	0.304	0.868	0.791	0.873	0.3750	0.0909	1.0000
375	0.0574	0.327	0.469	0.246	0.917	0.923	0.873	0.5000	0.4112	0.5888		0.8327	0.329	0.334	0.305	0.733	0.546	0.775	0.3125	0.0000	1.0000
380	0.0672	0.290	0.408	0.223	0.928	0.914	0.886	0.4346	0.3645	0.5047		0.5100	0.371	0.466	0.252	0.952	0.905	0.903	0.3750	0.0909	1.0000
385	0.0694	0.309	0.442	0.237	0.917	0.908	0.866	0.5280	0.4953	0.5607		0.8660	0.393	0.392	0.309	0.931	0.698	0.919	0.2500	0.0909	0.6000
390	0.0592	0.318	0.430	0.246	0.924	0.890	0.894	0.4813	0.4019	0.5607		0.6496	0.320	0.352	0.247	0.864	0.649	0.853	0.3750	0.1818	0.8000
395	0.0648	0.311	0.410	0.251	0.923	0.926	0.865	0.5093	0.4393	0.5794		0.4584	0.369	0.438	0.347	0.960	0.949	0.944	0.3750	0.1818	0.8000
400	0.0663	0.291	0.423	0.224	0.935	0.910	0.888	0.5280	0.4206	0.6355		0.4734	0.360	0.423	0.292	0.888	0.704	0.873	0.3750	0.0909	1.0000
405	0.0610	0.316	0.449	0.250	0.938	0.935	0.910	0.4439	0.2897	0.5981		0.9645	0.343	0.259	0.246	0.792	0.469	0.815	0.3125	0.0909	0.8000
410	0.0778	0.281	0.410	0.215	0.934	0.879	0.891	0.4813	0.3832	0.5794		0.4707	0.341	0.411	0.289	0.940	0.744	0.844	0.2500	0.0909	0.6000
415	0.0611	0.314	0.457	0.233	0.938	0.936	0.875	0.4953	0.3925	0.5981		0.6524	0.347	0.406	0.289	0.898	0.725	0.955	0.3125	0.1818	0.6000
420	0.0691	0.330	0.459	0.250	0.906	0.940	0.836	0.4626	0.3832	0.5421		0.8512	0.339	0.232	0.280	0.870	0.585	0.825	0.2500	0.0909	0.6000
425	0.0659	0.314	0.457	0.237	0.914	0.924	0.869	0.4486	0.4019	0.4953		0.5429	0.356	0.447	0.244	0.934	0.802	0.854	0.2500	0.0000	0.8000
430	0.0670	0.310	0.424	0.247	0.905	0.876	0.882	0.4953	0.4019	0.5888		0.8018	0.328	0.289	0.234	0.948	0.562	0.903	0.3125	0.1818	0.6000
435	0.0565	0.324	0.453	0.257	0.949	0.914	0.931	0.5327	0.3551	0.7103		0.3988	0.319	0.424	0.239	0.932	0.819	0.832	0.3125	0.0909	0.8000
440	0.0616	0.315	0.431	0.256	0.937	0.913	0.921	0.5374	0.4112	0.6636		0.4165	0.368	0.510	0.250	0.916	0.849	0.856	0.3125	0.1818	0.6000
445	0.0571	0.300	0.422	0.249	0.949	0.918	0.937	0.4626	0.3925	0.5327		0.4299	0.377	0.441	0.291	0.880	0.797	0.879	0.3125	0.0909	0.8000
450	0.0609	0.321	0.446	0.243	0.932	0.920	0.875	0.4860	0.4860	0.4860		0.7867	0.391	0.330	0.283	0.933	0.609	0.895	0.3750	0.0909	1.0000
455	0.0543	0.307	0.435	0.237	0.930	0.935	0.898	0.5000	0.4393	0.5607		0.3680	0.387	0.453	0.270	0.893	0.749	0.726	0.3750	0.1818	0.8000
460	0.0705	0.312	0.440	0.247	0.930	0.935	0.882	0.4720	0.3925	0.5514		0.3855	0.379	0.472	0.309	0.893	0.854	0.828	0.4375	0.2727	0.8000
465	0.0543	0.310	0.442	0.239	0.927	0.914	0.895	0.4860	0.4579	0.5140		0.3490	0.329	0.399	0.264	0.792	0.759	0.840	0.4375	0.2727	0.8000
470	0.0594	0.311	0.430	0.238	0.938	0.945	0.905	0.5467	0.5234	0.5701		0.4994	0.379	0.463	0.287	0.880	0.718	0.822	0.5000	0.3636	0.8000
475	0.0740	0.318	0.442	0.248	0.931	0.926	0.883	0.5047	0.4579	0.5514		0.4308	0.337	0.511	0.248	0.842	0.812	0.721	0.3750	0.0909	1.0000
480	0.0586	0.327	0.475	0.242	0.937	0.930	0.905	0.5000	0.3925	0.6075		0.5997	0.397	0.399	0.270	0.907	0.746	0.869	0.3750	0.3636	0.4000
485	0.0555	0.326	0.441	0.261	0.964	0.962	0.936	0.4626	0.3645	0.5607		0.4510	0.374	0.442	0.344	0.927	0.849	0.868	0.2500	0.0909	0.6000
490	0.0494	0.331	0.447	0.270	0.939	0.931	0.910	0.5093	0.4206	0.5981		0.5152	0.394	0.456	0.316	0.807	0.742	0.765	0.4375	0.1818	1.0000
495	0.0550	0.337	0.486	0.257	0.931	0.949	0.878	0.4953	0.3178	0.6729		0.5195	0.342	0.479	0.243	0.853	0.808	0.731	0.4375	0.2727	0.8000
500	0.0533	0.318	0.415	0.270	0.938	0.936	0.914	0.4486	0.3832	0.5140		0.6716	0.379	0.449	0.310	0.863	0.747	0.863	0.2500	0.0000	0.8000
505	0.0487	0.334	0.476	0.256	0.954	0.924	0.939	0.5280	0.4206	0.6355		0.6013	0.379	0.413	0.312	0.884	0.729	0.952	0.2500	0.0909	0.6000
510	0.0486	0.348	0.500	0.278	0.933	0.939	0.897	0.4953	0.3925	0.5981		0.7042	0.410	0.467	0.318	0.889	0.728	0.819	0.4375	0.1818	1.0000
515	0.0493	0.342	0.462	0.279	0.932	0.951	0.899	0.4907	0.4299	0.5514		0.5347	0.394	0.500	0.268	0.918	0.866	0.862	0.2500	0.1818	0.4000
520	0.0602	0.338	0.455	0.267	0.937	0.918	0.879	0.4626	0.4112	0.5140		0.3992	0.326	0.448	0.250	0.888	0.918	0.851	0.4375	0.2727	0.8000
525	0.0458	0.346	0.448	0.283	0.930	0.887	0.917	0.4953	0.4206	0.5701		0.5925	0.410	0.486	0.312	0.791	0.766	0.727	0.3750	0.0909	1.0000
530	0.0471	0.332	0.447	0.261	0.955	0.936	0.904	0.5514	0.5421	0.5607		0.4933	0.415	0.529	0.280	0.890	0.824	0.763	0.2500	0.0909	0.6000
535	0.0502	0.345	0.432	0.267	0.954	0.930	0.922	0.5421	0.4953	0.5888		0.4667	0.401	0.486	0.295	0.915	0.925	0.841	0.5625	0.4545	0.8000
540	0.0493	0.341	0.456	0.277	0.957	0.917	0.936	0.4533	0.4112	0.4953		0.4134	0.393	0.560	0.283	0.918	0.769	0.906	0.4375	0.1818	1.0000
545	0.0482	0.346	0.459	0.288	0.932	0.906	0.920	0.5654	0.5047	0.6262		0.2942	0.352	0.530	0.232	0.871	0.820	0.821	0.4375	0.1818	1.0000
550	0.0496	0.344	0.463	0.264	0.946	0.953	0.903	0.4907	0.4206	0.5607		0.3905	0.425	0.501	0.314	0.904	0.829	0.843	0.5000	0.2727	1.0000
555	0.0474	0.355	0.473	0.285	0.943	0.948	0.896	0.5654	0.5234	0.6075		0.4702	0.376	0.412	0.273	0.845	0.587	0.853	0.5000	0.3636	0.8000
560	0.0476	0.349	0.457	0.284	0.956	0.956	0.935	0.5374	0.4766	0.5981		0.4555	0.370	0.409	0.311	0.868	0.743	0.822	0.3125	0.1818	0.6000
565	0.0473	0.348	0.453	0.279	0.943	0.909	0.922	0.5374	0.4486	0.6262		0.4074	0.437	0.539	0.284	0.860	0.794	0.695	0.3750	0.1818	0.8000
570	0.0514	0.337	0.450	0.270	0.939	0.967	0.893	0.5234	0.4393	0.6075		0.3816	0.374	0.514	0.260	0.906	0.838	0.860	0.3125	0.2727	0.4000
575	0.0462	0.344	0.488	0.276	0.944	0.944	0.927	0.5654	0.5421	0.5888		0.3956	0.370	0.567	0.255	0.843	0.808	0.767	0.3750	0.2727	0.6000
580	0.0496	0.350	0.456	0.287	0.945	0.940	0.920	0.5000	0.4393	0.5607		0.6950	0.419	0.434	0.324	0.895	0.744	0.826	0.3750	0.1818	0.8000
585	0.0454	0.343	0.447	0.284	0.948	0.960	0.913	0.4720	0.4019	0.5421		0.6456	0.376	0.449	0.273	0.842	0.610	0.776	0.4375	0.1818	1.0000
590	0.0478	0.350	0.499	0.266	0.956	0.979	0.908	0.4813	0.4579	0.5047		0.3439	0.378	0.420	0.292	0.811	0.765	0.764	0.5625	0.3636	1.0000
595	0.0448	0.348	0.472	0.278	0.937	0.955	0.917	0.4720	0.3925	0.5514		0.3927	0.390	0.480	0.318	0.783	0.850	0.648	0.3750	0.2727	0.6000
600	0.0533	0.324	0.442	0.250	0.957	0.942	0.917	0.4626	0.3084	0.6168		0.5135	0.411	0.443	0.273	0.876	0.720	0.833	0.2500	0.0909	0.6000
605	0.0386	0.366	0.482	0.292	0.947	0.939	0.920	0.4907	0.4393	0.5421		0.5609	0.383	0.356	0.288	0.847	0.618	0.849	0.2500	0.0909	0.6000
610	0.0459	0.356	0.462	0.287	0.937	0.942	0.898	0.4065	0.3178	0.4953		0.3866	0.373	0.438	0.307	0.905	0.809	0.880	0.4375	0.1818	1.0000
615	0.0647	0.339	0.471	0.277	0.942	0.921	0.909	0.4907	0.4299	0.5514		1.0837	0.365	0.260	0.285	0.951	0.565	0.945	0.2500	0.0000	0.8000
620	0.0474	0.341	0.450	0.284	0.936	0.909	0.921	0.5093	0.4860	0.5327		0.7379	0.388	0.383	0.283	0.870	0.618	0.814	0.3125	0.0000	1.0000
