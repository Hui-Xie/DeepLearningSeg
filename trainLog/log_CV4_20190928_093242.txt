=============training from sratch============
Program ID: 1781

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy', '4', '3,2,1']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      
      
         

Discarded changes:                  

Experiment setting:
Input CT data: 51*171*171 ROI around primary cancer

Loss Function:  SoftMax

Data:   total 36 patients with 50-80% label, 6-fold cross validation, test 6, validation 6, and training 24.  
    script: python3.7 statisticsLabelFiles.py 
    Total 36 in /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
    0 has 48159408 elements, with a rate of  0.8970491562903105 
    1 has 5527068 elements, with a rate of  0.10295084370968957

Training strategy: 

          

Program starting Time: 2019-09-28 09:32:42.845276
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190928_093242

Info: this is the 4th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 6

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190928_093242.
6-fold cross validation: the 4th fold is for test, the 5th fold is for validation, remaining folds are for training.

training dataset: total 24 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Total 24 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
0 has 32276114 elements, with a rate of  0.9017945413291795 
1 has 3514870 elements, with a rate of  0.09820545867082056 
loss weight = tensor([1.0000, 9.1827])
Network has total 73,047,746 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		60.9678		0.04028		5268.1001		0.00000		5337.4844		0.00000
5	1.0000e-02		8.2341		0.41231		12.8869		0.44587		12.5317		0.27780
10	1.0000e-02		6.0546		0.48428		12.3131		0.42609		13.4619		0.34815
15	1.0000e-02		6.5115		0.53202		6.6639		0.54340		7.6848		0.45082
20	1.0000e-02		4.9172		0.56317		6.3158		0.59520		6.8334		0.51666
25	1.0000e-02		4.9657		0.52315		6.0452		0.61981		6.1567		0.52972
30	1.0000e-02		5.1652		0.49983		7.0263		0.62714		6.3923		0.53143
35	1.0000e-02		4.5933		0.58321		5.0003		0.62494		5.8134		0.51559
40	1.0000e-02		5.0559		0.56827		6.2483		0.53001		8.4019		0.43885
45	1.0000e-02		4.7113		0.59745		6.5247		0.64701		6.2477		0.56268
50	1.0000e-02		4.7692		0.55943		6.1495		0.61397		6.7861		0.49939
55	1.0000e-02		4.6291		0.54509		6.1365		0.58885		8.3866		0.48978
60	1.0000e-02		4.9455		0.56304		5.8000		0.64619		6.8486		0.50233
65	1.0000e-02		5.9627		0.56500		5.3960		0.63498		5.2740		0.56185
70	1.0000e-02		4.2057		0.58714		8.3663		0.62191		6.5937		0.57476
75	1.0000e-02		4.7304		0.55567		5.5833		0.60133		5.7512		0.49023
80	1.0000e-02		5.7463		0.56231		6.6914		0.56352		7.5934		0.43727
85	1.0000e-02		5.4316		0.52880		6.6144		0.57147		7.0324		0.51399
90	1.0000e-03		3.9462		0.58509		5.6112		0.64970		5.0152		0.58916
95	1.0000e-03		4.2663		0.59895		5.3811		0.64285		5.2963		0.56921
100	1.0000e-03		3.5277		0.60042		5.7530		0.63746		5.9156		0.56569
105	1.0000e-03		4.1489		0.59826		5.7516		0.65103		5.7507		0.58245
110	1.0000e-03		4.4987		0.60098		5.4039		0.64656		5.8692		0.55946
115	1.0000e-03		4.0016		0.66022		5.4133		0.66028		5.8809		0.56472
120	1.0000e-03		3.7163		0.64796		5.5335		0.67521		6.1798		0.57562
125	1.0000e-03		3.0976		0.60046		5.0396		0.65343		6.0511		0.55123
130	1.0000e-03		3.7023		0.63845		5.1340		0.66981		6.2717		0.56985
135	1.0000e-03		3.2971		0.61228		4.9841		0.66741		5.8465		0.57696
140	1.0000e-03		2.6999		0.64836		5.4404		0.66434		6.1237		0.58498
145	1.0000e-03		4.3251		0.63778		4.7996		0.64902		5.8211		0.56215
150	1.0000e-03		3.4143		0.64129		5.2153		0.67886		5.9043		0.59501
155	1.0000e-03		3.0733		0.64434		5.1905		0.65607		6.2851		0.57805
160	1.0000e-03		3.0748		0.67034		5.2308		0.65018		6.3997		0.56495
165	1.0000e-03		2.7601		0.67310		5.5565		0.68801		6.4874		0.58499
170	1.0000e-03		3.5502		0.65670		5.2852		0.65510		6.2444		0.56716
175	1.0000e-03		2.9791		0.64423		5.3861		0.67645		6.5311		0.57251
180	1.0000e-03		2.7664		0.64318		4.9164		0.67181		6.6364		0.56305
185	1.0000e-03		3.5883		0.65068		4.8222		0.67992		6.1105		0.56440
190	1.0000e-03		2.8886		0.67179		4.5966		0.68098		6.3859		0.56939
195	1.0000e-03		2.7528		0.67240		5.1427		0.65769		6.6195		0.55229
200	1.0000e-03		3.2286		0.67713		5.0493		0.66103		6.3570		0.56939
205	1.0000e-03		2.7171		0.68545		5.5326		0.67389		7.5588		0.54284
210	1.0000e-03		2.8308		0.67960		6.0338		0.67607		6.8000		0.58188
215	1.0000e-03		2.7366		0.66984		5.3081		0.68244		7.9289		0.53372
220	1.0000e-03		2.5310		0.67189		4.6243		0.65451		7.2569		0.53215
225	1.0000e-03		3.0108		0.67550		5.2508		0.68994		7.4317		0.57118
230	1.0000e-03		2.8329		0.61081		5.8067		0.64014		7.0963		0.52677
235	1.0000e-03		2.8295		0.67134		6.0706		0.66570		7.6991		0.57240
240	1.0000e-03		2.3246		0.67801		5.7645		0.65602		8.0771		0.52568
245	1.0000e-04		3.4270		0.64704		4.8344		0.67033		6.9035		0.55787
250	1.0000e-04		2.5211		0.67105		4.9326		0.68181		7.2395		0.55427
255	1.0000e-04		3.1238		0.66221		5.4800		0.68564		7.8118		0.54771
260	1.0000e-04		2.2364		0.68373		5.0522		0.67811		6.9398		0.56137
265	1.0000e-04		2.4399		0.70078		5.3519		0.68382		7.1680		0.56484
270	1.0000e-04		2.2528		0.67167		5.0551		0.67877		7.0543		0.56334
275	1.0000e-04		2.4457		0.70458		5.3564		0.67649		7.0074		0.56468
280	1.0000e-04		2.5861		0.71357		5.8060		0.68386		7.4913		0.55766
285	1.0000e-04		2.4013		0.68728		5.8552		0.65350		6.8292		0.55076
290	1.0000e-04		2.5873		0.69587		5.4800		0.66290		7.2063		0.53640
295	1.0000e-04		2.5921		0.67970		5.2568		0.65888		7.1992		0.54050
300	1.0000e-05		2.5408		0.67492		4.9829		0.69072		7.1355		0.55110
305	1.0000e-05		2.1708		0.69117		5.1749		0.67487		7.2493		0.55027
310	1.0000e-05		2.6743		0.69717		5.2637		0.68483		7.6764		0.54202
315	1.0000e-05		2.3629		0.69920		5.1363		0.67508		7.5435		0.54278
320	1.0000e-05		2.4028		0.72450		5.2353		0.66856		7.3915		0.54378
325	1.0000e-05		2.7311		0.68357		5.0998		0.67302		7.7668		0.53942
330	1.0000e-05		2.7813		0.67849		5.0784		0.68696		7.3162		0.54913
335	1.0000e-05		2.2475		0.67661		5.0703		0.67662		7.2211		0.54176
340	1.0000e-05		2.3311		0.70543		5.3921		0.67884		7.4329		0.54297
345	1.0000e-05		2.4497		0.70227		5.3755		0.68045		7.3612		0.54941
350	1.0000e-05		2.2406		0.70216		5.4524		0.68571		7.5243		0.54645
355	1.0000e-06		2.6214		0.69359		5.2808		0.67193		7.7533		0.53964
360	1.0000e-06		2.3221		0.71855		5.3979		0.67765		7.5057		0.53934
365	1.0000e-06		2.3862		0.69552		5.2854		0.67245		7.7203		0.53615
370	1.0000e-06		2.6011		0.66693		5.8008		0.64608		7.2513		0.54029
375	1.0000e-06		3.2835		0.67130		5.6329		0.66809		7.2711		0.54528
380	1.0000e-06		2.3166		0.68664		5.2530		0.68048		7.5291		0.53979
385	1.0000e-06		2.2860		0.70482		5.2572		0.68943		7.6127		0.54885
390	1.0000e-06		2.7426		0.68898		5.2897		0.67894		7.3072		0.55130
395	1.0000e-06		2.5472		0.69043		5.2998		0.67860		7.7290		0.54442
400	1.0000e-06		2.5376		0.67755		5.2437		0.67567		7.6036		0.54240
405	1.0000e-06		2.4136		0.69730		5.0360		0.66917		7.6889		0.53925
410	1.0000e-07		2.4524		0.69390		5.4196		0.68055		7.4584		0.54395
415	1.0000e-07		2.4516		0.69865		5.1190		0.68342		7.2999		0.54889
420	1.0000e-07		2.3199		0.67733		5.3721		0.67060		7.4801		0.54197
425	1.0000e-07		2.3706		0.69312		5.2307		0.67192		7.3614		0.54794
430	1.0000e-07		2.7715		0.66399		5.5978		0.65584		8.0106		0.52855
435	1.0000e-07		2.6606		0.69287		5.2095		0.67494		7.7530		0.53977
440	1.0000e-07		2.1872		0.70437		5.2688		0.68014		7.6921		0.54355
445	1.0000e-07		2.9986		0.70178		5.3373		0.67171		7.6202		0.54252
450	1.0000e-07		2.5233		0.71275		5.2005		0.68185		7.7663		0.53510
455	1.0000e-07		2.5373		0.69236		5.2691		0.67243		7.6743		0.54335
460	1.0000e-07		2.5924		0.67884		5.4715		0.66887		7.7314		0.53943
465	1.0000e-08		2.4018		0.68158		5.5434		0.67131		7.4491		0.55138
470	1.0000e-08		2.4097		0.70403		5.6233		0.67468		7.6884		0.54449
475	1.0000e-08		2.6329		0.68169		5.6359		0.65293		7.4828		0.54241
480	1.0000e-08		2.4592		0.68641		5.4598		0.67853		7.2875		0.54552
485	1.0000e-08		2.6695		0.71038		5.3948		0.68086		7.7804		0.54189
490	1.0000e-08		2.5575		0.67045		5.4078		0.66139		7.6525		0.53879
495	1.0000e-08		2.4021		0.71470		5.2847		0.67392		7.6200		0.54057
500	1.0000e-08		2.2791		0.70483		5.2158		0.67709		7.3224		0.54369
505	1.0000e-08		2.3215		0.65593		5.6529		0.66659		7.1566		0.54920
510	1.0000e-08		2.3264		0.68453		5.4546		0.66442		7.4290		0.54323
515	1.0000e-08		2.7210		0.69219		5.4688		0.65767		7.9420		0.53292
520	1.0000e-08		2.7438		0.68970		5.5149		0.66650		7.4747		0.54212
525	1.0000e-08		2.4762		0.67317		5.3544		0.68047		7.3695		0.54713
530	1.0000e-08		2.5024		0.68430		5.5850		0.67141		7.4015		0.55165
535	1.0000e-08		2.5421		0.68066		5.9907		0.65201		7.0561		0.55521
540	1.0000e-08		2.2405		0.68835		5.5781		0.66906		7.8621		0.53843
545	1.0000e-08		2.5645		0.70178		5.5960		0.69023		7.8024		0.54596
550	1.0000e-08		3.1171		0.66349		5.4974		0.67826		7.6693		0.53742
555	1.0000e-08		2.3009		0.68913		5.5156		0.67671		7.2097		0.55214
560	1.0000e-08		4.0030		0.67600		5.3433		0.67978		7.1599		0.55234
565	1.0000e-08		2.7925		0.67120		5.2884		0.66757		7.5961		0.54183
570	1.0000e-08		2.9968		0.69005		5.1684		0.67652		7.6027		0.54167
575	1.0000e-08		2.2297		0.71618		5.2536		0.68243		7.4370		0.55265
580	1.0000e-08		2.0429		0.69623		5.4039		0.67479		7.4804		0.54423
