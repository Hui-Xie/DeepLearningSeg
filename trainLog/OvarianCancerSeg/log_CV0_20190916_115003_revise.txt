=============training from sratch============
Program ID: 3370

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy', '0', '3,2,1']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
         

Discarded changes:                  

Experiment setting:
Input CT data: 51*171*171 ROI around primary cancer

Loss Function:  SoftMax

Data:   total 36 patients with 50-80% label, 6-fold cross validation, test 6, validation 6, and training 24.  
    script: python3.7 statisticsLabelFiles.py 
    Total 36 in /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
    0 has 48159408 elements, with a rate of  0.8970491562903105 
    1 has 5527068 elements, with a rate of  0.10295084370968957

Training strategy: 

          

Program starting Time: 2019-09-16 11:50:03.325315
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190916_115003

Info: this is the 0th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 6

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190916_115003.
6-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 24 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Network has total 32,972,258 parameters.

In order to observe loss, I copied the row of epoch5 into row of epoch0. 


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-01		0.6754		0.21460		0.6025		0.32998		0.6169		0.23564
5	1.0000e-01		0.6754		0.21460		0.6025		0.32998		0.6169		0.23564
10	1.0000e-01		0.6133		0.19076		0.5647		0.35526		0.6173		0.17248
15	1.0000e-01		0.6087		0.23312		0.8484		0.36563		1.7194		0.17079
20	1.0000e-01		0.5867		0.23620		0.5398		0.39581		0.7498		0.20244
25	1.0000e-01		0.6092		0.26760		0.4946		0.39338		0.5304		0.28070
30	1.0000e-01		0.5237		0.30609		0.4544		0.47103		0.4937		0.34434
35	1.0000e-01		0.4500		0.38106		0.5045		0.55866		0.5055		0.42436
40	1.0000e-01		0.4370		0.51192		0.4755		0.60131		0.4644		0.46528
45	1.0000e-01		0.3846		0.44483		0.5793		0.62179		0.4850		0.51723
50	1.0000e-02		0.3000		0.51115		0.4095		0.66740		0.3349		0.56160
55	1.0000e-02		0.3403		0.51116		0.3038		0.64125		0.2810		0.54071
60	1.0000e-02		0.3371		0.48928		0.3076		0.64177		0.2774		0.54602
65	1.0000e-02		0.3101		0.49412		0.3221		0.65104		0.2848		0.56466
70	1.0000e-02		0.3010		0.53920		0.3022		0.65156		0.2822		0.55526
75	1.0000e-02		0.3035		0.53117		0.3088		0.66390		0.2797		0.56675
80	1.0000e-02		0.3374		0.50384		0.2949		0.65462		0.2756		0.54971
85	1.0000e-02		0.3186		0.50449		0.3008		0.66148		0.2743		0.55921
90	1.0000e-02		0.3073		0.50556		0.2881		0.65519		0.2742		0.54269
95	1.0000e-02		0.3575		0.49493		0.2840		0.63956		0.2785		0.52402
100	1.0000e-02		0.3209		0.51751		0.2893		0.65087		0.2758		0.54435
105	1.0000e-02		0.2970		0.51134		0.2812		0.64634		0.2733		0.52726
110	1.0000e-02		0.3351		0.51047		0.3030		0.64646		0.2724		0.54680
115	1.0000e-02		0.3717		0.49199		0.3137		0.65993		0.2741		0.56315
120	1.0000e-02		0.3018		0.50294		0.2941		0.65532		0.2722		0.54421
125	1.0000e-02		0.3051		0.49701		0.2954		0.65663		0.2681		0.55107
130	1.0000e-02		0.3201		0.50747		0.3117		0.67480		0.2821		0.57147
135	1.0000e-02		0.3436		0.54172		0.2943		0.66413		0.2735		0.55432
140	1.0000e-02		0.3019		0.50478		0.3188		0.68007		0.2944		0.57275
145	1.0000e-02		0.3320		0.50678		0.3034		0.67303		0.2851		0.56045
150	1.0000e-03		0.2942		0.52036		0.2939		0.66410		0.2760		0.55065
155	1.0000e-03		0.3095		0.46882		0.2798		0.65579		0.2735		0.53354
160	1.0000e-03		0.3241		0.48335		0.2820		0.65589		0.2720		0.53608
165	1.0000e-03		0.3034		0.49183		0.2864		0.64674		0.2665		0.53336
170	1.0000e-03		0.3027		0.52793		0.2736		0.64823		0.2728		0.52286
175	1.0000e-03		0.3012		0.48868		0.2754		0.64521		0.2722		0.52076
180	1.0000e-03		0.3024		0.47657		0.2727		0.64507		0.2714		0.51946
185	1.0000e-03		0.2808		0.50346		0.2733		0.64815		0.2717		0.52338
190	1.0000e-03		0.2948		0.49268		0.2748		0.65139		0.2707		0.52883
195	1.0000e-03		0.2972		0.51267		0.2849		0.64985		0.2669		0.53699
200	1.0000e-03		0.2904		0.52040		0.2844		0.65006		0.2657		0.53751
205	1.0000e-03		0.2966		0.51480		0.2829		0.65276		0.2683		0.53875
210	1.0000e-03		0.2935		0.50602		0.2789		0.64801		0.2668		0.53160
215	1.0000e-03		0.3564		0.48408		0.2794		0.65483		0.2676		0.53738
220	1.0000e-03		0.2773		0.50655		0.2885		0.65462		0.2664		0.54259
225	1.0000e-03		0.2792		0.50522		0.2836		0.66005		0.2704		0.54144
230	1.0000e-03		0.3522		0.51427		0.2794		0.65319		0.2673		0.53557
235	1.0000e-03		0.2919		0.51752		0.2869		0.65873		0.2688		0.54471
240	1.0000e-03		0.3137		0.50509		0.2713		0.64919		0.2717		0.52424
245	1.0000e-03		0.3389		0.51307		0.2687		0.64477		0.2699		0.52148
250	1.0000e-04		0.2875		0.51222		0.2775		0.65076		0.2662		0.53433
255	1.0000e-04		0.3174		0.50983		0.2799		0.64917		0.2645		0.53503
260	1.0000e-04		0.3187		0.50731		0.2736		0.65483		0.2683		0.53405
265	1.0000e-04		0.3311		0.49348		0.2692		0.64204		0.2685		0.51923
270	1.0000e-04		0.3046		0.48869		0.2685		0.64140		0.2685		0.52006
275	1.0000e-04		0.3212		0.50533		0.2707		0.64129		0.2672		0.52040
280	1.0000e-04		0.3291		0.49594		0.2710		0.64836		0.2666		0.52713
285	1.0000e-04		0.3303		0.52101		0.2705		0.65080		0.2715		0.52546
290	1.0000e-04		0.2922		0.51114		0.2764		0.65449		0.2676		0.53629
295	1.0000e-04		0.3294		0.44844		0.2774		0.65183		0.2659		0.53493
300	1.0000e-04		0.3160		0.48531		0.2741		0.64846		0.2675		0.52883
305	1.0000e-04		0.3448		0.47468		0.2770		0.64959		0.2657		0.53183
310	1.0000e-04		0.2948		0.51287		0.2701		0.64598		0.2675		0.52408
315	1.0000e-04		0.3120		0.49230		0.2782		0.65448		0.2660		0.53660
320	1.0000e-04		0.2918		0.49352		0.2747		0.65286		0.2689		0.53188
325	1.0000e-04		0.3178		0.49779		0.2684		0.64857		0.2703		0.52308
330	1.0000e-04		0.2810		0.48816		0.2720		0.64988		0.2669		0.52931
335	1.0000e-04		0.3489		0.47863		0.2742		0.65228		0.2669		0.53302
340	1.0000e-04		0.3440		0.51406		0.2729		0.65063		0.2680		0.52987
345	1.0000e-04		0.3133		0.51012		0.2705		0.65026		0.2696		0.52775
350	1.0000e-04		0.3163		0.46938		0.2710		0.64853		0.2665		0.52860
355	1.0000e-04		0.2940		0.50554		0.2743		0.65617		0.2698		0.53311
360	1.0000e-04		0.2891		0.50572		0.2700		0.64745		0.2689		0.52510
365	1.0000e-04		0.3237		0.52923		0.2756		0.64747		0.2660		0.53009
370	1.0000e-04		0.3046		0.51363		0.2783		0.65196		0.2672		0.53516
375	1.0000e-04		0.2990		0.52122		0.2712		0.64391		0.2678		0.52310
380	1.0000e-04		0.2959		0.51244		0.2712		0.64671		0.2662		0.52663
385	1.0000e-04		0.3173		0.48093		0.2838		0.65630		0.2646		0.54396
390	1.0000e-04		0.3072		0.51307		0.2747		0.64333		0.2652		0.52572
395	1.0000e-04		0.3054		0.51868		0.2706		0.65190		0.2715		0.52715
400	1.0000e-05		0.2870		0.50615		0.2819		0.65033		0.2642		0.53628
405	1.0000e-05		0.3182		0.51098		0.2728		0.64707		0.2660		0.52830
410	1.0000e-05		0.3050		0.49795		0.2795		0.65706		0.2654		0.54135
415	1.0000e-05		0.2967		0.51049		0.2820		0.65371		0.2644		0.53977
420	1.0000e-05		0.3131		0.49941		0.2751		0.64675		0.2643		0.52936
425	1.0000e-05		0.3010		0.49801		0.2707		0.64672		0.2669		0.52493
430	1.0000e-05		0.3012		0.51111		0.2723		0.64845		0.2658		0.52808
435	1.0000e-05		0.3128		0.51268		0.2750		0.64899		0.2651		0.53023
440	1.0000e-05		0.3078		0.52757		0.2704		0.64717		0.2689		0.52366
445	1.0000e-05		0.3337		0.49463		0.2784		0.65615		0.2652		0.53970
450	1.0000e-05		0.3081		0.50672		0.2746		0.65218		0.2667		0.53406
455	1.0000e-05		0.2935		0.49166		0.2737		0.64936		0.2664		0.52973
460	1.0000e-05		0.3496		0.48777		0.2786		0.65325		0.2649		0.53653
