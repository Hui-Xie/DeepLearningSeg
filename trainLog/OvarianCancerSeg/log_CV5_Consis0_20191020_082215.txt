=============training from sratch============
Program ID: 31543

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy', '5', '3', '0']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      Sep 30th, 2019
      1   With size-reduced ROI of size 51*149*149;
      2   reduce the translation of data augmentation;
      3   reduce all data into 35 patients, excluding a very blur patient.
      Oct 5th, 2019
      1   use uniform physical size 147mm*147mm*147mm, input pixel size: 49*147*147 with spacing size 3mm*1mm*1mm;
      2   change V model with inputsize 49*147*147
      Oct 6th, 2019
      1   add filter number to 48 at the first layer. 
      Oct 7th, 2019
      1   restore to 32 of number of filters in the first layer;
      2   add bottom number of filters to 1024, and keep down sample and add filter number together. 
      Oct 8th, 2019
      1   discard the cancer with size exceeding 147mm*147mm*147mm; Now remains 29 patients data; 
      Oct 9th, 2019
      1   In the first layer of V model, remove the residual link; 
           with the residula link at first layer: Tr dice:54%, Validation Dice 27%, Test Dice 56%;  Not good.
      2   the final output layer, change into 1*1*1 convolution, instead of 3*3*3 convolution;
      3   add labelConsistencyLoss, it use 64 dimension feature extracted from 2 ends of V model:
           It gets stable Training Dice 61%, validation Dice 27%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      Oct 11th, 2019
      1   use feature tensor just from the output end of V model. It is 32 dimensions.
          It gets stable Training Dice 61%, validation Dice 23%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      2   windows size for consistency loss changes to 3;
      Oct 12th, 2019
      1   change image window level to 100/50; relaunch training;
      2   change consistencyLoss to use ground truth for comparing diff of feature vector;
      Oct 13th, 2019
      1    use conistencyLoss3: ((G1-G2)-(P1-P2))**2 as loss.
      
      Oct 18th, 2019
      1   use 48 filters at the first layer with inputsize 49*147*147 with scaled ROI.
      
      Oct 20th, 2019
      1   at final output layer of V model, change 1*1*1 conv to 5*5*5 conv, in order to consider context for final output
      
       
      
       
      

          
         

Discarded changes:                  
          

Program starting Time: 2019-10-20 08:22:15.200593
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191020_082215

Info: this is the 5th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 1

Info: useConsistencyLoss = False and searchWindowSize= 0

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191020_082215.
6-fold cross validation: the 5th fold is for test, the 0th fold is for validation, remaining folds are for training.

training dataset: total 24 image files.

validation dataset: total 6 image files.

test dataset: total 5 image files.
Total 24 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy
0 has 19573793 elements, with a rate of  0.7702522931519779 
1 has 5838391 elements, with a rate of  0.2297477068480222 
loss weight = tensor([1.0000, 3.3526])
Network has total 254,664,050 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		44.0119		0.25202		9.2355		0.23473		47.5546		0.12798
5	1.0000e-02		3.2828		0.57796		8.7187		0.02197		4.8686		0.19921
10	1.0000e-02		5.7949		0.50391		173.2709		0.31233		538.0168		0.15543
15	1.0000e-02		2.0572		0.65195		1.5111		0.72461		4.2467		0.56249
20	1.0000e-02		2.1845		0.65143		2.0745		0.65322		4.6718		0.51603
25	1.0000e-02		2.8247		0.65523		1.8543		0.68572		4.5748		0.54137
30	1.0000e-02		2.2440		0.66850		1.7494		0.70371		5.9615		0.53835
35	1.0000e-02		2.0210		0.66671		2.4865		0.47550		9.0998		0.31340
40	1.0000e-02		1.7323		0.68023		1.5984		0.71451		2.9571		0.60103
45	1.0000e-02		2.5884		0.59690		8.1222		0.55865		11.0244		0.42186
50	1.0000e-02		2.2189		0.65742		1.6982		0.67765		3.1818		0.56459
55	1.0000e-02		3.0862		0.59104		2.0641		0.66747		2.6941		0.57499
60	1.0000e-02		2.6447		0.60822		2.3308		0.59946		2.0445		0.60927
65	1.0000e-02		1.9179		0.70276		2.1497		0.66617		4.1897		0.41524
70	1.0000e-03		2.0612		0.68420		1.6158		0.70815		3.4503		0.44056
75	1.0000e-03		1.6558		0.70681		1.5114		0.71341		3.0903		0.50332
80	1.0000e-03		2.2865		0.74065		1.6616		0.69621		3.5022		0.45671
85	1.0000e-03		1.4381		0.75657		1.7386		0.68937		3.2084		0.48741
90	1.0000e-03		1.3950		0.73595		1.6752		0.69565		3.7800		0.48915
95	1.0000e-03		1.3781		0.73022		1.4892		0.71638		2.1130		0.61687
100	1.0000e-03		1.0691		0.74312		1.5384		0.72096		1.7641		0.60080
105	1.0000e-03		1.3668		0.73478		1.5667		0.71163		2.9567		0.59762
110	1.0000e-03		1.1788		0.74554		1.4600		0.72697		1.9225		0.65475
115	1.0000e-03		1.4611		0.73817		1.6427		0.70377		2.7629		0.60965
120	1.0000e-03		1.1367		0.78162		1.5066		0.71973		2.2131		0.64378
125	1.0000e-03		1.1185		0.77446		3.4303		0.60459		3.1233		0.54073
130	1.0000e-03		1.4457		0.73776		1.6580		0.70251		3.7087		0.58361
135	1.0000e-03		1.2408		0.75928		1.9643		0.67544		3.8029		0.58017
140	1.0000e-03		1.0237		0.78425		1.8683		0.69256		4.3498		0.59858
145	1.0000e-03		1.1080		0.78308		1.5807		0.71460		2.9910		0.62886
150	1.0000e-03		0.9629		0.79797		2.6876		0.57466		3.8592		0.60125
155	1.0000e-03		1.0117		0.80794		1.8618		0.70789		4.1669		0.53563
160	1.0000e-03		0.9907		0.78194		1.6181		0.71697		3.2041		0.58087
165	1.0000e-04		0.8798		0.80397		1.8241		0.70307		3.4782		0.56378
170	1.0000e-04		1.0618		0.79594		1.8033		0.70844		3.4588		0.53680
175	1.0000e-04		0.9309		0.80355		1.6839		0.72304		3.3133		0.49940
180	1.0000e-04		0.7194		0.81318		1.7245		0.71541		3.2333		0.50890
185	1.0000e-04		0.7131		0.80954		1.7460		0.72281		3.8214		0.50461
190	1.0000e-04		0.7643		0.81818		1.8307		0.70797		3.6223		0.50053
195	1.0000e-04		0.8150		0.82514		2.0073		0.69193		4.0512		0.50161
200	1.0000e-04		0.8150		0.81339		1.8710		0.70758		3.0001		0.52813
205	1.0000e-04		0.7839		0.81981		1.8347		0.71539		4.0601		0.51626
210	1.0000e-04		0.7150		0.82691		2.0359		0.67110		3.8733		0.52444
215	1.0000e-04		0.8221		0.81085		1.7824		0.72089		4.9267		0.48661
220	1.0000e-05		0.9446		0.81018		2.2846		0.68507		5.0068		0.50113
225	1.0000e-05		0.8104		0.82108		2.1051		0.68403		4.5321		0.48900
230	1.0000e-05		0.8334		0.81814		1.9569		0.71182		4.4710		0.47541
235	1.0000e-05		0.8022		0.81560		1.9596		0.70534		5.1631		0.48847
240	1.0000e-05		0.8887		0.81751		1.9135		0.71303		4.6359		0.47717
245	1.0000e-05		0.6588		0.80738		2.2337		0.68729		4.3642		0.47613
250	1.0000e-05		0.9212		0.80870		2.0929		0.70061		4.2776		0.51561
255	1.0000e-05		0.6632		0.82762		1.9219		0.70427		3.3772		0.49611
260	1.0000e-05		0.8491		0.81493		1.9951		0.70371		3.9484		0.48409
265	1.0000e-05		0.6237		0.82440		2.3635		0.64586		5.3633		0.48816
270	1.0000e-05		0.8145		0.80917		2.1758		0.69443		4.1442		0.52779
275	1.0000e-06		0.7759		0.80820		1.8936		0.71957		4.1159		0.48715
280	1.0000e-06		0.7338		0.83064		2.1485		0.69712		4.2212		0.54009
285	1.0000e-06		0.8532		0.82736		1.9764		0.70866		4.8453		0.47961
290	1.0000e-06		0.6899		0.82617		1.9833		0.71239		4.2968		0.47652
295	1.0000e-06		0.8017		0.81903		1.9183		0.71358		3.7081		0.49471
300	1.0000e-06		0.7701		0.82089		2.0377		0.69880		4.1337		0.54201
305	1.0000e-06		0.8170		0.82095		2.1160		0.70218		4.5050		0.48261
310	1.0000e-06		0.7269		0.82423		2.0138		0.70469		4.1340		0.49567
315	1.0000e-06		0.7939		0.82277		1.8659		0.72531		4.4839		0.48553
320	1.0000e-06		0.7668		0.80787		1.8730		0.71916		4.5852		0.47758
325	1.0000e-06		0.7612		0.81123		2.1307		0.69551		3.6451		0.49755
330	1.0000e-07		0.8234		0.81420		2.0272		0.70887		4.8022		0.47982
335	1.0000e-07		0.7321		0.82296		2.2798		0.66049		5.2608		0.49567
340	1.0000e-07		0.7909		0.82139		2.0350		0.71100		5.0093		0.48139
345	1.0000e-07		0.8122		0.80915		2.0371		0.70866		4.7048		0.49876
350	1.0000e-07		0.7419		0.81492		2.0727		0.70264		3.8828		0.51618
355	1.0000e-07		0.8840		0.82526		2.1565		0.68974		5.2069		0.48057
360	1.0000e-07		0.6575		0.82434		1.9725		0.71326		4.7422		0.52142
365	1.0000e-07		0.7646		0.82062		2.0242		0.70398		4.8847		0.49809
370	1.0000e-07		0.8679		0.80739		2.0102		0.69915		3.8577		0.57094
375	1.0000e-07		0.8238		0.81671		1.9764		0.71206		4.0941		0.48305
380	1.0000e-07		0.8932		0.82677		1.9076		0.71730		3.8997		0.48954
385	1.0000e-08		0.8765		0.82957		2.0438		0.70597		3.8423		0.48783
390	1.0000e-08		0.6213		0.82533		2.1494		0.70133		4.3625		0.47187
395	1.0000e-08		0.8496		0.81380		1.9784		0.71096		4.0846		0.47569
400	1.0000e-08		0.7878		0.82218		1.9619		0.70851		4.4846		0.58391
405	1.0000e-08		0.6500		0.82407		2.1318		0.69392		3.5603		0.49626
410	1.0000e-08		0.8252		0.81411		1.9059		0.71487		4.0930		0.48067
415	1.0000e-08		0.6593		0.82827		1.8733		0.71787		4.8574		0.48247
420	1.0000e-08		0.7720		0.81181		2.4170		0.68049		4.8152		0.52750
425	1.0000e-08		0.6494		0.83038		1.8658		0.72414		4.3976		0.48493
430	1.0000e-08		0.7450		0.83343		1.9696		0.71213		3.8491		0.50218
435	1.0000e-08		0.7280		0.83019		1.8945		0.71889		4.2419		0.48489
440	1.0000e-08		0.7136		0.82210		2.0020		0.70999		4.6296		0.47690
445	1.0000e-08		0.7624		0.82465		1.9472		0.71611		4.8650		0.47903
450	1.0000e-08		0.7268		0.81961		2.1752		0.69010		5.2004		0.49003
455	1.0000e-08		0.7796		0.82062		1.9882		0.70354		4.0085		0.47868
460	1.0000e-08		0.7460		0.83366		2.0508		0.70427		4.5248		0.48719
465	1.0000e-08		0.7025		0.82432		2.2351		0.68630		4.1864		0.55235
470	1.0000e-08		0.6488		0.82119		1.8610		0.71760		4.0102		0.49196
475	1.0000e-08		0.7918		0.83026		1.9609		0.71640		4.1237		0.49385
480	1.0000e-08		0.7926		0.82278		2.0484		0.71608		5.5184		0.49366
485	1.0000e-08		0.8181		0.81886		1.8547		0.72409		4.8676		0.48202
490	1.0000e-08		0.6839		0.82427		1.9230		0.71488		4.2960		0.48048
495	1.0000e-08		1.0778		0.80798		2.0605		0.70907		4.8111		0.52483
500	1.0000e-08		0.7470		0.83512		1.9743		0.71549		4.1849		0.48661
505	1.0000e-08		0.7198		0.82233		1.9400		0.71435		4.5499		0.48451
510	1.0000e-08		0.7767		0.81705		2.1529		0.69899		4.7054		0.54097
515	1.0000e-08		0.7367		0.81994		1.9722		0.71461		4.8330		0.47794
520	1.0000e-08		0.7872		0.81785		1.9706		0.72100		5.4454		0.47623
525	1.0000e-08		0.7092		0.82931		2.0886		0.70262		4.4860		0.46979
530	1.0000e-08		0.7363		0.81307		2.0414		0.70260		3.8505		0.52735
535	1.0000e-08		0.8386		0.82527		1.8930		0.71669		3.3386		0.50696
540	1.0000e-08		0.7938		0.82040		1.9814		0.71270		4.7985		0.48922
545	1.0000e-08		0.7613		0.82054		2.0375		0.71155		5.3496		0.48473
550	1.0000e-08		0.8430		0.80709		2.3098		0.67372		3.7675		0.56512
555	1.0000e-08		0.6457		0.81855		2.0369		0.70489		4.0343		0.51280
560	1.0000e-08		0.6043		0.83472		1.8948		0.71643		3.8761		0.49944
565	1.0000e-08		0.7965		0.83010		1.9421		0.71499		3.4204		0.50630
570	1.0000e-08		0.7818		0.82465		1.9207		0.72004		4.8091		0.47620
575	1.0000e-08		0.8275		0.82303		2.0040		0.71079		4.5375		0.47174
580	1.0000e-08		0.8017		0.82460		1.9719		0.70895		4.2428		0.47644
585	1.0000e-08		0.8807		0.81391		1.9899		0.71093		3.9021		0.48990
590	1.0000e-08		0.7520		0.83490		1.8709		0.71410		4.6079		0.48282
595	1.0000e-08		1.0026		0.82246		1.9676		0.71337		4.2041		0.48696
600	1.0000e-08		0.6598		0.81622		1.9556		0.71169		4.2994		0.54578
605	1.0000e-08		0.7801		0.81736		1.9344		0.71559		4.4194		0.47781
610	1.0000e-08		0.7774		0.81535		2.0178		0.70894		4.5409		0.54814
615	1.0000e-08		0.8336		0.82194		1.9121		0.71367		4.0291		0.48290
620	1.0000e-08		0.6841		0.80492		2.0565		0.70487		4.5022		0.47021
625	1.0000e-08		0.8098		0.82016		1.8859		0.71579		4.4257		0.47844
630	1.0000e-08		0.8279		0.82807		2.0353		0.71250		4.2063		0.48799
635	1.0000e-08		0.6457		0.82122		1.9817		0.71089		4.4971		0.49091
640	1.0000e-08		0.6253		0.81234		1.8699		0.71919		4.3625		0.48237
645	1.0000e-08		0.7918		0.83347		2.0521		0.71299		5.5361		0.49090
650	1.0000e-08		0.7526		0.81910		2.0936		0.69870		4.3294		0.53762
655	1.0000e-08		0.7084		0.81252		1.9275		0.71791		4.4478		0.47687
660	1.0000e-08		0.7488		0.81966		1.9859		0.70624		5.1106		0.48063
665	1.0000e-08		0.6196		0.81448		2.0510		0.70321		4.4751		0.46790
670	1.0000e-08		0.7781		0.82479		1.9818		0.71105		4.5025		0.47686
675	1.0000e-08		0.9936		0.81411		2.1216		0.69935		4.2372		0.51491
680	1.0000e-08		0.8436		0.82978		2.0637		0.70572		4.4370		0.48489
685	1.0000e-08		0.6599		0.82304		1.9562		0.71566		4.5272		0.47450
690	1.0000e-08		0.8986		0.82072		1.8810		0.72521		4.3959		0.48552
695	1.0000e-08		0.7646		0.81639		1.9065		0.72161		4.9529		0.48181
700	1.0000e-08		0.8975		0.80994		2.1098		0.70041		4.4359		0.49179
705	1.0000e-08		0.9604		0.80530		1.9556		0.71205		4.8245		0.49198
710	1.0000e-08		0.7714		0.80515		2.7503		0.65371		4.4261		0.55087
715	1.0000e-08		0.8107		0.82500		1.9475		0.71624		5.1756		0.47553
720	1.0000e-08		0.7355		0.82087		1.9634		0.71373		3.7250		0.49963
725	1.0000e-08		0.7072		0.82366		1.9041		0.72334		5.0072		0.47763
730	1.0000e-08		0.7935		0.82222		1.9603		0.70892		3.9484		0.49151
735	1.0000e-08		0.7158		0.82153		1.8969		0.71615		3.7281		0.49423
740	1.0000e-08		0.9051		0.82669		1.9624		0.71102		4.2524		0.49327
745	1.0000e-08		0.6852		0.82995		1.9139		0.71753		5.1259		0.48411
750	1.0000e-08		0.6320		0.82379		1.9548		0.71214		3.8289		0.49374
755	1.0000e-08		0.7581		0.82318		2.0421		0.70305		4.0137		0.50993
760	1.0000e-08		0.8292		0.81485		1.9876		0.71052		4.3742		0.47511
765	1.0000e-08		0.8160		0.82010		1.8909		0.71809		4.9090		0.47976
770	1.0000e-08		0.8598		0.80161		2.6071		0.65648		3.5488		0.57598
775	1.0000e-08		0.7087		0.83052		1.9355		0.71462		4.7694		0.47865
780	1.0000e-08		0.6840		0.83141		1.8708		0.72118		3.9782		0.48503
785	1.0000e-08		0.8317		0.82444		2.0712		0.68711		4.4242		0.49479
790	1.0000e-08		0.7777		0.82367		1.9158		0.72004		4.8570		0.48463
795	1.0000e-08		0.7586		0.80422		1.9051		0.72174		4.7132		0.47836
800	1.0000e-08		0.7610		0.82103		1.9171		0.71107		3.8861		0.48690
805	1.0000e-08		0.7523		0.81832		2.0890		0.69769		4.1599		0.53255
810	1.0000e-08		0.7628		0.81218		1.9914		0.71324		4.0943		0.48840
815	1.0000e-08		0.9100		0.81858		1.9301		0.71689		4.5451		0.47990
820	1.0000e-08		0.7382		0.81825		1.8718		0.71665		3.6341		0.51076
825	1.0000e-08		0.9132		0.81374		1.9042		0.71625		4.7716		0.47690
830	1.0000e-08		0.8000		0.82647		1.9451		0.72282		5.4289		0.48619
835	1.0000e-08		0.8056		0.83429		2.0622		0.70693		5.5202		0.47423
840	1.0000e-08		0.7546		0.81938		1.9863		0.71726		4.6565		0.48253
845	1.0000e-08		0.8312		0.81968		2.1784		0.70942		5.1445		0.48258
850	1.0000e-08		0.7605		0.81625		1.9416		0.71548		4.7268		0.48440
855	1.0000e-08		0.6859		0.82562		2.0071		0.71116		4.8278		0.47286
860	1.0000e-08		0.7038		0.83241		1.9090		0.71481		3.6771		0.50243
865	1.0000e-08		0.7642		0.82363		1.9222		0.71399		4.3395		0.47752
870	1.0000e-08		0.6834		0.81289		2.0507		0.70850		4.4313		0.47236
875	1.0000e-08		0.8263		0.82139		1.9893		0.70627		4.1325		0.49340
880	1.0000e-08		0.8060		0.81192		2.0167		0.70137		4.6379		0.48551
885	1.0000e-08		0.7839		0.83687		1.9648		0.71272		4.2494		0.49531
890	1.0000e-08		0.6652		0.81596		2.1504		0.69819		4.8473		0.49176
895	1.0000e-08		0.8341		0.82392		2.1453		0.69882		3.7633		0.49038
900	1.0000e-08		0.6980		0.83028		1.9276		0.71363		5.0006		0.48653
905	1.0000e-08		0.7104		0.82705		2.0142		0.70688		4.2837		0.48888
910	1.0000e-08		0.7184		0.82320		2.0393		0.69918		4.9036		0.48121
915	1.0000e-08		0.7273		0.83077		2.1950		0.69423		5.6238		0.48768
920	1.0000e-08		1.1466		0.81081		2.2078		0.69278		4.9242		0.54969
925	1.0000e-08		0.7510		0.80912		2.3414		0.68260		3.9826		0.54045
930	1.0000e-08		0.6661		0.83352		2.0218		0.71592		4.4787		0.47398
935	1.0000e-08		0.6881		0.83357		1.9362		0.71834		4.2528		0.48050
940	1.0000e-08		0.7557		0.81595		1.9212		0.71175		4.6215		0.48810
945	1.0000e-08		0.7792		0.81667		1.9381		0.72325		4.7526		0.48187
950	1.0000e-08		0.9675		0.81574		2.2903		0.68793		4.0924		0.47534
955	1.0000e-08		0.8962		0.80985		2.0333		0.70986		5.5309		0.48969
960	1.0000e-08		0.8112		0.82595		2.0829		0.68210		4.5852		0.49325
965	1.0000e-08		1.2299		0.81602		1.8990		0.72180		5.0130		0.47766
970	1.0000e-08		0.6824		0.82651		1.9830		0.71446		4.9298		0.50160
975	1.0000e-08		0.8146		0.80641		2.4211		0.68147		3.9840		0.50470
980	1.0000e-08		0.6737		0.81789		2.0464		0.70424		3.8069		0.49841
985	1.0000e-08		0.9269		0.81301		1.9293		0.71809		4.3128		0.48202
990	1.0000e-08		0.7999		0.81716		2.1432		0.70188		5.7287		0.48367
995	1.0000e-08		0.7139		0.82145		2.0740		0.70535		4.3896		0.52906
1000	1.0000e-08		0.7895		0.82672		1.9712		0.72018		5.2582		0.48194
1005	1.0000e-08		0.7699		0.81580		2.0748		0.70593		4.6521		0.46747
1010	1.0000e-08		0.7943		0.82630		2.0373		0.71235		5.6063		0.48086
1015	1.0000e-08		0.7541		0.83487		1.9393		0.71617		4.6750		0.47272
1020	1.0000e-08		0.7439		0.81454		1.8598		0.71778		4.1199		0.48345
1025	1.0000e-08		0.8316		0.82631		2.0702		0.71820		6.3684		0.48404
1030	1.0000e-08		0.7631		0.81467		2.0805		0.70551		4.7101		0.48505
1035	1.0000e-08		0.6467		0.82185		1.9549		0.71496		4.1839		0.48302
1040	1.0000e-08		0.8074		0.81378		1.9433		0.71136		3.8711		0.49110
1045	1.0000e-08		0.9064		0.81971		1.8855		0.71591		4.3514		0.48024
1050	1.0000e-08		0.6892		0.82588		1.8883		0.71745		4.3064		0.47953
1055	1.0000e-08		0.7626		0.82499		1.9296		0.71587		4.2317		0.48746
1060	1.0000e-08		0.7096		0.81715		1.9812		0.69945		4.0720		0.57519
1065	1.0000e-08		0.8410		0.82846		2.0113		0.70738		4.4293		0.48856
1070	1.0000e-08		0.7214		0.81926		1.9114		0.71916		5.1926		0.47346
1075	1.0000e-08		0.7027		0.81471		1.9218		0.71830		3.9668		0.49323
1080	1.0000e-08		0.7174		0.82739		2.0331		0.69111		4.3501		0.49815
1085	1.0000e-08		0.7117		0.81628		1.8915		0.71388		3.5599		0.50077
1090	1.0000e-08		0.9076		0.83118		2.0237		0.71074		4.8084		0.48210
1095	1.0000e-08		0.8224		0.81530		2.4758		0.67100		3.6599		0.56088
1100	1.0000e-08		0.6984		0.82043		1.9802		0.70212		3.4788		0.53379
1105	1.0000e-08		0.6694		0.83027		1.9583		0.71211		4.4791		0.47854
1110	1.0000e-08		0.7484		0.81755		1.8912		0.72188		4.5398		0.48596
1115	1.0000e-08		0.7551		0.83722		1.9207		0.72429		5.1995		0.47881
1120	1.0000e-08		0.7127		0.82363		1.9465		0.71598		4.2400		0.47793
1125	1.0000e-08		0.8313		0.82388		2.0700		0.70869		4.7839		0.47243
1130	1.0000e-08		0.7826		0.82833		1.9084		0.71155		4.5397		0.48161
1135	1.0000e-08		0.7450		0.82593		1.9584		0.71412		4.5826		0.49598
1140	1.0000e-08		0.8522		0.81494		1.9737		0.71721		4.3395		0.48257
1145	1.0000e-08		0.7702		0.81129		2.1297		0.69403		3.8209		0.52376
1150	1.0000e-08		0.7554		0.83175		2.0025		0.70832		4.8587		0.48402
1155	1.0000e-08		0.7636		0.81888		2.0732		0.70405		3.8273		0.48285
1160	1.0000e-08		0.9588		0.80858		1.9604		0.71609		4.9834		0.47745
1165	1.0000e-08		0.7318		0.82888		2.0115		0.71989		5.4378		0.48449
1170	1.0000e-08		0.6816		0.82822		1.8906		0.72336		4.5762		0.47885
1175	1.0000e-08		0.8146		0.83065		1.9454		0.71354		4.6505		0.49517
1180	1.0000e-08		0.6525		0.82605		2.0970		0.69195		3.3356		0.54209
1185	1.0000e-08		0.7478		0.82710		1.8941		0.72230		4.5918		0.48325
1190	1.0000e-08		0.8425		0.82125		2.1037		0.69202		4.4335		0.48612
1195	1.0000e-08		0.8654		0.82353		1.8802		0.71499		3.8797		0.48837
1200	1.0000e-08		0.7418		0.81835		1.9976		0.71271		4.0446		0.48244
1205	1.0000e-08		0.7712		0.82145		2.0127		0.70381		3.4896		0.56172
1210	1.0000e-08		0.7117		0.82505		1.9596		0.70408		3.5596		0.51037
1215	1.0000e-08		0.8185		0.81119		2.1428		0.69619		4.0439		0.53502
1220	1.0000e-08		0.7438		0.82299		1.9470		0.71442		5.0593		0.47509
1225	1.0000e-08		0.8800		0.82339		1.9469		0.71221		4.3471		0.48962
1230	1.0000e-08		0.7762		0.82490		1.8616		0.71637		3.6568		0.50192
1235	1.0000e-08		0.8174		0.81854		1.9378		0.71191		4.4435		0.47626
1240	1.0000e-08		0.6856		0.82329		2.2040		0.69278		4.5036		0.52783
1245	1.0000e-08		0.8403		0.80119		2.2247		0.69071		4.6713		0.55885
1250	1.0000e-08		0.6320		0.81886		2.0980		0.70198		3.9411		0.48138
1255	1.0000e-08		0.7113		0.83837		1.9487		0.71652		3.9656		0.50038
1260	1.0000e-08		0.7738		0.81622		1.9576		0.71657		4.4564		0.47758
1265	1.0000e-08		0.7325		0.82303		1.9680		0.71208		5.1687		0.52795
1270	1.0000e-08		0.7006		0.81797		1.9006		0.71662		4.0780		0.47852
1275	1.0000e-08		0.7686		0.82095		1.9508		0.72043		4.6349		0.47726
1280	1.0000e-08		0.7845		0.80997		1.8918		0.71924		5.0063		0.47636
1285	1.0000e-08		0.7547		0.83302		2.0416		0.71021		4.0463		0.48968
1290	1.0000e-08		0.7579		0.81634		1.9286		0.71277		3.9816		0.48244
