=============training from sratch============
Program ID: 17291

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy', '0', '1', '0']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      Sep 30th, 2019
      1   With size-reduced ROI of size 51*149*149;
      2   reduce the translation of data augmentation;
      3   reduce all data into 35 patients, excluding a very blur patient.
      Oct 5th, 2019
      1   use uniform physical size 147mm*147mm*147mm, input pixel size: 49*147*147 with spacing size 3mm*1mm*1mm;
      2   change V model with inputsize 49*147*147
      Oct 6th, 2019
      1   add filter number to 48 at the first layer. 
      Oct 7th, 2019
      1   restore to 32 of number of filters in the first layer;
      2   add bottom number of filters to 1024, and keep down sample and add filter number together. 
      Oct 8th, 2019
      1   discard the cancer with size exceeding 147mm*147mm*147mm; Now remains 29 patients data; 
      Oct 9th, 2019
      1   In the first layer of V model, remove the residual link; 
           with the residula link at first layer: Tr dice:54%, Validation Dice 27%, Test Dice 56%;  Not good.
      2   the final output layer, change into 1*1*1 convolution, instead of 3*3*3 convolution;
      3   add labelConsistencyLoss, it use 64 dimension feature extracted from 2 ends of V model:
           It gets stable Training Dice 61%, validation Dice 27%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      Oct 11th, 2019
      1   use feature tensor just from the output end of V model. It is 32 dimensions.
          It gets stable Training Dice 61%, validation Dice 23%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      2   windows size for consistency loss changes to 3;
      Oct 12th, 2019
      1   change image window level to 100/50; relaunch training;
      2   change consistencyLoss to use ground truth for comparing diff of feature vector;
      Oct 13th, 2019
      1    use conistencyLoss3: ((G1-G2)-(P1-P2))**2 as loss.
      
      Oct 18th, 2019
      1   use 48 filters at the first layer with inputsize 49*147*147 with scaled ROI.
       
      
       
      

          
         

Discarded changes:                  
          

Program starting Time: 2019-10-18 15:02:26.276798
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191018_150226

Info: this is the 0th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 1

Info: useConsistencyLoss = False and searchWindowSize= 0

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191018_150226.
6-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 23 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Total 23 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy
0 has 19152100 elements, with a rate of  0.7864259128613267 
1 has 5201243 elements, with a rate of  0.21357408713867332 
loss weight = tensor([1.0000, 3.6822])
Network has total 254,652,146 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		5.4232		0.21122		4.4119		0.44132		4.1420		0.41827
5	1.0000e-02		2.1688		0.63287		1.5480		0.74453		1.7888		0.68451
10	1.0000e-02		1.8590		0.65524		1.5488		0.76434		1.6222		0.71541
15	1.0000e-02		2.2869		0.64662		2.7979		0.71058		1.8137		0.70101
20	1.0000e-02		2.2990		0.63208		1.6834		0.76310		1.8305		0.69838
25	1.0000e-02		2.0216		0.64307		1.6612		0.76844		1.8945		0.69301
30	1.0000e-02		1.8642		0.66499		2.2216		0.72195		2.5599		0.64337
35	1.0000e-02		1.6608		0.68455		1.7888		0.73593		1.7419		0.66565
40	1.0000e-02		2.0361		0.67050		1.7755		0.71912		1.7860		0.67012
45	1.0000e-02		1.3460		0.73465		3.3572		0.64909		1.9425		0.71512
50	1.0000e-02		1.6688		0.69693		1.7640		0.75201		1.8001		0.70552
55	1.0000e-02		1.8974		0.64229		2.5599		0.72198		1.8968		0.71984
60	1.0000e-03		1.4077		0.71052		2.4909		0.70376		3.5741		0.53325
65	1.0000e-03		1.1137		0.74910		2.2380		0.73301		2.2590		0.69728
70	1.0000e-03		1.0941		0.78287		1.8341		0.75561		2.4940		0.67218
75	1.0000e-03		1.2312		0.75396		1.4108		0.77550		1.9745		0.70389
80	1.0000e-03		1.1613		0.75707		1.5067		0.77473		2.7363		0.64444
85	1.0000e-03		1.0863		0.78148		1.6706		0.74817		2.1611		0.68795
90	1.0000e-03		1.0383		0.78601		1.8296		0.75139		2.0665		0.70113
95	1.0000e-03		0.9147		0.78635		1.8962		0.74838		2.3924		0.68715
100	1.0000e-03		1.0002		0.77994		2.0791		0.73308		2.1202		0.69374
105	1.0000e-03		0.8593		0.77692		2.0524		0.74693		2.0625		0.70034
110	1.0000e-03		0.9569		0.80857		1.6093		0.76023		2.9632		0.61926
115	1.0000e-03		0.8394		0.79119		1.5752		0.76971		2.2151		0.69931
120	1.0000e-03		1.0513		0.79073		2.8751		0.69173		2.6579		0.69183
125	1.0000e-03		0.7312		0.80981		2.3980		0.72001		2.3714		0.70677
130	1.0000e-04		1.0695		0.76129		2.5294		0.68922		2.2194		0.70298
135	1.0000e-04		0.7274		0.81732		1.6262		0.76172		2.3270		0.68587
140	1.0000e-04		0.9607		0.81554		1.5120		0.77639		2.2710		0.69328
145	1.0000e-04		0.8027		0.82053		1.4318		0.77224		2.1483		0.70521
150	1.0000e-04		0.7863		0.82730		1.5915		0.76981		2.2621		0.67642
155	1.0000e-04		0.8326		0.80828		1.4660		0.77888		2.2790		0.69754
160	1.0000e-04		0.6942		0.82671		2.0117		0.74146		2.7779		0.62030
165	1.0000e-04		0.6441		0.82207		1.6277		0.76481		2.5019		0.65816
170	1.0000e-04		0.7401		0.83078		1.8870		0.75631		3.2286		0.58803
175	1.0000e-04		0.6199		0.81267		1.8900		0.75048		2.6733		0.63291
180	1.0000e-04		0.6537		0.82265		1.7517		0.75428		2.5424		0.66860
185	1.0000e-05		0.7330		0.82728		1.8004		0.75611		2.7595		0.63076
190	1.0000e-05		0.6364		0.82273		1.7648		0.75270		2.6133		0.66794
195	1.0000e-05		0.6079		0.83373		1.6075		0.75764		2.5808		0.66594
200	1.0000e-05		0.6112		0.82846		1.5901		0.76137		2.4398		0.69007
205	1.0000e-05		0.6949		0.83332		1.8008		0.75839		3.5038		0.58729
210	1.0000e-05		0.7504		0.81818		1.8575		0.75208		3.0635		0.60703
215	1.0000e-05		0.6730		0.83524		1.7049		0.76133		3.0029		0.61920
220	1.0000e-05		0.7518		0.82412		1.8479		0.74950		2.8502		0.62440
225	1.0000e-05		0.7468		0.81135		1.6582		0.76018		2.6106		0.67070
230	1.0000e-05		0.7884		0.81980		1.6947		0.74905		2.5843		0.67421
235	1.0000e-05		0.6609		0.82472		1.6593		0.76316		2.4747		0.66246
240	1.0000e-06		0.6848		0.82756		1.7670		0.75969		2.7463		0.62857
245	1.0000e-06		0.8151		0.80336		1.5645		0.76053		2.4845		0.68324
250	1.0000e-06		0.7976		0.81965		2.1013		0.73405		2.7691		0.61845
255	1.0000e-06		0.5790		0.83504		1.6751		0.75317		2.4440		0.69288
260	1.0000e-06		0.5747		0.83473		1.7956		0.75953		2.9091		0.61117
265	1.0000e-06		0.6469		0.83082		1.8122		0.75335		2.9695		0.61952
270	1.0000e-06		0.7014		0.82719		1.6384		0.76801		2.6255		0.64528
275	1.0000e-06		0.6815		0.83435		1.7064		0.76295		2.3145		0.67402
280	1.0000e-06		0.6650		0.81908		1.6488		0.76029		2.5322		0.66633
285	1.0000e-06		0.5818		0.81738		1.6126		0.76633		2.4965		0.67824
290	1.0000e-06		0.6152		0.83039		1.5690		0.77059		2.4804		0.66309
295	1.0000e-07		0.6029		0.82092		1.6630		0.76120		2.5985		0.66085
300	1.0000e-07		0.6272		0.83596		1.8124		0.75783		2.8288		0.61449
305	1.0000e-07		0.6883		0.82754		1.5989		0.76170		2.5007		0.68635
310	1.0000e-07		0.7825		0.80420		1.9366		0.75069		2.8189		0.61113
315	1.0000e-07		0.6281		0.83873		2.0950		0.74801		4.4937		0.52448
320	1.0000e-07		0.6195		0.81774		1.8342		0.75733		2.7040		0.62660
325	1.0000e-07		0.6532		0.82538		1.6899		0.75789		2.3850		0.70039
330	1.0000e-07		1.0340		0.82363		2.1004		0.73815		3.5592		0.56219
335	1.0000e-07		0.6410		0.83008		1.7090		0.76251		2.6048		0.64936
340	1.0000e-07		0.7252		0.82675		1.8460		0.75827		3.0027		0.59743
345	1.0000e-07		0.6678		0.82268		1.7481		0.76513		2.5147		0.65238
350	1.0000e-08		0.8796		0.80931		1.7062		0.76828		2.5875		0.64581
355	1.0000e-08		0.7457		0.82924		1.7042		0.75888		2.4327		0.67919
360	1.0000e-08		0.9462		0.81857		1.7873		0.76015		3.1305		0.60873
365	1.0000e-08		0.6110		0.82266		1.7005		0.75006		2.4044		0.69531
370	1.0000e-08		0.7564		0.81401		1.8760		0.75316		2.7476		0.62981
375	1.0000e-08		0.9487		0.81460		1.6455		0.76756		2.6412		0.64743
380	1.0000e-08		0.7240		0.82348		1.9671		0.74948		3.0828		0.60251
385	1.0000e-08		0.7375		0.81953		1.8761		0.75243		2.6369		0.63571
390	1.0000e-08		0.6356		0.81072		1.7679		0.76180		2.5858		0.65143
395	1.0000e-08		0.7310		0.81206		1.7734		0.75877		2.6897		0.63363
400	1.0000e-08		0.6534		0.82344		1.7852		0.76144		2.6194		0.63285
405	1.0000e-08		0.8155		0.83372		1.6641		0.76748		2.7185		0.62907
410	1.0000e-08		0.6985		0.82295		1.6865		0.76729		2.9441		0.62056
415	1.0000e-08		0.7416		0.81339		1.5584		0.76698		2.5071		0.67109
420	1.0000e-08		0.6962		0.82346		1.7179		0.75436		2.4451		0.69142
425	1.0000e-08		0.5861		0.82654		1.6250		0.76572		2.5533		0.65375
430	1.0000e-08		0.6985		0.84211		1.6249		0.75552		2.4041		0.68555
435	1.0000e-08		0.6450		0.83380		2.0699		0.73458		2.8976		0.60461
440	1.0000e-08		1.0445		0.81960		1.6827		0.76081		2.6915		0.64602
445	1.0000e-08		0.6143		0.83536		1.5839		0.76960		2.4950		0.66505
450	1.0000e-08		0.7559		0.83979		1.6532		0.76538		3.0238		0.61280
455	1.0000e-08		0.7398		0.81763		1.8304		0.75673		3.3438		0.58347
460	1.0000e-08		0.6384		0.82512		1.6484		0.75013		2.4389		0.69349
465	1.0000e-08		0.7038		0.82905		1.5761		0.76881		2.4279		0.67071
470	1.0000e-08		0.9473		0.81349		1.9538		0.74564		3.1142		0.58926
475	1.0000e-08		0.5431		0.84780		1.5949		0.75996		2.4245		0.68519
480	1.0000e-08		0.6052		0.82086		1.6518		0.76966		2.6270		0.64446
485	1.0000e-08		0.6845		0.81474		1.6399		0.76512		2.5586		0.65661
490	1.0000e-08		0.7047		0.83936		1.8540		0.76002		3.4220		0.57595
495	1.0000e-08		0.8041		0.81731		1.7557		0.75846		2.5627		0.64714
500	1.0000e-08		0.6666		0.82023		1.9150		0.75110		2.6580		0.63477
505	1.0000e-08		0.6380		0.83673		1.6916		0.75878		2.7071		0.65143
510	1.0000e-08		0.6580		0.82402		1.5758		0.76754		2.4734		0.67542
515	1.0000e-08		0.6496		0.82889		1.8600		0.75172		2.7501		0.63357
520	1.0000e-08		0.6648		0.82628		2.0827		0.74108		3.2664		0.58036
525	1.0000e-08		0.7674		0.81663		1.6222		0.76251		2.4599		0.68317
530	1.0000e-08		0.5762		0.84434		1.7488		0.75798		3.4088		0.59170
535	1.0000e-08		0.5702		0.82804		1.7466		0.75497		2.5322		0.67936
540	1.0000e-08		0.8936		0.82607		1.6214		0.76604		2.5567		0.65563
545	1.0000e-08		0.6480		0.82960		1.9329		0.75408		2.7645		0.63331
550	1.0000e-08		0.7270		0.82110		1.7124		0.76045		2.4286		0.67945
555	1.0000e-08		0.5869		0.83123		1.5682		0.76733		2.4135		0.67955
560	1.0000e-08		0.6012		0.82141		1.9045		0.73865		2.6352		0.69731
565	1.0000e-08		0.8436		0.82599		1.6436		0.76859		2.4978		0.65269
570	1.0000e-08		0.6946		0.82718		1.6737		0.75541		2.4784		0.67297
575	1.0000e-08		0.6814		0.82681		1.5981		0.76599		2.4206		0.67571
580	1.0000e-08		0.7111		0.82435		1.5738		0.76517		2.4756		0.67781
585	1.0000e-08		0.7077		0.82489		1.7975		0.75231		2.4571		0.66476
590	1.0000e-08		0.6900		0.82824		1.8046		0.76127		3.7046		0.56531
595	1.0000e-08		0.6864		0.83023		1.8307		0.75712		2.8694		0.61551
600	1.0000e-08		0.5913		0.83722		1.7907		0.75618		2.8915		0.61888
605	1.0000e-08		0.6627		0.83440		1.7575		0.75839		2.7682		0.62849
610	1.0000e-08		0.7848		0.83018		1.5596		0.76442		2.3878		0.68932
615	1.0000e-08		0.6872		0.81513		1.7142		0.74894		2.4634		0.69586
620	1.0000e-08		0.6678		0.82332		1.6270		0.77332		2.5751		0.63750
625	1.0000e-08		0.7680		0.81869		1.8388		0.75299		2.4840		0.67022
630	1.0000e-08		0.7126		0.82399		1.6018		0.76924		2.6152		0.64980
635	1.0000e-08		0.6466		0.81655		1.6129		0.76190		2.3271		0.70301
640	1.0000e-08		0.7366		0.81911		1.6497		0.76079		2.5389		0.67241
645	1.0000e-08		0.6369		0.83334		1.5342		0.77252		2.4533		0.66237
650	1.0000e-08		0.6862		0.83104		1.7108		0.76303		2.6804		0.63818
655	1.0000e-08		0.7021		0.82973		1.6205		0.76572		2.5803		0.65682
660	1.0000e-08		0.9084		0.81572		1.5946		0.76122		2.3609		0.69066
665	1.0000e-08		0.6410		0.83664		1.7066		0.75117		2.4962		0.69092
670	1.0000e-08		0.7293		0.83134		1.7667		0.75566		3.1484		0.60340
675	1.0000e-08		0.7823		0.82991		1.6520		0.76788		2.4795		0.65856
680	1.0000e-08		0.7106		0.81853		1.7751		0.75595		2.6263		0.64410
685	1.0000e-08		0.7633		0.81528		1.6306		0.76504		2.5418		0.66615
690	1.0000e-08		0.6838		0.83987		1.5779		0.77291		2.7166		0.63613
695	1.0000e-08		0.7624		0.82577		1.9201		0.75063		2.5870		0.63426
700	1.0000e-08		0.7523		0.82840		1.7189		0.75390		2.4542		0.68414
705	1.0000e-08		0.7807		0.82117		1.9298		0.75059		2.9388		0.60349
710	1.0000e-08		0.6062		0.83358		2.7826		0.68963		4.6346		0.50188
715	1.0000e-08		0.6086		0.82749		1.6714		0.75455		2.4674		0.69491
720	1.0000e-08		0.7399		0.81697		1.8281		0.74132		2.4853		0.69982
725	1.0000e-08		0.8684		0.82278		1.7994		0.75805		2.7224		0.62621
730	1.0000e-08		0.6248		0.82643		1.9855		0.74843		2.8917		0.60753
735	1.0000e-08		0.7518		0.81198		1.7106		0.76094		2.4177		0.66804
740	1.0000e-08		0.6255		0.83541		2.0176		0.74013		3.1975		0.58296
745	1.0000e-08		0.6091		0.83231		1.6278		0.75572		2.4271		0.69024
750	1.0000e-08		0.6784		0.82331		1.8693		0.75334		2.4887		0.64984
755	1.0000e-08		0.6730		0.83795		1.9445		0.74912		3.4942		0.57471
760	1.0000e-08		0.6835		0.81961		1.5839		0.76565		2.4555		0.66799
765	1.0000e-08		0.6234		0.83217		1.7023		0.75219		2.3758		0.69815
770	1.0000e-08		0.7576		0.83486		1.6310		0.77222		2.9652		0.60905
775	1.0000e-08		0.6802		0.83581		1.5861		0.76248		2.6538		0.66028
780	1.0000e-08		0.6978		0.82477		2.0625		0.73332		2.9154		0.60841
785	1.0000e-08		0.6491		0.82784		1.7548		0.75990		2.5145		0.65495
790	1.0000e-08		0.7128		0.82395		1.8497		0.75461		2.8200		0.61881
795	1.0000e-08		0.6674		0.83073		1.7655		0.75600		2.4671		0.65944
800	1.0000e-08		0.6436		0.82491		1.8368		0.74853		2.3997		0.70227
805	1.0000e-08		0.7371		0.83124		1.9186		0.75471		3.5718		0.57849
810	1.0000e-08		0.6210		0.82605		1.6964		0.75264		2.4252		0.70213
815	1.0000e-08		0.6519		0.83041		1.7719		0.74430		2.4604		0.69857
820	1.0000e-08		0.6475		0.82078		1.6763		0.75230		2.5590		0.66834
825	1.0000e-08		0.6417		0.82738		1.9217		0.74973		2.8491		0.60930
830	1.0000e-08		0.6863		0.81093		1.6457		0.75552		2.5150		0.68392
835	1.0000e-08		0.8248		0.81193		1.5911		0.76831		2.4687		0.66937
840	1.0000e-08		0.5608		0.82525		1.9066		0.74788		3.1115		0.59870
845	1.0000e-08		0.5638		0.84924		1.9003		0.75375		3.9194		0.57232
850	1.0000e-08		0.6416		0.82714		1.6294		0.76268		2.7722		0.63996
855	1.0000e-08		0.6493		0.84810		1.7227		0.75287		3.1120		0.61782
860	1.0000e-08		0.6358		0.82425		1.6598		0.76181		2.5620		0.65816
865	1.0000e-08		0.7444		0.83434		1.7045		0.75791		2.5447		0.66306
870	1.0000e-08		0.6326		0.81593		1.7591		0.76138		2.4193		0.67403
875	1.0000e-08		0.7675		0.81887		1.8690		0.75152		2.8292		0.61812
880	1.0000e-08		0.6566		0.82593		1.7785		0.76265		2.5944		0.64157
885	1.0000e-08		0.7325		0.82750		1.5560		0.76819		2.4262		0.67606
890	1.0000e-08		0.8835		0.82594		1.9452		0.74887		2.9974		0.60292
895	1.0000e-08		0.6278		0.83489		1.5887		0.76495		2.7809		0.65305
900	1.0000e-08		0.6637		0.82602		1.7793		0.75539		2.8454		0.62961
905	1.0000e-08		0.5842		0.83963		1.8724		0.75057		2.6648		0.63334
910	1.0000e-08		0.7475		0.82796		1.6148		0.76722		2.3615		0.69577
915	1.0000e-08		0.6414		0.82651		1.6838		0.76606		2.5560		0.64989
920	1.0000e-08		0.6242		0.83440		1.6749		0.76373		2.6358		0.64479
925	1.0000e-08		0.6070		0.83765		1.8048		0.75802		2.9746		0.60369
930	1.0000e-08		0.7862		0.82028		1.5920		0.76213		2.8308		0.64988
935	1.0000e-08		0.9205		0.81809		1.7703		0.75785		3.2394		0.60577
940	1.0000e-08		0.6431		0.83291		1.7760		0.75869		2.8251		0.61960
945	1.0000e-08		0.6097		0.83623		1.5853		0.76598		2.3450		0.68063
950	1.0000e-08		0.7142		0.83321		2.6146		0.69849		3.7395		0.53993
955	1.0000e-08		0.8310		0.82186		1.6123		0.76699		2.7107		0.64403
960	1.0000e-08		0.8414		0.82044		1.9279		0.74767		2.9656		0.60098
965	1.0000e-08		0.6072		0.83080		1.6001		0.76954		2.6945		0.63774
970	1.0000e-08		0.9680		0.81864		1.8080		0.73794		2.5390		0.69166
975	1.0000e-08		0.7157		0.82591		1.7006		0.75594		2.3458		0.69901
980	1.0000e-08		0.5988		0.82883		1.5325		0.76785		2.5430		0.66230
985	1.0000e-08		0.8921		0.82629		1.8109		0.75830		2.6849		0.63254
990	1.0000e-08		0.6314		0.83282		1.6700		0.75739		2.4872		0.67967
995	1.0000e-08		0.6812		0.82826		1.7025		0.76183		2.8944		0.62814
1000	1.0000e-08		0.6245		0.82727		1.7060		0.75839		2.3505		0.68638
1005	1.0000e-08		0.7928		0.82660		2.0768		0.73705		3.9832		0.56217
1010	1.0000e-08		0.6383		0.83308		1.7572		0.75603		2.7216		0.63113
1015	1.0000e-08		0.7013		0.82195		1.6275		0.76867		2.6068		0.64602
1020	1.0000e-08		0.7127		0.82696		1.6562		0.76106		2.4558		0.67243
1025	1.0000e-08		0.9260		0.82370		1.6286		0.76052		2.6940		0.65360
1030	1.0000e-08		0.6024		0.82134		1.8562		0.75203		2.5764		0.64582
1035	1.0000e-08		0.6893		0.82415		1.6819		0.76018		2.5237		0.67519
1040	1.0000e-08		0.9583		0.81724		1.7262		0.76418		2.5365		0.65543
1045	1.0000e-08		0.7192		0.82660		1.5554		0.76653		2.4096		0.68822
1050	1.0000e-08		0.7364		0.81674		1.7125		0.76044		2.5432		0.65344
1055	1.0000e-08		0.7017		0.83911		1.5893		0.77052		2.6303		0.64087
1060	1.0000e-08		0.6864		0.81525		1.8516		0.74505		2.3905		0.70512
1065	1.0000e-08		0.6215		0.83405		1.7307		0.75335		2.3247		0.69693
1070	1.0000e-08		0.6700		0.82406		1.6886		0.75546		2.3919		0.69387
1075	1.0000e-08		0.8287		0.83001		2.4032		0.71564		4.6486		0.50936
1080	1.0000e-08		0.6576		0.82802		1.5990		0.76275		2.3802		0.67628
1085	1.0000e-08		0.6771		0.82116		1.6624		0.76854		2.7018		0.63796
1090	1.0000e-08		0.7169		0.82365		1.8564		0.75097		2.6880		0.63311
1095	1.0000e-08		0.6369		0.83101		1.5706		0.77064		2.7189		0.64244
1100	1.0000e-08		0.7533		0.80613		1.6886		0.75759		2.5253		0.67313
1105	1.0000e-08		0.7912		0.82631		1.6315		0.76477		2.6087		0.65744
1110	1.0000e-08		0.8196		0.81977		1.6381		0.76573		2.4149		0.68698
1115	1.0000e-08		0.7113		0.82814		1.8269		0.75256		2.9900		0.62037
1120	1.0000e-08		0.7164		0.84038		1.9557		0.75303		3.5646		0.58701
