=============training from sratch============
Program ID: 17990

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy', '3', '0', '0']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      Sep 30th, 2019
      1   With size-reduced ROI of size 51*149*149;
      2   reduce the translation of data augmentation;
      3   reduce all data into 35 patients, excluding a very blur patient.
      Oct 5th, 2019
      1   use uniform physical size 147mm*147mm*147mm, input pixel size: 49*147*147 with spacing size 3mm*1mm*1mm;
      2   change V model with inputsize 49*147*147
      Oct 6th, 2019
      1   add filter number to 48 at the first layer. 
      Oct 7th, 2019
      1   restore to 32 of number of filters in the first layer;
      2   add bottom number of filters to 1024, and keep down sample and add filter number together. 
      Oct 8th, 2019
      1   discard the cancer with size exceeding 147mm*147mm*147mm; Now remains 29 patients data; 
      Oct 9th, 2019
      1   In the first layer of V model, remove the residual link; 
           with the residula link at first layer: Tr dice:54%, Validation Dice 27%, Test Dice 56%;  Not good.
      2   the final output layer, change into 1*1*1 convolution, instead of 3*3*3 convolution;
      3   add labelConsistencyLoss, it use 64 dimension feature extracted from 2 ends of V model:
           It gets stable Training Dice 61%, validation Dice 27%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      Oct 11th, 2019
      1   use feature tensor just from the output end of V model. It is 32 dimensions.
          It gets stable Training Dice 61%, validation Dice 23%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      2   windows size for consistency loss changes to 3;
      Oct 12th, 2019
      1   change image window level to 100/50; relaunch training;
      2   change consistencyLoss to use ground truth for comparing diff of feature vector;
      Oct 13th, 2019
      1    use conistencyLoss3: ((G1-G2)-(P1-P2))**2 as loss.
      
      Oct 18th, 2019
      1   use 48 filters at the first layer with inputsize 49*147*147 with scaled ROI.
       
      
       
      

          
         

Discarded changes:                  
          

Program starting Time: 2019-10-18 15:09:29.247849
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191018_150929

Info: this is the 3th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 1

Info: useConsistencyLoss = False and searchWindowSize= 0

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191018_150929.
6-fold cross validation: the 3th fold is for test, the 4th fold is for validation, remaining folds are for training.

training dataset: total 23 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Total 23 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROISmall/labels_npy
0 has 19147801 elements, with a rate of  0.7862493867884996 
1 has 5205542 elements, with a rate of  0.21375061321150038 
loss weight = tensor([1.0000, 3.6783])
Network has total 254,652,146 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		4.9312		0.13536		4.1769		0.43565		4.3729		0.51414
5	1.0000e-02		2.0862		0.65982		2.6285		0.61000		2.2178		0.68021
10	1.0000e-02		2.2227		0.63761		1.8450		0.67212		1.8645		0.75889
15	1.0000e-02		1.9706		0.66324		2.0082		0.66543		1.5874		0.76886
20	1.0000e-02		1.5782		0.71560		2.1256		0.63936		1.7733		0.74143
25	1.0000e-02		1.6364		0.68741		1.9570		0.63107		1.8874		0.72018
30	1.0000e-02		1.9466		0.66234		2.3035		0.64656		2.9608		0.58697
35	1.0000e-02		1.5379		0.70220		2.0483		0.66912		1.8619		0.74740
40	1.0000e-02		1.8593		0.65374		2.8666		0.53723		2.1176		0.75448
45	1.0000e-02		1.5237		0.71266		4.0015		0.54850		3.9586		0.64565
50	1.0000e-02		1.8482		0.69172		1.6689		0.71053		1.9533		0.71100
55	1.0000e-02		1.7619		0.72984		2.3211		0.64079		2.0029		0.70996
60	1.0000e-02		1.6427		0.69441		2.0501		0.66019		2.3432		0.68368
65	1.0000e-02		1.4090		0.73270		2.1374		0.65968		2.0754		0.75311
70	1.0000e-02		1.2211		0.75731		2.3676		0.65380		1.4864		0.76766
75	1.0000e-02		1.0306		0.74029		2.9801		0.63640		3.1934		0.65488
80	1.0000e-02		1.3104		0.74466		3.3690		0.59177		3.8597		0.61762
85	1.0000e-02		1.2188		0.74479		2.3731		0.60671		3.4149		0.65207
90	1.0000e-02		1.3236		0.75007		2.7017		0.63083		3.3568		0.62425
95	1.0000e-02		1.1395		0.76017		2.4752		0.58335		2.5904		0.68882
100	1.0000e-02		1.0626		0.77996		2.4401		0.65938		2.3598		0.71132
105	1.0000e-03		0.8434		0.78353		2.4638		0.64073		2.8796		0.68850
110	1.0000e-03		1.0156		0.79930		2.0078		0.67913		2.2875		0.75143
115	1.0000e-03		0.9314		0.79010		2.0463		0.66467		2.6226		0.73318
120	1.0000e-03		0.8729		0.79660		2.0518		0.67505		2.4734		0.72148
125	1.0000e-03		0.7636		0.79964		2.2303		0.65863		2.8419		0.71873
130	1.0000e-03		0.7688		0.80301		2.2944		0.65870		2.9501		0.72047
135	1.0000e-03		0.9082		0.81239		2.6102		0.63324		3.1709		0.70860
140	1.0000e-03		0.8552		0.81022		2.6180		0.63606		3.2707		0.71033
145	1.0000e-03		0.8958		0.80086		2.5251		0.64119		3.3963		0.69718
150	1.0000e-03		0.7920		0.81636		2.6768		0.64304		3.3542		0.73742
155	1.0000e-03		0.6681		0.81691		2.6002		0.62680		3.5732		0.70092
160	1.0000e-04		0.7940		0.80695		2.6622		0.61826		2.5735		0.75040
165	1.0000e-04		0.7294		0.80892		2.3897		0.64411		3.0708		0.73033
170	1.0000e-04		0.6991		0.81246		2.2795		0.65595		2.9324		0.73328
175	1.0000e-04		0.7953		0.81861		2.7391		0.61388		3.0833		0.73481
180	1.0000e-04		0.6896		0.82267		2.4077		0.64890		3.1974		0.72866
185	1.0000e-04		0.6780		0.81035		2.2985		0.63914		3.3997		0.70391
190	1.0000e-04		0.6886		0.83417		2.9359		0.59476		3.7790		0.70430
195	1.0000e-04		0.7996		0.82546		2.5226		0.64283		3.2703		0.72647
200	1.0000e-04		0.8349		0.82009		2.7825		0.61240		3.6352		0.70638
205	1.0000e-04		0.9347		0.80664		2.5141		0.64414		3.1166		0.72733
210	1.0000e-04		0.8980		0.81777		2.7082		0.58613		3.0167		0.71797
215	1.0000e-05		0.7406		0.82851		2.8050		0.59923		3.9028		0.69249
220	1.0000e-05		0.6575		0.82149		2.8025		0.60002		3.4966		0.70888
225	1.0000e-05		0.5942		0.81948		2.5914		0.62171		3.5185		0.70088
230	1.0000e-05		0.7431		0.82218		2.8061		0.61516		3.6365		0.71205
235	1.0000e-05		0.7768		0.81130		2.6831		0.61438		3.8338		0.69647
240	1.0000e-05		0.6282		0.82193		2.6580		0.62052		3.4338		0.71213
245	1.0000e-05		0.7012		0.82057		2.5403		0.63440		3.5188		0.70854
250	1.0000e-05		0.6645		0.83126		2.6630		0.63010		3.6308		0.70137
255	1.0000e-05		0.5974		0.83139		2.6897		0.61347		3.8349		0.69173
260	1.0000e-05		0.7732		0.82756		2.6501		0.62558		3.5383		0.71290
265	1.0000e-05		0.7037		0.80973		2.6346		0.61703		3.4526		0.70240
270	1.0000e-06		0.7459		0.81764		2.5840		0.62821		3.3701		0.71518
275	1.0000e-06		0.8027		0.81865		2.8385		0.60364		3.6998		0.70317
280	1.0000e-06		0.7238		0.81370		2.3703		0.62845		3.2750		0.71511
285	1.0000e-06		0.6625		0.82955		2.6501		0.61260		3.5237		0.71099
290	1.0000e-06		0.6551		0.81974		2.6696		0.61766		3.5921		0.70048
295	1.0000e-06		0.7167		0.81654		2.4143		0.63978		3.4393		0.70575
300	1.0000e-06		0.6850		0.82529		2.6242		0.63810		3.4590		0.71300
305	1.0000e-06		0.6853		0.81147		2.5925		0.63296		3.7322		0.69543
310	1.0000e-06		0.8196		0.81868		3.3218		0.57091		4.5876		0.67260
315	1.0000e-06		0.6942		0.82368		2.9205		0.59926		4.0026		0.69332
320	1.0000e-06		0.7712		0.81917		2.4925		0.63961		3.4699		0.71400
325	1.0000e-07		0.7702		0.81984		2.5227		0.62677		3.4858		0.70388
330	1.0000e-07		0.6807		0.83453		2.6281		0.61383		3.5077		0.71382
335	1.0000e-07		0.6837		0.83003		2.9837		0.59383		4.2030		0.69101
340	1.0000e-07		0.6748		0.82289		2.5636		0.61769		3.4630		0.70487
345	1.0000e-07		0.7326		0.80367		2.6565		0.59663		3.1972		0.70717
350	1.0000e-07		0.6672		0.81963		2.7294		0.61220		3.3757		0.71473
355	1.0000e-07		0.6557		0.82098		2.5404		0.60492		3.3150		0.70970
360	1.0000e-07		0.7361		0.81933		2.4868		0.64538		3.2007		0.71895
365	1.0000e-07		0.7253		0.82407		2.5083		0.62500		3.2875		0.72053
370	1.0000e-07		0.6669		0.82238		2.3194		0.62579		3.4446		0.70491
375	1.0000e-07		0.8021		0.80586		2.3303		0.62575		3.1844		0.70636
380	1.0000e-08		0.8933		0.82127		3.0365		0.58400		3.8514		0.69966
385	1.0000e-08		0.7240		0.82251		2.5912		0.62224		3.9165		0.69408
390	1.0000e-08		0.5835		0.83094		2.6796		0.61274		3.9345		0.69640
395	1.0000e-08		0.7438		0.82654		2.6347		0.61512		3.6410		0.70757
400	1.0000e-08		0.6974		0.81740		2.6415		0.61570		3.4251		0.70813
405	1.0000e-08		0.6335		0.82371		2.5465		0.61688		3.5965		0.70578
410	1.0000e-08		0.6217		0.83384		2.8273		0.61242		4.1698		0.69020
415	1.0000e-08		0.7231		0.82581		2.8250		0.60696		3.5788		0.71475
420	1.0000e-08		0.6623		0.81636		2.7941		0.60805		3.8430		0.69533
425	1.0000e-08		0.6767		0.83935		3.0335		0.59053		4.1876		0.68802
430	1.0000e-08		0.6026		0.82502		2.7545		0.60776		3.4680		0.70761
435	1.0000e-08		0.7203		0.82344		2.5965		0.63768		3.6323		0.70950
440	1.0000e-08		0.7933		0.81591		2.6799		0.61144		3.4651		0.71419
445	1.0000e-08		0.6321		0.82224		2.5873		0.60462		3.3355		0.70073
450	1.0000e-08		1.0106		0.80674		2.6793		0.59699		3.1933		0.71864
455	1.0000e-08		0.7846		0.82941		2.7722		0.62032		3.6024		0.70916
460	1.0000e-08		0.8113		0.80839		2.5904		0.62448		3.4753		0.70347
465	1.0000e-08		0.7030		0.81822		2.5953		0.62683		3.7192		0.70007
470	1.0000e-08		0.6550		0.82147		2.6322		0.61968		3.5639		0.70139
475	1.0000e-08		0.6257		0.82738		2.9445		0.60400		4.2086		0.68984
480	1.0000e-08		0.7470		0.82212		2.6698		0.61891		3.6683		0.69871
485	1.0000e-08		0.6404		0.82732		2.7519		0.60953		3.7403		0.70269
490	1.0000e-08		0.6757		0.82616		2.3423		0.64836		3.3746		0.70923
495	1.0000e-08		0.6832		0.83308		2.4538		0.65550		3.5104		0.70721
500	1.0000e-08		0.6801		0.82167		2.9622		0.59827		3.9686		0.69581
505	1.0000e-08		0.6944		0.81753		2.6238		0.59703		3.4311		0.71339
510	1.0000e-08		0.7753		0.82165		2.5411		0.63428		3.4864		0.70564
515	1.0000e-08		0.6837		0.82310		2.5783		0.62111		3.3769		0.71352
520	1.0000e-08		0.7137		0.81572		2.9294		0.59134		3.5348		0.70738
525	1.0000e-08		0.8548		0.80820		2.5965		0.63463		3.4832		0.71461
530	1.0000e-08		0.7331		0.81883		2.5740		0.61273		3.2512		0.71788
535	1.0000e-08		0.7227		0.80932		2.6309		0.63408		3.4546		0.71433
540	1.0000e-08		0.7569		0.82920		2.7103		0.61162		3.7087		0.70202
545	1.0000e-08		0.6681		0.82123		2.4908		0.62202		3.3510		0.71355
550	1.0000e-08		0.6462		0.82899		2.8581		0.60166		3.9128		0.69348
555	1.0000e-08		0.7391		0.82274		2.7236		0.60518		3.7853		0.70151
560	1.0000e-08		0.7541		0.82584		2.6855		0.60701		3.5150		0.70492
565	1.0000e-08		0.6752		0.82140		2.4325		0.63265		3.3598		0.70611
570	1.0000e-08		0.5918		0.82952		2.5096		0.62503		3.6510		0.68338
575	1.0000e-08		0.9607		0.81863		2.8088		0.60975		3.8486		0.70481
580	1.0000e-08		0.7177		0.81574		2.3099		0.64216		3.2023		0.71714
585	1.0000e-08		0.7525		0.82520		2.9087		0.59290		3.4030		0.71640
590	1.0000e-08		0.6710		0.83556		2.8053		0.61289		4.2771		0.68541
595	1.0000e-08		0.7746		0.82063		2.3723		0.64220		3.5512		0.71149
600	1.0000e-08		0.7645		0.81086		2.3746		0.63402		3.7288		0.70474
605	1.0000e-08		0.7497		0.80769		2.5380		0.60319		3.2867		0.71683
610	1.0000e-08		0.7987		0.81146		2.7303		0.61077		3.1446		0.72197
615	1.0000e-08		0.6506		0.82877		2.8095		0.60705		3.5610		0.70502
620	1.0000e-08		0.6273		0.82393		2.5346		0.63277		3.4498		0.69870
625	1.0000e-08		0.6178		0.82603		2.5204		0.62512		3.5098		0.70025
630	1.0000e-08		0.8548		0.81315		2.5823		0.63185		3.1557		0.72439
635	1.0000e-08		0.7179		0.81581		2.3711		0.63875		3.4711		0.70616
640	1.0000e-08		0.6749		0.81487		2.3493		0.62996		3.3306		0.71117
645	1.0000e-08		0.7722		0.82757		2.8623		0.59316		3.2039		0.72079
650	1.0000e-08		0.6119		0.82158		2.4879		0.61914		3.4268		0.71161
655	1.0000e-08		0.7109		0.82794		2.6634		0.59967		3.3035		0.71492
660	1.0000e-08		0.6411		0.82223		2.3938		0.63157		3.2868		0.70318
665	1.0000e-08		0.6877		0.82206		3.2278		0.56900		4.1623		0.68215
670	1.0000e-08		0.7335		0.81919		2.5149		0.62769		3.4699		0.70996
675	1.0000e-08		0.6940		0.82116		2.6104		0.60608		3.4724		0.71303
680	1.0000e-08		0.6282		0.81792		2.5218		0.62676		3.3699		0.70908
685	1.0000e-08		0.7386		0.82443		3.0122		0.58920		4.1793		0.68414
690	1.0000e-08		0.7412		0.82796		3.3685		0.54606		4.1780		0.68298
695	1.0000e-08		0.7276		0.82162		2.4764		0.64240		3.7178		0.69740
700	1.0000e-08		0.7106		0.82478		2.9343		0.60315		4.1982		0.68680
705	1.0000e-08		0.6269		0.82224		2.4046		0.64145		3.4103		0.71320
710	1.0000e-08		0.7912		0.83133		3.4341		0.54473		4.3001		0.68233
715	1.0000e-08		0.7448		0.81544		2.3702		0.64183		3.6821		0.70259
720	1.0000e-08		0.6842		0.81466		2.5052		0.62741		3.4439		0.70020
725	1.0000e-08		0.6435		0.82497		2.4257		0.61555		3.4392		0.69700
730	1.0000e-08		0.6154		0.83295		2.8848		0.61432		4.0783		0.69417
735	1.0000e-08		0.7095		0.82160		2.4888		0.60894		3.4242		0.70992
740	1.0000e-08		0.6953		0.82038		2.8986		0.59551		3.4868		0.71257
745	1.0000e-08		0.6735		0.81916		2.6530		0.61260		3.7692		0.69863
750	1.0000e-08		0.6813		0.81643		2.7515		0.60261		3.2962		0.69480
755	1.0000e-08		0.6826		0.82600		3.0451		0.59149		4.3267		0.67693
760	1.0000e-08		0.7283		0.82363		3.0076		0.58298		3.8126		0.69745
765	1.0000e-08		0.7700		0.83102		2.8406		0.60896		4.0244		0.68745
770	1.0000e-08		0.6535		0.82670		2.5712		0.63201		3.4105		0.70693
775	1.0000e-08		0.6903		0.81579		2.4884		0.60918		3.3473		0.70718
780	1.0000e-08		0.6629		0.81993		2.5914		0.61177		3.4177		0.71268
785	1.0000e-08		0.6764		0.82223		2.8297		0.59917		3.6680		0.69893
790	1.0000e-08		0.7154		0.82633		2.7500		0.61010		3.8518		0.69204
795	1.0000e-08		0.6074		0.83490		2.7018		0.62797		3.5473		0.70566
800	1.0000e-08		0.7717		0.81885		2.7403		0.61644		3.3490		0.71961
805	1.0000e-08		0.8881		0.82586		2.6756		0.62385		3.8408		0.69852
810	1.0000e-08		0.8435		0.82219		2.6558		0.62026		3.8876		0.69958
815	1.0000e-08		0.7204		0.82758		2.6898		0.61426		3.5174		0.71042
820	1.0000e-08		0.7729		0.81959		2.7844		0.62140		3.8165		0.70250
825	1.0000e-08		0.7373		0.80931		2.4606		0.62835		3.5604		0.71076
830	1.0000e-08		0.6797		0.81175		2.6007		0.61444		3.4340		0.71247
835	1.0000e-08		0.7225		0.82601		2.8493		0.60293		3.7233		0.70151
840	1.0000e-08		0.7734		0.81399		2.5313		0.60416		3.3689		0.71019
845	1.0000e-08		0.7255		0.81354		2.8328		0.58569		3.2384		0.71441
850	1.0000e-08		0.7620		0.81382		2.5756		0.60366		3.1653		0.71735
855	1.0000e-08		0.7752		0.82227		2.8668		0.59976		3.7938		0.70596
860	1.0000e-08		0.5859		0.83195		2.5781		0.63806		3.6101		0.70964
865	1.0000e-08		0.8451		0.81740		2.7804		0.61953		3.7074		0.70905
870	1.0000e-08		0.6529		0.82171		2.4637		0.62194		3.4041		0.71936
875	1.0000e-08		0.7316		0.82854		2.6340		0.61163		3.7016		0.70258
880	1.0000e-08		0.7795		0.82711		2.3626		0.63286		3.2322		0.71553
885	1.0000e-08		0.7310		0.82190		3.0673		0.57763		3.9371		0.69482
890	1.0000e-08		0.7146		0.83581		3.0287		0.59359		4.2748		0.68367
895	1.0000e-08		0.7409		0.82424		2.9884		0.59729		4.0771		0.68805
900	1.0000e-08		0.6443		0.82720		3.1137		0.56937		3.9059		0.69506
905	1.0000e-08		0.7531		0.81869		3.0908		0.58095		3.7561		0.70408
910	1.0000e-08		0.6242		0.81546		2.6730		0.60204		3.6156		0.71565
915	1.0000e-08		0.7487		0.81665		2.4808		0.61184		3.5563		0.71722
920	1.0000e-08		0.7473		0.82113		2.4160		0.63225		3.0447		0.71882
925	1.0000e-08		0.7019		0.83013		3.1583		0.58316		4.5185		0.67197
930	1.0000e-08		0.7740		0.81672		2.4523		0.63681		3.7472		0.69711
935	1.0000e-08		0.7448		0.81037		2.5633		0.63663		3.2243		0.71741
940	1.0000e-08		0.6749		0.83702		2.7527		0.61660		3.6562		0.70972
945	1.0000e-08		0.6151		0.83528		2.7488		0.61578		4.0166		0.69085
950	1.0000e-08		0.6106		0.83204		2.7849		0.61322		3.8841		0.70641
955	1.0000e-08		0.7348		0.82557		2.6121		0.61137		3.6297		0.70743
960	1.0000e-08		0.7342		0.82110		3.0546		0.57526		3.6746		0.69904
965	1.0000e-08		0.7393		0.81862		3.0562		0.58428		4.0871		0.68657
970	1.0000e-08		0.8836		0.81303		2.3927		0.64611		3.6532		0.69221
975	1.0000e-08		0.6666		0.81828		2.5774		0.60965		3.3414		0.72163
980	1.0000e-08		0.6984		0.82643		2.6911		0.59988		3.6741		0.70451
985	1.0000e-08		0.6747		0.82926		3.0427		0.59103		4.2172		0.68551
990	1.0000e-08		0.6576		0.82895		2.5795		0.61586		3.5405		0.71023
995	1.0000e-08		0.7734		0.82297		2.7986		0.60588		3.7548		0.69105
1000	1.0000e-08		0.7395		0.82396		2.5100		0.62958		3.1847		0.72095
1005	1.0000e-08		0.7569		0.81655		2.8515		0.59472		3.5749		0.70746
1010	1.0000e-08		0.6802		0.82699		3.0001		0.58665		3.8399		0.68845
1015	1.0000e-08		0.5602		0.82603		3.0139		0.58093		3.2478		0.69635
1020	1.0000e-08		0.6917		0.82355		2.9271		0.60471		4.0975		0.69641
1025	1.0000e-08		0.6728		0.83193		2.5909		0.61317		3.2673		0.71965
1030	1.0000e-08		0.8201		0.81475		3.0702		0.57925		4.1344		0.68421
1035	1.0000e-08		0.6890		0.81716		2.4749		0.60895		3.3412		0.70870
1040	1.0000e-08		0.6399		0.81979		2.6896		0.63141		3.8294		0.70292
1045	1.0000e-08		0.6109		0.83320		2.5853		0.61381		3.3544		0.71371
1050	1.0000e-08		0.6092		0.82128		2.5151		0.63506		3.6702		0.69486
1055	1.0000e-08		0.7918		0.82200		2.4373		0.64092		3.4127		0.70570
1060	1.0000e-08		0.6622		0.82213		2.5358		0.61747		3.5134		0.71061
1065	1.0000e-08		0.6850		0.81816		2.8326		0.61276		3.8566		0.70103
1070	1.0000e-08		0.6572		0.83096		2.9013		0.60213		3.8344		0.69458
1075	1.0000e-08		0.7442		0.81684		2.5511		0.60460		3.2873		0.72097
1080	1.0000e-08		0.7067		0.81807		2.4866		0.62788		3.4303		0.71204
1085	1.0000e-08		0.7877		0.82915		3.0937		0.58159		4.0062		0.69540
1090	1.0000e-08		0.7219		0.82512		2.7353		0.60680		3.7324		0.68384
1095	1.0000e-08		0.6822		0.82849		2.6239		0.61955		3.6367		0.70482
1100	1.0000e-08		0.7226		0.81814		2.6033		0.61043		3.2503		0.71554
1105	1.0000e-08		0.7551		0.82174		2.7811		0.61650		3.7418		0.70083
1110	1.0000e-08		0.7801		0.83634		3.4360		0.55575		4.6432		0.67421
1115	1.0000e-08		0.7187		0.82449		2.7354		0.61784		3.5057		0.69933
1120	1.0000e-08		0.7432		0.81923		2.7709		0.59737		3.3316		0.71496
