=============training from sratch============
Program ID: 11988

Program command: 
 ['TrainResNeXtVNet.py', '/home/hxie1/temp_netParameters/OvarianCancer/ResNeXtVNet', '1', '/home/hxie1/data/OvarianCancerCT/pixelSize223withLabel/numpy', '/home/hxie1/data/OvarianCancerCT/pixelSize223withLabel/numpyLabel', '0', '3,2,1']

Major program changes: 
     1  a V model with ResNeXt block: use z convolution, and then xy convolution, to implement 3D convolution.
     2  at ground truth, only check the segmented slices, about 3 slices per patient;
     3  the input is whole 3D volume, instead of ROI around a segmented slice;
     4  support input data augmentation: affine in xy plane, and translation in z direction;
     5  input Size: 231*251*251 with label, instead of previous SkyWatch Model of 29*140*140;
     6  treat all 1,2,3 labels as 1, in other words, do not differentiate primary, metastase, and nymph node;  
    

Discarded changes:                  

Experiment setting:
Input CT data: maximum size 231*251*251 (zyx) of 3D numpy array with spacing size(3*2*2)

Loss Function:  BCELogitLoss

Data:   total 143 patients with weak annotaton label, 5-fold cross validation, test 29, validation 29, and training 85.  

Training strategy: 

          

Program starting Time: 2019-09-01 03:04:05.854085
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/ResNeXtVNet/20190901_030405

Info: this is the 0th fold leave for test in the 5-fold cross-validation.

Info: batchSize = 12

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/ResNeXtVNet/20190901_030405.
5-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 85 image files.

validation dataset: total 29 image files.

test dataset: total 29 image files.
Network has total 26,372,379 parameters.


************** Table of Train Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-01		8220767.9375	0.03211		3235281.8333	0.00456		5010955.9167	0.00213
5	1.0000e-01		1438906.0234	0.07489		2005310.1250	0.02622		2781561.5833	0.02608
10	1.0000e-01		1501736.2910	0.08201		1787014.1250	0.08246		2732802.0833	0.06758
15	1.0000e-01		1373243.2754	0.10230		2270532.6042	0.00432		3265236.3958	0.00639
20	1.0000e-01		1559853.6284	0.09118		1920949.1667	0.06933		2458226.0000	0.08720
25	1.0000e-01		1360472.4639	0.09686		2006730.7500	0.09796		3112314.1875	0.10014
30	1.0000e-01		1284182.5654	0.10351		2418842.9375	0.08325		3412412.1250	0.08624
35	1.0000e-01		1229454.2988	0.11133		1946536.3958	0.08241		2437125.2708	0.09936
40	1.0000e-01		1193919.2788	0.09632		4677055.5000	0.05974		5008409.9167	0.07245
