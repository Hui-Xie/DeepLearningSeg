Program ID 29097

Program command: 
 ['/home/hxie1/Projects/OvarianCancer/TrainSegV.py', '/home/hxie1/temp_netParameters/OvarianCancer/Label0_1', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainImages', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels', '2D', '0,1,2']

Major program changes: ConvDense uses Conv-Bn-ReLU order (CBR)
                       Dense Layer = 4 
                       output layer use conv with 3*3 fiter instead of 1*1 filter. 
                       use boundary loss with weight 0 at beginning, and pretrain CE loss. 
                       special convInput Module
                       convOutput moudel uses 1*1 conv to get tranparent gradient 
                       ConvOutput use residual module.
                       first layer filter = 96
                       use Mixup and DenseNet
                       Boundary Loss supports multi-class.
                       For 0,1,2 three classes clasfication for primary and metastases
                       
            

Program starting Time: 2019-05-13 16:51:14.095144
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/Label0_1

Infor: program test labels: [0, 1, 2]
Infor: program suppressed labels: [3]
Infor: program test labels: [0, 1, 2]
Infor: program suppressed labels: [3]
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels has 436 segmented slices for remained labels [0, 1, 2].
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/testLabels has 136 segmented slices for remained labels [0, 1, 2].
Info: program uses 2D input.
TrainData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=3

TestData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=3

Info: program uses Mixup with alpha=0.4, and mixupProb = 0.5.
Network trains from scratch.
Network has total 115864227 parameters.
Info: network dropout rate = 0.2
Infor: Cross Entropy Weight: [1.0416883685076772, 39.37007874015748, 68.39945280437757]

====================Net Architecture===========================
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 96, 281, 281]             960
       BatchNorm2d-2         [-1, 96, 281, 281]             192
              ReLU-3         [-1, 96, 281, 281]               0
    BN_ReLU_Conv2d-4         [-1, 96, 281, 281]               0
            Conv2d-5         [-1, 96, 281, 281]           9,312
       BatchNorm2d-6         [-1, 96, 281, 281]             192
              ReLU-7         [-1, 96, 281, 281]               0
    BN_ReLU_Conv2d-8         [-1, 96, 281, 281]               0
            Conv2d-9         [-1, 24, 281, 281]          20,760
      BatchNorm2d-10         [-1, 24, 281, 281]              48
             ReLU-11         [-1, 24, 281, 281]               0
   BN_ReLU_Conv2d-12         [-1, 24, 281, 281]               0
           Conv2d-13         [-1, 96, 281, 281]          11,616
      BatchNorm2d-14         [-1, 96, 281, 281]             192
             ReLU-15         [-1, 96, 281, 281]               0
   BN_ReLU_Conv2d-16         [-1, 96, 281, 281]               0
           Conv2d-17         [-1, 24, 281, 281]          20,760
      BatchNorm2d-18         [-1, 24, 281, 281]              48
             ReLU-19         [-1, 24, 281, 281]               0
   BN_ReLU_Conv2d-20         [-1, 24, 281, 281]               0
           Conv2d-21         [-1, 96, 281, 281]          13,920
      BatchNorm2d-22         [-1, 96, 281, 281]             192
             ReLU-23         [-1, 96, 281, 281]               0
   BN_ReLU_Conv2d-24         [-1, 96, 281, 281]               0
           Conv2d-25         [-1, 24, 281, 281]          20,760
      BatchNorm2d-26         [-1, 24, 281, 281]              48
             ReLU-27         [-1, 24, 281, 281]               0
   BN_ReLU_Conv2d-28         [-1, 24, 281, 281]               0
           Conv2d-29         [-1, 96, 281, 281]          16,224
      BatchNorm2d-30         [-1, 96, 281, 281]             192
             ReLU-31         [-1, 96, 281, 281]               0
   BN_ReLU_Conv2d-32         [-1, 96, 281, 281]               0
           Conv2d-33         [-1, 24, 281, 281]          20,760
      BatchNorm2d-34         [-1, 24, 281, 281]              48
             ReLU-35         [-1, 24, 281, 281]               0
   BN_ReLU_Conv2d-36         [-1, 24, 281, 281]               0
           Conv2d-37         [-1, 96, 281, 281]          18,528
      BatchNorm2d-38         [-1, 96, 281, 281]             192
             ReLU-39         [-1, 96, 281, 281]               0
   BN_ReLU_Conv2d-40         [-1, 96, 281, 281]               0
        ConvDense-41         [-1, 96, 281, 281]               0
ConvBuildingBlock-42         [-1, 96, 281, 281]               0
        ConvInput-43         [-1, 96, 281, 281]               0
           Conv2d-44         [-1, 96, 139, 139]         230,496
      BatchNorm2d-45         [-1, 96, 139, 139]             192
             ReLU-46         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-47         [-1, 96, 139, 139]               0
           Conv2d-48         [-1, 96, 139, 139]           9,312
      BatchNorm2d-49         [-1, 96, 139, 139]             192
             ReLU-50         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-51         [-1, 96, 139, 139]               0
           Conv2d-52         [-1, 24, 139, 139]          20,760
      BatchNorm2d-53         [-1, 24, 139, 139]              48
             ReLU-54         [-1, 24, 139, 139]               0
   BN_ReLU_Conv2d-55         [-1, 24, 139, 139]               0
           Conv2d-56         [-1, 96, 139, 139]          11,616
      BatchNorm2d-57         [-1, 96, 139, 139]             192
             ReLU-58         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-59         [-1, 96, 139, 139]               0
           Conv2d-60         [-1, 24, 139, 139]          20,760
      BatchNorm2d-61         [-1, 24, 139, 139]              48
             ReLU-62         [-1, 24, 139, 139]               0
   BN_ReLU_Conv2d-63         [-1, 24, 139, 139]               0
           Conv2d-64         [-1, 96, 139, 139]          13,920
      BatchNorm2d-65         [-1, 96, 139, 139]             192
             ReLU-66         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-67         [-1, 96, 139, 139]               0
           Conv2d-68         [-1, 24, 139, 139]          20,760
      BatchNorm2d-69         [-1, 24, 139, 139]              48
             ReLU-70         [-1, 24, 139, 139]               0
   BN_ReLU_Conv2d-71         [-1, 24, 139, 139]               0
           Conv2d-72         [-1, 96, 139, 139]          16,224
      BatchNorm2d-73         [-1, 96, 139, 139]             192
             ReLU-74         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-75         [-1, 96, 139, 139]               0
           Conv2d-76         [-1, 24, 139, 139]          20,760
      BatchNorm2d-77         [-1, 24, 139, 139]              48
             ReLU-78         [-1, 24, 139, 139]               0
   BN_ReLU_Conv2d-79         [-1, 24, 139, 139]               0
           Conv2d-80         [-1, 96, 139, 139]          18,528
      BatchNorm2d-81         [-1, 96, 139, 139]             192
             ReLU-82         [-1, 96, 139, 139]               0
   BN_ReLU_Conv2d-83         [-1, 96, 139, 139]               0
        ConvDense-84         [-1, 96, 139, 139]               0
ConvBuildingBlock-85         [-1, 96, 139, 139]               0
         Down2dBB-86         [-1, 96, 139, 139]               0
        Dropout2d-87         [-1, 96, 139, 139]               0
           Conv2d-88          [-1, 192, 69, 69]         166,080
      BatchNorm2d-89          [-1, 192, 69, 69]             384
             ReLU-90          [-1, 192, 69, 69]               0
   BN_ReLU_Conv2d-91          [-1, 192, 69, 69]               0
           Conv2d-92          [-1, 192, 69, 69]          37,056
      BatchNorm2d-93          [-1, 192, 69, 69]             384
             ReLU-94          [-1, 192, 69, 69]               0
   BN_ReLU_Conv2d-95          [-1, 192, 69, 69]               0
           Conv2d-96           [-1, 48, 69, 69]          82,992
      BatchNorm2d-97           [-1, 48, 69, 69]              96
             ReLU-98           [-1, 48, 69, 69]               0
   BN_ReLU_Conv2d-99           [-1, 48, 69, 69]               0
          Conv2d-100          [-1, 192, 69, 69]          46,272
     BatchNorm2d-101          [-1, 192, 69, 69]             384
            ReLU-102          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-103          [-1, 192, 69, 69]               0
          Conv2d-104           [-1, 48, 69, 69]          82,992
     BatchNorm2d-105           [-1, 48, 69, 69]              96
            ReLU-106           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-107           [-1, 48, 69, 69]               0
          Conv2d-108          [-1, 192, 69, 69]          55,488
     BatchNorm2d-109          [-1, 192, 69, 69]             384
            ReLU-110          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-111          [-1, 192, 69, 69]               0
          Conv2d-112           [-1, 48, 69, 69]          82,992
     BatchNorm2d-113           [-1, 48, 69, 69]              96
            ReLU-114           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-115           [-1, 48, 69, 69]               0
          Conv2d-116          [-1, 192, 69, 69]          64,704
     BatchNorm2d-117          [-1, 192, 69, 69]             384
            ReLU-118          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-119          [-1, 192, 69, 69]               0
          Conv2d-120           [-1, 48, 69, 69]          82,992
     BatchNorm2d-121           [-1, 48, 69, 69]              96
            ReLU-122           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-123           [-1, 48, 69, 69]               0
          Conv2d-124          [-1, 192, 69, 69]          73,920
     BatchNorm2d-125          [-1, 192, 69, 69]             384
            ReLU-126          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-127          [-1, 192, 69, 69]               0
       ConvDense-128          [-1, 192, 69, 69]               0
ConvBuildingBlock-129          [-1, 192, 69, 69]               0
        Down2dBB-130          [-1, 192, 69, 69]               0
       Dropout2d-131          [-1, 192, 69, 69]               0
          Conv2d-132          [-1, 384, 33, 33]       1,843,584
     BatchNorm2d-133          [-1, 384, 33, 33]             768
            ReLU-134          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-135          [-1, 384, 33, 33]               0
          Conv2d-136          [-1, 384, 33, 33]         147,840
     BatchNorm2d-137          [-1, 384, 33, 33]             768
            ReLU-138          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-139          [-1, 384, 33, 33]               0
          Conv2d-140           [-1, 96, 33, 33]         331,872
     BatchNorm2d-141           [-1, 96, 33, 33]             192
            ReLU-142           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-143           [-1, 96, 33, 33]               0
          Conv2d-144          [-1, 384, 33, 33]         184,704
     BatchNorm2d-145          [-1, 384, 33, 33]             768
            ReLU-146          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-147          [-1, 384, 33, 33]               0
          Conv2d-148           [-1, 96, 33, 33]         331,872
     BatchNorm2d-149           [-1, 96, 33, 33]             192
            ReLU-150           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-151           [-1, 96, 33, 33]               0
          Conv2d-152          [-1, 384, 33, 33]         221,568
     BatchNorm2d-153          [-1, 384, 33, 33]             768
            ReLU-154          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-155          [-1, 384, 33, 33]               0
          Conv2d-156           [-1, 96, 33, 33]         331,872
     BatchNorm2d-157           [-1, 96, 33, 33]             192
            ReLU-158           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-159           [-1, 96, 33, 33]               0
          Conv2d-160          [-1, 384, 33, 33]         258,432
     BatchNorm2d-161          [-1, 384, 33, 33]             768
            ReLU-162          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-163          [-1, 384, 33, 33]               0
          Conv2d-164           [-1, 96, 33, 33]         331,872
     BatchNorm2d-165           [-1, 96, 33, 33]             192
            ReLU-166           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-167           [-1, 96, 33, 33]               0
          Conv2d-168          [-1, 384, 33, 33]         295,296
     BatchNorm2d-169          [-1, 384, 33, 33]             768
            ReLU-170          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-171          [-1, 384, 33, 33]               0
       ConvDense-172          [-1, 384, 33, 33]               0
ConvBuildingBlock-173          [-1, 384, 33, 33]               0
        Down2dBB-174          [-1, 384, 33, 33]               0
       Dropout2d-175          [-1, 384, 33, 33]               0
          Conv2d-176          [-1, 768, 15, 15]       7,373,568
     BatchNorm2d-177          [-1, 768, 15, 15]           1,536
            ReLU-178          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-179          [-1, 768, 15, 15]               0
          Conv2d-180          [-1, 768, 15, 15]         590,592
     BatchNorm2d-181          [-1, 768, 15, 15]           1,536
            ReLU-182          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-183          [-1, 768, 15, 15]               0
          Conv2d-184          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-185          [-1, 192, 15, 15]             384
            ReLU-186          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-187          [-1, 192, 15, 15]               0
          Conv2d-188          [-1, 768, 15, 15]         738,048
     BatchNorm2d-189          [-1, 768, 15, 15]           1,536
            ReLU-190          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-191          [-1, 768, 15, 15]               0
          Conv2d-192          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-193          [-1, 192, 15, 15]             384
            ReLU-194          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-195          [-1, 192, 15, 15]               0
          Conv2d-196          [-1, 768, 15, 15]         885,504
     BatchNorm2d-197          [-1, 768, 15, 15]           1,536
            ReLU-198          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-199          [-1, 768, 15, 15]               0
          Conv2d-200          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-201          [-1, 192, 15, 15]             384
            ReLU-202          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-203          [-1, 192, 15, 15]               0
          Conv2d-204          [-1, 768, 15, 15]       1,032,960
     BatchNorm2d-205          [-1, 768, 15, 15]           1,536
            ReLU-206          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-207          [-1, 768, 15, 15]               0
          Conv2d-208          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-209          [-1, 192, 15, 15]             384
            ReLU-210          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-211          [-1, 192, 15, 15]               0
          Conv2d-212          [-1, 768, 15, 15]       1,180,416
     BatchNorm2d-213          [-1, 768, 15, 15]           1,536
            ReLU-214          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-215          [-1, 768, 15, 15]               0
       ConvDense-216          [-1, 768, 15, 15]               0
ConvBuildingBlock-217          [-1, 768, 15, 15]               0
        Down2dBB-218          [-1, 768, 15, 15]               0
       Dropout2d-219          [-1, 768, 15, 15]               0
          Conv2d-220           [-1, 1536, 7, 7]      10,618,368
     BatchNorm2d-221           [-1, 1536, 7, 7]           3,072
            ReLU-222           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-223           [-1, 1536, 7, 7]               0
          Conv2d-224           [-1, 1536, 7, 7]       2,360,832
     BatchNorm2d-225           [-1, 1536, 7, 7]           3,072
            ReLU-226           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-227           [-1, 1536, 7, 7]               0
          Conv2d-228            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-229            [-1, 384, 7, 7]             768
            ReLU-230            [-1, 384, 7, 7]               0
  BN_ReLU_Conv2d-231            [-1, 384, 7, 7]               0
          Conv2d-232           [-1, 1536, 7, 7]       2,950,656
     BatchNorm2d-233           [-1, 1536, 7, 7]           3,072
            ReLU-234           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-235           [-1, 1536, 7, 7]               0
          Conv2d-236            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-237            [-1, 384, 7, 7]             768
            ReLU-238            [-1, 384, 7, 7]               0
  BN_ReLU_Conv2d-239            [-1, 384, 7, 7]               0
          Conv2d-240           [-1, 1536, 7, 7]       3,540,480
     BatchNorm2d-241           [-1, 1536, 7, 7]           3,072
            ReLU-242           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-243           [-1, 1536, 7, 7]               0
          Conv2d-244            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-245            [-1, 384, 7, 7]             768
            ReLU-246            [-1, 384, 7, 7]               0
  BN_ReLU_Conv2d-247            [-1, 384, 7, 7]               0
          Conv2d-248           [-1, 1536, 7, 7]       4,130,304
     BatchNorm2d-249           [-1, 1536, 7, 7]           3,072
            ReLU-250           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-251           [-1, 1536, 7, 7]               0
          Conv2d-252            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-253            [-1, 384, 7, 7]             768
            ReLU-254            [-1, 384, 7, 7]               0
  BN_ReLU_Conv2d-255            [-1, 384, 7, 7]               0
          Conv2d-256           [-1, 1536, 7, 7]       4,720,128
     BatchNorm2d-257           [-1, 1536, 7, 7]           3,072
            ReLU-258           [-1, 1536, 7, 7]               0
  BN_ReLU_Conv2d-259           [-1, 1536, 7, 7]               0
       ConvDense-260           [-1, 1536, 7, 7]               0
ConvBuildingBlock-261           [-1, 1536, 7, 7]               0
        Down2dBB-262           [-1, 1536, 7, 7]               0
       Dropout2d-263           [-1, 1536, 7, 7]               0
 ConvTranspose2d-264          [-1, 768, 15, 15]      10,617,600
     BatchNorm2d-265          [-1, 768, 15, 15]           1,536
            ReLU-266          [-1, 768, 15, 15]               0
 BN_ReLU_ConvT2d-267          [-1, 768, 15, 15]               0
          Conv2d-268          [-1, 768, 15, 15]         590,592
     BatchNorm2d-269          [-1, 768, 15, 15]           1,536
            ReLU-270          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-271          [-1, 768, 15, 15]               0
          Conv2d-272          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-273          [-1, 192, 15, 15]             384
            ReLU-274          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-275          [-1, 192, 15, 15]               0
          Conv2d-276          [-1, 768, 15, 15]         738,048
     BatchNorm2d-277          [-1, 768, 15, 15]           1,536
            ReLU-278          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-279          [-1, 768, 15, 15]               0
          Conv2d-280          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-281          [-1, 192, 15, 15]             384
            ReLU-282          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-283          [-1, 192, 15, 15]               0
          Conv2d-284          [-1, 768, 15, 15]         885,504
     BatchNorm2d-285          [-1, 768, 15, 15]           1,536
            ReLU-286          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-287          [-1, 768, 15, 15]               0
          Conv2d-288          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-289          [-1, 192, 15, 15]             384
            ReLU-290          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-291          [-1, 192, 15, 15]               0
          Conv2d-292          [-1, 768, 15, 15]       1,032,960
     BatchNorm2d-293          [-1, 768, 15, 15]           1,536
            ReLU-294          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-295          [-1, 768, 15, 15]               0
          Conv2d-296          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-297          [-1, 192, 15, 15]             384
            ReLU-298          [-1, 192, 15, 15]               0
  BN_ReLU_Conv2d-299          [-1, 192, 15, 15]               0
          Conv2d-300          [-1, 768, 15, 15]       1,180,416
     BatchNorm2d-301          [-1, 768, 15, 15]           1,536
            ReLU-302          [-1, 768, 15, 15]               0
  BN_ReLU_Conv2d-303          [-1, 768, 15, 15]               0
       ConvDense-304          [-1, 768, 15, 15]               0
ConvBuildingBlock-305          [-1, 768, 15, 15]               0
          Up2dBB-306          [-1, 768, 15, 15]               0
       Dropout2d-307          [-1, 768, 15, 15]               0
 ConvTranspose2d-308          [-1, 384, 33, 33]      14,745,984
     BatchNorm2d-309          [-1, 384, 33, 33]             768
            ReLU-310          [-1, 384, 33, 33]               0
 BN_ReLU_ConvT2d-311          [-1, 384, 33, 33]               0
          Conv2d-312          [-1, 384, 33, 33]         147,840
     BatchNorm2d-313          [-1, 384, 33, 33]             768
            ReLU-314          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-315          [-1, 384, 33, 33]               0
          Conv2d-316           [-1, 96, 33, 33]         331,872
     BatchNorm2d-317           [-1, 96, 33, 33]             192
            ReLU-318           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-319           [-1, 96, 33, 33]               0
          Conv2d-320          [-1, 384, 33, 33]         184,704
     BatchNorm2d-321          [-1, 384, 33, 33]             768
            ReLU-322          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-323          [-1, 384, 33, 33]               0
          Conv2d-324           [-1, 96, 33, 33]         331,872
     BatchNorm2d-325           [-1, 96, 33, 33]             192
            ReLU-326           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-327           [-1, 96, 33, 33]               0
          Conv2d-328          [-1, 384, 33, 33]         221,568
     BatchNorm2d-329          [-1, 384, 33, 33]             768
            ReLU-330          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-331          [-1, 384, 33, 33]               0
          Conv2d-332           [-1, 96, 33, 33]         331,872
     BatchNorm2d-333           [-1, 96, 33, 33]             192
            ReLU-334           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-335           [-1, 96, 33, 33]               0
          Conv2d-336          [-1, 384, 33, 33]         258,432
     BatchNorm2d-337          [-1, 384, 33, 33]             768
            ReLU-338          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-339          [-1, 384, 33, 33]               0
          Conv2d-340           [-1, 96, 33, 33]         331,872
     BatchNorm2d-341           [-1, 96, 33, 33]             192
            ReLU-342           [-1, 96, 33, 33]               0
  BN_ReLU_Conv2d-343           [-1, 96, 33, 33]               0
          Conv2d-344          [-1, 384, 33, 33]         295,296
     BatchNorm2d-345          [-1, 384, 33, 33]             768
            ReLU-346          [-1, 384, 33, 33]               0
  BN_ReLU_Conv2d-347          [-1, 384, 33, 33]               0
       ConvDense-348          [-1, 384, 33, 33]               0
ConvBuildingBlock-349          [-1, 384, 33, 33]               0
          Up2dBB-350          [-1, 384, 33, 33]               0
       Dropout2d-351          [-1, 384, 33, 33]               0
 ConvTranspose2d-352          [-1, 192, 69, 69]       3,686,592
     BatchNorm2d-353          [-1, 192, 69, 69]             384
            ReLU-354          [-1, 192, 69, 69]               0
 BN_ReLU_ConvT2d-355          [-1, 192, 69, 69]               0
          Conv2d-356          [-1, 192, 69, 69]          37,056
     BatchNorm2d-357          [-1, 192, 69, 69]             384
            ReLU-358          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-359          [-1, 192, 69, 69]               0
          Conv2d-360           [-1, 48, 69, 69]          82,992
     BatchNorm2d-361           [-1, 48, 69, 69]              96
            ReLU-362           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-363           [-1, 48, 69, 69]               0
          Conv2d-364          [-1, 192, 69, 69]          46,272
     BatchNorm2d-365          [-1, 192, 69, 69]             384
            ReLU-366          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-367          [-1, 192, 69, 69]               0
          Conv2d-368           [-1, 48, 69, 69]          82,992
     BatchNorm2d-369           [-1, 48, 69, 69]              96
            ReLU-370           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-371           [-1, 48, 69, 69]               0
          Conv2d-372          [-1, 192, 69, 69]          55,488
     BatchNorm2d-373          [-1, 192, 69, 69]             384
            ReLU-374          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-375          [-1, 192, 69, 69]               0
          Conv2d-376           [-1, 48, 69, 69]          82,992
     BatchNorm2d-377           [-1, 48, 69, 69]              96
            ReLU-378           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-379           [-1, 48, 69, 69]               0
          Conv2d-380          [-1, 192, 69, 69]          64,704
     BatchNorm2d-381          [-1, 192, 69, 69]             384
            ReLU-382          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-383          [-1, 192, 69, 69]               0
          Conv2d-384           [-1, 48, 69, 69]          82,992
     BatchNorm2d-385           [-1, 48, 69, 69]              96
            ReLU-386           [-1, 48, 69, 69]               0
  BN_ReLU_Conv2d-387           [-1, 48, 69, 69]               0
          Conv2d-388          [-1, 192, 69, 69]          73,920
     BatchNorm2d-389          [-1, 192, 69, 69]             384
            ReLU-390          [-1, 192, 69, 69]               0
  BN_ReLU_Conv2d-391          [-1, 192, 69, 69]               0
       ConvDense-392          [-1, 192, 69, 69]               0
ConvBuildingBlock-393          [-1, 192, 69, 69]               0
          Up2dBB-394          [-1, 192, 69, 69]               0
       Dropout2d-395          [-1, 192, 69, 69]               0
 ConvTranspose2d-396         [-1, 96, 139, 139]         331,872
     BatchNorm2d-397         [-1, 96, 139, 139]             192
            ReLU-398         [-1, 96, 139, 139]               0
 BN_ReLU_ConvT2d-399         [-1, 96, 139, 139]               0
          Conv2d-400         [-1, 96, 139, 139]           9,312
     BatchNorm2d-401         [-1, 96, 139, 139]             192
            ReLU-402         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-403         [-1, 96, 139, 139]               0
          Conv2d-404         [-1, 24, 139, 139]          20,760
     BatchNorm2d-405         [-1, 24, 139, 139]              48
            ReLU-406         [-1, 24, 139, 139]               0
  BN_ReLU_Conv2d-407         [-1, 24, 139, 139]               0
          Conv2d-408         [-1, 96, 139, 139]          11,616
     BatchNorm2d-409         [-1, 96, 139, 139]             192
            ReLU-410         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-411         [-1, 96, 139, 139]               0
          Conv2d-412         [-1, 24, 139, 139]          20,760
     BatchNorm2d-413         [-1, 24, 139, 139]              48
            ReLU-414         [-1, 24, 139, 139]               0
  BN_ReLU_Conv2d-415         [-1, 24, 139, 139]               0
          Conv2d-416         [-1, 96, 139, 139]          13,920
     BatchNorm2d-417         [-1, 96, 139, 139]             192
            ReLU-418         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-419         [-1, 96, 139, 139]               0
          Conv2d-420         [-1, 24, 139, 139]          20,760
     BatchNorm2d-421         [-1, 24, 139, 139]              48
            ReLU-422         [-1, 24, 139, 139]               0
  BN_ReLU_Conv2d-423         [-1, 24, 139, 139]               0
          Conv2d-424         [-1, 96, 139, 139]          16,224
     BatchNorm2d-425         [-1, 96, 139, 139]             192
            ReLU-426         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-427         [-1, 96, 139, 139]               0
          Conv2d-428         [-1, 24, 139, 139]          20,760
     BatchNorm2d-429         [-1, 24, 139, 139]              48
            ReLU-430         [-1, 24, 139, 139]               0
  BN_ReLU_Conv2d-431         [-1, 24, 139, 139]               0
          Conv2d-432         [-1, 96, 139, 139]          18,528
     BatchNorm2d-433         [-1, 96, 139, 139]             192
            ReLU-434         [-1, 96, 139, 139]               0
  BN_ReLU_Conv2d-435         [-1, 96, 139, 139]               0
       ConvDense-436         [-1, 96, 139, 139]               0
ConvBuildingBlock-437         [-1, 96, 139, 139]               0
          Up2dBB-438         [-1, 96, 139, 139]               0
       Dropout2d-439         [-1, 96, 139, 139]               0
 ConvTranspose2d-440         [-1, 96, 281, 281]         460,896
     BatchNorm2d-441         [-1, 96, 281, 281]             192
            ReLU-442         [-1, 96, 281, 281]               0
 BN_ReLU_ConvT2d-443         [-1, 96, 281, 281]               0
          Conv2d-444         [-1, 96, 281, 281]           9,312
     BatchNorm2d-445         [-1, 96, 281, 281]             192
            ReLU-446         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-447         [-1, 96, 281, 281]               0
          Conv2d-448         [-1, 24, 281, 281]          20,760
     BatchNorm2d-449         [-1, 24, 281, 281]              48
            ReLU-450         [-1, 24, 281, 281]               0
  BN_ReLU_Conv2d-451         [-1, 24, 281, 281]               0
          Conv2d-452         [-1, 96, 281, 281]          11,616
     BatchNorm2d-453         [-1, 96, 281, 281]             192
            ReLU-454         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-455         [-1, 96, 281, 281]               0
          Conv2d-456         [-1, 24, 281, 281]          20,760
     BatchNorm2d-457         [-1, 24, 281, 281]              48
            ReLU-458         [-1, 24, 281, 281]               0
  BN_ReLU_Conv2d-459         [-1, 24, 281, 281]               0
          Conv2d-460         [-1, 96, 281, 281]          13,920
     BatchNorm2d-461         [-1, 96, 281, 281]             192
            ReLU-462         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-463         [-1, 96, 281, 281]               0
          Conv2d-464         [-1, 24, 281, 281]          20,760
     BatchNorm2d-465         [-1, 24, 281, 281]              48
            ReLU-466         [-1, 24, 281, 281]               0
  BN_ReLU_Conv2d-467         [-1, 24, 281, 281]               0
          Conv2d-468         [-1, 96, 281, 281]          16,224
     BatchNorm2d-469         [-1, 96, 281, 281]             192
            ReLU-470         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-471         [-1, 96, 281, 281]               0
          Conv2d-472         [-1, 24, 281, 281]          20,760
     BatchNorm2d-473         [-1, 24, 281, 281]              48
            ReLU-474         [-1, 24, 281, 281]               0
  BN_ReLU_Conv2d-475         [-1, 24, 281, 281]               0
          Conv2d-476         [-1, 96, 281, 281]          18,528
     BatchNorm2d-477         [-1, 96, 281, 281]             192
            ReLU-478         [-1, 96, 281, 281]               0
  BN_ReLU_Conv2d-479         [-1, 96, 281, 281]               0
       ConvDense-480         [-1, 96, 281, 281]               0
ConvBuildingBlock-481         [-1, 96, 281, 281]               0
          Up2dBB-482         [-1, 96, 281, 281]               0
       Dropout2d-483         [-1, 96, 281, 281]               0
          Conv2d-484        [-1, 192, 281, 281]          37,056
     BatchNorm2d-485        [-1, 192, 281, 281]             384
            ReLU-486        [-1, 192, 281, 281]               0
  BN_ReLU_Conv2d-487        [-1, 192, 281, 281]               0
          Conv2d-488         [-1, 48, 281, 281]          82,992
     BatchNorm2d-489         [-1, 48, 281, 281]              96
            ReLU-490         [-1, 48, 281, 281]               0
  BN_ReLU_Conv2d-491         [-1, 48, 281, 281]               0
          Conv2d-492        [-1, 192, 281, 281]          46,272
     BatchNorm2d-493        [-1, 192, 281, 281]             384
            ReLU-494        [-1, 192, 281, 281]               0
  BN_ReLU_Conv2d-495        [-1, 192, 281, 281]               0
          Conv2d-496         [-1, 48, 281, 281]          82,992
     BatchNorm2d-497         [-1, 48, 281, 281]              96
            ReLU-498         [-1, 48, 281, 281]               0
  BN_ReLU_Conv2d-499         [-1, 48, 281, 281]               0
          Conv2d-500        [-1, 192, 281, 281]          55,488
     BatchNorm2d-501        [-1, 192, 281, 281]             384
            ReLU-502        [-1, 192, 281, 281]               0
  BN_ReLU_Conv2d-503        [-1, 192, 281, 281]               0
          Conv2d-504         [-1, 48, 281, 281]          82,992
     BatchNorm2d-505         [-1, 48, 281, 281]              96
            ReLU-506         [-1, 48, 281, 281]               0
  BN_ReLU_Conv2d-507         [-1, 48, 281, 281]               0
          Conv2d-508        [-1, 192, 281, 281]          64,704
     BatchNorm2d-509        [-1, 192, 281, 281]             384
            ReLU-510        [-1, 192, 281, 281]               0
  BN_ReLU_Conv2d-511        [-1, 192, 281, 281]               0
          Conv2d-512         [-1, 48, 281, 281]          82,992
     BatchNorm2d-513         [-1, 48, 281, 281]              96
            ReLU-514         [-1, 48, 281, 281]               0
  BN_ReLU_Conv2d-515         [-1, 48, 281, 281]               0
          Conv2d-516        [-1, 192, 281, 281]          73,920
     BatchNorm2d-517        [-1, 192, 281, 281]             384
            ReLU-518        [-1, 192, 281, 281]               0
  BN_ReLU_Conv2d-519        [-1, 192, 281, 281]               0
       ConvDense-520        [-1, 192, 281, 281]               0
ConvBuildingBlock-521        [-1, 192, 281, 281]               0
          Conv2d-522          [-1, 3, 281, 281]             579
      ConvOutput-523          [-1, 3, 281, 281]               0
================================================================
Total params: 115,863,843
Trainable params: 115,863,843
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.30
Forward/backward pass size (MB): 8313.34
Params size (MB): 441.99
Estimated Total Size (MB): 8755.62
----------------------------------------------------------------
===================End of Net Architecture =====================

Info: program will use 4 GPUs.
Loss Functions List: FocalCELoss with weight of 1; 	BoundaryLoss with weight of 0; 
Hints: Test Dice_0 is the dice coeff for all non-zero labels
Hints: Test Dice_1 is for primary cancer(green), 	
 test Dice_2 is for metastasis(yellow), 	
 and test Dice_3 is for invaded lymph node(brown).
Hints: Test TPR_0 is the TPR for all non-zero labels
Hints: Test TPR_1 is for primary cancer(green), 	
 TPR_2 is for metastasis(yellow), 	
 and TPR_3 is for invaded lymph node(brown).

Epoch 	 TrainingLoss	Dice_0	Dice_1	Dice_2	TPR_0	TPR_1	TPR_2	 TestLoss Dice_0Dice_1	Dice_2	TPR_0	TPR_1	TPR_2		
0 	 0.3759 	0.158	0.176	0.084	0.928	0.454	0.586	0.3492	0.161	0.448	0.043	0.865	0.824	0.215
1 	 0.3217 	0.240	0.300	0.112	0.915	0.569	0.543	0.3657	0.157	0.328	0.061	0.920	0.618	0.496
2 	 0.3052 	0.262	0.334	0.109	0.879	0.611	0.392	0.2737	0.218	0.000	0.148	0.956	0.000	0.959
3 	 0.2924 	0.299	0.327	0.152	0.931	0.467	0.587	0.2879	0.220	0.545	0.048	0.965	0.939	0.226
4 	 0.2873 	0.287	0.411	0.158	0.919	0.506	0.563	0.2428	0.246	0.654	0.085	0.934	0.810	0.468
5 	 0.2684 	0.320	0.468	0.181	0.926	0.648	0.611	0.2506	0.243	0.000	0.169	0.928	0.000	0.914
6 	 0.2663 	0.291	0.357	0.152	0.933	0.491	0.639	0.2460	0.284	0.657	0.122	0.895	0.849	0.438
7 	 0.2671 	0.289	0.584	0.113	0.921	0.764	0.457	0.2293	0.259	0.653	0.122	0.936	0.773	0.589
8 	 0.2689 	0.265	0.460	0.131	0.922	0.630	0.633	0.2661	0.194	0.637	0.050	0.967	0.924	0.338
9 	 0.2481 	0.271	0.537	0.136	0.919	0.725	0.563	0.2490	0.277	0.644	0.126	0.830	0.818	0.412
10 	 0.2638 	0.276	0.478	0.158	0.924	0.605	0.653	0.3078	0.198	0.582	0.060	0.961	0.901	0.320
11 	 0.2671 	0.267	0.579	0.149	0.931	0.722	0.615	0.2446	0.211	0.656	0.107	0.968	0.774	0.688
12 	 0.2658 	0.241	0.368	0.160	0.934	0.486	0.728	0.2627	0.209	0.644	0.072	0.975	0.881	0.466
13 	 0.2518 	0.294	0.464	0.187	0.921	0.626	0.662	0.2085	0.280	0.581	0.206	0.879	0.569	0.816
14 	 0.2579 	0.276	0.432	0.197	0.918	0.527	0.785	0.2115	0.257	0.675	0.150	0.911	0.795	0.671
15 	 0.2485 	0.267	0.550	0.167	0.930	0.781	0.687	0.2838	0.245	0.573	0.202	0.795	0.630	0.675
16 	 0.2596 	0.282	0.553	0.165	0.927	0.703	0.688	0.2716	0.295	0.428	0.219	0.757	0.366	0.713
17 	 0.2447 	0.257	0.575	0.176	0.922	0.802	0.733	0.2229	0.255	0.508	0.176	0.874	0.813	0.642
18 	 0.2509 	0.279	0.543	0.167	0.912	0.697	0.670	0.2036	0.258	0.640	0.175	0.857	0.890	0.701
19 	 0.2509 	0.278	0.556	0.151	0.918	0.799	0.615	0.2102	0.249	0.554	0.176	0.943	0.694	0.843
20 	 0.2427 	0.288	0.546	0.162	0.942	0.828	0.673	0.2238	0.237	0.556	0.143	0.940	0.895	0.607
21 	 0.2329 	0.251	0.545	0.185	0.938	0.722	0.782	0.2045	0.251	0.574	0.175	0.882	0.857	0.719
22 	 0.2268 	0.289	0.564	0.189	0.913	0.795	0.721	0.2029	0.288	0.658	0.207	0.780	0.796	0.677
23 	 0.2374 	0.272	0.535	0.203	0.939	0.805	0.759	0.1941	0.260	0.601	0.182	0.804	0.880	0.641
24 	 0.2205 	0.268	0.572	0.178	0.911	0.822	0.713	0.1891	0.240	0.627	0.165	0.936	0.962	0.724
25 	 0.2285 	0.276	0.492	0.204	0.921	0.812	0.734	0.1974	0.269	0.582	0.181	0.871	0.936	0.634
26 	 0.2269 	0.282	0.558	0.182	0.915	0.802	0.714	0.2723	0.317	0.544	0.233	0.619	0.569	0.517
27 	 0.2327 	0.277	0.533	0.176	0.932	0.838	0.712	0.1783	0.231	0.604	0.158	0.930	0.880	0.814
28 	 0.2323 	0.285	0.556	0.171	0.931	0.794	0.709	0.2371	0.267	0.577	0.193	0.766	0.806	0.562
29 	 0.2303 	0.287	0.440	0.200	0.935	0.699	0.745	0.2240	0.251	0.508	0.180	0.934	0.520	0.914
30 	 0.2294 	0.269	0.509	0.194	0.921	0.807	0.718	0.1767	0.276	0.628	0.199	0.878	0.871	0.746
31 	 0.2341 	0.289	0.540	0.203	0.933	0.818	0.727	0.1900	0.248	0.562	0.173	0.931	0.811	0.821
32 	 0.2094 	0.292	0.570	0.213	0.928	0.859	0.759	0.1663	0.260	0.605	0.184	0.940	0.817	0.845
33 	 0.2092 	0.287	0.520	0.212	0.935	0.801	0.742	0.1868	0.304	0.571	0.226	0.833	0.676	0.786
34 	 0.2079 	0.307	0.506	0.227	0.938	0.838	0.708	0.1597	0.283	0.625	0.212	0.928	0.870	0.816
35 	 0.2151 	0.280	0.545	0.193	0.939	0.843	0.815	0.2162	0.303	0.563	0.235	0.848	0.749	0.754
36 	 0.2055 	0.307	0.544	0.218	0.940	0.788	0.769	0.1410	0.292	0.608	0.229	0.921	0.928	0.789
37 	 0.2064 	0.274	0.546	0.189	0.952	0.867	0.782	0.1580	0.262	0.600	0.194	0.948	0.871	0.859
38 	 0.2088 	0.313	0.569	0.195	0.940	0.883	0.754	0.1544	0.300	0.606	0.218	0.834	0.912	0.678
39 	 0.1978 	0.286	0.543	0.218	0.947	0.858	0.810	0.1499	0.307	0.652	0.245	0.848	0.878	0.755
40 	 0.2033 	0.262	0.496	0.205	0.939	0.807	0.786	0.1510	0.308	0.660	0.226	0.849	0.864	0.753
41 	 0.1904 	0.308	0.554	0.235	0.937	0.906	0.790	0.1533	0.286	0.596	0.216	0.929	0.826	0.843
42 	 0.1922 	0.326	0.566	0.256	0.950	0.870	0.825	0.2301	0.285	0.485	0.213	0.884	0.568	0.865
43 	 0.2125 	0.300	0.544	0.201	0.947	0.776	0.798	0.1869	0.309	0.620	0.223	0.858	0.910	0.636
44 	 0.1760 	0.313	0.511	0.244	0.954	0.842	0.815	0.1565	0.306	0.597	0.252	0.865	0.819	0.789
45 	 0.1757 	0.301	0.518	0.230	0.930	0.868	0.772	0.1494	0.261	0.570	0.211	0.951	0.834	0.880
46 	 0.1889 	0.304	0.537	0.231	0.944	0.876	0.804	0.1507	0.296	0.633	0.220	0.924	0.871	0.848
47 	 0.1957 	0.291	0.487	0.218	0.938	0.823	0.782	0.1550	0.297	0.612	0.200	0.893	0.922	0.742
48 	 0.1812 	0.286	0.523	0.217	0.941	0.884	0.821	0.1502	0.307	0.584	0.230	0.907	0.824	0.821
49 	 0.1948 	0.288	0.490	0.237	0.957	0.818	0.842	0.1577	0.292	0.596	0.210	0.926	0.795	0.875
50 	 0.1975 	0.303	0.537	0.243	0.963	0.943	0.845	0.1799	0.247	0.536	0.185	0.930	0.908	0.792
51 	 0.1836 	0.311	0.527	0.243	0.943	0.874	0.815	0.1438	0.273	0.607	0.203	0.956	0.874	0.880
52 	 0.1864 	0.311	0.538	0.242	0.960	0.846	0.834	0.1567	0.311	0.667	0.224	0.926	0.894	0.790
53 	 0.1902 	0.313	0.477	0.260	0.957	0.877	0.838	0.1605	0.302	0.646	0.218	0.923	0.902	0.822
54 	 0.2006 	0.321	0.548	0.234	0.964	0.821	0.838	0.1673	0.237	0.582	0.166	0.981	0.928	0.834
55 	 0.2210 	0.285	0.476	0.223	0.949	0.792	0.809	0.1828	0.269	0.561	0.203	0.961	0.952	0.802
56 	 0.1976 	0.290	0.543	0.215	0.944	0.850	0.813	0.1426	0.277	0.593	0.202	0.952	0.916	0.861
57 	 0.1817 	0.326	0.595	0.224	0.939	0.868	0.783	0.1919	0.324	0.568	0.254	0.892	0.681	0.857
58 	 0.1838 	0.289	0.544	0.214	0.949	0.899	0.821	0.1992	0.266	0.571	0.187	0.940	0.711	0.879
59 	 0.1664 	0.302	0.525	0.234	0.962	0.912	0.863	0.1525	0.294	0.625	0.206	0.948	0.932	0.806
60 	 0.1557 	0.317	0.559	0.240	0.953	0.893	0.794	0.1356	0.253	0.644	0.164	0.962	0.897	0.882
61 	 0.1620 	0.322	0.533	0.256	0.936	0.852	0.822	0.1605	0.270	0.629	0.210	0.936	0.865	0.853
62 	 0.1887 	0.294	0.540	0.219	0.961	0.890	0.829	0.1412	0.322	0.654	0.241	0.918	0.910	0.815
63 	 0.1799 	0.310	0.544	0.214	0.951	0.832	0.801	0.1398	0.342	0.552	0.283	0.896	0.750	0.837
64 	 0.1672 	0.321	0.537	0.250	0.960	0.873	0.849	0.1368	0.299	0.599	0.223	0.926	0.907	0.820
65 	 0.1570 	0.312	0.533	0.232	0.944	0.869	0.837	0.4216	0.328	0.431	0.258	0.744	0.412	0.759
66 	 0.1659 	0.307	0.563	0.235	0.959	0.930	0.827	0.1397	0.300	0.539	0.224	0.934	0.844	0.849
67 	 0.1683 	0.330	0.576	0.264	0.942	0.894	0.824	0.1908	0.337	0.580	0.272	0.861	0.783	0.771
68 	 0.1597 	0.326	0.578	0.239	0.942	0.861	0.812	0.1711	0.292	0.605	0.196	0.924	0.769	0.857
69 	 0.1836 	0.279	0.499	0.238	0.945	0.863	0.846	0.2968	0.280	0.435	0.215	0.921	0.434	0.905
70 	 0.1716 	0.310	0.545	0.246	0.959	0.891	0.830	0.1427	0.257	0.567	0.189	0.968	0.906	0.873
71 	 0.1777 	0.313	0.576	0.235	0.948	0.910	0.815	0.1468	0.269	0.551	0.199	0.972	0.893	0.881
72 	 0.1647 	0.304	0.554	0.238	0.963	0.932	0.827	0.1395	0.296	0.582	0.236	0.947	0.802	0.896
73 	 0.1691 	0.304	0.535	0.248	0.952	0.892	0.832	0.1503	0.295	0.537	0.211	0.917	0.663	0.859
74 	 0.1819 	0.302	0.510	0.227	0.952	0.865	0.842	0.1540	0.281	0.560	0.202	0.932	0.702	0.907
75 	 0.1883 	0.321	0.528	0.253	0.960	0.901	0.893	0.2565	0.357	0.535	0.304	0.754	0.591	0.698
76 	 0.1635 	0.335	0.574	0.272	0.958	0.868	0.829	0.1542	0.286	0.562	0.217	0.953	0.914	0.834
77 	 0.1624 	0.323	0.576	0.237	0.951	0.917	0.817	0.1360	0.338	0.635	0.256	0.925	0.851	0.852
78 	 0.1555 	0.330	0.571	0.254	0.937	0.930	0.854	0.1536	0.257	0.576	0.165	0.981	0.946	0.858
79 	 0.1683 	0.321	0.546	0.218	0.952	0.852	0.805	0.5248	0.351	0.325	0.272	0.816	0.388	0.819
80 	 0.1716 	0.307	0.527	0.236	0.961	0.871	0.821	0.1553	0.311	0.619	0.222	0.909	0.809	0.848
81 	 0.1595 	0.313	0.495	0.245	0.949	0.889	0.808	0.1482	0.310	0.622	0.234	0.891	0.886	0.789
82 	 0.1585 	0.304	0.520	0.245	0.949	0.862	0.860	0.1452	0.314	0.553	0.242	0.917	0.828	0.842
83 	 0.1643 	0.338	0.562	0.253	0.950	0.885	0.820	0.1659	0.273	0.598	0.191	0.974	0.944	0.853
84 	 0.1635 	0.307	0.522	0.228	0.939	0.836	0.787	0.1459	0.290	0.565	0.215	0.945	0.808	0.890
85 	 0.1494 	0.340	0.570	0.276	0.943	0.908	0.837	0.1765	0.284	0.449	0.207	0.965	0.606	0.937
86 	 0.1835 	0.318	0.520	0.257	0.950	0.853	0.845	0.1442	0.282	0.537	0.209	0.958	0.826	0.898
87 	 0.1498 	0.327	0.545	0.249	0.952	0.863	0.841	0.1353	0.312	0.647	0.222	0.931	0.906	0.866
88 	 0.1416 	0.322	0.554	0.248	0.940	0.886	0.855	0.1276	0.281	0.641	0.192	0.944	0.905	0.863
89 	 0.1576 	0.338	0.523	0.259	0.949	0.885	0.817	0.2447	0.293	0.518	0.232	0.933	0.619	0.908
90 	 0.1932 	0.297	0.484	0.241	0.941	0.867	0.807	0.1668	0.273	0.499	0.220	0.888	0.833	0.783
91 	 0.1889 	0.307	0.525	0.223	0.954	0.843	0.884	0.1584	0.267	0.622	0.174	0.958	0.871	0.875
92 	 0.1874 	0.312	0.496	0.250	0.944	0.771	0.850	0.1468	0.336	0.595	0.256	0.911	0.791	0.845
93 	 0.1625 	0.327	0.580	0.249	0.959	0.930	0.837	0.1450	0.297	0.522	0.223	0.949	0.736	0.897
94 	 0.1572 	0.297	0.517	0.233	0.956	0.882	0.846	0.1321	0.303	0.601	0.218	0.938	0.885	0.856
95 	 0.1705 	0.317	0.496	0.272	0.935	0.860	0.854	0.1613	0.245	0.475	0.182	0.981	0.751	0.936
96 	 0.1567 	0.318	0.537	0.255	0.928	0.886	0.803	0.1276	0.296	0.641	0.210	0.956	0.864	0.901
97 	 0.1871 	0.308	0.554	0.220	0.944	0.833	0.805	0.1479	0.296	0.605	0.207	0.949	0.899	0.855
98 	 0.1446 	0.332	0.553	0.263	0.955	0.864	0.846	0.1495	0.262	0.549	0.182	0.965	0.788	0.887
99 	 0.1629 	0.331	0.563	0.256	0.941	0.856	0.814	0.1507	0.267	0.630	0.184	0.978	0.933	0.868
100 	 0.1671 	0.315	0.510	0.242	0.955	0.878	0.847	0.1356	0.276	0.612	0.184	0.969	0.872	0.891
101 	 0.1755 	0.328	0.536	0.261	0.960	0.857	0.846	0.1286	0.307	0.593	0.237	0.939	0.799	0.911
102 	 0.1607 	0.330	0.548	0.260	0.953	0.885	0.843	0.1379	0.291	0.547	0.230	0.966	0.836	0.908
103 	 0.1500 	0.356	0.571	0.276	0.943	0.907	0.858	0.1398	0.259	0.504	0.180	0.973	0.782	0.918
104 	 0.1661 	0.329	0.540	0.257	0.957	0.861	0.862	0.1420	0.296	0.648	0.200	0.963	0.887	0.893
105 	 0.1545 	0.352	0.536	0.290	0.959	0.878	0.860	0.1422	0.325	0.574	0.244	0.922	0.827	0.853
106 	 0.1598 	0.334	0.598	0.250	0.947	0.934	0.830	0.1824	0.266	0.598	0.195	0.961	0.884	0.891
107 	 0.1496 	0.369	0.594	0.283	0.952	0.847	0.829	0.1377	0.313	0.500	0.239	0.948	0.648	0.903
108 	 0.1490 	0.335	0.544	0.262	0.942	0.860	0.871	0.1515	0.301	0.636	0.197	0.926	0.841	0.856
109 	 0.1493 	0.337	0.536	0.267	0.943	0.895	0.835	0.1948	0.288	0.573	0.222	0.940	0.692	0.926
110 	 0.1470 	0.305	0.525	0.257	0.950	0.920	0.861	0.1383	0.294	0.602	0.205	0.946	0.899	0.846
111 	 0.1447 	0.350	0.562	0.283	0.954	0.913	0.857	0.1589	0.330	0.521	0.260	0.893	0.687	0.835
112 	 0.1532 	0.330	0.543	0.259	0.954	0.874	0.831	0.1295	0.310	0.558	0.228	0.918	0.806	0.855
113 	 0.1494 	0.329	0.531	0.253	0.952	0.879	0.824	0.1364	0.314	0.621	0.224	0.941	0.900	0.856
114 	 0.1418 	0.345	0.576	0.261	0.945	0.903	0.808	0.1361	0.332	0.629	0.238	0.909	0.908	0.812
115 	 0.1405 	0.321	0.539	0.241	0.954	0.883	0.872	0.1421	0.272	0.580	0.167	0.956	0.829	0.886
116 	 0.1455 	0.343	0.564	0.250	0.940	0.867	0.827	0.1689	0.298	0.612	0.193	0.909	0.889	0.777
117 	 0.1585 	0.329	0.519	0.226	0.944	0.792	0.804	0.1449	0.292	0.641	0.188	0.930	0.890	0.850
118 	 0.1452 	0.341	0.571	0.243	0.943	0.899	0.838	0.1270	0.333	0.620	0.249	0.929	0.933	0.835
119 	 0.1400 	0.343	0.579	0.260	0.962	0.895	0.853	0.1394	0.296	0.617	0.199	0.940	0.913	0.846
120 	 0.1507 	0.335	0.553	0.259	0.949	0.887	0.863	0.1403	0.308	0.651	0.211	0.917	0.894	0.824
121 	 0.1443 	0.320	0.531	0.256	0.950	0.880	0.839	0.1519	0.266	0.501	0.189	0.957	0.628	0.922
122 	 0.1447 	0.344	0.551	0.255	0.950	0.906	0.821	0.1389	0.326	0.584	0.258	0.917	0.835	0.842
123 	 0.1264 	0.336	0.542	0.268	0.949	0.891	0.876	0.1476	0.271	0.540	0.177	0.969	0.739	0.902
124 	 0.1438 	0.324	0.544	0.264	0.968	0.895	0.869	0.1379	0.302	0.624	0.217	0.945	0.920	0.844
125 	 0.1572 	0.351	0.549	0.264	0.961	0.861	0.860	0.1331	0.313	0.478	0.238	0.928	0.637	0.873
126 	 0.1469 	0.346	0.576	0.252	0.956	0.887	0.828	0.1300	0.301	0.596	0.217	0.939	0.869	0.860
127 	 0.1408 	0.354	0.587	0.275	0.953	0.908	0.872	0.1664	0.291	0.610	0.199	0.950	0.867	0.871
128 	 0.1399 	0.357	0.571	0.270	0.966	0.884	0.886	0.1261	0.326	0.640	0.234	0.938	0.912	0.856
129 	 0.1423 	0.349	0.565	0.271	0.959	0.889	0.890	0.1270	0.310	0.635	0.210	0.932	0.909	0.839
130 	 0.1267 	0.351	0.562	0.283	0.948	0.873	0.865	0.1304	0.305	0.619	0.213	0.945	0.943	0.814
131 	 0.1441 	0.342	0.557	0.262	0.938	0.878	0.842	0.1347	0.285	0.577	0.220	0.930	0.951	0.813
132 	 0.1473 	0.331	0.547	0.269	0.954	0.887	0.889	0.1380	0.327	0.653	0.229	0.940	0.844	0.873
133 	 0.1310 	0.349	0.536	0.268	0.953	0.909	0.863	0.1241	0.303	0.612	0.211	0.947	0.897	0.868
134 	 0.1208 	0.341	0.545	0.265	0.951	0.878	0.867	0.1313	0.297	0.577	0.216	0.939	0.846	0.870
135 	 0.1279 	0.340	0.572	0.276	0.958	0.889	0.884	0.1319	0.259	0.560	0.172	0.972	0.928	0.886
136 	 0.1203 	0.349	0.555	0.281	0.964	0.874	0.907	0.1430	0.333	0.623	0.237	0.910	0.936	0.783
137 	 0.1345 	0.345	0.546	0.277	0.952	0.893	0.875	0.1435	0.291	0.602	0.190	0.946	0.873	0.851
138 	 0.1344 	0.342	0.558	0.273	0.947	0.908	0.868	0.1399	0.348	0.551	0.265	0.924	0.774	0.858
139 	 0.1482 	0.371	0.551	0.278	0.943	0.898	0.845	0.1393	0.286	0.612	0.184	0.962	0.848	0.900
140 	 0.1527 	0.340	0.524	0.294	0.951	0.858	0.870	0.1325	0.322	0.625	0.228	0.925	0.881	0.852
141 	 0.1470 	0.344	0.562	0.260	0.953	0.876	0.866	0.1340	0.292	0.567	0.214	0.955	0.846	0.891
142 	 0.1431 	0.330	0.553	0.273	0.953	0.866	0.888	0.1385	0.286	0.587	0.205	0.960	0.951	0.849
143 	 0.1481 	0.332	0.581	0.245	0.935	0.903	0.854	0.1396	0.276	0.626	0.183	0.967	0.907	0.898
144 	 0.1263 	0.342	0.580	0.249	0.945	0.876	0.877	0.1292	0.288	0.596	0.211	0.935	0.884	0.883
145 	 0.1328 	0.344	0.565	0.262	0.949	0.907	0.846	0.2483	0.319	0.576	0.238	0.879	0.650	0.829
146 	 0.1417 	0.364	0.580	0.282	0.951	0.897	0.853	0.1309	0.271	0.618	0.180	0.974	0.818	0.941
147 	 0.1307 	0.337	0.546	0.269	0.961	0.898	0.868	0.1288	0.301	0.652	0.211	0.960	0.922	0.903
148 	 0.1341 	0.352	0.544	0.301	0.947	0.790	0.871	0.1362	0.275	0.586	0.186	0.942	0.822	0.901
149 	 0.1254 	0.348	0.548	0.272	0.939	0.923	0.819	0.1417	0.362	0.555	0.281	0.882	0.796	0.806
150 	 0.1173 	0.331	0.554	0.247	0.942	0.838	0.866	0.1327	0.298	0.614	0.199	0.960	0.817	0.912
151 	 0.1303 	0.335	0.576	0.255	0.954	0.857	0.862	0.1204	0.303	0.587	0.228	0.929	0.934	0.848
152 	 0.1436 	0.340	0.518	0.262	0.957	0.874	0.860	0.1372	0.300	0.631	0.202	0.935	0.922	0.844
153 	 0.1281 	0.370	0.594	0.283	0.948	0.916	0.851	0.1199	0.308	0.616	0.217	0.941	0.900	0.872
154 	 0.1235 	0.336	0.535	0.258	0.973	0.866	0.907	0.1199	0.313	0.571	0.234	0.940	0.841	0.895
155 	 0.1221 	0.339	0.543	0.268	0.965	0.948	0.887	0.1275	0.285	0.597	0.198	0.962	0.876	0.897
156 	 0.1181 	0.328	0.525	0.270	0.946	0.912	0.864	0.1214	0.292	0.650	0.194	0.968	0.913	0.894
157 	 0.1412 	0.344	0.556	0.257	0.961	0.895	0.874	0.1219	0.326	0.597	0.252	0.927	0.807	0.879
158 	 0.1282 	0.323	0.502	0.272	0.945	0.858	0.870	0.1458	0.324	0.630	0.229	0.920	0.906	0.841
159 	 0.1167 	0.361	0.577	0.296	0.947	0.915	0.858	0.1100	0.321	0.625	0.234	0.939	0.875	0.886
160 	 0.1222 	0.371	0.584	0.280	0.960	0.903	0.890	0.1135	0.307	0.593	0.222	0.951	0.945	0.865
161 	 0.1399 	0.355	0.598	0.256	0.963	0.922	0.859	0.1428	0.324	0.645	0.232	0.921	0.913	0.834
162 	 0.1240 	0.363	0.569	0.273	0.943	0.876	0.852	0.1365	0.316	0.605	0.236	0.926	0.873	0.846
163 	 0.1260 	0.355	0.554	0.293	0.947	0.896	0.847	0.1257	0.313	0.574	0.233	0.933	0.828	0.863
164 	 0.1319 	0.351	0.559	0.265	0.939	0.889	0.862	0.1555	0.289	0.561	0.206	0.938	0.801	0.854
