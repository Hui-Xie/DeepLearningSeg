=============training from sratch============
Program ID: 18874

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/labels_npy', '3', '0', '0']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      Sep 30th, 2019
      1   With size-reduced ROI of size 51*149*149;
      2   reduce the translation of data augmentation;
      3   reduce all data into 35 patients, excluding a very blur patient.
      Oct 5th, 2019
      1   use uniform physical size 147mm*147mm*147mm, input pixel size: 49*147*147 with spacing size 3mm*1mm*1mm;
      2   change V model with inputsize 49*147*147
      Oct 6th, 2019
      1   add filter number to 48 at the first layer. 
      Oct 7th, 2019
      1   restore to 32 of number of filters in the first layer;
      2   add bottom number of filters to 1024, and keep down sample and add filter number together. 
      Oct 8th, 2019
      1   discard the cancer with size exceeding 147mm*147mm*147mm; Now remains 29 patients data; 
      Oct 9th, 2019
      1   In the first layer of V model, remove the residual link; 
           with the residula link at first layer: Tr dice:54%, Validation Dice 27%, Test Dice 56%;  Not good.
      2   the final output layer, change into 1*1*1 convolution, instead of 3*3*3 convolution;
      3   add labelConsistencyLoss, it use 64 dimension feature extracted from 2 ends of V model:
           It gets stable Training Dice 61%, validation Dice 27%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      Oct 11th, 2019
      1   use feature tensor just from the output end of V model. It is 32 dimensions.
          It gets stable Training Dice 61%, validation Dice 23%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      2   windows size for consistency loss changes to 3;
      Oct 12th, 2019
      1   change image window level to 100/50; relaunch training;
      2   change consistencyLoss to use ground truth for comparing diff of feature vector;
      Oct 13th, 2019
      1    use conistencyLoss3: ((G1-G2)-(P1-P2))**2 as loss.
       
      

          
         

Discarded changes:                  
          

Program starting Time: 2019-10-13 08:31:34.702208
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191013_083134

Info: this is the 3th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 2

Info: useConsistencyLoss = False and searchWindowSize= 0

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191013_083134.
6-fold cross validation: the 3th fold is for test, the 4th fold is for validation, remaining folds are for training.

training dataset: total 19 image files.

validation dataset: total 5 image files.

test dataset: total 5 image files.
Total 19 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/labels_npy
0 has 18805544 elements, with a rate of  0.9347630793331676 
1 has 1312435 elements, with a rate of  0.06523692066683238 
loss weight = tensor([ 1.0000, 14.3287])
Network has total 113,191,074 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		6.6642		0.05211		55.4855		0.00000		15.4809		0.00000
5	1.0000e-02		3.3106		0.26795		4.9524		0.31777		9.1003		0.11075
10	1.0000e-02		2.9654		0.27181		5.0504		0.33693		5.6540		0.18286
15	1.0000e-02		3.4429		0.35266		4.9427		0.42223		7.4266		0.17820
20	1.0000e-02		2.3796		0.34597		5.1413		0.48235		5.0732		0.22322
25	1.0000e-02		2.5700		0.37578		3.5340		0.39918		4.4946		0.22122
30	1.0000e-02		2.3866		0.36687		1.9739		0.55245		6.8501		0.16603
35	1.0000e-02		1.7504		0.35150		1.9745		0.53652		4.5711		0.25880
40	1.0000e-02		2.0784		0.36582		2.0628		0.49989		7.5425		0.26396
45	1.0000e-02		1.2817		0.41740		3.1269		0.39379		4.9878		0.22184
50	1.0000e-02		2.2920		0.34282		2.6387		0.55813		3.8315		0.25028
55	1.0000e-02		1.8965		0.40039		1.5682		0.55099		2.1635		0.35200
60	1.0000e-02		1.1927		0.45116		2.1244		0.54093		2.2952		0.32270
65	1.0000e-02		1.7166		0.41584		2.4781		0.42669		4.8863		0.17875
70	1.0000e-02		1.8355		0.38366		1.5018		0.52758		3.5662		0.28984
75	1.0000e-02		1.2190		0.41181		1.4773		0.52689		2.5243		0.29500
80	1.0000e-02		1.5831		0.40994		1.7451		0.57467		5.0853		0.24983
85	1.0000e-02		2.5977		0.32222		2.5998		0.46216		1.7647		0.38794
90	1.0000e-02		1.1221		0.45975		1.4729		0.54611		2.6445		0.29002
95	1.0000e-02		1.1845		0.41746		1.5276		0.56550		4.6701		0.22415
100	1.0000e-02		1.3284		0.39912		1.7678		0.48427		2.8464		0.25478
105	1.0000e-02		1.5547		0.46969		1.8994		0.47255		1.9097		0.41353
110	1.0000e-02		1.1012		0.42089		1.3984		0.54074		2.9894		0.28814
115	1.0000e-02		1.1225		0.44128		1.4391		0.56294		3.9612		0.28428
120	1.0000e-02		0.9601		0.42475		1.3634		0.56491		5.7806		0.24046
125	1.0000e-02		1.1254		0.43093		4.5408		0.47804		6.6198		0.24790
130	1.0000e-02		0.8577		0.47244		1.9223		0.49559		2.6242		0.28677
135	1.0000e-02		1.8444		0.37152		3.0344		0.49290		7.4344		0.19722
140	1.0000e-02		1.1216		0.46345		1.6417		0.56609		3.0112		0.29846
145	1.0000e-02		1.4990		0.38575		1.8415		0.57416		5.8022		0.21493
150	1.0000e-02		0.9809		0.44652		1.8335		0.55469		1.8782		0.37906
155	1.0000e-02		0.9043		0.47185		1.7046		0.53386		1.9739		0.32417
160	1.0000e-02		0.8506		0.51341		1.5085		0.54250		5.0917		0.28871
165	1.0000e-02		1.1686		0.50130		1.5256		0.55130		2.8242		0.32165
170	1.0000e-02		0.9265		0.45759		1.6664		0.55480		4.1363		0.30487
175	1.0000e-03		1.2460		0.41526		2.2650		0.45435		3.0228		0.30167
180	1.0000e-03		0.8168		0.45023		1.8301		0.48644		3.4179		0.29579
185	1.0000e-03		0.9162		0.45900		1.6052		0.51634		3.5460		0.28761
190	1.0000e-03		0.7485		0.48070		1.6650		0.50894		3.0730		0.30731
195	1.0000e-03		1.0977		0.50425		1.5708		0.51221		3.9506		0.30859
200	1.0000e-03		0.8133		0.50728		1.6071		0.50568		3.4177		0.32708
205	1.0000e-03		0.6506		0.55433		1.6390		0.49624		2.6829		0.34043
210	1.0000e-03		0.6305		0.53016		1.5087		0.52509		3.0896		0.32943
215	1.0000e-03		0.7910		0.55722		1.3702		0.53869		3.8310		0.31794
220	1.0000e-03		0.6694		0.58823		1.4974		0.51247		3.7237		0.30650
225	1.0000e-03		0.4562		0.60716		1.5640		0.52426		3.7114		0.30430
230	1.0000e-04		0.6009		0.54545		1.4803		0.52249		3.9330		0.31603
235	1.0000e-04		0.4702		0.57508		1.4878		0.51962		3.6124		0.32089
240	1.0000e-04		0.5972		0.57791		1.4767		0.52755		3.3960		0.33162
245	1.0000e-04		0.6199		0.56760		1.6328		0.51216		3.8759		0.29450
250	1.0000e-04		0.9040		0.56736		1.5160		0.51379		3.6094		0.34479
