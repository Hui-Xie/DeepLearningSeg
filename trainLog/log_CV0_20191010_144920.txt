=============training from sratch============
Program ID: 18119

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/labels_npy', '0', '0']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      Sep 30th, 2019
      1   With size-reduced ROI of size 51*149*149;
      2   reduce the translation of data augmentation;
      3   reduce all data into 35 patients, excluding a very blur patient.
      Oct 5th, 2019
      1   use uniform physical size 147mm*147mm*147mm, input pixel size: 49*147*147 with spacing size 3mm*1mm*1mm;
      2   change V model with inputsize 49*147*147
      Oct 6th, 2019
      1   add filter number to 48 at the first layer. 
      Oct 7th, 2019
      1   restore to 32 of number of filters in the first layer;
      2   add bottom number of filters to 1024, and keep down sample and add filter number together. 
      Oct 8th, 2019
      1   discard the cancer with size exceeding 147mm*147mm*147mm; Now remains 29 patients data; 
      Oct 9th, 209
      1   In the first layer of V model, remove the residual link; 
           with the residula link at first layer: Tr dice:54%, Validation Dice 27%, Test Dice 56%;  Not good.
      2   the final output layer, change into 1*1*1 convolution, instead of 3*3*3 convolution;
      3   add labelConsistencyLoss;
          
         

Discarded changes:                  
          

Program starting Time: 2019-10-10 14:49:20.425062
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191010_144920

Info: this is the 0th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 1

Info: useLabelConsistencyLoss = True

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191010_144920.
6-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 19 image files.

validation dataset: total 5 image files.

test dataset: total 5 image files.
Total 19 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/labels_npy
0 has 18433812 elements, with a rate of  0.9162854777808447 
1 has 1684167 elements, with a rate of  0.08371452221915532 
loss weight = tensor([ 1.0000, 10.9454])
Network has total 113,191,074 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		4.2528		0.13855		1.7815		0.11823		2.7909		0.38801
5	1.0000e-02		2.6947		0.30845		2.0064		0.17431		1.9745		0.35111
10	1.0000e-02		2.6203		0.38356		1.4141		0.21050		1.5474		0.37545
15	1.0000e-02		2.2414		0.41807		1.1116		0.26557		1.2626		0.50722
20	1.0000e-02		2.3756		0.39207		1.8182		0.21928		1.3018		0.44382
25	1.0000e-02		2.1295		0.37017		1.2484		0.24087		1.3159		0.43990
30	1.0000e-02		2.6972		0.39657		2.8342		0.15943		1.7195		0.41443
35	1.0000e-02		2.0572		0.34913		0.9695		0.25268		1.3380		0.45112
40	1.0000e-02		2.1104		0.41586		0.9677		0.26005		1.1634		0.44930
45	1.0000e-02		2.1460		0.44579		1.0565		0.29507		1.1385		0.46728
50	1.0000e-02		2.5186		0.38628		1.5197		0.22172		1.4811		0.42440
55	1.0000e-02		2.0735		0.40928		1.2642		0.24444		1.4400		0.44129
60	1.0000e-02		2.3667		0.41786		0.9817		0.29379		1.2324		0.45721
65	1.0000e-02		1.3702		0.48692		1.0211		0.30703		0.9680		0.50418
70	1.0000e-02		1.3168		0.44816		1.1468		0.25724		1.2931		0.44064
75	1.0000e-02		1.5053		0.51253		1.3170		0.25365		1.3985		0.45983
80	1.0000e-02		1.3716		0.48385		1.0810		0.27038		1.4237		0.41923
85	1.0000e-02		1.8144		0.42591		1.0517		0.26662		1.2347		0.45623
90	1.0000e-02		1.8304		0.45813		1.1521		0.22794		1.2047		0.51415
95	1.0000e-03		1.2454		0.46352		1.2462		0.22995		1.3905		0.39036
100	1.0000e-03		1.0846		0.53859		1.0693		0.31849		0.9276		0.54267
105	1.0000e-03		1.2390		0.54369		1.1402		0.26898		0.9456		0.51278
110	1.0000e-03		0.9608		0.57419		1.0711		0.23848		0.9555		0.53100
115	1.0000e-03		0.9716		0.58400		1.2819		0.24781		0.9607		0.51013
120	1.0000e-03		0.8412		0.61322		1.2226		0.27601		1.0039		0.48834
125	1.0000e-03		1.1601		0.56163		1.3513		0.23326		0.9845		0.47899
