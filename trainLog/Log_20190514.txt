Program ID 19267

Program command: 
 ['/home/hxie1/Projects/OvarianCancer/TrainSegV.py', '/home/hxie1/temp_netParameters/OvarianCancer/Label0_1_2', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainImages', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels', '2D', '0,1,2']

Major program changes: ConvDense uses Conv-Bn-ReLU order (CBR)
                       Dense Layer = 4 
                       output layer use conv with 3*3 fiter instead of 1*1 filter. 
                       use boundary loss with weight 0 at beginning, and pretrain CE loss. 
                       special convInput Module
                       convOutput moudel uses 1*1 conv to get tranparent gradient 
                       ConvOutput use residual module.
                       first layer filter = 128
                       use Mixup and DenseNet
                       Boundary Loss supports multi-class, and weight
                       For 0,1,2 three classes clasfication for primary and metastases
                       dropout rate = 0.0
                       
            

Program starting Time: 2019-05-14 13:13:10.062653
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/Label0_1_2

Infor: program test labels: [0, 1, 2]
Infor: program suppressed labels: [3]
Infor: program test labels: [0, 1, 2]
Infor: program suppressed labels: [3]
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels has 436 segmented slices for remained labels [0, 1, 2].
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/testLabels has 136 segmented slices for remained labels [0, 1, 2].
Info: program uses 2D input.
TrainData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=3

TestData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=3

Info: program uses Mixup with alpha=0.4, and mixupProb = 0.5.
Network trains from scratch.
Network has total 157684243 parameters.
Info: network dropout rate = 0
Infor: Cross Entropy Weight: [1.0416883685076772, 39.37007874015748, 68.39945280437757]

====================Net Architecture===========================
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1        [-1, 112, 281, 281]           1,120
       BatchNorm2d-2        [-1, 112, 281, 281]             224
              ReLU-3        [-1, 112, 281, 281]               0
    BN_ReLU_Conv2d-4        [-1, 112, 281, 281]               0
            Conv2d-5        [-1, 112, 281, 281]          12,656
       BatchNorm2d-6        [-1, 112, 281, 281]             224
              ReLU-7        [-1, 112, 281, 281]               0
    BN_ReLU_Conv2d-8        [-1, 112, 281, 281]               0
            Conv2d-9         [-1, 28, 281, 281]          28,252
      BatchNorm2d-10         [-1, 28, 281, 281]              56
             ReLU-11         [-1, 28, 281, 281]               0
   BN_ReLU_Conv2d-12         [-1, 28, 281, 281]               0
           Conv2d-13        [-1, 112, 281, 281]          15,792
      BatchNorm2d-14        [-1, 112, 281, 281]             224
             ReLU-15        [-1, 112, 281, 281]               0
   BN_ReLU_Conv2d-16        [-1, 112, 281, 281]               0
           Conv2d-17         [-1, 28, 281, 281]          28,252
      BatchNorm2d-18         [-1, 28, 281, 281]              56
             ReLU-19         [-1, 28, 281, 281]               0
   BN_ReLU_Conv2d-20         [-1, 28, 281, 281]               0
           Conv2d-21        [-1, 112, 281, 281]          18,928
      BatchNorm2d-22        [-1, 112, 281, 281]             224
             ReLU-23        [-1, 112, 281, 281]               0
   BN_ReLU_Conv2d-24        [-1, 112, 281, 281]               0
           Conv2d-25         [-1, 28, 281, 281]          28,252
      BatchNorm2d-26         [-1, 28, 281, 281]              56
             ReLU-27         [-1, 28, 281, 281]               0
   BN_ReLU_Conv2d-28         [-1, 28, 281, 281]               0
           Conv2d-29        [-1, 112, 281, 281]          22,064
      BatchNorm2d-30        [-1, 112, 281, 281]             224
             ReLU-31        [-1, 112, 281, 281]               0
   BN_ReLU_Conv2d-32        [-1, 112, 281, 281]               0
           Conv2d-33         [-1, 28, 281, 281]          28,252
      BatchNorm2d-34         [-1, 28, 281, 281]              56
             ReLU-35         [-1, 28, 281, 281]               0
   BN_ReLU_Conv2d-36         [-1, 28, 281, 281]               0
           Conv2d-37        [-1, 112, 281, 281]          25,200
      BatchNorm2d-38        [-1, 112, 281, 281]             224
             ReLU-39        [-1, 112, 281, 281]               0
   BN_ReLU_Conv2d-40        [-1, 112, 281, 281]               0
        ConvDense-41        [-1, 112, 281, 281]               0
ConvBuildingBlock-42        [-1, 112, 281, 281]               0
        ConvInput-43        [-1, 112, 281, 281]               0
           Conv2d-44        [-1, 112, 139, 139]         313,712
      BatchNorm2d-45        [-1, 112, 139, 139]             224
             ReLU-46        [-1, 112, 139, 139]               0
   BN_ReLU_Conv2d-47        [-1, 112, 139, 139]               0
           Conv2d-48        [-1, 112, 139, 139]          12,656
      BatchNorm2d-49        [-1, 112, 139, 139]             224
             ReLU-50        [-1, 112, 139, 139]               0
   BN_ReLU_Conv2d-51        [-1, 112, 139, 139]               0
           Conv2d-52         [-1, 28, 139, 139]          28,252
      BatchNorm2d-53         [-1, 28, 139, 139]              56
             ReLU-54         [-1, 28, 139, 139]               0
   BN_ReLU_Conv2d-55         [-1, 28, 139, 139]               0
           Conv2d-56        [-1, 112, 139, 139]          15,792
      BatchNorm2d-57        [-1, 112, 139, 139]             224
             ReLU-58        [-1, 112, 139, 139]               0
   BN_ReLU_Conv2d-59        [-1, 112, 139, 139]               0
           Conv2d-60         [-1, 28, 139, 139]          28,252
      BatchNorm2d-61         [-1, 28, 139, 139]              56
             ReLU-62         [-1, 28, 139, 139]               0
   BN_ReLU_Conv2d-63         [-1, 28, 139, 139]               0
           Conv2d-64        [-1, 112, 139, 139]          18,928
      BatchNorm2d-65        [-1, 112, 139, 139]             224
             ReLU-66        [-1, 112, 139, 139]               0
   BN_ReLU_Conv2d-67        [-1, 112, 139, 139]               0
           Conv2d-68         [-1, 28, 139, 139]          28,252
      BatchNorm2d-69         [-1, 28, 139, 139]              56
             ReLU-70         [-1, 28, 139, 139]               0
   BN_ReLU_Conv2d-71         [-1, 28, 139, 139]               0
           Conv2d-72        [-1, 112, 139, 139]          22,064
      BatchNorm2d-73        [-1, 112, 139, 139]             224
             ReLU-74        [-1, 112, 139, 139]               0
   BN_ReLU_Conv2d-75        [-1, 112, 139, 139]               0
           Conv2d-76         [-1, 28, 139, 139]          28,252
      BatchNorm2d-77         [-1, 28, 139, 139]              56
             ReLU-78         [-1, 28, 139, 139]               0
   BN_ReLU_Conv2d-79         [-1, 28, 139, 139]               0
           Conv2d-80        [-1, 112, 139, 139]          25,200
      BatchNorm2d-81        [-1, 112, 139, 139]             224
             ReLU-82        [-1, 112, 139, 139]               0
   BN_ReLU_Conv2d-83        [-1, 112, 139, 139]               0
        ConvDense-84        [-1, 112, 139, 139]               0
ConvBuildingBlock-85        [-1, 112, 139, 139]               0
         Down2dBB-86        [-1, 112, 139, 139]               0
        Dropout2d-87        [-1, 112, 139, 139]               0
           Conv2d-88          [-1, 224, 69, 69]         226,016
      BatchNorm2d-89          [-1, 224, 69, 69]             448
             ReLU-90          [-1, 224, 69, 69]               0
   BN_ReLU_Conv2d-91          [-1, 224, 69, 69]               0
           Conv2d-92          [-1, 224, 69, 69]          50,400
      BatchNorm2d-93          [-1, 224, 69, 69]             448
             ReLU-94          [-1, 224, 69, 69]               0
   BN_ReLU_Conv2d-95          [-1, 224, 69, 69]               0
           Conv2d-96           [-1, 56, 69, 69]         112,952
      BatchNorm2d-97           [-1, 56, 69, 69]             112
             ReLU-98           [-1, 56, 69, 69]               0
   BN_ReLU_Conv2d-99           [-1, 56, 69, 69]               0
          Conv2d-100          [-1, 224, 69, 69]          62,944
     BatchNorm2d-101          [-1, 224, 69, 69]             448
            ReLU-102          [-1, 224, 69, 69]               0
  BN_ReLU_Conv2d-103          [-1, 224, 69, 69]               0
          Conv2d-104           [-1, 56, 69, 69]         112,952
     BatchNorm2d-105           [-1, 56, 69, 69]             112
            ReLU-106           [-1, 56, 69, 69]               0
  BN_ReLU_Conv2d-107           [-1, 56, 69, 69]               0
          Conv2d-108          [-1, 224, 69, 69]          75,488
     BatchNorm2d-109          [-1, 224, 69, 69]             448
            ReLU-110          [-1, 224, 69, 69]               0
  BN_ReLU_Conv2d-111          [-1, 224, 69, 69]               0
          Conv2d-112           [-1, 56, 69, 69]         112,952
     BatchNorm2d-113           [-1, 56, 69, 69]             112
            ReLU-114           [-1, 56, 69, 69]               0
  BN_ReLU_Conv2d-115           [-1, 56, 69, 69]               0
          Conv2d-116          [-1, 224, 69, 69]          88,032
     BatchNorm2d-117          [-1, 224, 69, 69]             448
            ReLU-118          [-1, 224, 69, 69]               0
  BN_ReLU_Conv2d-119          [-1, 224, 69, 69]               0
          Conv2d-120           [-1, 56, 69, 69]         112,952
     BatchNorm2d-121           [-1, 56, 69, 69]             112
            ReLU-122           [-1, 56, 69, 69]               0
  BN_ReLU_Conv2d-123           [-1, 56, 69, 69]               0
          Conv2d-124          [-1, 224, 69, 69]         100,576
     BatchNorm2d-125          [-1, 224, 69, 69]             448
            ReLU-126          [-1, 224, 69, 69]               0
  BN_ReLU_Conv2d-127          [-1, 224, 69, 69]               0
       ConvDense-128          [-1, 224, 69, 69]               0
ConvBuildingBlock-129          [-1, 224, 69, 69]               0
        Down2dBB-130          [-1, 224, 69, 69]               0
       Dropout2d-131          [-1, 224, 69, 69]               0
          Conv2d-132          [-1, 448, 33, 33]       2,509,248
     BatchNorm2d-133          [-1, 448, 33, 33]             896
            ReLU-134          [-1, 448, 33, 33]               0
  BN_ReLU_Conv2d-135          [-1, 448, 33, 33]               0
          Conv2d-136          [-1, 448, 33, 33]         201,152
     BatchNorm2d-137          [-1, 448, 33, 33]             896
            ReLU-138          [-1, 448, 33, 33]               0
  BN_ReLU_Conv2d-139          [-1, 448, 33, 33]               0
          Conv2d-140          [-1, 112, 33, 33]         451,696
     BatchNorm2d-141          [-1, 112, 33, 33]             224
            ReLU-142          [-1, 112, 33, 33]               0
  BN_ReLU_Conv2d-143          [-1, 112, 33, 33]               0
          Conv2d-144          [-1, 448, 33, 33]         251,328
     BatchNorm2d-145          [-1, 448, 33, 33]             896
            ReLU-146          [-1, 448, 33, 33]               0
  BN_ReLU_Conv2d-147          [-1, 448, 33, 33]               0
          Conv2d-148          [-1, 112, 33, 33]         451,696
     BatchNorm2d-149          [-1, 112, 33, 33]             224
            ReLU-150          [-1, 112, 33, 33]               0
  BN_ReLU_Conv2d-151          [-1, 112, 33, 33]               0
          Conv2d-152          [-1, 448, 33, 33]         301,504
     BatchNorm2d-153          [-1, 448, 33, 33]             896
            ReLU-154          [-1, 448, 33, 33]               0
  BN_ReLU_Conv2d-155          [-1, 448, 33, 33]               0
          Conv2d-156          [-1, 112, 33, 33]         451,696
     BatchNorm2d-157          [-1, 112, 33, 33]             224
            ReLU-158          [-1, 112, 33, 33]               0
  BN_ReLU_Conv2d-159          [-1, 112, 33, 33]               0
          Conv2d-160          [-1, 448, 33, 33]         351,680
     BatchNorm2d-161          [-1, 448, 33, 33]             896
            ReLU-162          [-1, 448, 33, 33]               0
  BN_ReLU_Conv2d-163          [-1, 448, 33, 33]               0
          Conv2d-164          [-1, 112, 33, 33]         451,696
     BatchNorm2d-165          [-1, 112, 33, 33]             224
            ReLU-166          [-1, 112, 33, 33]               0
  BN_ReLU_Conv2d-167          [-1, 112, 33, 33]               0
          Conv2d-168          [-1, 448, 33, 33]         401,856
     BatchNorm2d-169          [-1, 448, 33, 33]             896
            ReLU-170          [-1, 448, 33, 33]               0
  BN_ReLU_Conv2d-171          [-1, 448, 33, 33]               0
       ConvDense-172          [-1, 448, 33, 33]               0
ConvBuildingBlock-173          [-1, 448, 33, 33]               0
        Down2dBB-174          [-1, 448, 33, 33]               0
       Dropout2d-175          [-1, 448, 33, 33]               0
          Conv2d-176          [-1, 896, 15, 15]      10,036,096
     BatchNorm2d-177          [-1, 896, 15, 15]           1,792
            ReLU-178          [-1, 896, 15, 15]               0
  BN_ReLU_Conv2d-179          [-1, 896, 15, 15]               0
          Conv2d-180          [-1, 896, 15, 15]         803,712
     BatchNorm2d-181          [-1, 896, 15, 15]           1,792
            ReLU-182          [-1, 896, 15, 15]               0
  BN_ReLU_Conv2d-183          [-1, 896, 15, 15]               0
          Conv2d-184          [-1, 224, 15, 15]       1,806,560
     BatchNorm2d-185          [-1, 224, 15, 15]             448
            ReLU-186          [-1, 224, 15, 15]               0
  BN_ReLU_Conv2d-187          [-1, 224, 15, 15]               0
          Conv2d-188          [-1, 896, 15, 15]       1,004,416
     BatchNorm2d-189          [-1, 896, 15, 15]           1,792
            ReLU-190          [-1, 896, 15, 15]               0
  BN_ReLU_Conv2d-191          [-1, 896, 15, 15]               0
          Conv2d-192          [-1, 224, 15, 15]       1,806,560
     BatchNorm2d-193          [-1, 224, 15, 15]             448
            ReLU-194          [-1, 224, 15, 15]               0
  BN_ReLU_Conv2d-195          [-1, 224, 15, 15]               0
          Conv2d-196          [-1, 896, 15, 15]       1,205,120
     BatchNorm2d-197          [-1, 896, 15, 15]           1,792
            ReLU-198          [-1, 896, 15, 15]               0
  BN_ReLU_Conv2d-199          [-1, 896, 15, 15]               0
          Conv2d-200          [-1, 224, 15, 15]       1,806,560
     BatchNorm2d-201          [-1, 224, 15, 15]             448
            ReLU-202          [-1, 224, 15, 15]               0
  BN_ReLU_Conv2d-203          [-1, 224, 15, 15]               0
          Conv2d-204          [-1, 896, 15, 15]       1,405,824
     BatchNorm2d-205          [-1, 896, 15, 15]           1,792
            ReLU-206          [-1, 896, 15, 15]               0
  BN_ReLU_Conv2d-207          [-1, 896, 15, 15]               0
          Conv2d-208          [-1, 224, 15, 15]       1,806,560
     BatchNorm2d-209          [-1, 224, 15, 15]             448
            ReLU-210          [-1, 224, 15, 15]               0
  BN_ReLU_Conv2d-211          [-1, 224, 15, 15]               0
          Conv2d-212          [-1, 896, 15, 15]       1,606,528
     BatchNorm2d-213          [-1, 896, 15, 15]           1,792
            ReLU-214          [-1, 896, 15, 15]               0
  BN_ReLU_Conv2d-215          [-1, 896, 15, 15]               0
       ConvDense-216          [-1, 896, 15, 15]               0
ConvBuildingBlock-217          [-1, 896, 15, 15]               0
        Down2dBB-218          [-1, 896, 15, 15]               0
       Dropout2d-219          [-1, 896, 15, 15]               0
          Conv2d-220           [-1, 1792, 7, 7]      14,452,480
     BatchNorm2d-221           [-1, 1792, 7, 7]           3,584
            ReLU-222           [-1, 1792, 7, 7]               0
  BN_ReLU_Conv2d-223           [-1, 1792, 7, 7]               0
          Conv2d-224           [-1, 1792, 7, 7]       3,213,056
     BatchNorm2d-225           [-1, 1792, 7, 7]           3,584
            ReLU-226           [-1, 1792, 7, 7]               0
  BN_ReLU_Conv2d-227           [-1, 1792, 7, 7]               0
          Conv2d-228            [-1, 448, 7, 7]       7,225,792
     BatchNorm2d-229            [-1, 448, 7, 7]             896
            ReLU-230            [-1, 448, 7, 7]               0
  BN_ReLU_Conv2d-231            [-1, 448, 7, 7]               0
          Conv2d-232           [-1, 1792, 7, 7]       4,015,872
     BatchNorm2d-233           [-1, 1792, 7, 7]           3,584
            ReLU-234           [-1, 1792, 7, 7]               0
  BN_ReLU_Conv2d-235           [-1, 1792, 7, 7]               0
          Conv2d-236            [-1, 448, 7, 7]       7,225,792
     BatchNorm2d-237            [-1, 448, 7, 7]             896
            ReLU-238            [-1, 448, 7, 7]               0
  BN_ReLU_Conv2d-239            [-1, 448, 7, 7]               0
          Conv2d-240           [-1, 1792, 7, 7]       4,818,688
     BatchNorm2d-241           [-1, 1792, 7, 7]           3,584
            ReLU-242           [-1, 1792, 7, 7]               0
  BN_ReLU_Conv2d-243           [-1, 1792, 7, 7]               0
          Conv2d-244            [-1, 448, 7, 7]       7,225,792
     BatchNorm2d-245            [-1, 448, 7, 7]             896
            ReLU-246            [-1, 448, 7, 7]               0
  BN_ReLU_Conv2d-247            [-1, 448, 7, 7]               0
          Conv2d-248           [-1, 1792, 7, 7]       5,621,504
     BatchNorm2d-249           [-1, 1792, 7, 7]           3,584
            ReLU-250           [-1, 1792, 7, 7]               0
  BN_ReLU_Conv2d-251           [-1, 1792, 7, 7]               0
          Conv2d-252            [-1, 448, 7, 7]       7,225,792
     BatchNorm2d-253            [-1, 448, 7, 7]             896
            ReLU-254            [-1, 448, 7, 7]               0
  BN_ReLU_Conv2d-255            [-1, 448, 7, 7]               0
          Conv2d-256           [-1, 1792, 7, 7]       6,424,320
     BatchNorm2d-257           [-1, 1792, 7, 7]           3,584
            ReLU-258           [-1, 1792, 7, 7]               0
  BN_ReLU_Conv2d-259           [-1, 1792, 7, 7]               0
       ConvDense-260           [-1, 1792, 7, 7]               0
ConvBuildingBlock-261           [-1, 1792, 7, 7]               0
        Down2dBB-262           [-1, 1792, 7, 7]               0
       Dropout2d-263           [-1, 1792, 7, 7]               0
 ConvTranspose2d-264          [-1, 896, 15, 15]      14,451,584
     BatchNorm2d-265          [-1, 896, 15, 15]           1,792
            ReLU-266          [-1, 896, 15, 15]               0
 BN_ReLU_ConvT2d-267          [-1, 896, 15, 15]               0
          Conv2d-268          [-1, 896, 15, 15]         803,712
     BatchNorm2d-269          [-1, 896, 15, 15]           1,792
            ReLU-270          [-1, 896, 15, 15]               0
  BN_ReLU_Conv2d-271          [-1, 896, 15, 15]               0
          Conv2d-272          [-1, 224, 15, 15]       1,806,560
     BatchNorm2d-273          [-1, 224, 15, 15]             448
            ReLU-274          [-1, 224, 15, 15]               0
  BN_ReLU_Conv2d-275          [-1, 224, 15, 15]               0
          Conv2d-276          [-1, 896, 15, 15]       1,004,416
     BatchNorm2d-277          [-1, 896, 15, 15]           1,792
            ReLU-278          [-1, 896, 15, 15]               0
  BN_ReLU_Conv2d-279          [-1, 896, 15, 15]               0
          Conv2d-280          [-1, 224, 15, 15]       1,806,560
     BatchNorm2d-281          [-1, 224, 15, 15]             448
            ReLU-282          [-1, 224, 15, 15]               0
  BN_ReLU_Conv2d-283          [-1, 224, 15, 15]               0
          Conv2d-284          [-1, 896, 15, 15]       1,205,120
     BatchNorm2d-285          [-1, 896, 15, 15]           1,792
            ReLU-286          [-1, 896, 15, 15]               0
  BN_ReLU_Conv2d-287          [-1, 896, 15, 15]               0
          Conv2d-288          [-1, 224, 15, 15]       1,806,560
     BatchNorm2d-289          [-1, 224, 15, 15]             448
            ReLU-290          [-1, 224, 15, 15]               0
  BN_ReLU_Conv2d-291          [-1, 224, 15, 15]               0
          Conv2d-292          [-1, 896, 15, 15]       1,405,824
     BatchNorm2d-293          [-1, 896, 15, 15]           1,792
            ReLU-294          [-1, 896, 15, 15]               0
  BN_ReLU_Conv2d-295          [-1, 896, 15, 15]               0
          Conv2d-296          [-1, 224, 15, 15]       1,806,560
     BatchNorm2d-297          [-1, 224, 15, 15]             448
            ReLU-298          [-1, 224, 15, 15]               0
  BN_ReLU_Conv2d-299          [-1, 224, 15, 15]               0
          Conv2d-300          [-1, 896, 15, 15]       1,606,528
     BatchNorm2d-301          [-1, 896, 15, 15]           1,792
            ReLU-302          [-1, 896, 15, 15]               0
  BN_ReLU_Conv2d-303          [-1, 896, 15, 15]               0
       ConvDense-304          [-1, 896, 15, 15]               0
ConvBuildingBlock-305          [-1, 896, 15, 15]               0
          Up2dBB-306          [-1, 896, 15, 15]               0
       Dropout2d-307          [-1, 896, 15, 15]               0
 ConvTranspose2d-308          [-1, 448, 33, 33]      20,070,848
     BatchNorm2d-309          [-1, 448, 33, 33]             896
            ReLU-310          [-1, 448, 33, 33]               0
 BN_ReLU_ConvT2d-311          [-1, 448, 33, 33]               0
          Conv2d-312          [-1, 448, 33, 33]         201,152
     BatchNorm2d-313          [-1, 448, 33, 33]             896
            ReLU-314          [-1, 448, 33, 33]               0
  BN_ReLU_Conv2d-315          [-1, 448, 33, 33]               0
          Conv2d-316          [-1, 112, 33, 33]         451,696
     BatchNorm2d-317          [-1, 112, 33, 33]             224
            ReLU-318          [-1, 112, 33, 33]               0
  BN_ReLU_Conv2d-319          [-1, 112, 33, 33]               0
          Conv2d-320          [-1, 448, 33, 33]         251,328
     BatchNorm2d-321          [-1, 448, 33, 33]             896
            ReLU-322          [-1, 448, 33, 33]               0
  BN_ReLU_Conv2d-323          [-1, 448, 33, 33]               0
          Conv2d-324          [-1, 112, 33, 33]         451,696
     BatchNorm2d-325          [-1, 112, 33, 33]             224
            ReLU-326          [-1, 112, 33, 33]               0
  BN_ReLU_Conv2d-327          [-1, 112, 33, 33]               0
          Conv2d-328          [-1, 448, 33, 33]         301,504
     BatchNorm2d-329          [-1, 448, 33, 33]             896
            ReLU-330          [-1, 448, 33, 33]               0
  BN_ReLU_Conv2d-331          [-1, 448, 33, 33]               0
          Conv2d-332          [-1, 112, 33, 33]         451,696
     BatchNorm2d-333          [-1, 112, 33, 33]             224
            ReLU-334          [-1, 112, 33, 33]               0
  BN_ReLU_Conv2d-335          [-1, 112, 33, 33]               0
          Conv2d-336          [-1, 448, 33, 33]         351,680
     BatchNorm2d-337          [-1, 448, 33, 33]             896
            ReLU-338          [-1, 448, 33, 33]               0
  BN_ReLU_Conv2d-339          [-1, 448, 33, 33]               0
          Conv2d-340          [-1, 112, 33, 33]         451,696
     BatchNorm2d-341          [-1, 112, 33, 33]             224
            ReLU-342          [-1, 112, 33, 33]               0
  BN_ReLU_Conv2d-343          [-1, 112, 33, 33]               0
          Conv2d-344          [-1, 448, 33, 33]         401,856
     BatchNorm2d-345          [-1, 448, 33, 33]             896
            ReLU-346          [-1, 448, 33, 33]               0
  BN_ReLU_Conv2d-347          [-1, 448, 33, 33]               0
       ConvDense-348          [-1, 448, 33, 33]               0
ConvBuildingBlock-349          [-1, 448, 33, 33]               0
          Up2dBB-350          [-1, 448, 33, 33]               0
       Dropout2d-351          [-1, 448, 33, 33]               0
 ConvTranspose2d-352          [-1, 224, 69, 69]       5,017,824
     BatchNorm2d-353          [-1, 224, 69, 69]             448
            ReLU-354          [-1, 224, 69, 69]               0
 BN_ReLU_ConvT2d-355          [-1, 224, 69, 69]               0
          Conv2d-356          [-1, 224, 69, 69]          50,400
     BatchNorm2d-357          [-1, 224, 69, 69]             448
            ReLU-358          [-1, 224, 69, 69]               0
  BN_ReLU_Conv2d-359          [-1, 224, 69, 69]               0
          Conv2d-360           [-1, 56, 69, 69]         112,952
     BatchNorm2d-361           [-1, 56, 69, 69]             112
            ReLU-362           [-1, 56, 69, 69]               0
  BN_ReLU_Conv2d-363           [-1, 56, 69, 69]               0
          Conv2d-364          [-1, 224, 69, 69]          62,944
     BatchNorm2d-365          [-1, 224, 69, 69]             448
            ReLU-366          [-1, 224, 69, 69]               0
  BN_ReLU_Conv2d-367          [-1, 224, 69, 69]               0
          Conv2d-368           [-1, 56, 69, 69]         112,952
     BatchNorm2d-369           [-1, 56, 69, 69]             112
            ReLU-370           [-1, 56, 69, 69]               0
  BN_ReLU_Conv2d-371           [-1, 56, 69, 69]               0
          Conv2d-372          [-1, 224, 69, 69]          75,488
     BatchNorm2d-373          [-1, 224, 69, 69]             448
            ReLU-374          [-1, 224, 69, 69]               0
  BN_ReLU_Conv2d-375          [-1, 224, 69, 69]               0
          Conv2d-376           [-1, 56, 69, 69]         112,952
     BatchNorm2d-377           [-1, 56, 69, 69]             112
            ReLU-378           [-1, 56, 69, 69]               0
  BN_ReLU_Conv2d-379           [-1, 56, 69, 69]               0
          Conv2d-380          [-1, 224, 69, 69]          88,032
     BatchNorm2d-381          [-1, 224, 69, 69]             448
            ReLU-382          [-1, 224, 69, 69]               0
  BN_ReLU_Conv2d-383          [-1, 224, 69, 69]               0
          Conv2d-384           [-1, 56, 69, 69]         112,952
     BatchNorm2d-385           [-1, 56, 69, 69]             112
            ReLU-386           [-1, 56, 69, 69]               0
  BN_ReLU_Conv2d-387           [-1, 56, 69, 69]               0
          Conv2d-388          [-1, 224, 69, 69]         100,576
     BatchNorm2d-389          [-1, 224, 69, 69]             448
            ReLU-390          [-1, 224, 69, 69]               0
  BN_ReLU_Conv2d-391          [-1, 224, 69, 69]               0
       ConvDense-392          [-1, 224, 69, 69]               0
ConvBuildingBlock-393          [-1, 224, 69, 69]               0
          Up2dBB-394          [-1, 224, 69, 69]               0
       Dropout2d-395          [-1, 224, 69, 69]               0
 ConvTranspose2d-396        [-1, 112, 139, 139]         451,696
     BatchNorm2d-397        [-1, 112, 139, 139]             224
            ReLU-398        [-1, 112, 139, 139]               0
 BN_ReLU_ConvT2d-399        [-1, 112, 139, 139]               0
          Conv2d-400        [-1, 112, 139, 139]          12,656
     BatchNorm2d-401        [-1, 112, 139, 139]             224
            ReLU-402        [-1, 112, 139, 139]               0
  BN_ReLU_Conv2d-403        [-1, 112, 139, 139]               0
          Conv2d-404         [-1, 28, 139, 139]          28,252
     BatchNorm2d-405         [-1, 28, 139, 139]              56
            ReLU-406         [-1, 28, 139, 139]               0
  BN_ReLU_Conv2d-407         [-1, 28, 139, 139]               0
          Conv2d-408        [-1, 112, 139, 139]          15,792
     BatchNorm2d-409        [-1, 112, 139, 139]             224
            ReLU-410        [-1, 112, 139, 139]               0
  BN_ReLU_Conv2d-411        [-1, 112, 139, 139]               0
          Conv2d-412         [-1, 28, 139, 139]          28,252
     BatchNorm2d-413         [-1, 28, 139, 139]              56
            ReLU-414         [-1, 28, 139, 139]               0
  BN_ReLU_Conv2d-415         [-1, 28, 139, 139]               0
          Conv2d-416        [-1, 112, 139, 139]          18,928
     BatchNorm2d-417        [-1, 112, 139, 139]             224
            ReLU-418        [-1, 112, 139, 139]               0
  BN_ReLU_Conv2d-419        [-1, 112, 139, 139]               0
          Conv2d-420         [-1, 28, 139, 139]          28,252
     BatchNorm2d-421         [-1, 28, 139, 139]              56
            ReLU-422         [-1, 28, 139, 139]               0
  BN_ReLU_Conv2d-423         [-1, 28, 139, 139]               0
          Conv2d-424        [-1, 112, 139, 139]          22,064
     BatchNorm2d-425        [-1, 112, 139, 139]             224
            ReLU-426        [-1, 112, 139, 139]               0
  BN_ReLU_Conv2d-427        [-1, 112, 139, 139]               0
          Conv2d-428         [-1, 28, 139, 139]          28,252
     BatchNorm2d-429         [-1, 28, 139, 139]              56
            ReLU-430         [-1, 28, 139, 139]               0
  BN_ReLU_Conv2d-431         [-1, 28, 139, 139]               0
          Conv2d-432        [-1, 112, 139, 139]          25,200
     BatchNorm2d-433        [-1, 112, 139, 139]             224
            ReLU-434        [-1, 112, 139, 139]               0
  BN_ReLU_Conv2d-435        [-1, 112, 139, 139]               0
       ConvDense-436        [-1, 112, 139, 139]               0
ConvBuildingBlock-437        [-1, 112, 139, 139]               0
          Up2dBB-438        [-1, 112, 139, 139]               0
       Dropout2d-439        [-1, 112, 139, 139]               0
 ConvTranspose2d-440        [-1, 112, 281, 281]         627,312
     BatchNorm2d-441        [-1, 112, 281, 281]             224
            ReLU-442        [-1, 112, 281, 281]               0
 BN_ReLU_ConvT2d-443        [-1, 112, 281, 281]               0
          Conv2d-444        [-1, 112, 281, 281]          12,656
     BatchNorm2d-445        [-1, 112, 281, 281]             224
            ReLU-446        [-1, 112, 281, 281]               0
  BN_ReLU_Conv2d-447        [-1, 112, 281, 281]               0
          Conv2d-448         [-1, 28, 281, 281]          28,252
     BatchNorm2d-449         [-1, 28, 281, 281]              56
            ReLU-450         [-1, 28, 281, 281]               0
  BN_ReLU_Conv2d-451         [-1, 28, 281, 281]               0
          Conv2d-452        [-1, 112, 281, 281]          15,792
     BatchNorm2d-453        [-1, 112, 281, 281]             224
            ReLU-454        [-1, 112, 281, 281]               0
  BN_ReLU_Conv2d-455        [-1, 112, 281, 281]               0
          Conv2d-456         [-1, 28, 281, 281]          28,252
     BatchNorm2d-457         [-1, 28, 281, 281]              56
            ReLU-458         [-1, 28, 281, 281]               0
  BN_ReLU_Conv2d-459         [-1, 28, 281, 281]               0
          Conv2d-460        [-1, 112, 281, 281]          18,928
     BatchNorm2d-461        [-1, 112, 281, 281]             224
            ReLU-462        [-1, 112, 281, 281]               0
  BN_ReLU_Conv2d-463        [-1, 112, 281, 281]               0
          Conv2d-464         [-1, 28, 281, 281]          28,252
     BatchNorm2d-465         [-1, 28, 281, 281]              56
            ReLU-466         [-1, 28, 281, 281]               0
  BN_ReLU_Conv2d-467         [-1, 28, 281, 281]               0
          Conv2d-468        [-1, 112, 281, 281]          22,064
     BatchNorm2d-469        [-1, 112, 281, 281]             224
            ReLU-470        [-1, 112, 281, 281]               0
  BN_ReLU_Conv2d-471        [-1, 112, 281, 281]               0
          Conv2d-472         [-1, 28, 281, 281]          28,252
     BatchNorm2d-473         [-1, 28, 281, 281]              56
            ReLU-474         [-1, 28, 281, 281]               0
  BN_ReLU_Conv2d-475         [-1, 28, 281, 281]               0
          Conv2d-476        [-1, 112, 281, 281]          25,200
     BatchNorm2d-477        [-1, 112, 281, 281]             224
            ReLU-478        [-1, 112, 281, 281]               0
  BN_ReLU_Conv2d-479        [-1, 112, 281, 281]               0
       ConvDense-480        [-1, 112, 281, 281]               0
ConvBuildingBlock-481        [-1, 112, 281, 281]               0
          Up2dBB-482        [-1, 112, 281, 281]               0
       Dropout2d-483        [-1, 112, 281, 281]               0
          Conv2d-484        [-1, 224, 281, 281]          50,400
     BatchNorm2d-485        [-1, 224, 281, 281]             448
            ReLU-486        [-1, 224, 281, 281]               0
  BN_ReLU_Conv2d-487        [-1, 224, 281, 281]               0
          Conv2d-488         [-1, 56, 281, 281]         112,952
     BatchNorm2d-489         [-1, 56, 281, 281]             112
            ReLU-490         [-1, 56, 281, 281]               0
  BN_ReLU_Conv2d-491         [-1, 56, 281, 281]               0
          Conv2d-492        [-1, 224, 281, 281]          62,944
     BatchNorm2d-493        [-1, 224, 281, 281]             448
            ReLU-494        [-1, 224, 281, 281]               0
  BN_ReLU_Conv2d-495        [-1, 224, 281, 281]               0
          Conv2d-496         [-1, 56, 281, 281]         112,952
     BatchNorm2d-497         [-1, 56, 281, 281]             112
            ReLU-498         [-1, 56, 281, 281]               0
  BN_ReLU_Conv2d-499         [-1, 56, 281, 281]               0
          Conv2d-500        [-1, 224, 281, 281]          75,488
     BatchNorm2d-501        [-1, 224, 281, 281]             448
            ReLU-502        [-1, 224, 281, 281]               0
  BN_ReLU_Conv2d-503        [-1, 224, 281, 281]               0
          Conv2d-504         [-1, 56, 281, 281]         112,952
     BatchNorm2d-505         [-1, 56, 281, 281]             112
            ReLU-506         [-1, 56, 281, 281]               0
  BN_ReLU_Conv2d-507         [-1, 56, 281, 281]               0
          Conv2d-508        [-1, 224, 281, 281]          88,032
     BatchNorm2d-509        [-1, 224, 281, 281]             448
            ReLU-510        [-1, 224, 281, 281]               0
  BN_ReLU_Conv2d-511        [-1, 224, 281, 281]               0
          Conv2d-512         [-1, 56, 281, 281]         112,952
     BatchNorm2d-513         [-1, 56, 281, 281]             112
            ReLU-514         [-1, 56, 281, 281]               0
  BN_ReLU_Conv2d-515         [-1, 56, 281, 281]               0
          Conv2d-516        [-1, 224, 281, 281]         100,576
     BatchNorm2d-517        [-1, 224, 281, 281]             448
            ReLU-518        [-1, 224, 281, 281]               0
  BN_ReLU_Conv2d-519        [-1, 224, 281, 281]               0
       ConvDense-520        [-1, 224, 281, 281]               0
ConvBuildingBlock-521        [-1, 224, 281, 281]               0
          Conv2d-522          [-1, 3, 281, 281]             675
      ConvOutput-523          [-1, 3, 281, 281]               0
================================================================
Total params: 157,683,795
Trainable params: 157,683,795
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.30
Forward/backward pass size (MB): 9698.29
Params size (MB): 601.52
Estimated Total Size (MB): 10300.11
----------------------------------------------------------------
===================End of Net Architecture =====================

Info: program will use 4 GPUs.
Loss Functions List: FocalCELoss with weight of 1; 	BoundaryLoss with weight of 0; 
Hints: Test Dice_0 is the dice coeff for all non-zero labels
Hints: Test Dice_1 is for primary cancer(green), 	
 test Dice_2 is for metastasis(yellow), 	
 and test Dice_3 is for invaded lymph node(brown).
Hints: Test TPR_0 is the TPR for all non-zero labels
Hints: Test TPR_1 is for primary cancer(green), 	
 TPR_2 is for metastasis(yellow), 	
 and TPR_3 is for invaded lymph node(brown).

Epoch	TrLoss	Dice0	Dice1	Dice2	TPR_0	TPR_1	TPR_2	TsLoss	Dice0	Dice1	Dice2	TPR_0	TPR_1	TPR_2
0	0.3816	0.162	0.156	0.082	0.910	0.462	0.559	0.3430	0.159	0.405	0.029	0.911	0.885	0.131
1	0.3163	0.228	0.252	0.099	0.876	0.525	0.427	0.2971	0.216	0.000	0.150	0.951	0.000	0.947
2	0.2886	0.289	0.383	0.108	0.926	0.608	0.528	0.3422	0.238	0.488	0.087	0.843	0.675	0.309
3	0.2827	0.272	0.562	0.083	0.890	0.759	0.374	0.2824	0.216	0.633	0.043	0.966	0.935	0.261
4	0.2860	0.281	0.409	0.126	0.931	0.567	0.562	0.2445	0.234	0.012	0.148	0.942	0.007	0.877
5	0.2717	0.293	0.575	0.113	0.908	0.737	0.468	0.3057	0.268	0.440	0.166	0.697	0.363	0.562
6	0.2735	0.297	0.525	0.122	0.927	0.668	0.509	0.2254	0.305	0.670	0.164	0.849	0.739	0.558
7	0.2574	0.285	0.491	0.156	0.911	0.598	0.671	0.2195	0.254	0.646	0.143	0.894	0.670	0.730
8	0.2522	0.260	0.556	0.142	0.917	0.687	0.646	0.2745	0.239	0.646	0.064	0.914	0.909	0.346
9	0.2573	0.248	0.525	0.128	0.917	0.681	0.555	0.2225	0.236	0.702	0.102	0.949	0.862	0.593
10	0.2649	0.261	0.443	0.153	0.926	0.578	0.664	0.2217	0.256	0.114	0.183	0.866	0.084	0.783
11	0.2505	0.275	0.555	0.153	0.932	0.654	0.659	0.2008	0.266	0.660	0.173	0.913	0.716	0.769
12	0.2244	0.302	0.543	0.186	0.925	0.669	0.699	0.2210	0.249	0.694	0.125	0.946	0.894	0.599
13	0.2456	0.269	0.465	0.150	0.934	0.628	0.688	0.2332	0.296	0.687	0.153	0.830	0.843	0.525
14	0.2474	0.276	0.547	0.155	0.917	0.718	0.665	0.1937	0.269	0.668	0.178	0.926	0.809	0.772
15	0.2475	0.281	0.568	0.161	0.943	0.690	0.712	0.2142	0.282	0.626	0.198	0.802	0.714	0.654
16	0.2214	0.273	0.550	0.173	0.927	0.696	0.686	0.2060	0.240	0.640	0.146	0.941	0.925	0.687
17	0.2266	0.267	0.527	0.175	0.941	0.736	0.720	0.1841	0.235	0.666	0.146	0.930	0.901	0.724
18	0.2417	0.270	0.477	0.173	0.936	0.691	0.709	0.2081	0.230	0.571	0.144	0.926	0.936	0.607
19	0.2232	0.312	0.604	0.187	0.929	0.838	0.705	0.1725	0.318	0.668	0.234	0.819	0.831	0.685
20	0.2223	0.289	0.560	0.199	0.923	0.754	0.718	0.1708	0.226	0.654	0.152	0.967	0.780	0.892
21	0.2191	0.280	0.599	0.166	0.932	0.768	0.729	0.1889	0.254	0.644	0.194	0.949	0.840	0.875
22	0.2238	0.269	0.564	0.177	0.934	0.781	0.774	0.1660	0.258	0.683	0.170	0.929	0.926	0.764
23	0.2127	0.274	0.499	0.193	0.935	0.772	0.720	0.3300	0.334	0.406	0.280	0.784	0.464	0.699
24	0.2235	0.297	0.608	0.172	0.917	0.777	0.684	0.1642	0.266	0.644	0.191	0.824	0.827	0.720
25	0.2096	0.289	0.524	0.219	0.943	0.780	0.767	0.2506	0.259	0.553	0.182	0.889	0.824	0.522
26	0.2079	0.299	0.575	0.217	0.934	0.822	0.733	0.1786	0.311	0.633	0.248	0.828	0.934	0.637
27	0.2193	0.282	0.507	0.202	0.934	0.706	0.749	0.1583	0.252	0.627	0.200	0.930	0.824	0.869
28	0.2192	0.294	0.581	0.198	0.936	0.889	0.680	0.1780	0.244	0.543	0.188	0.964	0.772	0.834
29	0.2132	0.290	0.548	0.207	0.943	0.805	0.803	0.1589	0.253	0.644	0.174	0.926	0.795	0.859
30	0.2078	0.295	0.584	0.196	0.920	0.850	0.720	0.1682	0.289	0.635	0.217	0.931	0.899	0.769
31	0.2017	0.301	0.558	0.215	0.921	0.795	0.735	0.1876	0.247	0.624	0.168	0.941	0.945	0.712
32	0.2002	0.272	0.518	0.198	0.932	0.756	0.782	0.1498	0.270	0.679	0.195	0.941	0.931	0.814
33	0.2032	0.312	0.536	0.226	0.956	0.830	0.785	0.1872	0.283	0.611	0.220	0.905	0.817	0.782
34	0.2078	0.282	0.521	0.227	0.932	0.858	0.758	0.1434	0.252	0.639	0.196	0.967	0.903	0.872
35	0.1913	0.313	0.516	0.235	0.938	0.759	0.831	0.1445	0.308	0.675	0.241	0.863	0.875	0.794
36	0.1736	0.311	0.537	0.251	0.951	0.838	0.832	0.1589	0.263	0.626	0.187	0.957	0.970	0.792
37	0.1807	0.311	0.559	0.239	0.944	0.846	0.803	0.2104	0.253	0.587	0.162	0.970	0.980	0.481
38	0.1893	0.340	0.569	0.254	0.941	0.833	0.819	0.1434	0.248	0.675	0.181	0.973	0.867	0.928
39	0.1926	0.316	0.555	0.228	0.946	0.852	0.752	0.1596	0.305	0.538	0.251	0.885	0.686	0.781
40	0.1713	0.305	0.572	0.244	0.940	0.917	0.801	0.1412	0.275	0.654	0.206	0.907	0.848	0.831
41	0.1749	0.318	0.578	0.240	0.947	0.876	0.808	0.1596	0.255	0.577	0.177	0.951	0.632	0.908
42	0.1849	0.317	0.562	0.229	0.957	0.879	0.789	0.1374	0.259	0.621	0.191	0.966	0.787	0.915
43	0.1922	0.322	0.569	0.256	0.939	0.833	0.827	0.1468	0.332	0.676	0.260	0.817	0.925	0.685
44	0.1892	0.278	0.552	0.206	0.953	0.838	0.857	0.1417	0.266	0.542	0.202	0.959	0.749	0.908
45	0.1613	0.313	0.559	0.237	0.933	0.838	0.822	0.1578	0.306	0.612	0.263	0.931	0.954	0.720
46	0.1793	0.321	0.566	0.236	0.944	0.828	0.798	0.1464	0.339	0.678	0.266	0.851	0.923	0.724
47	0.1916	0.292	0.530	0.246	0.931	0.838	0.817	0.1520	0.272	0.652	0.213	0.964	0.902	0.868
48	0.1687	0.337	0.582	0.261	0.944	0.835	0.819	0.1483	0.308	0.616	0.249	0.875	0.953	0.673
49	0.1709	0.325	0.556	0.260	0.954	0.871	0.810	0.1316	0.324	0.682	0.246	0.921	0.908	0.838
50	0.1726	0.333	0.512	0.260	0.939	0.784	0.794	0.2073	0.257	0.507	0.218	0.968	0.732	0.896
51	0.1927	0.308	0.538	0.209	0.935	0.896	0.731	0.1413	0.272	0.658	0.193	0.945	0.912	0.880
52	0.1823	0.347	0.552	0.287	0.949	0.826	0.818	0.1649	0.215	0.530	0.186	0.982	0.893	0.927
53	0.1679	0.333	0.573	0.264	0.945	0.852	0.836	0.1998	0.339	0.675	0.247	0.783	0.857	0.553
54	0.1774	0.283	0.545	0.234	0.933	0.836	0.837	0.1736	0.223	0.594	0.176	0.980	0.917	0.891
55	0.1761	0.328	0.551	0.248	0.944	0.850	0.846	0.1315	0.302	0.631	0.260	0.937	0.891	0.843
56	0.1660	0.332	0.527	0.296	0.946	0.853	0.854	0.2176	0.305	0.591	0.277	0.859	0.791	0.735
57	0.1860	0.324	0.542	0.252	0.942	0.850	0.794	0.1424	0.313	0.637	0.258	0.920	0.936	0.791
58	0.1562	0.347	0.602	0.272	0.944	0.885	0.827	0.1638	0.301	0.575	0.265	0.890	0.877	0.727
59	0.1772	0.326	0.567	0.239	0.947	0.846	0.794	0.1333	0.294	0.638	0.225	0.936	0.941	0.823
60	0.1518	0.316	0.557	0.231	0.936	0.881	0.833	0.1353	0.314	0.664	0.237	0.882	0.917	0.783
61	0.1748	0.327	0.590	0.247	0.944	0.858	0.846	0.2541	0.297	0.483	0.252	0.817	0.469	0.845
62	0.1677	0.354	0.586	0.269	0.961	0.883	0.811	0.1402	0.318	0.599	0.250	0.887	0.805	0.797
63	0.1738	0.332	0.551	0.253	0.950	0.831	0.806	0.1812	0.233	0.625	0.148	0.972	0.919	0.821
64	0.1568	0.321	0.583	0.250	0.956	0.901	0.821	0.1406	0.311	0.615	0.250	0.917	0.865	0.847
65	0.1629	0.338	0.592	0.259	0.955	0.869	0.844	0.2575	0.273	0.472	0.217	0.638	0.409	0.673
66	0.1576	0.346	0.579	0.271	0.958	0.868	0.850	0.1565	0.275	0.652	0.200	0.954	0.891	0.852
67	0.1586	0.327	0.553	0.272	0.934	0.863	0.805	0.1565	0.279	0.573	0.233	0.934	0.904	0.773
68	0.1617	0.327	0.598	0.241	0.934	0.889	0.793	0.1616	0.253	0.613	0.179	0.980	0.783	0.940
69	0.1607	0.312	0.561	0.236	0.943	0.896	0.812	0.1323	0.308	0.583	0.242	0.946	0.713	0.910
70	0.1648	0.349	0.611	0.265	0.939	0.875	0.823	0.1316	0.296	0.645	0.240	0.959	0.908	0.886
71	0.1612	0.339	0.577	0.261	0.958	0.849	0.816	0.1305	0.319	0.664	0.257	0.913	0.885	0.845
72	0.1441	0.355	0.540	0.295	0.938	0.888	0.812	0.1311	0.341	0.603	0.293	0.860	0.818	0.791
73	0.1675	0.321	0.557	0.257	0.950	0.847	0.845	0.1415	0.308	0.602	0.265	0.919	0.907	0.813
74	0.1710	0.345	0.568	0.287	0.957	0.922	0.844	0.1397	0.300	0.665	0.235	0.959	0.934	0.852
75	0.1467	0.349	0.610	0.271	0.945	0.917	0.827	0.1308	0.327	0.625	0.255	0.885	0.812	0.820
76	0.1581	0.324	0.567	0.258	0.946	0.905	0.855	0.1556	0.281	0.651	0.209	0.916	0.856	0.851
77	0.1754	0.311	0.528	0.224	0.933	0.905	0.784	0.1869	0.298	0.618	0.236	0.883	0.932	0.584
78	0.1427	0.335	0.563	0.266	0.947	0.866	0.839	0.3416	0.260	0.546	0.060	0.848	0.930	0.197
79	0.1570	0.339	0.540	0.264	0.962	0.842	0.852	0.3031	0.212	0.380	0.142	0.986	0.422	0.985
80	0.1648	0.338	0.565	0.254	0.924	0.852	0.780	0.1333	0.302	0.701	0.207	0.937	0.871	0.886
81	0.1417	0.315	0.578	0.264	0.948	0.899	0.850	0.1452	0.307	0.635	0.263	0.931	0.860	0.826
82	0.1569	0.343	0.565	0.285	0.950	0.848	0.869	0.1465	0.301	0.635	0.239	0.920	0.950	0.807
83	0.1580	0.335	0.561	0.264	0.954	0.874	0.859	0.1515	0.295	0.633	0.214	0.943	0.952	0.725
84	0.1647	0.337	0.619	0.257	0.949	0.871	0.871	0.1456	0.350	0.657	0.273	0.895	0.826	0.813
85	0.1646	0.330	0.609	0.262	0.937	0.915	0.866	0.1341	0.308	0.605	0.248	0.955	0.881	0.860
86	0.1306	0.357	0.597	0.297	0.941	0.914	0.873	0.1347	0.334	0.672	0.258	0.919	0.878	0.834
87	0.1538	0.336	0.565	0.271	0.945	0.867	0.864	0.2143	0.259	0.511	0.245	0.920	0.802	0.676
88	0.1621	0.312	0.550	0.244	0.932	0.833	0.838	0.1554	0.345	0.676	0.242	0.903	0.910	0.687
89	0.1427	0.354	0.604	0.269	0.941	0.905	0.818	0.1224	0.301	0.637	0.234	0.941	0.888	0.874
90	0.1745	0.323	0.539	0.253	0.953	0.883	0.825	0.1756	0.279	0.566	0.210	0.953	0.720	0.881
91	0.1796	0.299	0.491	0.227	0.938	0.750	0.775	0.1560	0.313	0.631	0.257	0.911	0.917	0.781
92	0.1572	0.330	0.584	0.254	0.932	0.877	0.824	0.1300	0.288	0.628	0.219	0.961	0.894	0.863
93	0.1603	0.339	0.558	0.276	0.955	0.849	0.856	0.1327	0.332	0.571	0.287	0.908	0.787	0.825
94	0.1544	0.339	0.614	0.287	0.959	0.919	0.878	0.2141	0.320	0.647	0.242	0.755	0.927	0.522
95	0.1566	0.357	0.583	0.305	0.964	0.888	0.859	0.1554	0.295	0.611	0.242	0.952	0.925	0.803
96	0.1619	0.339	0.596	0.263	0.953	0.865	0.877	0.1386	0.309	0.644	0.247	0.949	0.928	0.832
97	0.1653	0.332	0.557	0.260	0.936	0.870	0.820	0.1398	0.318	0.661	0.242	0.937	0.900	0.826
98	0.1434	0.363	0.589	0.292	0.946	0.878	0.844	0.1333	0.317	0.587	0.253	0.945	0.796	0.880
99	0.1429	0.324	0.625	0.243	0.946	0.936	0.849	0.1394	0.317	0.582	0.272	0.936	0.852	0.858
100	0.1663	0.333	0.555	0.278	0.971	0.865	0.920	0.1866	0.280	0.587	0.249	0.934	0.940	0.651
101	0.1544	0.375	0.594	0.294	0.957	0.928	0.846	0.1338	0.297	0.620	0.233	0.956	0.922	0.874
102	0.1382	0.340	0.607	0.264	0.955	0.936	0.853	0.1353	0.307	0.359	0.238	0.954	0.410	0.920
103	0.1569	0.319	0.565	0.242	0.958	0.886	0.848	0.1386	0.290	0.623	0.230	0.967	0.948	0.880
104	0.1393	0.359	0.643	0.289	0.941	0.932	0.856	0.1663	0.291	0.443	0.284	0.873	0.663	0.751
105	0.1664	0.373	0.573	0.305	0.957	0.878	0.856	0.1505	0.272	0.593	0.202	0.970	0.779	0.947
106	0.1680	0.360	0.607	0.291	0.967	0.934	0.885	0.1586	0.328	0.656	0.279	0.919	0.921	0.814
107	0.1447	0.374	0.615	0.296	0.951	0.862	0.875	0.1373	0.320	0.675	0.242	0.916	0.882	0.864
108	0.1511	0.374	0.626	0.278	0.925	0.886	0.797	0.1495	0.294	0.603	0.247	0.912	0.936	0.798
109	0.1741	0.336	0.568	0.242	0.952	0.900	0.841	0.1401	0.330	0.665	0.259	0.923	0.796	0.898
110	0.1926	0.351	0.589	0.270	0.931	0.881	0.826	0.1762	0.263	0.584	0.207	0.975	0.961	0.866
111	0.1707	0.354	0.595	0.282	0.939	0.906	0.863	0.1635	0.336	0.639	0.276	0.919	0.906	0.822
112	0.1914	0.349	0.573	0.289	0.919	0.884	0.862	0.1622	0.308	0.629	0.249	0.936	0.941	0.841
113	0.1638	0.366	0.568	0.292	0.936	0.888	0.829	0.1389	0.334	0.634	0.265	0.919	0.918	0.842
114	0.2057	0.342	0.549	0.260	0.919	0.826	0.815	0.1432	0.294	0.653	0.207	0.957	0.865	0.891
115	0.1639	0.371	0.615	0.296	0.926	0.879	0.852	0.1606	0.270	0.624	0.182	0.978	0.909	0.906
116	0.1879	0.363	0.633	0.282	0.920	0.868	0.828	0.1691	0.288	0.614	0.218	0.969	0.745	0.947
117	0.1865	0.377	0.580	0.301	0.925	0.847	0.815	0.1894	0.274	0.423	0.197	0.948	0.425	0.938
118	0.1672	0.366	0.600	0.282	0.924	0.907	0.827	0.1529	0.335	0.634	0.286	0.902	0.940	0.810
119	0.1661	0.377	0.628	0.282	0.934	0.890	0.847	0.1640	0.305	0.663	0.218	0.966	0.914	0.893
120	0.1858	0.364	0.585	0.303	0.927	0.867	0.840	0.1919	0.346	0.643	0.258	0.907	0.809	0.809
121	0.1972	0.382	0.586	0.311	0.915	0.845	0.825	0.1573	0.351	0.658	0.275	0.927	0.925	0.829
122	0.1533	0.397	0.607	0.332	0.927	0.917	0.845	0.1494	0.338	0.655	0.254	0.937	0.925	0.856
123	0.1760	0.395	0.580	0.344	0.937	0.912	0.866	0.1508	0.341	0.652	0.266	0.919	0.911	0.845
124	0.1933	0.374	0.580	0.299	0.936	0.900	0.831	0.1625	0.349	0.657	0.292	0.895	0.954	0.784
125	0.1848	0.384	0.632	0.270	0.913	0.915	0.812	0.1535	0.362	0.692	0.259	0.894	0.904	0.808
126	0.1790	0.394	0.606	0.315	0.913	0.888	0.828	0.1653	0.339	0.632	0.270	0.901	0.882	0.816
127	0.1707	0.406	0.613	0.334	0.950	0.899	0.866	0.1559	0.351	0.632	0.259	0.895	0.807	0.844
128	0.1682	0.395	0.616	0.312	0.932	0.894	0.864	0.1525	0.372	0.685	0.290	0.922	0.865	0.866
129	0.1592	0.401	0.595	0.322	0.917	0.861	0.851	0.1585	0.337	0.700	0.236	0.934	0.895	0.864
130	0.1745	0.398	0.616	0.324	0.926	0.869	0.862	0.1688	0.330	0.667	0.241	0.938	0.942	0.862
131	0.2106	0.396	0.609	0.287	0.945	0.897	0.846	0.1826	0.332	0.598	0.280	0.897	0.844	0.824
132	0.1941	0.409	0.596	0.323	0.927	0.885	0.832	0.1579	0.344	0.653	0.265	0.898	0.909	0.818
133	0.1774	0.382	0.552	0.315	0.921	0.848	0.861	0.1761	0.323	0.629	0.227	0.954	0.834	0.899
134	0.1551	0.419	0.620	0.327	0.928	0.901	0.853	0.1769	0.336	0.718	0.250	0.935	0.903	0.864
135	0.1901	0.390	0.556	0.326	0.914	0.878	0.839	0.1826	0.375	0.697	0.276	0.881	0.801	0.838
136	0.1924	0.424	0.624	0.317	0.922	0.905	0.821	0.1660	0.359	0.604	0.265	0.912	0.740	0.856
137	0.1641	0.417	0.618	0.332	0.922	0.885	0.860	0.1688	0.354	0.666	0.276	0.904	0.904	0.816
138	0.1826	0.393	0.609	0.286	0.914	0.919	0.832	0.1906	0.361	0.629	0.307	0.869	0.970	0.749
139	0.1727	0.401	0.603	0.322	0.906	0.927	0.820	0.1726	0.363	0.651	0.295	0.916	0.928	0.823
140	0.2009	0.426	0.677	0.328	0.922	0.951	0.859	0.1845	0.304	0.542	0.233	0.952	0.845	0.890
141	0.2184	0.404	0.604	0.345	0.912	0.874	0.855	0.1819	0.346	0.672	0.282	0.917	0.945	0.831
142	0.1435	0.430	0.605	0.346	0.918	0.899	0.826	0.1822	0.352	0.644	0.257	0.918	0.795	0.885
143	0.2159	0.403	0.610	0.326	0.923	0.882	0.845	0.1813	0.337	0.662	0.261	0.934	0.920	0.826
144	0.1886	0.414	0.629	0.327	0.926	0.912	0.823	0.1761	0.363	0.681	0.271	0.933	0.894	0.857
145	0.1887	0.441	0.626	0.343	0.913	0.856	0.846	0.1771	0.368	0.627	0.291	0.896	0.818	0.851
146	0.1855	0.450	0.620	0.366	0.930	0.901	0.856	0.1661	0.352	0.613	0.279	0.915	0.817	0.866
147	0.2275	0.418	0.640	0.292	0.913	0.902	0.811	0.1786	0.319	0.630	0.250	0.917	0.929	0.831
148	0.1974	0.397	0.578	0.312	0.922	0.907	0.854	0.1678	0.360	0.666	0.257	0.911	0.849	0.853
149	0.1702	0.432	0.615	0.357	0.931	0.874	0.865	0.2043	0.402	0.653	0.311	0.813	0.764	0.756
150	0.2115	0.416	0.602	0.342	0.906	0.892	0.822	0.1810	0.370	0.624	0.278	0.924	0.803	0.876
151	0.2085	0.427	0.629	0.345	0.893	0.865	0.825	0.2183	0.382	0.694	0.289	0.856	0.805	0.781
152	0.1691	0.434	0.631	0.332	0.927	0.879	0.864	0.1867	0.384	0.638	0.285	0.898	0.739	0.852
153	0.2080	0.455	0.654	0.355	0.923	0.919	0.816	0.1793	0.351	0.651	0.281	0.920	0.894	0.853
154	0.1631	0.467	0.633	0.375	0.914	0.869	0.847	0.1802	0.360	0.671	0.274	0.919	0.890	0.848
155	0.1830	0.451	0.656	0.334	0.900	0.884	0.801	0.1774	0.379	0.664	0.296	0.897	0.892	0.822
156	0.1910	0.432	0.628	0.330	0.896	0.909	0.817	0.2030	0.381	0.695	0.296	0.888	0.914	0.799
157	0.1792	0.461	0.648	0.380	0.917	0.920	0.837	0.2051	0.387	0.626	0.292	0.876	0.745	0.830
158	0.1804	0.417	0.594	0.329	0.917	0.881	0.848	0.1951	0.394	0.656	0.300	0.877	0.809	0.814
159	0.1763	0.448	0.653	0.350	0.899	0.908	0.816	0.1820	0.357	0.667	0.281	0.911	0.922	0.829
160	0.2026	0.447	0.637	0.338	0.929	0.899	0.876	0.2016	0.387	0.672	0.314	0.849	0.896	0.742
161	0.1770	0.466	0.654	0.367	0.914	0.939	0.840	0.1859	0.374	0.669	0.287	0.907	0.897	0.828
162	0.1907	0.442	0.625	0.369	0.925	0.871	0.873	0.1881	0.380	0.712	0.291	0.898	0.916	0.829
163	0.1587	0.455	0.669	0.363	0.918	0.939	0.843	0.1802	0.350	0.703	0.246	0.927	0.884	0.870
164	0.1717	0.445	0.625	0.367	0.934	0.904	0.875	0.1890	0.395	0.703	0.314	0.846	0.913	0.762
165	0.1823	0.453	0.660	0.364	0.910	0.927	0.846	0.1903	0.369	0.653	0.272	0.887	0.856	0.810
166	0.1929	0.434	0.623	0.345	0.923	0.885	0.866	0.1843	0.385	0.677	0.328	0.865	0.946	0.772
167	0.1791	0.428	0.619	0.335	0.918	0.907	0.847	0.1936	0.389	0.687	0.329	0.850	0.921	0.749
168	0.1899	0.479	0.673	0.363	0.918	0.957	0.843	0.1811	0.381	0.677	0.283	0.919	0.888	0.849
169	0.1769	0.449	0.643	0.342	0.918	0.920	0.875	0.1916	0.380	0.648	0.285	0.904	0.851	0.844
170	0.1770	0.458	0.639	0.378	0.920	0.911	0.865	0.2186	0.402	0.721	0.302	0.866	0.821	0.826
171	0.1960	0.442	0.616	0.348	0.895	0.886	0.821	0.1913	0.377	0.684	0.271	0.919	0.863	0.857
172	0.2020	0.493	0.682	0.382	0.905	0.916	0.829	0.1906	0.405	0.681	0.306	0.881	0.824	0.827
173	0.1666	0.455	0.631	0.361	0.919	0.912	0.859	0.1887	0.411	0.720	0.311	0.879	0.850	0.827
174	0.1802	0.423	0.636	0.328	0.916	0.892	0.842	0.2021	0.392	0.639	0.335	0.861	0.893	0.781
175	0.2100	0.440	0.657	0.324	0.921	0.939	0.845	0.1913	0.405	0.654	0.328	0.869	0.882	0.791
176	0.1883	0.413	0.586	0.340	0.886	0.918	0.818	0.1928	0.333	0.661	0.250	0.944	0.942	0.885
177	0.1855	0.446	0.624	0.355	0.924	0.888	0.884	0.1977	0.401	0.677	0.329	0.872	0.889	0.794
178	0.1880	0.485	0.705	0.378	0.941	0.924	0.879	0.1979	0.385	0.680	0.287	0.897	0.850	0.830
179	0.1768	0.467	0.649	0.372	0.901	0.882	0.841	0.1964	0.384	0.688	0.303	0.894	0.947	0.794
180	0.1962	0.448	0.634	0.365	0.912	0.921	0.861	0.1982	0.389	0.681	0.289	0.906	0.864	0.852
181	0.1997	0.433	0.629	0.346	0.893	0.903	0.827	0.1885	0.363	0.710	0.261	0.928	0.897	0.882
182	0.2080	0.446	0.652	0.354	0.907	0.877	0.862	0.1950	0.385	0.688	0.317	0.909	0.955	0.821
183	0.1759	0.449	0.644	0.345	0.896	0.892	0.826	0.1975	0.383	0.627	0.290	0.913	0.792	0.854
