Program ID 18431

Program command: 
 ['/home/hxie1/Projects/OvarianCancer/TrainSegV.py', '/home/hxie1/temp_netParameters/OvarianCancer/Label0_1', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainImages', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels', '2D', '0,1']

Major program changes: ConvResidual use BatchNorm-reLU-Conv structure; 
                       ConsDense also use BatchNorm-reLU-Conv structure.
                       Add ConvSegDecreaseChannels
                       and each block has 5 layers, 
                       Residual connect to each Conv, 
                       skip at least 2 layers.
                       output layer use conv with 3*3 fiter instead of 1*1 filter. 
                       use boundary loss with weight 0 at beginning, and pretrain CE loss. 
                       special convInput Module
                       convOutput moudel uses 1*1 conv to tranparent gradident 
                       ConvOutput use residual module.
                       Use Dense Net in the Building Block
                       add ConvBlock to wrapp the ConvResidual and ConvDense
                       first layer filter = 96, reducing from 128 of previous experiment
                       the nLayers in block is 4, increase from 2 of previous experiment
                       
            

Program starting Time: 2019-05-10 09:10:55.111350
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/Label0_1

Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Infor: program test labels: [0, 1]
Infor: program suppressed labels: [2, 3]
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/trainLabels has 164 segmented slices for remained labels [0, 1].
Building the Segmented Slice Tuple list, which may need 8 mins, please waiting......
Directory of /home/hxie1/data/OvarianCancerCT/Extract_uniform/testLabels has 31 segmented slices for remained labels [0, 1].
Info: program uses 2D input.
TrainData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

TestData Input:  batchSize=8, depth=1, height=281, width=281, NumClassfication=2

Network trains from scratch.
Network has total 115919522 parameters.
Info: network dropout rate = 0.3
Infor: Cross Entropy Weight: [1.0260619741432382, 39.37007874015748]

====================Net Architecture===========================
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 96, 281, 281]             960
       BatchNorm2d-2         [-1, 96, 281, 281]             192
              ReLU-3         [-1, 96, 281, 281]               0
            Conv2d-4         [-1, 96, 281, 281]           9,312
       BatchNorm2d-5         [-1, 96, 281, 281]             192
              ReLU-6         [-1, 96, 281, 281]               0
            Conv2d-7         [-1, 24, 281, 281]          20,760
       BatchNorm2d-8        [-1, 120, 281, 281]             240
              ReLU-9        [-1, 120, 281, 281]               0
           Conv2d-10         [-1, 96, 281, 281]          11,616
      BatchNorm2d-11         [-1, 96, 281, 281]             192
             ReLU-12         [-1, 96, 281, 281]               0
           Conv2d-13         [-1, 24, 281, 281]          20,760
      BatchNorm2d-14        [-1, 144, 281, 281]             288
             ReLU-15        [-1, 144, 281, 281]               0
           Conv2d-16         [-1, 96, 281, 281]          13,920
      BatchNorm2d-17         [-1, 96, 281, 281]             192
             ReLU-18         [-1, 96, 281, 281]               0
           Conv2d-19         [-1, 24, 281, 281]          20,760
      BatchNorm2d-20        [-1, 168, 281, 281]             336
             ReLU-21        [-1, 168, 281, 281]               0
           Conv2d-22         [-1, 96, 281, 281]          16,224
      BatchNorm2d-23         [-1, 96, 281, 281]             192
             ReLU-24         [-1, 96, 281, 281]               0
           Conv2d-25         [-1, 24, 281, 281]          20,760
      BatchNorm2d-26        [-1, 192, 281, 281]             384
             ReLU-27        [-1, 192, 281, 281]               0
           Conv2d-28         [-1, 96, 281, 281]          18,528
        ConvDense-29         [-1, 96, 281, 281]               0
        ConvBlock-30         [-1, 96, 281, 281]               0
        ConvInput-31         [-1, 96, 281, 281]               0
      BatchNorm2d-32         [-1, 96, 281, 281]             192
           Conv2d-33         [-1, 96, 139, 139]         230,496
      BatchNorm2d-34         [-1, 96, 139, 139]             192
             ReLU-35         [-1, 96, 139, 139]               0
           Conv2d-36         [-1, 96, 139, 139]           9,312
      BatchNorm2d-37         [-1, 96, 139, 139]             192
             ReLU-38         [-1, 96, 139, 139]               0
           Conv2d-39         [-1, 24, 139, 139]          20,760
      BatchNorm2d-40        [-1, 120, 139, 139]             240
             ReLU-41        [-1, 120, 139, 139]               0
           Conv2d-42         [-1, 96, 139, 139]          11,616
      BatchNorm2d-43         [-1, 96, 139, 139]             192
             ReLU-44         [-1, 96, 139, 139]               0
           Conv2d-45         [-1, 24, 139, 139]          20,760
      BatchNorm2d-46        [-1, 144, 139, 139]             288
             ReLU-47        [-1, 144, 139, 139]               0
           Conv2d-48         [-1, 96, 139, 139]          13,920
      BatchNorm2d-49         [-1, 96, 139, 139]             192
             ReLU-50         [-1, 96, 139, 139]               0
           Conv2d-51         [-1, 24, 139, 139]          20,760
      BatchNorm2d-52        [-1, 168, 139, 139]             336
             ReLU-53        [-1, 168, 139, 139]               0
           Conv2d-54         [-1, 96, 139, 139]          16,224
      BatchNorm2d-55         [-1, 96, 139, 139]             192
             ReLU-56         [-1, 96, 139, 139]               0
           Conv2d-57         [-1, 24, 139, 139]          20,760
      BatchNorm2d-58        [-1, 192, 139, 139]             384
             ReLU-59        [-1, 192, 139, 139]               0
           Conv2d-60         [-1, 96, 139, 139]          18,528
        ConvDense-61         [-1, 96, 139, 139]               0
        ConvBlock-62         [-1, 96, 139, 139]               0
         Down2dBB-63         [-1, 96, 139, 139]               0
        Dropout2d-64         [-1, 96, 139, 139]               0
      BatchNorm2d-65         [-1, 96, 139, 139]             192
           Conv2d-66          [-1, 192, 69, 69]         166,080
      BatchNorm2d-67          [-1, 192, 69, 69]             384
             ReLU-68          [-1, 192, 69, 69]               0
           Conv2d-69          [-1, 192, 69, 69]          37,056
      BatchNorm2d-70          [-1, 192, 69, 69]             384
             ReLU-71          [-1, 192, 69, 69]               0
           Conv2d-72           [-1, 48, 69, 69]          82,992
      BatchNorm2d-73          [-1, 240, 69, 69]             480
             ReLU-74          [-1, 240, 69, 69]               0
           Conv2d-75          [-1, 192, 69, 69]          46,272
      BatchNorm2d-76          [-1, 192, 69, 69]             384
             ReLU-77          [-1, 192, 69, 69]               0
           Conv2d-78           [-1, 48, 69, 69]          82,992
      BatchNorm2d-79          [-1, 288, 69, 69]             576
             ReLU-80          [-1, 288, 69, 69]               0
           Conv2d-81          [-1, 192, 69, 69]          55,488
      BatchNorm2d-82          [-1, 192, 69, 69]             384
             ReLU-83          [-1, 192, 69, 69]               0
           Conv2d-84           [-1, 48, 69, 69]          82,992
      BatchNorm2d-85          [-1, 336, 69, 69]             672
             ReLU-86          [-1, 336, 69, 69]               0
           Conv2d-87          [-1, 192, 69, 69]          64,704
      BatchNorm2d-88          [-1, 192, 69, 69]             384
             ReLU-89          [-1, 192, 69, 69]               0
           Conv2d-90           [-1, 48, 69, 69]          82,992
      BatchNorm2d-91          [-1, 384, 69, 69]             768
             ReLU-92          [-1, 384, 69, 69]               0
           Conv2d-93          [-1, 192, 69, 69]          73,920
        ConvDense-94          [-1, 192, 69, 69]               0
        ConvBlock-95          [-1, 192, 69, 69]               0
         Down2dBB-96          [-1, 192, 69, 69]               0
        Dropout2d-97          [-1, 192, 69, 69]               0
      BatchNorm2d-98          [-1, 192, 69, 69]             384
           Conv2d-99          [-1, 384, 33, 33]       1,843,584
     BatchNorm2d-100          [-1, 384, 33, 33]             768
            ReLU-101          [-1, 384, 33, 33]               0
          Conv2d-102          [-1, 384, 33, 33]         147,840
     BatchNorm2d-103          [-1, 384, 33, 33]             768
            ReLU-104          [-1, 384, 33, 33]               0
          Conv2d-105           [-1, 96, 33, 33]         331,872
     BatchNorm2d-106          [-1, 480, 33, 33]             960
            ReLU-107          [-1, 480, 33, 33]               0
          Conv2d-108          [-1, 384, 33, 33]         184,704
     BatchNorm2d-109          [-1, 384, 33, 33]             768
            ReLU-110          [-1, 384, 33, 33]               0
          Conv2d-111           [-1, 96, 33, 33]         331,872
     BatchNorm2d-112          [-1, 576, 33, 33]           1,152
            ReLU-113          [-1, 576, 33, 33]               0
          Conv2d-114          [-1, 384, 33, 33]         221,568
     BatchNorm2d-115          [-1, 384, 33, 33]             768
            ReLU-116          [-1, 384, 33, 33]               0
          Conv2d-117           [-1, 96, 33, 33]         331,872
     BatchNorm2d-118          [-1, 672, 33, 33]           1,344
            ReLU-119          [-1, 672, 33, 33]               0
          Conv2d-120          [-1, 384, 33, 33]         258,432
     BatchNorm2d-121          [-1, 384, 33, 33]             768
            ReLU-122          [-1, 384, 33, 33]               0
          Conv2d-123           [-1, 96, 33, 33]         331,872
     BatchNorm2d-124          [-1, 768, 33, 33]           1,536
            ReLU-125          [-1, 768, 33, 33]               0
          Conv2d-126          [-1, 384, 33, 33]         295,296
       ConvDense-127          [-1, 384, 33, 33]               0
       ConvBlock-128          [-1, 384, 33, 33]               0
        Down2dBB-129          [-1, 384, 33, 33]               0
       Dropout2d-130          [-1, 384, 33, 33]               0
     BatchNorm2d-131          [-1, 384, 33, 33]             768
          Conv2d-132          [-1, 768, 15, 15]       7,373,568
     BatchNorm2d-133          [-1, 768, 15, 15]           1,536
            ReLU-134          [-1, 768, 15, 15]               0
          Conv2d-135          [-1, 768, 15, 15]         590,592
     BatchNorm2d-136          [-1, 768, 15, 15]           1,536
            ReLU-137          [-1, 768, 15, 15]               0
          Conv2d-138          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-139          [-1, 960, 15, 15]           1,920
            ReLU-140          [-1, 960, 15, 15]               0
          Conv2d-141          [-1, 768, 15, 15]         738,048
     BatchNorm2d-142          [-1, 768, 15, 15]           1,536
            ReLU-143          [-1, 768, 15, 15]               0
          Conv2d-144          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-145         [-1, 1152, 15, 15]           2,304
            ReLU-146         [-1, 1152, 15, 15]               0
          Conv2d-147          [-1, 768, 15, 15]         885,504
     BatchNorm2d-148          [-1, 768, 15, 15]           1,536
            ReLU-149          [-1, 768, 15, 15]               0
          Conv2d-150          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-151         [-1, 1344, 15, 15]           2,688
            ReLU-152         [-1, 1344, 15, 15]               0
          Conv2d-153          [-1, 768, 15, 15]       1,032,960
     BatchNorm2d-154          [-1, 768, 15, 15]           1,536
            ReLU-155          [-1, 768, 15, 15]               0
          Conv2d-156          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-157         [-1, 1536, 15, 15]           3,072
            ReLU-158         [-1, 1536, 15, 15]               0
          Conv2d-159          [-1, 768, 15, 15]       1,180,416
       ConvDense-160          [-1, 768, 15, 15]               0
       ConvBlock-161          [-1, 768, 15, 15]               0
        Down2dBB-162          [-1, 768, 15, 15]               0
       Dropout2d-163          [-1, 768, 15, 15]               0
     BatchNorm2d-164          [-1, 768, 15, 15]           1,536
          Conv2d-165           [-1, 1536, 7, 7]      10,618,368
     BatchNorm2d-166           [-1, 1536, 7, 7]           3,072
            ReLU-167           [-1, 1536, 7, 7]               0
          Conv2d-168           [-1, 1536, 7, 7]       2,360,832
     BatchNorm2d-169           [-1, 1536, 7, 7]           3,072
            ReLU-170           [-1, 1536, 7, 7]               0
          Conv2d-171            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-172           [-1, 1920, 7, 7]           3,840
            ReLU-173           [-1, 1920, 7, 7]               0
          Conv2d-174           [-1, 1536, 7, 7]       2,950,656
     BatchNorm2d-175           [-1, 1536, 7, 7]           3,072
            ReLU-176           [-1, 1536, 7, 7]               0
          Conv2d-177            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-178           [-1, 2304, 7, 7]           4,608
            ReLU-179           [-1, 2304, 7, 7]               0
          Conv2d-180           [-1, 1536, 7, 7]       3,540,480
     BatchNorm2d-181           [-1, 1536, 7, 7]           3,072
            ReLU-182           [-1, 1536, 7, 7]               0
          Conv2d-183            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-184           [-1, 2688, 7, 7]           5,376
            ReLU-185           [-1, 2688, 7, 7]               0
          Conv2d-186           [-1, 1536, 7, 7]       4,130,304
     BatchNorm2d-187           [-1, 1536, 7, 7]           3,072
            ReLU-188           [-1, 1536, 7, 7]               0
          Conv2d-189            [-1, 384, 7, 7]       5,308,800
     BatchNorm2d-190           [-1, 3072, 7, 7]           6,144
            ReLU-191           [-1, 3072, 7, 7]               0
          Conv2d-192           [-1, 1536, 7, 7]       4,720,128
       ConvDense-193           [-1, 1536, 7, 7]               0
       ConvBlock-194           [-1, 1536, 7, 7]               0
        Down2dBB-195           [-1, 1536, 7, 7]               0
       Dropout2d-196           [-1, 1536, 7, 7]               0
     BatchNorm2d-197           [-1, 1536, 7, 7]           3,072
 ConvTranspose2d-198          [-1, 768, 15, 15]      10,617,600
     BatchNorm2d-199          [-1, 768, 15, 15]           1,536
            ReLU-200          [-1, 768, 15, 15]               0
          Conv2d-201          [-1, 768, 15, 15]         590,592
     BatchNorm2d-202          [-1, 768, 15, 15]           1,536
            ReLU-203          [-1, 768, 15, 15]               0
          Conv2d-204          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-205          [-1, 960, 15, 15]           1,920
            ReLU-206          [-1, 960, 15, 15]               0
          Conv2d-207          [-1, 768, 15, 15]         738,048
     BatchNorm2d-208          [-1, 768, 15, 15]           1,536
            ReLU-209          [-1, 768, 15, 15]               0
          Conv2d-210          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-211         [-1, 1152, 15, 15]           2,304
            ReLU-212         [-1, 1152, 15, 15]               0
          Conv2d-213          [-1, 768, 15, 15]         885,504
     BatchNorm2d-214          [-1, 768, 15, 15]           1,536
            ReLU-215          [-1, 768, 15, 15]               0
          Conv2d-216          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-217         [-1, 1344, 15, 15]           2,688
            ReLU-218         [-1, 1344, 15, 15]               0
          Conv2d-219          [-1, 768, 15, 15]       1,032,960
     BatchNorm2d-220          [-1, 768, 15, 15]           1,536
            ReLU-221          [-1, 768, 15, 15]               0
          Conv2d-222          [-1, 192, 15, 15]       1,327,296
     BatchNorm2d-223         [-1, 1536, 15, 15]           3,072
            ReLU-224         [-1, 1536, 15, 15]               0
          Conv2d-225          [-1, 768, 15, 15]       1,180,416
       ConvDense-226          [-1, 768, 15, 15]               0
       ConvBlock-227          [-1, 768, 15, 15]               0
          Up2dBB-228          [-1, 768, 15, 15]               0
       Dropout2d-229          [-1, 768, 15, 15]               0
     BatchNorm2d-230         [-1, 1536, 15, 15]           3,072
 ConvTranspose2d-231          [-1, 384, 33, 33]      14,745,984
     BatchNorm2d-232          [-1, 384, 33, 33]             768
            ReLU-233          [-1, 384, 33, 33]               0
          Conv2d-234          [-1, 384, 33, 33]         147,840
     BatchNorm2d-235          [-1, 384, 33, 33]             768
            ReLU-236          [-1, 384, 33, 33]               0
          Conv2d-237           [-1, 96, 33, 33]         331,872
     BatchNorm2d-238          [-1, 480, 33, 33]             960
            ReLU-239          [-1, 480, 33, 33]               0
          Conv2d-240          [-1, 384, 33, 33]         184,704
     BatchNorm2d-241          [-1, 384, 33, 33]             768
            ReLU-242          [-1, 384, 33, 33]               0
          Conv2d-243           [-1, 96, 33, 33]         331,872
     BatchNorm2d-244          [-1, 576, 33, 33]           1,152
            ReLU-245          [-1, 576, 33, 33]               0
          Conv2d-246          [-1, 384, 33, 33]         221,568
     BatchNorm2d-247          [-1, 384, 33, 33]             768
            ReLU-248          [-1, 384, 33, 33]               0
          Conv2d-249           [-1, 96, 33, 33]         331,872
     BatchNorm2d-250          [-1, 672, 33, 33]           1,344
            ReLU-251          [-1, 672, 33, 33]               0
          Conv2d-252          [-1, 384, 33, 33]         258,432
     BatchNorm2d-253          [-1, 384, 33, 33]             768
            ReLU-254          [-1, 384, 33, 33]               0
          Conv2d-255           [-1, 96, 33, 33]         331,872
     BatchNorm2d-256          [-1, 768, 33, 33]           1,536
            ReLU-257          [-1, 768, 33, 33]               0
          Conv2d-258          [-1, 384, 33, 33]         295,296
       ConvDense-259          [-1, 384, 33, 33]               0
       ConvBlock-260          [-1, 384, 33, 33]               0
          Up2dBB-261          [-1, 384, 33, 33]               0
       Dropout2d-262          [-1, 384, 33, 33]               0
     BatchNorm2d-263          [-1, 768, 33, 33]           1,536
 ConvTranspose2d-264          [-1, 192, 69, 69]       3,686,592
     BatchNorm2d-265          [-1, 192, 69, 69]             384
            ReLU-266          [-1, 192, 69, 69]               0
          Conv2d-267          [-1, 192, 69, 69]          37,056
     BatchNorm2d-268          [-1, 192, 69, 69]             384
            ReLU-269          [-1, 192, 69, 69]               0
          Conv2d-270           [-1, 48, 69, 69]          82,992
     BatchNorm2d-271          [-1, 240, 69, 69]             480
            ReLU-272          [-1, 240, 69, 69]               0
          Conv2d-273          [-1, 192, 69, 69]          46,272
     BatchNorm2d-274          [-1, 192, 69, 69]             384
            ReLU-275          [-1, 192, 69, 69]               0
          Conv2d-276           [-1, 48, 69, 69]          82,992
     BatchNorm2d-277          [-1, 288, 69, 69]             576
            ReLU-278          [-1, 288, 69, 69]               0
          Conv2d-279          [-1, 192, 69, 69]          55,488
     BatchNorm2d-280          [-1, 192, 69, 69]             384
            ReLU-281          [-1, 192, 69, 69]               0
          Conv2d-282           [-1, 48, 69, 69]          82,992
     BatchNorm2d-283          [-1, 336, 69, 69]             672
            ReLU-284          [-1, 336, 69, 69]               0
          Conv2d-285          [-1, 192, 69, 69]          64,704
     BatchNorm2d-286          [-1, 192, 69, 69]             384
            ReLU-287          [-1, 192, 69, 69]               0
          Conv2d-288           [-1, 48, 69, 69]          82,992
     BatchNorm2d-289          [-1, 384, 69, 69]             768
            ReLU-290          [-1, 384, 69, 69]               0
          Conv2d-291          [-1, 192, 69, 69]          73,920
       ConvDense-292          [-1, 192, 69, 69]               0
       ConvBlock-293          [-1, 192, 69, 69]               0
          Up2dBB-294          [-1, 192, 69, 69]               0
       Dropout2d-295          [-1, 192, 69, 69]               0
     BatchNorm2d-296          [-1, 384, 69, 69]             768
 ConvTranspose2d-297         [-1, 96, 139, 139]         331,872
     BatchNorm2d-298         [-1, 96, 139, 139]             192
            ReLU-299         [-1, 96, 139, 139]               0
          Conv2d-300         [-1, 96, 139, 139]           9,312
     BatchNorm2d-301         [-1, 96, 139, 139]             192
            ReLU-302         [-1, 96, 139, 139]               0
          Conv2d-303         [-1, 24, 139, 139]          20,760
     BatchNorm2d-304        [-1, 120, 139, 139]             240
            ReLU-305        [-1, 120, 139, 139]               0
          Conv2d-306         [-1, 96, 139, 139]          11,616
     BatchNorm2d-307         [-1, 96, 139, 139]             192
            ReLU-308         [-1, 96, 139, 139]               0
          Conv2d-309         [-1, 24, 139, 139]          20,760
     BatchNorm2d-310        [-1, 144, 139, 139]             288
            ReLU-311        [-1, 144, 139, 139]               0
          Conv2d-312         [-1, 96, 139, 139]          13,920
     BatchNorm2d-313         [-1, 96, 139, 139]             192
            ReLU-314         [-1, 96, 139, 139]               0
          Conv2d-315         [-1, 24, 139, 139]          20,760
     BatchNorm2d-316        [-1, 168, 139, 139]             336
            ReLU-317        [-1, 168, 139, 139]               0
          Conv2d-318         [-1, 96, 139, 139]          16,224
     BatchNorm2d-319         [-1, 96, 139, 139]             192
            ReLU-320         [-1, 96, 139, 139]               0
          Conv2d-321         [-1, 24, 139, 139]          20,760
     BatchNorm2d-322        [-1, 192, 139, 139]             384
            ReLU-323        [-1, 192, 139, 139]               0
          Conv2d-324         [-1, 96, 139, 139]          18,528
       ConvDense-325         [-1, 96, 139, 139]               0
       ConvBlock-326         [-1, 96, 139, 139]               0
          Up2dBB-327         [-1, 96, 139, 139]               0
       Dropout2d-328         [-1, 96, 139, 139]               0
     BatchNorm2d-329        [-1, 192, 139, 139]             384
 ConvTranspose2d-330         [-1, 96, 281, 281]         460,896
     BatchNorm2d-331         [-1, 96, 281, 281]             192
            ReLU-332         [-1, 96, 281, 281]               0
          Conv2d-333         [-1, 96, 281, 281]           9,312
     BatchNorm2d-334         [-1, 96, 281, 281]             192
            ReLU-335         [-1, 96, 281, 281]               0
          Conv2d-336         [-1, 24, 281, 281]          20,760
     BatchNorm2d-337        [-1, 120, 281, 281]             240
            ReLU-338        [-1, 120, 281, 281]               0
          Conv2d-339         [-1, 96, 281, 281]          11,616
     BatchNorm2d-340         [-1, 96, 281, 281]             192
            ReLU-341         [-1, 96, 281, 281]               0
          Conv2d-342         [-1, 24, 281, 281]          20,760
     BatchNorm2d-343        [-1, 144, 281, 281]             288
            ReLU-344        [-1, 144, 281, 281]               0
          Conv2d-345         [-1, 96, 281, 281]          13,920
     BatchNorm2d-346         [-1, 96, 281, 281]             192
            ReLU-347         [-1, 96, 281, 281]               0
          Conv2d-348         [-1, 24, 281, 281]          20,760
     BatchNorm2d-349        [-1, 168, 281, 281]             336
            ReLU-350        [-1, 168, 281, 281]               0
          Conv2d-351         [-1, 96, 281, 281]          16,224
     BatchNorm2d-352         [-1, 96, 281, 281]             192
            ReLU-353         [-1, 96, 281, 281]               0
          Conv2d-354         [-1, 24, 281, 281]          20,760
     BatchNorm2d-355        [-1, 192, 281, 281]             384
            ReLU-356        [-1, 192, 281, 281]               0
          Conv2d-357         [-1, 96, 281, 281]          18,528
       ConvDense-358         [-1, 96, 281, 281]               0
       ConvBlock-359         [-1, 96, 281, 281]               0
          Up2dBB-360         [-1, 96, 281, 281]               0
       Dropout2d-361         [-1, 96, 281, 281]               0
     BatchNorm2d-362        [-1, 192, 281, 281]             384
            ReLU-363        [-1, 192, 281, 281]               0
          Conv2d-364        [-1, 192, 281, 281]          37,056
     BatchNorm2d-365        [-1, 192, 281, 281]             384
            ReLU-366        [-1, 192, 281, 281]               0
          Conv2d-367         [-1, 48, 281, 281]          82,992
     BatchNorm2d-368        [-1, 240, 281, 281]             480
            ReLU-369        [-1, 240, 281, 281]               0
          Conv2d-370        [-1, 192, 281, 281]          46,272
     BatchNorm2d-371        [-1, 192, 281, 281]             384
            ReLU-372        [-1, 192, 281, 281]               0
          Conv2d-373         [-1, 48, 281, 281]          82,992
     BatchNorm2d-374        [-1, 288, 281, 281]             576
            ReLU-375        [-1, 288, 281, 281]               0
          Conv2d-376        [-1, 192, 281, 281]          55,488
     BatchNorm2d-377        [-1, 192, 281, 281]             384
            ReLU-378        [-1, 192, 281, 281]               0
          Conv2d-379         [-1, 48, 281, 281]          82,992
     BatchNorm2d-380        [-1, 336, 281, 281]             672
            ReLU-381        [-1, 336, 281, 281]               0
          Conv2d-382        [-1, 192, 281, 281]          64,704
     BatchNorm2d-383        [-1, 192, 281, 281]             384
            ReLU-384        [-1, 192, 281, 281]               0
          Conv2d-385         [-1, 48, 281, 281]          82,992
     BatchNorm2d-386        [-1, 384, 281, 281]             768
            ReLU-387        [-1, 384, 281, 281]               0
          Conv2d-388        [-1, 192, 281, 281]          73,920
       ConvDense-389        [-1, 192, 281, 281]               0
       ConvBlock-390        [-1, 192, 281, 281]               0
     BatchNorm2d-391        [-1, 192, 281, 281]             384
          Conv2d-392          [-1, 2, 281, 281]             386
      ConvOutput-393          [-1, 2, 281, 281]               0
================================================================
Total params: 115,919,522
Trainable params: 115,919,522
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.30
Forward/backward pass size (MB): 9476.45
Params size (MB): 442.20
Estimated Total Size (MB): 9918.95
----------------------------------------------------------------
===================End of Net Architecture =====================

Info: program will use 4 GPUs.
Loss Functions List: FocalCELoss with weight of 1; 	BoundaryLoss with weight of 0; 
Hints: Test Dice_0 is the dice coeff for all non-zero labels
Hints: Test Dice_1 is for primary cancer(green), test Dice_2 is for metastasis(yellow), and test Dice_3 is for invaded lymph node(brown).
Hints: Test TPR_0 is the TPR for all non-zero labels
Hints: Test TPR_1 is for primary cancer(green), TPR_2 is for metastasis(yellow), and TPR_3 is for invaded lymph node(brown).

Epoch 	 TrainingLoss 	 TestLoss 	Dice_0	Dice_1	TPR_0	TPR_1
0 	 0.0993 	 0.1166 	0.171	0.171	1.000	1.000
1 	 0.0786 	 0.0867 	0.287	0.287	0.999	0.999
2 	 0.0682 	 0.0572 	0.479	0.479	0.933	0.933
3 	 0.0590 	 0.1396 	0.519	0.519	0.813	0.813
4 	 0.0569 	 0.0437 	0.552	0.552	0.953	0.953
5 	 0.0471 	 0.0440 	0.551	0.551	0.969	0.969
6 	 0.0464 	 0.0561 	0.549	0.549	0.943	0.943
7 	 0.0557 	 0.0753 	0.460	0.460	0.945	0.945
8 	 0.0484 	 0.0473 	0.493	0.493	0.986	0.986
9 	 0.0524 	 0.1104 	0.567	0.567	0.909	0.909
10 	 0.0551 	 0.1002 	0.560	0.560	0.935	0.935
11 	 0.0501 	 0.0390 	0.484	0.484	0.986	0.986
12 	 0.0418 	 0.0384 	0.607	0.607	0.961	0.961
13 	 0.0433 	 0.0635 	0.577	0.577	0.918	0.918
14 	 0.0427 	 0.0461 	0.481	0.481	0.965	0.965
15 	 0.0375 	 0.0431 	0.616	0.616	0.962	0.962
16 	 0.0369 	 0.0369 	0.537	0.537	0.992	0.992
17 	 0.0379 	 0.0890 	0.603	0.603	0.934	0.934
18 	 0.0402 	 0.0310 	0.648	0.648	0.962	0.962
19 	 0.0347 	 0.0374 	0.590	0.590	0.963	0.963
20 	 0.0331 	 0.0363 	0.579	0.579	0.970	0.970
21 	 0.0355 	 0.0394 	0.600	0.600	0.959	0.959
22 	 0.0362 	 0.0446 	0.611	0.611	0.955	0.955
23 	 0.0367 	 0.0367 	0.544	0.544	0.974	0.974
24 	 0.0366 	 0.0673 	0.657	0.657	0.917	0.917
25 	 0.0330 	 0.0352 	0.538	0.538	0.985	0.985
26 	 0.0323 	 0.0306 	0.567	0.567	0.988	0.988
27 	 0.0306 	 0.0390 	0.623	0.623	0.964	0.964
28 	 0.0319 	 0.0721 	0.625	0.625	0.933	0.933
29 	 0.0341 	 0.0593 	0.593	0.593	0.957	0.957
30 	 0.0352 	 0.0300 	0.606	0.606	0.984	0.984
31 	 0.0338 	 0.0849 	0.657	0.657	0.892	0.892
32 	 0.0333 	 0.0370 	0.634	0.634	0.956	0.956
33 	 0.0369 	 0.0553 	0.556	0.556	0.952	0.952
