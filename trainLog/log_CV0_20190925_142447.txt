=============training from sratch============
Program ID: 18343

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy', '0', '3,2,1']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      
         

Discarded changes:                  

Experiment setting:
Input CT data: 51*171*171 ROI around primary cancer

Loss Function:  SoftMax

Data:   total 36 patients with 50-80% label, 6-fold cross validation, test 6, validation 6, and training 24.  
    script: python3.7 statisticsLabelFiles.py 
    Total 36 in /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
    0 has 48159408 elements, with a rate of  0.8970491562903105 
    1 has 5527068 elements, with a rate of  0.10295084370968957

Training strategy: 

          

Program starting Time: 2019-09-25 14:24:47.126694
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190925_142447

Info: this is the 0th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 6

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20190925_142447.
6-fold cross validation: the 0th fold is for test, the 1th fold is for validation, remaining folds are for training.

training dataset: total 24 image files.

validation dataset: total 6 image files.

test dataset: total 6 image files.
Total 24 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROI/labels_npy
0 has 32252453 elements, with a rate of  0.9011334530506342 
1 has 3538531 elements, with a rate of  0.0988665469493658 
loss weight = tensor([1.0000, 9.1146])
Network has total 32,972,258 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		27.8655		0.09781		1576298.2500		0.00000		1105813.3750		0.00000
5	1.0000e-02		11.2810		0.27275		17.4621		0.28655		15.0879		0.30319
10	1.0000e-02		8.5563		0.37350		8.7204		0.47265		10.2043		0.35466
15	1.0000e-02		7.7212		0.45954		6.7899		0.53608		8.2362		0.41137
20	1.0000e-02		5.2085		0.55156		7.5013		0.58184		9.3383		0.42559
25	1.0000e-02		5.8866		0.53418		5.3008		0.63535		5.9976		0.50133
30	1.0000e-02		6.3488		0.52160		6.6198		0.58583		7.6116		0.44199
35	1.0000e-02		5.9616		0.51839		5.3062		0.64084		6.8926		0.48800
40	1.0000e-02		5.9232		0.45579		5.0579		0.66191		4.6939		0.55936
45	1.0000e-02		4.8354		0.54470		6.9918		0.68644		5.0547		0.61615
50	1.0000e-03		3.8019		0.57864		10.7068		0.61082		4.9775		0.63611
55	1.0000e-03		4.4651		0.55431		5.6202		0.67258		4.5217		0.56317
60	1.0000e-03		4.6338		0.57374		6.1170		0.65115		4.6690		0.53865
65	1.0000e-03		4.4766		0.57721		5.6740		0.67357		4.2593		0.57265
70	1.0000e-03		4.4050		0.56793		5.5926		0.66730		4.3788		0.55787
75	1.0000e-03		4.4284		0.59628		5.8126		0.66726		4.3044		0.56629
