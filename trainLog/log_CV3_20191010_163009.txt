=============training from sratch============
Program ID: 24207

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/labels_npy', '3', '3,2,1']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      Sep 30th, 2019
      1   With size-reduced ROI of size 51*149*149;
      2   reduce the translation of data augmentation;
      3   reduce all data into 35 patients, excluding a very blur patient.
      Oct 5th, 2019
      1   use uniform physical size 147mm*147mm*147mm, input pixel size: 49*147*147 with spacing size 3mm*1mm*1mm;
      2   change V model with inputsize 49*147*147
      Oct 6th, 2019
      1   add filter number to 48 at the first layer. 
      Oct 7th, 2019
      1   restore to 32 of number of filters in the first layer;
      2   add bottom number of filters to 1024, and keep down sample and add filter number together. 
      Oct 8th, 2019
      1   discard the cancer with size exceeding 147mm*147mm*147mm; Now remains 29 patients data; 
      Oct 9th, 209
      1   In the first layer of V model, remove the residual link; 
           with the residula link at first layer: Tr dice:54%, Validation Dice 27%, Test Dice 56%;  Not good.
      2   the final output layer, change into 1*1*1 convolution, instead of 3*3*3 convolution;
      3   add labelConsistencyLoss;
          
         

Discarded changes:                  
          

Program starting Time: 2019-10-10 16:30:09.886516
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191010_163009

Info: this is the 3th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 6

Info: useLabelConsistencyLoss = False

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191010_163009.
6-fold cross validation: the 3th fold is for test, the 4th fold is for validation, remaining folds are for training.

training dataset: total 19 image files.

validation dataset: total 5 image files.

test dataset: total 5 image files.
Total 19 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/labels_npy
0 has 18805544 elements, with a rate of  0.9347630793331676 
1 has 1312435 elements, with a rate of  0.06523692066683238 
loss weight = tensor([ 1.0000, 14.3287])
Network has total 113,191,074 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		16.1365		0.05343		3091.0396		0.00000		3898.9785		0.00000
5	1.0000e-02		9.3840		0.15505		19.2414		0.30553		9.8729		0.17147
10	1.0000e-02		6.9431		0.27723		10.4075		0.43878		7.1759		0.28760
15	1.0000e-02		6.6542		0.29360		29.3282		0.42500		15.9988		0.26189
20	1.0000e-02		6.7652		0.32562		38.0293		0.29525		10.7057		0.22099
25	1.0000e-02		5.9515		0.26177		20.0517		0.31059		10.1625		0.23631
30	1.0000e-02		7.7630		0.29343		24.1435		0.39437		7.9337		0.26233
35	1.0000e-02		5.0956		0.35997		8.1795		0.41646		8.0361		0.26322
40	1.0000e-02		3.9771		0.39429		7.2636		0.45097		6.0279		0.36983
45	1.0000e-02		4.9198		0.32348		12.7660		0.38428		18.3789		0.22250
50	1.0000e-02		3.8861		0.37787		7.3236		0.46304		24.9878		0.23408
55	1.0000e-02		5.3981		0.27562		7.4695		0.49780		5.5372		0.37343
60	1.0000e-02		5.0814		0.36501		6.6565		0.45726		6.0895		0.31474
65	1.0000e-02		6.2250		0.39471		10.7976		0.46946		17.6387		0.25943
70	1.0000e-02		4.7656		0.24993		6.8206		0.45957		5.2421		0.37443
75	1.0000e-02		4.8319		0.33858		8.1640		0.42647		5.8112		0.34507
80	1.0000e-02		4.0845		0.35361		6.9757		0.46032		12.0697		0.32043
85	1.0000e-02		4.8567		0.34445		7.4778		0.43582		7.7944		0.29434
90	1.0000e-02		3.8373		0.43341		9.8809		0.46581		5.6736		0.41436
95	1.0000e-02		3.5033		0.39409		9.1542		0.50662		7.9511		0.35764
100	1.0000e-02		3.5912		0.38830		4.7471		0.53036		5.8191		0.46515
