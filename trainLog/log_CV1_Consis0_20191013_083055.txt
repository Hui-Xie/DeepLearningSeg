=============training from sratch============
Program ID: 18819

Program command: 
 ['TrainSegV3d_ROI.py', '/home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI', '1', '/home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/nrrd_npy', '/home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/labels_npy', '1', '2', '0']

Major program changes: 
      1  3D V model for primary cancer ROI;
      2  Uniform ROI size: 51*171*171 in z,y,x directon;
      3  Total 36 patient data, in which training data 24 patients, validation 6 patients, and test 6 patients;
      4  all 36 patients data have 50-80% 3D label;
      5  Dice coefficient is 3D dice coefficient against corresponding 3D ground truth;
      6  training data augmentation in the fly: affine in XY plane, translation in Z direction;
      7  In the bottle neck of V model, the latent vector has size of 512*2*9*9;
      Sep 16th, 2019:
      1   add dynamic loss weight according trainin  data;
      2   refine learning rate decay.
      Sep 21st, 2019
      1   add improved Boundary Loss2, and inherit the previous learningrate of network of pure CELoss;
      Sep 23rd, 2019:
      1   improve mean of boundary loss limited on the A,B regions;
      2   use log(segProb) instead of segProb in the boudary loss;
      3   CrossEntropy weight reduces 0.01 per 5 epochs from 1 to 0.01, while boundary Loss weight increase 0.01 per 5 epochs from 0.01 to 1. 
      Sep 24th, 2019
      1   Use boundaryLoss1, which is considering the whole volume. 
      Sep 25th, 2019
      1   use boundaryLoss3, which is a stronger gradient signal to improve loss.
      2   unbalanced weight for class is applied on logP,and just use boundaryLoss3 with CELoss.
      3   use CELoss and boundaryLoss together.
      4   Use truncated DistanceCrossEntropy Loss alone;
      5   change LRScheduler into reduce into Plateau with initial LR=0.1
      Sep 26th, 2019
      1   Add one layer in the bottom of V model;
      2   Add residual connnection in each layer;
      Sep 30th, 2019
      1   With size-reduced ROI of size 51*149*149;
      2   reduce the translation of data augmentation;
      3   reduce all data into 35 patients, excluding a very blur patient.
      Oct 5th, 2019
      1   use uniform physical size 147mm*147mm*147mm, input pixel size: 49*147*147 with spacing size 3mm*1mm*1mm;
      2   change V model with inputsize 49*147*147
      Oct 6th, 2019
      1   add filter number to 48 at the first layer. 
      Oct 7th, 2019
      1   restore to 32 of number of filters in the first layer;
      2   add bottom number of filters to 1024, and keep down sample and add filter number together. 
      Oct 8th, 2019
      1   discard the cancer with size exceeding 147mm*147mm*147mm; Now remains 29 patients data; 
      Oct 9th, 2019
      1   In the first layer of V model, remove the residual link; 
           with the residula link at first layer: Tr dice:54%, Validation Dice 27%, Test Dice 56%;  Not good.
      2   the final output layer, change into 1*1*1 convolution, instead of 3*3*3 convolution;
      3   add labelConsistencyLoss, it use 64 dimension feature extracted from 2 ends of V model:
           It gets stable Training Dice 61%, validation Dice 27%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      Oct 11th, 2019
      1   use feature tensor just from the output end of V model. It is 32 dimensions.
          It gets stable Training Dice 61%, validation Dice 23%, and test dice 49%, for fold 0 in the fixed physical size:147mm*147mm*147mm; 
      2   windows size for consistency loss changes to 3;
      Oct 12th, 2019
      1   change image window level to 100/50; relaunch training;
      2   change consistencyLoss to use ground truth for comparing diff of feature vector;
      Oct 13th, 2019
      1    use conistencyLoss3: ((G1-G2)-(P1-P2))**2 as loss.
       
      

          
         

Discarded changes:                  
          

Program starting Time: 2019-10-13 08:30:55.398247
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191013_083055

Info: this is the 1th fold leave for test in the 6-fold cross-validation.

Info: batchSize = 2

Info: useConsistencyLoss = False and searchWindowSize= 0

Net parameters is saved in  /home/hxie1/temp_netParameters/OvarianCancer/SegV3d_ROI/20191013_083055.
6-fold cross validation: the 1th fold is for test, the 2th fold is for validation, remaining folds are for training.

training dataset: total 19 image files.

validation dataset: total 5 image files.

test dataset: total 5 image files.
Total 19 training files  extracted from /home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/labels_npy
0 has 18657366 elements, with a rate of  0.9273976277637033 
1 has 1460613 elements, with a rate of  0.0726023722362967 
loss weight = tensor([ 1.0000, 12.7737])
Network has total 113,191,074 parameters.


************** Table of Training Log **************
Epoch	LearningRate		TrainingLoss	Dice		ValidationLoss	Dice		TestLoss	Dice
0	1.0000e-02		5.4881		0.17370		324.9028		0.17986		275.4861		0.04956
5	1.0000e-02		2.5944		0.31212		2.8932		0.36604		2.3362		0.15719
10	1.0000e-02		2.8239		0.31733		3.8345		0.33158		3.8589		0.13610
15	1.0000e-02		2.0081		0.38907		6.5935		0.34655		9.2880		0.10214
20	1.0000e-02		2.8574		0.41085		6.8185		0.34380		8.2698		0.10910
25	1.0000e-02		1.7153		0.36853		5.0859		0.32097		6.0934		0.11449
30	1.0000e-02		1.7090		0.40627		1.7437		0.47320		2.3936		0.18108
35	1.0000e-02		1.4245		0.43919		5.1296		0.37184		8.3760		0.10520
40	1.0000e-02		1.4657		0.48319		2.8588		0.36988		2.5008		0.17657
45	1.0000e-02		1.4807		0.47920		1.8487		0.43407		1.9406		0.20816
50	1.0000e-02		1.1747		0.44158		1.1110		0.56896		2.0536		0.20304
55	1.0000e-02		1.6334		0.45503		1.9936		0.42340		1.9455		0.19774
60	1.0000e-02		1.2393		0.45220		2.0393		0.53695		1.7542		0.23205
65	1.0000e-02		1.3673		0.47450		1.4132		0.52318		2.1435		0.18013
70	1.0000e-02		1.2912		0.47249		1.7002		0.52364		0.9746		0.29111
75	1.0000e-02		1.4107		0.46858		1.9001		0.45673		1.1977		0.22219
80	1.0000e-02		1.8105		0.38859		5.3184		0.34565		4.4724		0.13832
85	1.0000e-02		1.5322		0.41059		2.6518		0.57005		1.2503		0.24840
90	1.0000e-02		1.3168		0.48649		2.8081		0.47934		2.1302		0.17324
95	1.0000e-02		1.2100		0.44760		3.3030		0.45069		1.1750		0.26257
100	1.0000e-02		1.0830		0.49137		2.8457		0.50529		1.3225		0.24189
105	1.0000e-03		1.4242		0.47197		3.8600		0.39450		3.6464		0.13572
110	1.0000e-03		1.1013		0.46634		1.9784		0.47649		1.0258		0.27221
115	1.0000e-03		1.1011		0.46366		2.1380		0.47968		1.1196		0.26406
120	1.0000e-03		0.9818		0.51707		2.3504		0.49750		1.0259		0.27613
125	1.0000e-03		1.0664		0.51709		2.6529		0.52886		1.2907		0.25838
130	1.0000e-03		1.0576		0.49793		2.6845		0.50412		1.1980		0.25850
135	1.0000e-03		1.1635		0.52205		2.2902		0.52577		1.0192		0.28021
140	1.0000e-03		1.0301		0.51896		2.6352		0.51735		1.0944		0.27917
145	1.0000e-03		0.9555		0.53491		3.0484		0.50645		0.8896		0.29881
150	1.0000e-03		1.5150		0.48742		2.8839		0.56613		1.0741		0.30868
155	1.0000e-03		1.1813		0.49530		2.3743		0.56446		0.9395		0.31142
160	1.0000e-04		0.9360		0.55224		2.7516		0.54976		1.0055		0.32054
165	1.0000e-04		0.9250		0.53360		3.6140		0.52409		1.0066		0.33581
170	1.0000e-04		0.9629		0.54576		3.9078		0.50848		0.9324		0.33221
175	1.0000e-04		1.0515		0.53355		3.2201		0.53065		0.8430		0.32634
180	1.0000e-04		1.0484		0.53667		3.4102		0.54265		0.8865		0.33386
185	1.0000e-04		0.9224		0.52493		2.9139		0.53233		0.8983		0.32153
190	1.0000e-04		0.9336		0.52481		3.2688		0.53157		0.8899		0.32565
195	1.0000e-04		0.8813		0.54044		3.0386		0.51517		0.8809		0.31528
200	1.0000e-04		0.8526		0.51971		3.0907		0.54205		0.8791		0.33513
205	1.0000e-04		0.8239		0.51992		2.9146		0.56296		0.8604		0.33627
210	1.0000e-04		0.8302		0.53555		3.5991		0.54284		0.8592		0.35686
215	1.0000e-05		0.8725		0.55776		3.4104		0.52774		0.8775		0.34279
220	1.0000e-05		0.9473		0.53896		2.6156		0.53585		0.9268		0.31419
225	1.0000e-05		1.1662		0.52839		2.5327		0.51936		0.9364		0.31067
230	1.0000e-05		0.8920		0.52309		2.9774		0.53157		0.8655		0.33217
235	1.0000e-05		1.0989		0.56827		3.9075		0.52905		0.8280		0.34669
240	1.0000e-05		1.1373		0.52595		2.6716		0.55308		0.8675		0.33371
245	1.0000e-05		0.8663		0.55539		4.2086		0.52635		0.8447		0.35200
250	1.0000e-05		0.8766		0.49668		2.7345		0.51834		0.9811		0.29711
