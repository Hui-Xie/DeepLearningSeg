Program ID of Predictive Network training:5103

Program command: 
 ['TrainPredictNet.py', '/home/hxie1/temp_netParameters/OvarianCancer/Predict', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/trainImages_zoom_147_281_281', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/testImages_zoom_147_281_281', '/home/hxie1/data/OvarianCancerCT/Extract_uniform/patientResponseDict.json', 'image3dZoom']

Major program changes: 
                      the nunmber of filters in 1st layer in V model = 96
                      latent Vector size: 1536*51*49 (featureMap* slices * axisPlaneLatentVector)
                      PredictModel is convsDenseModule+FC network.
                      there total 162 patient data, in which, 130 with smaller patientId as training data, 
                                                          and 32 with bigger patientID as test data

Experiment setting for Latent to response:
Input: 1536*51*49 Tensor as latent vector,
       where 1536 is the  number of filter at the bottleneck of V model, 
             51 is the number of slices of ROI CT image with size 51*281*281 for input to V model, 
             49 =7*7 is the flatted feature map for each filter.

Predictive Model: 1,  first 4-layer dense conv block reducing feature space into 768 with tensor size 768*51*49 
                  2,  and 4 dense conv blocks each of which includes a stride 2 conv and 4-layers dense conv block; now the the tensor is with size 48*2*2
                  3,  and a simple conv-batchNorm-Relu layer with filter size(2,2) change the tensor with size of  48*1;
                  4,  and 2 fully connected layers  changes the tensor into size 2*1;
                  5  final a softmax for binary classification;
                  Total network learning parameters are 29 millions.
                  Network architecture is referred at https://github.com/Hui-Xie/OvarianCancer/blob/master/LatentPredictModel.py

Loss Function:   Cross Entropy with weight [3.3, 1.4] for [0,1] class separately, as [0,1] uneven distribution.

Data:            training data has 130 patients, and test data has 32 patients with training/test rate 80/20.

Training strategy:  50% probability of data are mixed up with beta distribution with alpha =0.4, to feed into network for training. 
                    No other data augmentation, and no dropout.
                                                          
                                                         
Experiment setting for Image3d Zoom to response:
Input: 147*281*281 scaled 3D CT raw image as numpy array 
       
others same with Image3d ROI model.


Experiment setting for Image3d ROI to response:
Input: 147*281*281  3D CT raw image ROI as numpy array 
       
Predictive Model: 1,  first 3-layer dense conv block with channel size 24.
                  2,  and 6 dense conv DownBB blocks,  each of which includes a stride 2 conv and 3-layers dense conv block; 
                  3,  and 3 fully connected layers  changes the tensor into size 2*1;
                  4,  final a softmax for binary classification;
                  Total network learning parameters are 236K.
                  Network architecture is referred at https://github.com/Hui-Xie/OvarianCancer/blob/master/Image3dPredictModel.py

Loss Function:   Cross Entropy with weight [3.3, 1.4] for [0,1] class separately, as [0,1] uneven distribution.

Data:            training data has 130 patients, and test data has 32 patients with training/test rate 80/20.

Training strategy:  50% probability of data are mixed up with beta distribution with alpha =0.4, to feed into network for training. 
                    No other data augmentation, and no dropout.  
                    
                    change patience of learningRate scheduler to 30.                                         

            

Program starting Time: 2019-06-03 16:06:29.243880
Info: netPath = /home/hxie1/temp_netParameters/OvarianCancer/Predict

Now program get 130 input files.
Now program get 32 input files.
TrainData Input:  batchSize=4, depth=147, height=281, width=281, NumClassfication=2

TestData Input:  batchSize=4, depth=147, height=281, width=281, NumClassfication=2

Info: the size of bottle neck in the net = 24* (1, 3, 3)

Info: program uses Mixup with alpha=0.4, and mixupProb = 0.5.
Network trains from scratch.
Network has total 236,648 parameters.
Infor: Cross Entropy Weight: [3.3333333333333335, 1.4285714285714286] for label[0, 1]
Info: program will use 4 GPUs.
Loss Functions List: FocalCELoss with weight of 1; 
Hints: Optimal_Result = Yes = 1,  Optimal_Result = No = 0 


Epoch		TrLoss	TrainAccuracy	TsLoss	TestAccuracy
