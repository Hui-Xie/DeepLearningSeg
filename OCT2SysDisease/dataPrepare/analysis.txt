# Dec 14th, 2020
Experiment on Lnx-idea006.ecn.uiowa.edu:
Experiment: expOCT2SysD_20201211_J
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_J
Experiment: expOCT2SysD_20201211_E
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_E
Experiment: expOCT2SysD_20201211_H
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_H
Experiment: expOCT2SysD_20201211_F
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_F
Experiment: expOCT2SysD_20201211_I
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_I
Experiment: expOCT2SysD_20201211_G
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_G

Program in c-xwu000:
(base) [c-xwu000:network]#ps 23367 23346 23269 30671
  PID TTY      STAT   TIME COMMAND
23269 ?        Rl   2826:34 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_C.yaml
23346 ?        Rl   2823:30 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_B.yaml
23367 ?        Rl   2823:33 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_D.yaml
30671 ?        Rl   2110:31 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_J.yaml

program in c-iibi007:
ps 104438 104116 104226 104297 104369
   PID TTY      STAT   TIME COMMAND
104116 ?        Rl   2192:51 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_E_iibi007.yaml
104226 ?        Rl   2190:57 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_F_iibi007.yaml
104297 ?        Rl   2193:27 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_G_iibi007.yaml
104369 ?        Rl   2209:29 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_H_iibi007.yaml
104438 ?        Rl   2210:10 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_I_iibi007.yaml

Analysis:
Best network for 1Conv + 1FC layer:
    expOCT2SysD_20201212_E:  on lnx-idea005 _> iibi007
    channels:     [32]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0.8]  # 1 dropout layers.
    at epoch 57, validaLoss > trainingLoss.  but validation still decrease, with training loss: 0.6149, validation loss: 0.6223
    threshold 0.46, TPR 0.78, TNR 0.42, Acc 0.61.

Best network for 2Conv + 1Fc layer:
    expOCT2SysD_20201211_I: in lnx-idea006.ecn.uiowa.edu   (worth to research.)
    channels:     [32, 16]
    dropoutRates: [0.8,0.8]  # 2 dropout layers.
    at epoch 700, validaLoss = trainingLoss.  No explict overfitting, with training loss: 0.6261, validation loss: 0.6248
    threshold 0.47, TPR 0.84, TNR 0.35, Acc 0.62.

    expOCT2SysD_20201211_J: in lnx-idea006.ecn.uiowa.edu
    channels:     [16, 8]
    dropoutRates: [0.5,0.5]  # 2 dropout layers.
    at epoch 18, validaLoss > trainingLoss.  overfitting. But sum is 1.823, with training loss: 0.5909, validation loss: 0.6218
    threshold 0.44, TPR 0.67, TNR 0.55, Acc 0.61.

Further improvement, and reduce batchSize:
expOCT2SysD_20201211_K:
    channels:     [16, 8]
    dropoutRates: [0.8,0.8]  # 2 dropout layers.

expOCT2SysD_20201211_L:
    channels:     [48, 16]
    dropoutRates: [0.8,0.8]  # 2 dropout layers.

expOCT2SysD_20201212_K:  same with config expOCT2SysD_20201212_E
    channels:     [32]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0.8]  # 1 dropout layers.

expOCT2SysD_20201212_L:
    channels:     [24]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0.8]  # 1 dropout layers.

expOCT2SysD_20201212_M:  on c-iibi007
    channels:     [1]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0]  # 1 dropout layers =0 .



# Dec 12th, Saturday,2020
Now 3 training programs are running on lnx-idea006.ecn.uiowa.edu.
Current program:
Gradually reduce network complexity (8 layers, 4 layers, 2 layers), and did experiments to reduce overfitting of thickness2Hypertension
thickness2Hypertension network now uses 2 layer network.
got result:threshold 0.47, TPR 0.71, TNR 0.49, Accuracy 0.61 on validation data with 45.6% of 0s and 54.4% of 1s.
But network still get overfitting at 30 epochs.
use the contrast of validation and training loss, instead of accuracy, to judge the reflection point of over-fitting;
loss directly indicates the error with respect with ground truth, without other factors;
while accuracy needs another threshold to measure accuracy values, and different thresholds will lead different accuracy values.





(base) [lnx-idea006:network]#nvidia-smi
Sat Dec 12 12:31:55 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.45.01    Driver Version: 455.45.01    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     On   | 00000000:01:00.0 Off |                  Off |
| 34%   40C    P8    30W / 260W |     49MiB / 24215MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Quadro RTX 6000     On   | 00000000:4B:00.0 Off |                  Off |
| 34%   49C    P2   175W / 260W |  20969MiB / 24220MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1529      G   /usr/lib/xorg/Xorg                 38MiB |
|    0   N/A  N/A      1916      G   /usr/bin/gnome-shell                6MiB |
|    0   N/A  N/A     17007      C   python3                             0MiB |
|    0   N/A  N/A     17055      C   python3                             0MiB |
|    0   N/A  N/A     17090      C   python3                             0MiB |
|    1   N/A  N/A      1529      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A      1916      G   /usr/bin/gnome-shell                0MiB |
|    1   N/A  N/A     17007      C   python3                          6987MiB |
|    1   N/A  N/A     17055      C   python3                          6987MiB |
|    1   N/A  N/A     17090      C   python3                          6987MiB |
+-----------------------------------------------------------------------------+
(base) [lnx-idea006:network]#ps 17007 17055 17090
    PID TTY      STAT   TIME COMMAND
  17007 pts/0    Rl     2:22 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201211_E.yaml
  17055 pts/0    Rl     1:46 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201211_F.yaml
  17090 pts/0    Rl     1:24 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201211_G.yaml
(base) [lnx-idea006:network]#^C
(base) [lnx-idea006:network]#


#Dec 11th, Friday, 2020
lessons:
1  use the contrast of validation and training loss, instead of accuracy, to judge the reflection point of over-fitting;
   loss directly indicates the error with respect with ground truth, without other factors;
   while accuracy needs another threshold to measure accuracy values, and different thresholds will lead different accuracy values,
2  Training accuracy stuck at some point(e.g. 67%) means network that network stucks at a local minimum;

current best result: 20201210_D;




# Dec 10th, Thursday, 2020
Current the best result: expOCT2SysD_20201205_D:




# Dec 8th, 2020
"Overfitting is also caused by a deep model over training data. In that case, you'll observe divergence in loss between val and train very early."
--https://datascience.stackexchange.com/questions/43191/validation-loss-is-not-decreasing

# Dec 4th, Friday, 2020
The memory footprint of full loading all data into memory:
For Tongren data:
42*31*496*512*4 = 1.32 GB
For BES_3K thickness data:
2288*9*31*512*4 = 1.307 GB
1.307 GB x2   = 2.614 GB  for OD/OS eyes together.
Therefore all BES_3K all training and validation data can load into memory at dataset initialization.  --done

Observe the mean and std of thickness map:
(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsThicknessMap.py /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/33089_OS_7812_Volume_thickness_enface.npy
thicknessMap: C=9, H=31, W=512 for all below files:

/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/33089_OS_7812_Volume_thickness_enface.npy:
 mean= 30.530215236283237, std=15.603827787207281
/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/979_OD_8857_Volume_thickness_enface.npy:
 mean= 29.698770283127836, std=21.908612855917635
/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/1955_OS_14474_Volume_thickness_enface.npy:
 mean= 32.7970074596143, std=17.958001387144986
/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/1858_OD_13526_Volume_thickness_enface.npy:
 mean= 34.320023420447065, std=21.11553166304982

 Therefore, our Guassian noise to the thickness is N(0, 3) , which is about 20% of std of original thickness map.  --done;

 # delete ID for no xml file
 ID: 574,  from trianID

Todo:
1  all training data do a normalization and save its mean and std for validation and test data to use; --done
2  change gaussian noise std to 0.1 after the input data has normalization;   --done.

Experiment:
expOCT2SysD_20201204_A:  channels: [30, 30, 30, 60, 60, 60, 60, 60],
                         Result: Overfitting.
                         at epoch 100, training loss = 0.00164, and validation loss = 2.706
                         at stable status, validation acc = 54%
expOCT2SysD_20201204_B:  channels: [15, 15, 15, 30, 30, 30, 30, 30],
                         Result: Overfitting.
                         at epoch 100, training loss = 0.0117, and validation loss = 2.56
                         at stable status, validation acc = 53%

expOCT2SysD_20201205_A:  channels: [9, 9, 9, 15, 15, 15, 15, 15]
                         Result: Overfitting. Stop training at 40 epochs.

expOCT2SysD_20201205_B:  channels: [9, 9, 9, 9, 9, 9, 9, 9]
                         Result: Overfitting. at 300 epochs, traiing accruacy get 93% while validation get 50%;


expOCT2SysD_20201205_C: channels: [9, 8, 7, 6, 5, 4, 3, 3]
                        Result: overfitting.  at 300 epochs, traiing accruacy get 85% while validation get 55%;
                        at epoch 8. validation start exceed and deviate from training loss.



expOCT2SysD_20201205_D: channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 56%, and training accuracy is 58%.
                        at epoch 42, validation loss > training loss.
                        at threshold 0.45,  TPR 70%, TNR 0.47, Acc 60.0%


expOCT2SysD_20201205_E: channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # # 7 dropout layers.
                        validation accuray is 55%, and training accuracy is 58%.
                        at epoch 34, validation loss > training loss.
                        at threshold 0.4333,  TPR 74%, TNR 0.43, Acc 60.0%


expOCT2SysD_20201205_F: channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                        dropoutRates: [0.5,0.5,0.5,0.5, 0.5, 0.5, 0.0]  # # 7 dropout layers.
                        validation accuray is 45%, and training accuracy is 47%.
                        at epoch 159, validation loss > training loss.
                        at threshold 0.497,  TPR 1.0, TNR 0, Acc 54%

expOCT2SysD_20201205_G: channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                        dropoutRates: [0.5,0.4,0.3,0.3, 0.5, 0.25, 0.0]  # # 7 dropout layers.
                        validation accuray is 55%, and training accuracy is 58%.
                        at epoch 45, validation loss > training loss.
                        at threshold 0.485,  TPR 0.685, TNR 0.474, Acc 59.5%

# add network capacities, and validation data without augmentation.
expOCT2SysD_20201206_D: channels:     [90, 80, 70, 60, 50, 40, 30, 30]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 56%, and training accuracy is 69% at stable phase.
                        at epoch 5, validation loss > training loss.
                        at threshold 0.50,  TPR 53%, TNR 0.62, Acc 57.0%


expOCT2SysD_20201206_E: channels:     [60, 60, 60, 60, 60, 60, 60, 60]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 55%, and training accuracy is 67%.
                        at epoch 10, validation loss > training loss.
                        at threshold 0.4333,  TPR 66%, TNR 0.47, Acc 58.0%


expOCT2SysD_20201206_F: channels:     [60, 60, 60, 60, 60, 60, 60, 60]
                        dropoutRates: [0.5,0.5,0.5,0.5, 0.5, 0.5, 0.0]  # 7 dropout layers.
                        validation accuray is 58%, and training accuracy is 60%.
                        at epoch 9, validation loss > training loss.
                        at threshold 0.48  TPR 62%, TNR 55%, Acc 59%

expOCT2SysD_20201206_G: channels:     [90, 80, 70, 60, 50, 40, 30, 30]
                        dropoutRates: [0.5,0.4,0.3,0.3, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 57%, and training accuracy is 64%.
                        at epoch 10, validation loss > training loss.
                        at threshold 0.485,  TPR 0.56, TNR 0.59, Acc 58%

# cancel dropout at beginning of network layers.
expOCT2SysD_20201206_D:  channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                         dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                         validation accuray is 55%, and training accuracy is 76%.
                        at epoch 1, validation loss > training loss.
                        at threshold 0.31,  TPR 0.69, TNR 0.42, Acc 57%

expOCT2SysD_20201207_E:  channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                         dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                         validation accuray is 54%, and training accuracy is 71%.
                        at epoch 12, validation loss > training loss.
                        at threshold 0.31,  TPR 0.76, TNR 0.33, Acc 57%

expOCT2SysD_20201207_F:  channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                         dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.5, 0.0]  # 7 dropout layers.
                         validation accuray is 54%, and training accuracy is 74%.
                        at epoch 6, validation loss > training loss.
                        at threshold 0.39,  TPR 0.70, TNR 0.40, Acc 56%

expOCT2SysD_20201207_G: channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                        dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.0, 0.0]  # 7 dropout layers.
                        validation accuray is 54%, and training accuracy is 77%.
                        at epoch 5, validation loss > training loss.
                        at threshold 0.72,  TPR 0.33, TNR 0.77 Acc 53%

# Dec 10th, 2020: change 4 FC layers into a AvgPooling + 1 FC:
# as accuracy depends on threshold, using loss to judge reflection point is better
expOCT2SysD_20201210_A: channels:     [9, 8, 7, 6]
                        dropoutRates: [0.0,0.0,0.0,0.0]  # 4 dropout layers.
                        at stable stage: 100 epochs,  training acc: 77% continue increasing  , validation acc: 54%
                        at epoch 2, validation loss > training loss.
                        at threshold 0.44,  TPR 0.63, TNR 0.55 , Acc 0.55


expOCT2SysD_20201210_B: channels:     [64, 64, 64, 64]
                        dropoutRates: [0.0,0.0,0.0,0.0]  # 4 dropout layers.
                        at stable stage: training acc: 99% , validation acc: 52%
                        at epoch 3, validation loss > training loss.
                        at threshold 0.90,  TPR 0.38, TNR 0.69 , Acc 0.52


expOCT2SysD_20201210_C: channels:     [32, 32, 32, 32]
                        dropoutRates: [0.0,0.0,0.0,0.0]  # 4 dropout layers.
                        at stable stage: training acc: 99% , validation acc: 54%
                        at epoch 0, validation loss > training loss.
                        at threshold 0.55,  TPR 0.57, TNR 0.52 , Acc 0.55

expOCT2SysD_20201210_D: channels:     [64, 64, 64, 64]
                        dropoutRates: [0.0,0.5,0.5,0.5]  # 4 dropout layers.
                        at stable stage: training acc: 69% , validation acc: 55%
                        at epoch 3, validation loss > training loss.
                        at threshold 0.46,  TPR 0.69, TNR 0.47 , Acc 0.59

# use 2 conv layer network with(31,31) filters.
expOCT2SysD_20201211_A:
channels:     [128, 64]
dropoutRates: [0.5,0.5]  # 2 dropout layers.
stable at training 0.77, validation 0.56
at epoch 8, validaLoss > trainingLoss.
threshold 0.48,, TPR 0.73, TNR 0.46, Acc 0.61.

expOCT2SysD_20201211_B:
channels:     [256, 128]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 43, validaLoss > trainingLoss.  overfitting.
threshold 0.47,, TPR 0.67, TNR 0.52, Acc 0.61.

expOCT2SysD_20201211_C:
channels:     [128, 64]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 76, validaLoss > trainingLoss.  overfitting
threshold 0.46,, TPR 0.76, TNR 0.42, Acc 0.61.

expOCT2SysD_20201211_D:
channels:     [64, 64]
dropoutRates: [0.5,0.5]  # 2 dropout layers.
at epoch 13, validaLoss > trainingLoss.
threshold 0.45,, TPR 0.70, TNR 0.50, Acc 0.61.
=======================================================
expOCT2SysD_20201211_E: in lnx-idea006.ecn.uiowa.edu
channels:     [64, 64]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 39, validaLoss > trainingLoss.  overfitting
threshold 0.47, TPR 0.66, TNR 0.53, Acc 0.60.

expOCT2SysD_20201211_F: in lnx-idea006.ecn.uiowa.edu
channels:     [512, 256]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 33, validaLoss > trainingLoss.  overfitting
threshold 0.48, TPR 0.66, TNR 0.52, Acc 0.60.

expOCT2SysD_20201211_G: in lnx-idea006.ecn.uiowa.edu
channels:     [128, 128]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 45, validaLoss > trainingLoss.  overfitting. validation loss didn't increase.
threshold 0.50, TPR 0.64, TNR 0.55, Acc 0.60.

expOCT2SysD_20201211_H: in lnx-idea006.ecn.uiowa.edu  (worth to research.)
channels:     [64, 32]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 625, validaLoss =  trainingLoss.  No explict overfitting
threshold 0.46, TPR 0.79, TNR 0.40, Acc 0.61.

expOCT2SysD_20201211_I: in lnx-idea006.ecn.uiowa.edu   (worth to research.)
channels:     [32, 16]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 700, validaLoss = trainingLoss.  No explict overfitting
threshold 0.47, TPR 0.84, TNR 0.35, Acc 0.62.

expOCT2SysD_20201211_J: in lnx-idea006.ecn.uiowa.edu
channels:     [16, 8]
dropoutRates: [0.5,0.5]  # 2 dropout layers.
at epoch 18, validaLoss > trainingLoss.  overfitting. But sum is 1.823
threshold 0.44, TPR 0.67, TNR 0.55, Acc 0.61.


==============================================
# one layer network  on Dec 12th, 2020
expOCT2SysD_20201212_A:  on c-xwu000
channels:     [512]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 15, validationLoss > trainingLoss.


expOCT2SysD_20201212_B: on c-xwu000
channels:     [256]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 44, validationLoss > trainingLoss.  Validaiton loss increase after inflection point. explict overfitting.
threshold 0.46, TPR 0.7, TNR 0.49, Acc 0.61


expOCT2SysD_20201212_C:  on c-xwu000
channels:     [128]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 44, validationLoss > trainingLoss.
threshold 0.46, TPR 0.73, TNR 0.45, Acc 0.60


expOCT2SysD_20201212_D:  on c-xwu000
channels:     [64]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 54, validationLoss > trainingLoss. overfitting.
threshold 0.49, TPR 0.62, TNR 0.57, Acc 0.60

===========================================

expOCT2SysD_20201212_E:  on lnx-idea005 _> iibi007
channels:     [32]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 57, validaLoss > trainingLoss.  but validation still decrease. (Not bad)
threshold 0.46, TPR 0.78, TNR 0.42, Acc 0.61.

expOCT2SysD_20201212_F:  on lnx-idea005 _> iibi007
channels:     [32]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 13, validaLoss > trainingLoss.  explict overfitting, validation loss increases.
threshold 0.47, TPR 0.64, TNR 0.53, Acc 0.59.

expOCT2SysD_20201212_G:  on lnx-idea005 _> iibi007
channels:     [16]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 69, validaLoss > trainingLoss.   a liitle overfitting.
threshold 0.47, TPR 0.77, TNR 0.40, Acc 0.60.


expOCT2SysD_20201212_H:  on lnx-idea005 _> iibi007
channels:     [16]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 15, validaLoss > trainingLoss.  explicit overfitting.
threshold 0.47, TPR 0.72, TNR 0.47, Acc 0.60.

expOCT2SysD_20201212_I:  on lnx-idea005 _> iibi007
channels:     [8]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 22, validaLoss > trainingLoss.  explicit overfitting.
threshold 0.46, TPR 0.74, TNR 0.43, Acc 0.60.

expOCT2SysD_20201212_J:  on lnx-idea005  _> c-xwu000 with pid: 30671  (too small is also not good.)
channels:     [4]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 20, validaLoss > trainingLoss.  overfitting.
threshold 0.49, TPR 0.69, TNR 0.47, Acc 0.58.


# Dec 3th, Thursday, 2020
generated all thickness enface images with 3x3 smooth filter.
at /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap

statistics age:
python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv Age$ number None
total 1807 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 1807 records
min=50.0; mean=63.38295517432208; max=93.0

python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv Age$ number None
total 481 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 481 records
min=50.0; mean=64.17671517671518; max=88.0

python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv Age$ number None
total 502 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 502 records
min=50.0; mean=63.83864541832669; max=87.0

Age prediction:
Han Peng, Weikang Gong, Christian F. Beckmann, Andrea Vedaldi, Stephen M. Smith.
``Accurate brain age prediction with lightweight deep neural networks"
bioRxiv 2019.12.17.879346; doi: https://doi.org/10.1101/2019.12.17.879346
used KL divergence loss with a gaussian distribution of mu=age, and sigma=1.

Age range: 40-100.

Network design for age:
1  layer as channel, input 2D conv network;
2  basic layer design:
layer name,   ouputSize,    channels,
input         31x512        9
conv_3x3      16x256        30
conv_3x3      8x128         30
conv_3x3      4x64          30
conv_3x3      2x32          60
conv_2x3      1x16          60
conv_1x4      1x8           60
conv_1x4      1x4           60
conv_1x4      1x1           60
conv_1x1      1x1           60
softmax       1x1           60
3  use 2 losses:
   A  KL divergence loss with mu=age, sigma=1;
   B  soft argmax + MSE;

Professor Wu directed first to do hypertension prediction.

Network design for hypertension:
1  layer as channel, input 2D conv network;
2  basic layer design:
layer name,   ouputSize,    channels,
input         31x512        9
conv_3x3      16x256        30
conv_3x3      8x128         30
conv_3x3      4x64          30
conv_3x3      2x32          60
conv_2x3      1x16          60
conv_1x4      1x8           60
conv_1x4      1x4           60
conv_1x4      1x1           60
conv_1x1      1x1           60
FC             1
BCEWithLogitsLoss      1






# Dec 1st, 2020
read a paper:
Yim, J., Chopra, R., Spitz, T. et al.
Predicting conversion to wet age-related macular degeneration using deep learning.
Nat Med 26, 892–899 (2020). https://doi.org/10.1038/s41591-020-0867-7

This paper from DeepMind used 3D one-hot-code tissue segmentation maps and raw 3D OCT image to ensemble to predict
the exAMD conversion of the follow eye after the first eye diagnosed as exAMD. It first segments OCT into 13 tissues and 3 artifacts
including vitreous body, neural retina, RPE, and hyper-reflective foci etc, and then code this 3D segmentation into one-hot
segmentation map as 13 channels to feed a 3D-dense-analog classification network to predict exAMD. And raw 3D OCT also feed a 3D-dense-analog
classification network to predict exAMD. Its ensemble is interesting which includes each fold model of 4-fold cross validation,
and each fold has 4 different initial parameter model, and 2 path(raw 3D OCT and segmentation map), so total 4x3x2 models ensemble with TTA.

This is an excellent paper, but with huge hardware resource. It trained 300K epochs in 16 GPUs for just one model,
which is not achievable in common university labs.

Its one-hot-code tissue segmentation map and reduced-parameter dense block design can be our reference in the future.



# Nov 26th, 2020
some raw images has problems:
1  91002_OD_4330_Volume data has problem. but it is not at hour training,validation, test set;

# Nov 25th, Wednesday, 2020
Meeting minute of OCT2SysDisease on Nov 24th, 2020
Attendants: Prof. Wu, Prof. Wang, Hui
Time: 20:00-21:30(Iowa Time) Nov 24th, 2020
Minutes:
1  It is better to choose big/major diseases:first hypertension, then diabetes;
2  The core of this project is not at prediction self; it is at the backward retina manifestation or retina impairment of systemic diseases;
3  Thickness map is the most important input, which can consider to use an average of 3x3 grid to alleviate segmentation error;
   A  use thickness map to predict age;
   B  use thickness map to predict hypertension;
   C  use thickness map to predict the severity of hypertension (systolic blood level);
4  Further design for next phase:
   A  description of the surface curvature may act as an input;
   B  axial length can be an input to judge its relation with hypertension;
   C  use thickness map plus 3D layer texture as input;
   D  use the OCT volume 5 years before strokes occur to predict stroke;
   E  use retina layer while keeping its layer curvature without flatting;

Professor Wu's comment:
1  It is better to choose big/major diseases:first hypertension, then diabetes;
2  The core of this project is not at prediction self; it is at the backward retina manifestation or retina impairment of systemic diseases;
3  Thickness map is the most important input, which can consider to use an average of 3x3 grid to alleviate segmentation error;
   A  use thickness map to predict age;
It should not be a prediction problem, but study the thickness changes with respect to ages.
   B  use thickness map to predict hypertension;
then to identify the retina impairment by hypertension.
   C  use thickness map to predict the severity of hypertension (systolic blood level);
4  Further design for next phase:
   A  description of the surface curvature may act as an input;
According to Prof. Wang, may NOT consider surface curvatures.
   B  axial length can be an input to judge its relation with hypertension;
   C  use thickness map plus 3D layer texture as input;
Let's see the results from the first experiment first.
   D  use the OCT volume 5 years before strokes occur to predict stroke;
This is a totally different project.
   E  use retina layer while keeping its layer curvature without flatting;
Somehow it's same as C. Let's see the results from the first experiment first.







# Nov 24th, 2020
Statistics on Congnitive$:

Cognitive Tag on Dataset:
                #cases    min  mean     max
training:       1760      5    24.80    30
validaiton:     473       4    26.11    30
test:           490       6    26.46    30

python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv Cognitive$ number 99
total 1807 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv
values for Cognitive$ have 1760 records
min=5.0; mean=24.79659090909091; max=30.0
 emptyValueIDList =
['287', '828', '1527', '1696', '2311', '2596', '3502', '4170', '4188', '4192', '4231', '4239', '4266', '4287', '4290', '4387', '4388', '4417', '4528', '4550', '4627', '4683', '4696', '4714', '4717', '4756', '4794', '4795', '4816', '4819', '4961', '4981', '4995', '5033', '5034', '5175', '5529', '6985', '31066', '34162', '34164', '34165', '34166', '34167', '34169', '34173', '120032']

python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv Cognitive$ number 99
total 481 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv
values for Cognitive$ have 473 records
min=4.0; mean=26.11416490486258; max=30.0
 emptyValueIDList =
['4184', '4253', '4549', '4822', '4969', '5239', '34065', '34170']

python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv Cognitive$ number 99
total 502 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv
values for Cognitive$ have 490 records
min=6.0; mean=26.46734693877551; max=30.0
 emptyValueIDList =
['551', '1186', '4182', '4187', '4191', '4475', '4477', '4682', '4779', '4913', '5021', '5174']





==================================
Hypertension data: 1: 1915; 0: 1535
input: 62-OCT
output: {0,1}

age range: [50,91], total 42 ranges


plan data division:
    training,   validation,    test,    sum
0,    1075  ,        230,     230,    1535
1,    1341  ,        287,     287,    1915
sum,  2416  ,        517,     517,    3450

Real data division according to hypertension:
    training,   validation,    test,    sum
0,    1007  ,        264,     264,    1535
1,    1257  ,        329,     329,    1915
sum,  2264  ,        593,     593,    3450

perAgeRange choice:
0,                    5-6       5-6
1,                    6-7       6-7

==========================================================================
=============Check Volumes and Clinical ID correspondence================
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/testID.csv
total 593 IDs in /home/hxie1/data/BES_3K/GTs/testID.csv
total 3288 OD volumes in /home/hxie1/data/BES_3K/raw
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/563_OD_5953_Volume', '/home/hxie1/data/BES_3K/raw/563_OD_5957_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1426_OD_16481_Volume', '/home/hxie1/data/BES_3K/raw/1426_OD_16511_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6892_OD_22210_Volume', '/home/hxie1/data/BES_3K/raw/6892_OD_27754_Volume']
find 560 corresponding volumes with ID
NonExistIDList: ['294', '365', '526', '528', '651', '1303', '1988', '2242', '2449', '3622', '4087', '4092', '4149', '4943', '5874', '6002', '6304', '6973', '32085', '34030', '34132', '34176', '110016', '110162', '110177', '110186', '110187', '120074', '170079', '170088']
total 30 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/validationID.csv
total 593 IDs in /home/hxie1/data/BES_3K/GTs/validationID.csv
total 3288 OD volumes in /home/hxie1/data/BES_3K/raw
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/82_OD_2614_Volume', '/home/hxie1/data/BES_3K/raw/82_OD_2791_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/179_OD_4915_Volume', '/home/hxie1/data/BES_3K/raw/179_OD_4914_Volume', '/home/hxie1/data/BES_3K/raw/179_OD_4907_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1703_OD_16532_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16571_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16531_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16582_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5191_OD_29751_Volume', '/home/hxie1/data/BES_3K/raw/5191_OD_29755_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34127_OD_24960_Volume', '/home/hxie1/data/BES_3K/raw/34127_OD_26784_Volume']
find 548 corresponding volumes with ID
NonExistIDList: ['88', '92', '203', '284', '1264', '1962', '1989', '2845', '4009', '4016', '4030', '4070', '4079', '4125', '4498', '4783', '4801', '4856', '4937', '4938', '4949', '5146', '5470', '5542', '5745', '6278', '6966', '32153', '33085', '34133', '34168', '34632', '110015', '120037', '120051', '120087', '120174', '170065', '170075', '170222']
total 40 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/trainID.csv
total 2264 IDs in /home/hxie1/data/BES_3K/GTs/trainID.csv
total 3288 OD volumes in /home/hxie1/data/BES_3K/raw
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/123_OD_25375_Volume', '/home/hxie1/data/BES_3K/raw/123_OD_1936_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/378_OD_954_Volume', '/home/hxie1/data/BES_3K/raw/378_OD_958_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/600_OD_4409_Volume', '/home/hxie1/data/BES_3K/raw/600_OD_4480_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/773_OD_5087_Volume', '/home/hxie1/data/BES_3K/raw/773_OD_5100_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1064_OD_8896_Volume', '/home/hxie1/data/BES_3K/raw/1064_OD_8892_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1070_OD_25149_Volume', '/home/hxie1/data/BES_3K/raw/1070_OD_16613_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1296_OD_9602_Volume', '/home/hxie1/data/BES_3K/raw/1296_OD_24884_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1536_OD_11367_Volume', '/home/hxie1/data/BES_3K/raw/1536_OD_11364_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1690_OD_15989_Volume', '/home/hxie1/data/BES_3K/raw/1690_OD_15976_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1947_OD_14086_Volume', '/home/hxie1/data/BES_3K/raw/1947_OD_13585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/2293_OD_10524_Volume', '/home/hxie1/data/BES_3K/raw/2293_OD_10533_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4479_OD_31798_Volume', '/home/hxie1/data/BES_3K/raw/4479_OD_31794_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4973_OD_29833_Volume', '/home/hxie1/data/BES_3K/raw/4973_OD_29837_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5152_OD_25166_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25157_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25171_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25169_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25167_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25168_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5834_OD_16804_Volume', '/home/hxie1/data/BES_3K/raw/5834_OD_16797_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6049_OD_19216_Volume', '/home/hxie1/data/BES_3K/raw/6049_OD_20607_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6253_OD_20370_Volume', '/home/hxie1/data/BES_3K/raw/6253_OD_20367_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6963_OD_22638_Volume', '/home/hxie1/data/BES_3K/raw/6963_OD_22651_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32009_OD_9268_Volume', '/home/hxie1/data/BES_3K/raw/32009_OD_12398_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32132_OD_15813_Volume', '/home/hxie1/data/BES_3K/raw/32132_OD_15817_Volume', '/home/hxie1/data/BES_3K/raw/32132_OD_15812_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/33019_OD_7226_Volume', '/home/hxie1/data/BES_3K/raw/33019_OD_7229_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34174_OD_31686_Volume', '/home/hxie1/data/BES_3K/raw/34174_OD_31683_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34540_OD_27868_Volume', '/home/hxie1/data/BES_3K/raw/34540_OD_27872_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34623_OD_28790_Volume', '/home/hxie1/data/BES_3K/raw/34623_OD_28817_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/120090_OD_3733_Volume', '/home/hxie1/data/BES_3K/raw/120090_OD_8398_Volume']
find 2034 corresponding volumes with ID
NonExistIDList: ['60', '289', '290', '315', '328', '333', '341', '349', '357', '530', '576', '577', '592', '626', '671', '696', '719', '755', '756', '900', '910', '911', '969', '1088', '1213', '1217', '1340', '1342', '1353', '1354', '1461', '1476', '1482', '1513', '1532', '1587', '1616', '1642', '1647', '1675', '1676', '1719', '1720', '1724', '1763', '1794', '1802', '1870', '1940', '1968', '1969', '2011', '2014', '2035', '2036', '2045', '2057', '2061', '2092', '2100', '2101', '2106', '2107', '2112', '2120', '2121', '2122', '2123', '2128', '2150', '2157', '2200', '2207', '2243', '2261', '2392', '2411', '2422', '2426', '2428', '2450', '2455', '2466', '2573', '2574', '2594', '2671', '2681', '2698', '2743', '2753', '2775', '2864', '3603', '3604', '3606', '3609', '3621', '4014', '4039', '4049', '4078', '4082', '4083', '4114', '4117', '4145', '4152', '4174', '4221', '4241', '4262', '4296', '4318', '4372', '4413', '4523', '4811', '4857', '4892', '4895', '4916', '4941', '4942', '4945', '4948', '4994', '5024', '5047', '5110', '5200', '5213', '5546', '5728', '5830', '5835', '5897', '5984', '6093', '6300', '6649', '6679', '6782', '6843', '6869', '6982', '7019', '31026', '31034', '31038', '31143', '32056', '32059', '32102', '32106', '32115', '32123', '32131', '32133', '32148', '32151', '32152', '32154', '32160', '32161', '34045', '34136', '34553', '34613', '34626', '110002', '110009', '110010', '110018', '110062', '110074', '110115', '110128', '120004', '120007', '120008', '120015', '120041', '120059', '120104', '120112', '120116', '120146', '120153', '120155', '120161', '120180', '120198', '120225', '120245', '120253', '120258', '140014', '140015', '170069', '170083', '170084', '170097', '170098', '170117']
total 205 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#

================================Tidy on Oct 2nd 2020===============

About the correspondence between clinical data and OD volume images.

Summary:
1  From the BES clinical excel file, there are 3450 IDs with hypertension ground truth {0,1};
2  5 original IDs use ????.1 float ID, Other use integer ID; (as Notes for future)
3  In above 3450 IDs, there are 275 IDs without corresponding OD volume images;
4  In above 3450 IDs, there are 33 IDs with multiple different OD volume images;
5  I directly do not use 275+33= 308 IDs , which make total data set of 3142 IDs for training, validation and test;
6  In 3142 patients: training 2034; validation 548; test 560;

ID list without OD volume images:
['60', '289', '290', '315', '328', '333', '341', '349', '357', '530', '576', '577', '592', '626', '671', '696', '719',
'755', '756', '900', '910', '911', '969', '1088', '1213', '1217', '1340', '1342', '1353', '1354', '1461', '1476', '1482',
'1513', '1532', '1587', '1616', '1642', '1647', '1675', '1676', '1719', '1720', '1724', '1763', '1794', '1802', '1870',
'1940', '1968', '1969', '2011', '2014', '2035', '2036', '2045', '2057', '2061', '2092', '2100', '2101', '2106', '2107',
'2112', '2120', '2121', '2122', '2123', '2128', '2150', '2157', '2200', '2207', '2243', '2261', '2392', '2411', '2422',
'2426', '2428', '2450', '2455', '2466', '2573', '2574', '2594', '2671', '2681', '2698', '2743', '2753', '2775', '2864',
'3603', '3604', '3606', '3609', '3621', '4014', '4039', '4049', '4078', '4082', '4083', '4114', '4117', '4145', '4152',
'4174', '4221', '4241', '4262', '4296', '4318', '4372', '4413', '4523', '4811', '4857', '4892', '4895', '4916', '4941',
'4942', '4945', '4948', '4994', '5024', '5047', '5110', '5200', '5213', '5546', '5728', '5830', '5835', '5897', '5984',
'6093', '6300', '6649', '6679', '6782', '6843', '6869', '6982', '7019', '31026', '31034', '31038', '31143', '32056',
'32059', '32102', '32106', '32115', '32123', '32131', '32133', '32148', '32151', '32152', '32154', '32160', '32161',
'34045', '34136', '34553', '34613', '34626', '110002', '110009', '110010', '110018', '110062', '110074', '110115',
'110128', '120004', '120007', '120008', '120015', '120041', '120059', '120104', '120112', '120116', '120146', '120153',
'120155', '120161', '120180', '120198', '120225', '120245', '120253', '120258', '140014', '140015', '170069', '170083',
'170084', '170097', '170098', '170117', '88', '92', '203', '284', '1264', '1962', '1989', '2845', '4009', '4016', '4030',
 '4070', '4079', '4125', '4498', '4783', '4801', '4856', '4937', '4938', '4949', '5146', '5470', '5542', '5745', '6278',
 '6966', '32153', '33085', '34133', '34168', '34632', '110015', '120037', '120051', '120087', '120174', '170065', '170075',
 '170222', '294', '365', '526', '528', '651', '1303', '1988', '2242', '2449', '3622', '4087', '4092', '4149', '4943',
 '5874', '6002', '6304', '6973', '32085', '34030', '34132', '34176', '110016', '110162', '110177', '110186', '110187',
 '120074', '170079', '170088']

Same ID has mulitple different OD volume images:
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/123_OD_25375_Volume', '/home/hxie1/data/BES_3K/raw/123_OD_1936_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/378_OD_954_Volume', '/home/hxie1/data/BES_3K/raw/378_OD_958_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/600_OD_4409_Volume', '/home/hxie1/data/BES_3K/raw/600_OD_4480_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/773_OD_5087_Volume', '/home/hxie1/data/BES_3K/raw/773_OD_5100_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1064_OD_8896_Volume', '/home/hxie1/data/BES_3K/raw/1064_OD_8892_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1070_OD_25149_Volume', '/home/hxie1/data/BES_3K/raw/1070_OD_16613_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1296_OD_9602_Volume', '/home/hxie1/data/BES_3K/raw/1296_OD_24884_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1536_OD_11367_Volume', '/home/hxie1/data/BES_3K/raw/1536_OD_11364_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1690_OD_15989_Volume', '/home/hxie1/data/BES_3K/raw/1690_OD_15976_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1947_OD_14086_Volume', '/home/hxie1/data/BES_3K/raw/1947_OD_13585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/2293_OD_10524_Volume', '/home/hxie1/data/BES_3K/raw/2293_OD_10533_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4479_OD_31798_Volume', '/home/hxie1/data/BES_3K/raw/4479_OD_31794_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4973_OD_29833_Volume', '/home/hxie1/data/BES_3K/raw/4973_OD_29837_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5152_OD_25166_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25157_Volume',
                    '/home/hxie1/data/BES_3K/raw/5152_OD_25171_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25169_Volume',
                    '/home/hxie1/data/BES_3K/raw/5152_OD_25167_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25168_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5834_OD_16804_Volume', '/home/hxie1/data/BES_3K/raw/5834_OD_16797_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6049_OD_19216_Volume', '/home/hxie1/data/BES_3K/raw/6049_OD_20607_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6253_OD_20370_Volume', '/home/hxie1/data/BES_3K/raw/6253_OD_20367_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6963_OD_22638_Volume', '/home/hxie1/data/BES_3K/raw/6963_OD_22651_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32009_OD_9268_Volume', '/home/hxie1/data/BES_3K/raw/32009_OD_12398_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32132_OD_15813_Volume', '/home/hxie1/data/BES_3K/raw/32132_OD_15817_Volume',
                    '/home/hxie1/data/BES_3K/raw/32132_OD_15812_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/33019_OD_7226_Volume', '/home/hxie1/data/BES_3K/raw/33019_OD_7229_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34174_OD_31686_Volume', '/home/hxie1/data/BES_3K/raw/34174_OD_31683_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34540_OD_27868_Volume', '/home/hxie1/data/BES_3K/raw/34540_OD_27872_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34623_OD_28790_Volume', '/home/hxie1/data/BES_3K/raw/34623_OD_28817_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/120090_OD_3733_Volume', '/home/hxie1/data/BES_3K/raw/120090_OD_8398_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/82_OD_2614_Volume', '/home/hxie1/data/BES_3K/raw/82_OD_2791_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/179_OD_4915_Volume', '/home/hxie1/data/BES_3K/raw/179_OD_4914_Volume',
                    '/home/hxie1/data/BES_3K/raw/179_OD_4907_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1703_OD_16532_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16571_Volume',
                   '/home/hxie1/data/BES_3K/raw/1703_OD_16531_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16582_Volume',
                   '/home/hxie1/data/BES_3K/raw/1703_OD_16585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5191_OD_29751_Volume', '/home/hxie1/data/BES_3K/raw/5191_OD_29755_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34127_OD_24960_Volume', '/home/hxie1/data/BES_3K/raw/34127_OD_26784_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/563_OD_5953_Volume', '/home/hxie1/data/BES_3K/raw/563_OD_5957_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1426_OD_16481_Volume', '/home/hxie1/data/BES_3K/raw/1426_OD_16511_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6892_OD_22210_Volume', '/home/hxie1/data/BES_3K/raw/6892_OD_27754_Volume']

# ID name strange:
ID: 5320, and 5320.1; 6084 and 6084.1 are different patients

# original raw data contain .1 volume:
ls -ld *.*_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:29 2697.1_OD_7130_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 2697.1_OS_7136_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 4453.1_OD_23184_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:31 4453.1_OS_23187_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:30 4912.1_OD_30008_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:34 4912.1_OS_30012_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:25 5320.1_OD_26315_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 5320.1_OS_26320_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 6084.1_OD_17542_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:33 6084.1_OS_17546_Volume

As voluem image save in integer Id directory, all above *.1 ID change 9*1 ID, eg. 2697.1 -> 926971
modify:
1  modify clinincal data 5 rows in the BESClinicalGT_Analysis.xlsx
2  modify 10 volume names below: eg. 2697.1 -> 926971;
    /home/hxie1/data/BES_3K/raw/2697.1_OD_7130_Volume,
    /home/hxie1/data/BES_3K/raw/2697.1_OS_7136_Volume,
    /home/hxie1/data/BES_3K/raw/4453.1_OD_23184_Volume
    /home/hxie1/data/BES_3K/raw/4453.1_OS_23187_Volume
    /home/hxie1/data/BES_3K/raw/4912.1_OD_30008_Volume
    /home/hxie1/data/BES_3K/raw/4912.1_OS_30012_Volume
    /home/hxie1/data/BES_3K/raw/5320.1_OD_26315_Volume
    /home/hxie1/data/BES_3K/raw/5320.1_OS_26320_Volume
    /home/hxie1/data/BES_3K/raw/6084.1_OD_17542_Volume
    /home/hxie1/data/BES_3K/raw/6084.1_OS_17546_Volume


below volumes are original *.1*_Volume:
[c-xwu000:raw]#ls -ld 9????1_*_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:29 926971_OD_7130_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 926971_OS_7136_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 944531_OD_23184_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:31 944531_OS_23187_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:30 949121_OD_30008_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:34 949121_OS_30012_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:25 953201_OD_26315_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 953201_OS_26320_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 960841_OD_17542_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:33 960841_OS_17546_Volume

Oct 2nd, 2020
Data division and basic statistics before coding:
below bracket() indicates patients number.

                    Training(2034)         Validation(548)     Test(560)
value               0,       1 ,          0,        1,       0,      1
hypertension:       44.4%  55.6%         44.9%     55.1%    44.3%   55.7%

                    1,       2 ,          1,        2,       1,       2
gender:             42.8%,  57.2%,       45.6%    54.4%,    45.4%,  54.6%


                      Training(2034)         Validation(548)            Test(560)
value               min,   avg,    max,      min,  avg,   max,         min, avg, max
age                 50,    64.0,   93,       50,   60.6,  88,          50,  64.5, 87


                       Training(1853)           Validation(547)              Test(560)
value               min,   avg,    max,      min,   avg,   max,         min,   avg,   max
AxialLength         18.96, 23.22, 30.88      19.39, 23.25, 30.69        21.09, 23.25, 26.76


                       Training(2033)           Validation(548)              Test(560)
value               min,   avg,    max,      min,   avg,   max,         min,   avg,   max
BP_Systolic:        78 ,   129 ,   217       74,    130,   216          70,    130,   205


                       Training(2034)           Validation(548)              Test(560)
value               min,   avg,    max,      min,   avg,   max,         min,   avg,   max
BP_Diastolic:       31,    69 ,    117       36,    69,    118          38,    70,   113


# Oct 3rd, 2020:
# check all volumes has 31 slices from the *_DelNonexist.csv list
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
total 2034 IDs in /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
total 3252 OD volumes in /home/hxie1/data/BES_3K/W512NumpyVolumes
find 2031 corresponding volumes with ID
NonExistIDList: ['574', '2750', '120035']
total 3 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
total 548 IDs in /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
total 3252 OD volumes in /home/hxie1/data/BES_3K/W512NumpyVolumes
find 546 corresponding volumes with ID
NonExistIDList: ['358', '1207']
total 2 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
total 560 IDs in /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
total 3252 OD volumes in /home/hxie1/data/BES_3K/W512NumpyVolumes
find 559 corresponding volumes with ID
NonExistIDList: ['367']
total 1 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/testID_delNonExist_final.csv

Final dataset division in the *_final.csv
train: 2031; validation: 546;  Test: 559;

# Oct 5th, 2020
(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final.csv hypertension_bp_plus_history$ binary
total 2031 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final.csv
values for hypertension_bp_plus_history$ have 2031 records
0 rate: 0.4441161989167898; 1 rate: 0.5558838010832102

total 546 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final.csv
values for hypertension_bp_plus_history$ have 546 records
0 rate: 0.45054945054945056; 1 rate: 0.5494505494505495

(base) [c-xwu000:dataPrepare]#python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_final.csv hypertension_bp_plus_history$ binary
total 559 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_final.csv
values for hypertension_bp_plus_history$ have 559 records
0 rate: 0.44364937388193204; 1 rate: 0.556350626118068



# Oct 6th, 2020
tail a small dataset for pretrain
train: 200, validation: 50
which are extracted from the first 200, and first 50 from the final dataset.
(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final_small.csv hypertension_bp_plus_history$ binary
total 200 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final_small.csv
values for hypertension_bp_plus_history$ have 200 records
0 rate: 0.36; 1 rate: 0.64

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final_small.csv hypertension_bp_plus_history$ binary
total 50 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final_small.csv
values for hypertension_bp_plus_history$ have 50 records
0 rate: 0.28; 1 rate: 0.72

# Oct 8th, 2020
delNonExist_final data:
training: 2031;  0: 44.4%;  1: 55.6%;
validation: 546; 0: 45.1%;  1: 54.9%;
test:     559;   0: 44.4%;  1: 55.6%;

A brief:
1 It needs 40 mins training for one epoch with an input of 31 slices per patients; It is unrealistic for training;
2 data set:
  training: 2031;  0: 44.4%;  1: 55.6%;
  validation: 546; 0: 45.1%;  1: 54.9%;
   test:     559;   0: 44.4%;  1: 55.6%;
3 Now I changed input as one middle slice of 31 slices of OD eye,
  it need one minute per epoch for VGG network; and 0.5 min per peoch for mobileNetV3;
4 Using mobileNet V3, it can get training accuracy 100% in about 400 epochs; but validation accuracy get stuck at 60%;
5 It shows nework at training, but overfiting, which is difefrent from Ovarian cancer project;
6 In future 2 days, I will spent time to reduce its overfitting;

If you are available, you may tell me your time when I can show some training result to you.

# Oct 8th, 2020
Experiment Analysis: for center slice as Input=====================================================================================
            Network                 Pooling     InputActivation LR     dropout  weightDecay    FC            OutputC     trainAccGet70%  trainAccGet100%  validation
20201008_A: Conv2DFeatureNet        Avg         True            0.1    0.5      None        [512, 256, 1]   1024        96              166             57% first big oscillaltion, plane
20201008_B: MobileNetV3_OCT2SysD    Avg         True            0.001  0.5      None        [512, 256, 1]   1024        272             418             56% small oscillation
20201008_C: MobileNetV3_OCT2SysD    Avg         False           0.01   0.5      1e-5        [512, 256, 1]   1024        29              160             57% later stable
20201008_D: Conv2DFeatureNet        Avg         False           0.1    0.5      None        [512, 256, 1]   1024        107             176             56% oscillation
20201008_G: MobileNetV3_OCT2SysD    Avg         False           0.01   0.5*2    1e-4        [512, 256, 1]   1024        29              121             55% oscillation ;  this is improved version of _C.
20201008_H: MobileNetV3_OCT2SysD    Avg         False           0.01   0.8      1e-3        [512,1]         1024        18              101             56% later stable;
20201009_A: moibleNetv3_small       Avg         False           0.01   0.5      1e-2        [64,1]          128         8               40              55% oscillation;
20201009_B: mobileNetv3_small       Max         False           0.01   0.8      1e-1        [64,1]          128         INF             INF             55%, (looks underfitting)
20201009_C: mobileNetv3_small       Max         False           0.01   0.5      1e-2        [64,1]          128         18              134             52%
*20201009_D: mobileNetv3_small       Max         False           0.01   0.8      1e-2        [64,1]          128         27              130             57.69% (Good basis)
20201009_E: mobileNetv3_small       Max         False           0.01   0.5      1e-1        [64,1]          128         INF             INF             55%, majority
20201009_F: mobileNetv3_small       Avg         False           0.01   0.5      1e-1        [64,1]          128         17              INF             55%, majority
20201009_G: mobileNetv3_small       Max         False           0.01   0.2      1e-1        [64,1]          128         INF             INF             55%, majority
20201009_H: mobileNetv3_small       Avg         False           0.01   0.8      1e-2        [64,1]          128         10              64              58%
20201009_I: mobileNetv3_small       IQR         False           0.01   0.8      1e-2        [64,1]          128         37              105             58%
20201009_J: mobileNetv3_small       Max         False           0.01   0.8      1e-2        [48,1]          96          29              127             53%
20201009_K: mobileNetv3_small       Avg         False           0.01   0.8      1e-2        [48,1]          96          11              70              57%
20201009_L: mobileNetv3_small       Avg         False           0.01   0.8      1e-2        [24,1]          48          9               135             56%
20201009_M: mobileNetv3_small       Max         False           0.01   0.8      1e-2        [24,1]          48          44              600             56%
20201009_N: mobileNetv3_small       Max         False           0.01   0.2      1e-2        [12,1]          24          26              153             54%
20201009_O: mobileNetv3_small       Avg         False           0.01   0.2      1e-2        [12,1]          24          8               74              57%
20201009_P: mobileNetv3_small       Max         False           0.01   0.2      1e-2        [1]             48          18              100             57%
20201009_Q: mobileNetv3_small       Max         False           0.01   0.2      1e-2        [1]             24          22              182             58% (Good result)
20201009_R: mobileNetv3_small       Avg         False           0.01   0.2      1e-2        [1]             12          5               70%             57%

Comparison:    OCT2SysD                OvarianCancer
data Size:      3136                    168
predict:        judge current status;   Predict future;
Image model:    Similar;                Various, Each patient cancer is unique;
Classification: Binary;                 Binary;
Network:        MobileNetV3;            MobileNetV3;


# Oct 10th, 2020
Use randoom single slice as input to network:

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv hypertension_bp_plus_history$  binary
total 2034 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
values for hypertension_bp_plus_history$ have 2034 records
0 rate: 0.443952802359882; 1 rate: 0.556047197640118

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv hypertension_bp_plus_history$  binary
total 548 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
values for hypertension_bp_plus_history$ have 548 records
0 rate: 0.4489051094890511; 1 rate: 0.551094890510949

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv hypertension_bp_plus_history$  binary
total 560 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
values for hypertension_bp_plus_history$ have 560 records
0 rate: 0.44285714285714284; 1 rate: 0.5571428571428572

delNonExist data:
training: 2034;  0: 44.4%;  1: 55.6%;
validation: 548; 0: 44.9%;  1: 55.1%;
test:     560;   0: 44.3%;  1: 55.7%;

delete W=384 image ID:
(base) [c-xwu000:dataPrepare]#python3.7 ./deleteNonStdID.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
deleted 1 IDs in /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#python3.7 ./deleteNonStdID.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
No ID deleted.
(base) [c-xwu000:dataPrepare]#python3.7 ./deleteNonStdID.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
deleted 1 IDs in /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#

20201010, statistics data distribution, with deleting error width ID
training: 2033;  0: 44.4%;  1: 55.6%;
validation: 548; 0: 44.9%;  1: 55.1%;
test:     559;   0: 44.4%;  1: 55.6%;

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv hypertension_bp_plus_history$ binary
total 2033 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv
values for hypertension_bp_plus_history$ have 2033 records
0 rate: 0.4441711756025578; 1 rate: 0.5558288243974422

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv hypertension_bp_plus_history$ binary
total 548 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv
values for hypertension_bp_plus_history$ have 548 records
0 rate: 0.4489051094890511; 1 rate: 0.551094890510949

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv hypertension_bp_plus_history$ binary
total 559 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv
values for hypertension_bp_plus_history$ have 559 records
0 rate: 0.44364937388193204; 1 rate: 0.556350626118068

=================Use Random Slice as input to Network on Oct 10th, 2020================================================================================================
            Network                 Pooling     InputActivation LR     LRPatience   dropout  weighDecay    FC            OutputC     trainAccGet60%  trainAccGet70%     trainAccGet100%    validation
20201010_A: mobileNetv3_small       Avg         False           0.01   3             0.2     1e-2          [1]           12          150                                                   max60%
20201010_B: mobileNetv3_small       Avg         False           0.01   3             0.8     1e-2          [64,1]        128         161                                                   max60%
20201010_C: mobileNetv3_small       Avg         False           0.01   30            0.2     1e-2          [1]           12          75               1.8K                                 max61.5%
20201010_D: mobileNetv3_small       Avg         False           0.01   30            0.8     1e-2          [64,1]        128         100                                                   max62%

Oct 13th, 2020 13:29
Current running program:
(base) [c-xwu000:network]#ps 941 938 615 642
GPU   PID TTY      STAT   TIME COMMAND
2     615 ?        Rl   9161:56 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201012_A.yaml
3     642 ?        Rl   8672:33 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201012_B.yaml
1     938 ?        Rl   29848:39 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201010_C.yaml
0     941 ?        Rl   29842:02 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201010_D.yaml

=================Use Random Slice as input to Network on Oct 10th, 2020, with batch size 107 ========================================================================
            Network                 Pooling     InputActivation LR     LRPatience LrDecayFactor  dropout  weighDecay    FC            OutputC     trainAccGet60%  trainAccGet80%     trainAccGet100%    validation
20201012_A: mobileNetv3_small       Avg         False           0.1    62         0.826          0.8     1e-2          [512,256,1]    1024        50                                                   max60%
20201012_B: mobileNetv3_small       Avg         False           0.1    62         0.826          0.8     1e-2          [256,128,1]    512         36                                                   max61.68%
20201015_A: mobile_small(pretrain)  Avg         False           0.1    5          0.8            0.5     1e-3          [256,128,1]    512         Inf oscillation at 55%
20201015_B: mobileNetv2_small       Avg         False           0.1    5          0.8            0.5     1e-3          [256,128,1]    512         28              INf                                  58%(max60%)
20201015_C: mobileNetv2_small       Avg         False           0.1    4          0.8            0.2     1e-4          [256,128,1]    512         Inf             INf                                  55%
20201016_A: large                   Avg         False           0.1    5          0.8            0.2     1e-4          [512,256,1]    1024        ===Stop===
20201016_B: large (NoGauss)         Avg         False           0.1    5          0.8            0.3     1e-5          [512,256,1]    1024        40                                                   60%
            Above: when validation ACC gets 60%, its TPR 61.5%, TNR 58.5%, threshold 0.5027

# below expeiment add gaussian and salt pepper noise:
            Network            Notes     Pooling     InputActivation LR     LRPatience LrDecayFactor  dropout  weighDecay    FC            OutputC     trainingAcc  validation
20201017_A: Large                        Avg         False           0.1    6          0.8            0       1e-5          [512,256,1]    1024        63%          ACC61%,TNR45%; TPR75%; Threshold0.44;
20201017_B: Large(No flip aug)           Avg         False           0.1    6          0.8            0       1e-5          [512,256,1]    1024        64%          ACC61%,TNR48%; TPR72%; Threshold0.48;
20201017_C: large                        Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024        63.8%        ACC62%,TNR49%; TPR73%; Threshold0.44; (best)
            batchsize=40
20201017_D: Large                        Avg         False           0.1    6          0.8            0.5     1e-5          [512,256,1]    1024        63%          ACC61%,TNR51%; TPR69%; Threshold0.45;
20201019_A: Conv2DFeatureNet             Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024
            batchsize =20
20201019_B: Conv2DFeatureNet  ValidAug   Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024
            bathsize =20

# Oct 17th, 2020:
for 20201016_B: 4min /epoch

# Oct 20th, 2020:
exclude some patients with disease like below:
1. High myopia (Axiallength_26_ormore_exclude$ =1)
2. Glaucoma (Glaucoma_exclude$ =1)
3. Macula or retinal diseases (Retina_exclude$=1)

tag: excludeMGM (Myopia, Glaucoma, Macula disease)
(base) [c-xwu000:dataPrepare]#python3.7 ./excludeMyopiaGlaucomaMaculaD4.py  /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv
deleted 57 IDs in /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv
(base) [c-xwu000:dataPrepare]#python3.7 ./excludeMyopiaGlaucomaMaculaD4.py  /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv
deleted 67 IDs in /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv
(base) [c-xwu000:dataPrepare]#python3.7 ./excludeMyopiaGlaucomaMaculaD4.py  /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv
deleted 226 IDs in /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv
(base) [c-xwu000:dataPrepare]#

After deleting MGM,  statistic hypertension:

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv  hypertension_bp_plus_history$ binary
total 1807 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv
values for hypertension_bp_plus_history$ have 1807 records
0 rate: 0.4565578306585501; 1 rate: 0.54344216934145

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv  hypertension_bp_plus_history$ binary
total 481 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv
values for hypertension_bp_plus_history$ have 481 records
0 rate: 0.45322245322245325; 1 rate: 0.5467775467775468

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv  hypertension_bp_plus_history$ binary
total 502 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv
values for hypertension_bp_plus_history$ have 502 records
0 rate: 0.4342629482071713; 1 rate: 0.5657370517928287

after delete MGM cases: high myopia, Glaucoma, Macula/Retina disease cases:

    dataset		&number &tag0  	&tag1 \\
	training	&1807  	&45.66\% &54.34\%  \\
	validation	&481  	&45.32\% &54.68\%  \\
	test		&502  	&43.43\% &56.57\%  \\

total: 2790 cases.


            Network            Notes     Pooling     InputActivation LR     LRPatience LrDecayFactor  dropout  weighDecay    FC            OutputC     trainingAcc  validation
20201020_A: large                        Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024         61%(max)    ACC61%,TNR53%; TPR68%; Threshold0.48;
            batchSize=40
            Validation Augment
            GPU=3

20201020_B: Conv2DFeatureNet             Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024        51%          55%(stop)
            bathsize =20
            Validation Augment
            GPU=2
20201020_C: large                        Avg         False           0.5    6          0.8            0.2     1e-5          [512,256,1]    1024        64%(max)     ACC61%,TNR51%; TPR69%; Threshold0.48;
            batchSize=40
            Validation Augment
            GPU=3

20201020_D: Conv2DFeatureNet             Avg         False           0.5    6          0.8            0.2     1e-5          [512,256,1]    1024        61%          57%(stop)
            bathsize =20
            Validation Augment
            GPU=2

20201021_A: large                        Avg         False           1      6          0.8            0.2     1e-5          [512,256,1]    1024       65%(max)      ACC63%,TNR56%; TPR68%; Threshold0.49; (best)
            batchSize=40
            Validation Augment
            GPU=0
            LR=1

20201022_A: large                        Avg         False           2      6           0.8            0.2     1e-5          [512,256,1]    1024      64%(max)      ACC61%,TNR59%; TPR63%; Threshold0.50;
            batchSize=40
            Validation Augment
            GPU=1
            LR=2
            LrSchedular uses sum.

20201022_B: large                        Avg         False           1      6           0.8            0.2     1e-5          [512,256,1]    1024      65(max)       ACC62%,TNR50%; TPR71%; Threshold0.50;             batchSize=40
            Validation Augment
            GPU=2
            LR=1
            LrSchedular uses sum.