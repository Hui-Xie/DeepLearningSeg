


# Jan 4th, Monday, 2021:
Professor:
1  Maybe adding gender is also an option. Do you know which layers can be used to distinguish genders?
2   For the texture features, again you need to select some radiomic features.

My answer:
For gender prediction, the (0 th , 5 th, 6 th, 7 th) thickness layer and the (1 th , 2 th ) texture enface maps have statistical significance difference crossing training, validation and test data.
There are some methods to use gender information:
1   use gender as input;
2   use gender as one of predection head to help better extract features;
3   use gender as pretraining network to get a better initialization network for further hypertension prediction;

===============================================
(base) [c-xwu000:dataAnalysis]#python3 ./analyzeHyt_pixel.py ./testConfig/expOCT_thicknessAnalyzeHyt_pixel_20210104_9x15x12.yaml
Experiment: expOCT_thicknessAnalyzeHyt_pixel_20210104_9x15x12
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x15x12
mask shape: (9, 15, 12)
total statistical significance pixel number: 137
at channel 0, statistical significance pixel number: 0
at channel 1, statistical significance pixel number: 0
at channel 2, statistical significance pixel number: 0
at channel 3, statistical significance pixel number: 0
at channel 4, statistical significance pixel number: 6
at channel 5, statistical significance pixel number: 91
at channel 6, statistical significance pixel number: 0
at channel 7, statistical significance pixel number: 27
at channel 8, statistical significance pixel number: 13
================ End of anlayzing thickness in each pixel ===============
(base) [c-xwu000:dataAnalysis]#python3 ./analyzeHyt_pixel.py ./testConfig/expOCT_thicknessAnalyzeHyt_pixel_20210104_9x31x25.yaml
Experiment: expOCT_thicknessAnalyzeHyt_pixel_20210104_9x31x25
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x31x25
mask shape: (9, 31, 25)
total statistical significance pixel number: 496
at channel 0, statistical significance pixel number: 0
at channel 1, statistical significance pixel number: 0
at channel 2, statistical significance pixel number: 1
at channel 3, statistical significance pixel number: 2
at channel 4, statistical significance pixel number: 11
at channel 5, statistical significance pixel number: 331
at channel 6, statistical significance pixel number: 0
at channel 7, statistical significance pixel number: 108
at channel 8, statistical significance pixel number: 43
================ End of anlayzing thickness in each pixel ===============
(base) [c-xwu000:dataAnalysis]#python3 ./analyzeHyt_pixel.py ./testConfig/expOCT_textureAnalyzeHyt_pixel_20210104_9x31x25.yaml
Experiment: expOCT_textureAnalyzeHyt_pixel_20210104_9x31x25
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x31x25
mask shape: (9, 31, 25)
total statistical significance pixel number: 114
at channel 0, statistical significance pixel number: 1
at channel 1, statistical significance pixel number: 0
at channel 2, statistical significance pixel number: 0
at channel 3, statistical significance pixel number: 1
at channel 4, statistical significance pixel number: 0
at channel 5, statistical significance pixel number: 0
at channel 6, statistical significance pixel number: 89
at channel 7, statistical significance pixel number: 22
at channel 8, statistical significance pixel number: 1
================ End of anlayzing thickness in each pixel ===============
(base) [c-xwu000:dataAnalysis]#python3 ./analyzeHyt_pixel.py ./testConfig/expOCT_textureAnalyzeHyt_pixel_20210104_9x15x12.yaml
Experiment: expOCT_textureAnalyzeHyt_pixel_20210104_9x15x12
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x15x12
mask shape: (9, 15, 12)
total statistical significance pixel number: 32
at channel 0, statistical significance pixel number: 0
at channel 1, statistical significance pixel number: 0
at channel 2, statistical significance pixel number: 0
at channel 3, statistical significance pixel number: 0
at channel 4, statistical significance pixel number: 0
at channel 5, statistical significance pixel number: 0
at channel 6, statistical significance pixel number: 26
at channel 7, statistical significance pixel number: 6
at channel 8, statistical significance pixel number: 0
================ End of anlayzing thickness in each pixel ===============

Further idea:
1  sum the thickness of 5th, 6th 7th, 8th layer to analyze its pixel-level p value;
2  sum the texture of 6th,7th layer to analyze its pixel-level p value;



# Jan 2nd, Saturday, 2020
conclusion:
1 if fixe learning rate, it is better at 0.001;
2 with learning decay, start at 0.01;
3 weight decay change to 1.0e-6, reducing from 1.0e-5.

after experiment:
1 initial learning rate: 0.005;
2 expOCT_thickTexture2HyT_20210102_ResNet_D_15x12 looks good;
3 channels:     [128, 160, 192, 224] , without dropout.


expOCT_thickTexture2HyT_20210102_ResNet_A_15x12:
     learning Rate:1.0e-2
     channels:     [96, 128, 160, 192] # the final channel is for FC layer
     dropoutRate: 0  # the dropout rate at final fully connected layer.
     at stable, trianing acc vs validation acc: 64% vs 57%
     SUM =  1.855 at epoch 1.628K
     TPR TNR ACC Threshold:

expOCT_thickTexture2HyT_20210102_ResNet_B_15x12:
     learning Rate: 5.0e-3
     channels:     [96, 128, 160, 192] # the final channel is for FC layer
     dropoutRate: 0  # the dropout rate at final fully connected layer.

     when stable, training acc stuck at  59% vs 58%.  both training and validation loss are oscillating.
     Sum=  1.853  at epoch 531.
     TPR:  TNR:   ACC:  Threshold
     at about 2min per epoch.

expOCT_thickTexture2HyT_20210102_ResNet_C_15x12:
     learning Rate: 1.0e-2
     channels:     [128, 160, 192, 224] # the final channel is for FC layer
     dropoutRate: 0  # the dropout rate at final fully connected layer.

     when stable, training acc stuck at  64% vs 56%
     Sum=  1.85  at epoch 1.285K
     TPR:  TNR:   ACC:  Threshold
     at about 2min per epoch.


expOCT_thickTexture2HyT_20210102_ResNet_D_15x12:   Good. Not the best.
     learning Rate: 5.0e-3
     channels:     [128, 160, 192, 224] # the final channel is for FC layer
     dropoutRate: 0  # the dropout rate at final fully connected layer.
     when stable, training acc stuck at  60% vs 55%
     Sum= 1.86  at epoch 1.057K
     TPR:0.75   TNR: 0.48   ACC:0.63  Threshold 0.47
     at about 2min per epoch.

expOCT_thickTexture2HyT_20210102_ResNet_E_15x12:
     learning Rate: 1.0e-2
     channels:     [128, 160, 192, 224] # the final channel is for FC layer
     dropoutRate: 0.2  # the dropout rate at final fully connected layer.
     when stable, training acc stuck at  64% vs 58%
     Sum= 1.834  at epoch 1.064K
     TPR:  TNR:   ACC:  Threshold
     at about 2min per epoch.


expOCT_thickTexture2HyT_20210102_ResNet_F_15x12:
     learning Rate: 1.0e-2
     channels:     [128, 160, 192, 224] # the final channel is for FC layer
     dropoutRate: 0.5  # the dropout rate at final fully connected layer.
     when stable, training acc stuck at 61% vs 56%
     Sum= 1.838 at epoch 1.807
     TPR:  TNR:   ACC:  Threshold
     at about 2min per epoch.


=================
Some experiment result:
expOCT_thickTexture2HyT_20210101_ResNet_A_15x12:
    channels:     [98, 98, 98, 98] # the final channel is for FC layer
    dropoutRate: 0  # the dropout rate at final fully connected layer.
    with channel:  initial learning rate 0.1
    when stable, training acc stuck at  74% vs 56%
    Sum=  1.823 at epoch 719.  initial learning rate is too big.
    TPR:  TNR:   ACC:  Threshold
    at about 2min per epoch.

expOCT_thickTexture2HyT_20210101_ResNet_B_15x12:
    channels:     [98, 98, 98, 98] # the final channel is for FC layer
    dropoutRate: 0.2  # the dropout rate at final fully connected layer.
    with channel:  initial learning rate 0.1
    when stable, training acc stuck at  74% vs 57%
    Sum=  1.818 at epoch 654.
    TPR:  TNR:   ACC:  Threshold
    at about 2min per epoch.

expOCT_thickTexture2HyT_20210101_ResNet_C_15x12:
    channels:     [96, 128, 160, 192] # the final channel is for FC layer
    dropoutRate: 0.2  # the dropout rate at final fully connected layer.
    with channel:  initial learning rate 0.1
    when stable, training acc stuck at  75% vs 56%
    Sum=  1.849 at epoch 22.
    TPR:  TNR:   ACC:  Threshold
    at about 2min per epoch.

expOCT_thickTexture2HyT_20210101_ResNet_D_15x12: (it is good, not the best)
    channels:     [96, 128, 160, 192] # the final channel is for FC layer
    dropoutRate: 0  # the dropout rate at final fully connected layer.
    with channel:  initial learning rate 0.1
    when stable, training acc stuck at  75% vs 54%
    Sum=  1.855 at epoch 38.
    TPR: 0.69 TNR: 0.53  ACC: 0.63  Threshold 0.425
    at about 2min per epoch.

expOCT_thickTexture2HyT_20210101_ResNet_E_15x12:
    channels:     [96, 128, 160, 192] # the final channel is for FC layer
    dropoutRate: 0.5  # the dropout rate at final fully connected layer.
    with channel:  initial learning rate 0.1
    when stable, training acc stuck at  75% vs 53%
    Sum=  1.816 at epoch 22.
    TPR:  TNR:   ACC:  Threshold
    at about 2min per epoch.




# Dec 31th, Thursday, 2020:

expOCT_thickTexture2HyT_20201231_ResNet_A_15x12:
       with channel: 18
       when stable, training acc stuck at 0.62
       Sum=1.839
       TPR:0.60,  TNR: 0.63  ACC: 0.61


expOCT_thickTexture2HyT_20201231_ResNet_B_15x12:
       with channel: 36
       when stable, training acc stuck at 0.68
       Sum=1.879 at epoch 124.
       TPR:0.69  TNR:0.56  ACC: 0.63

expOCT_thickTexture2HyT_20201231_ResNet_C_15x12:
       with channel: 9
       when stable, training acc stuck at 0.58
       Sum=1.857
       TPR:0.65  TNR:0.59  ACC: 0.62

expOCT_thickTexture2HyT_20201231_ResNet_D_15x12:  still in program, ID=9193
       with channel: 9  using fixed 1.0e-4 learning rate.
       when stable, training acc stuck at
       Sum= 1.768 at epoch 2.04K
       TPR:  TNR:  ACC:

expOCT_thickTexture2HyT_20201231_ResNet_E_15x12:
       with channel: 64 initial learning rate 0.01
       when stable, training acc stuck at
       Sum=  1.826 at epoch 298.
       TPR:  TNR:  ACC:

expOCT_thickTexture2HyT_20201231_ResNet_F_15x12:  (the best)  it looks no overfitting. reduce dropout rate is good.
       with channel: [98,98,98,98] initial learning rate 0.01, dropout 0.5
       when stable, training acc stuck at 60%.
       Sum= 1.881 at epoch 585.
       TPR: 0.73 TNR: 0.52  ACC: 0.635 .Threshold 0.473.
       at about 2min per epoch.

expOCT_thickTexture2HyT_20201231_ResNet_G_15x12:
       with channel: 128 initial learning rate 0.01
       when stable, training acc stuck at 60% vs 55%
       Sum=  1.872 at epoch 547.
       TPR:  0.61 TNR: 0.64 ACC: 0.62

expOCT_thickTexture2HyT_20201231_ResNet_H_15x12:
       with channel: 64 initial learning rate 0.001
       when stable, training acc stuck at
       Sum= 1.831 at epoch 589.
       TPR:  TNR:  ACC:

expOCT_thickTexture2HyT_20201231_ResNet_I_15x12:
       with channel: 96 initial learning rate 0.001
       when stable, training acc stuck at
       Sum= 1.795 at epoch 220.
       TPR:  TNR:  ACC:

expOCT_thickTexture2HyT_20201231_ResNet_J_15x12:
       with channel: 128  initial learning rate 0.001
       when stable, training acc stuck at
       Sum=  1.804 at epoch 261.
       TPR:  TNR:  ACC:

expOCT_thickTexture2HyT_20201231_ResNet_K_15x12:
       with channel: 256  initial learning rate 0.0001
       when stable, training acc stuck at
       Sum= 1.736  at epoch 492.
       TPR:  TNR:  ACC:


sense:
A. Age is a good assistanted factor to judge hypertension.
B. thickness is good to judge age;
C. Add age as channel will help judge hypertension.



Age statistics:
values for Age$ have 1806 records
min=50.0; mean=63.38538205980066; max=93.0

total 481 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 481 records
min=50.0; mean=64.17671517671518; max=88.0

total 501 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 501 records
min=50.0; mean=63.85429141716567; max=87.0

Age subgroup: 50-55, 55-60, 60-65, 65-70, 70-80,80-95; total 6 group.

Experiment: expOCT_thicknessAnalyzeAge_20201231_9x31x25

Note:
1 some patient has OD/OS eyes volumes; and some just has one eye volume;

=============================================================
============Age_train=======================================
AgeRange:	    50-55,	55-60,	60-65,	65-70,	70-80,	80-95,
NoHypertension:	470,	402,	265,	194,	274,	44,
Hypertension:	298,	322,	300,	313,	589,	129,
=============================================================

=============================================================
============Age_validation===================================
AgeRange:	    50-55,	55-60,	60-65,	65-70,	70-80,	80-95,
NoHypertension:	104,	91,	    70,	    56,	    96,	    18,
Hypertension:	81,	    88,	    78,	    84,	    155,	38,
============================================================

============================================================
============Age_test========================================
AgeRange:	    50-55,	55-60,	60-65,	65-70,	70-80,	80-95,
NoHypertension:	112,	100,	70,	    56,	    88,	    10,
Hypertension:	90,	    96,	    84,	    88,	    150,	56,
============================================================
================End of anlayzing thickness===================

check statistics significance (pvalue<0.05) between NoHypertension and Hypertension
crossing training, validation and test data
for different age groups and different layers
================================================================================
        layer0, layer1, layer2, layer3, layer4, layer5, layer6, layer7, layer8
50-55
55-60
60-65
65-70
70-80
80-95
================================================================================
No any age group and any layer has this statistics significance.

Some extra conclusions:
1  along age increasing, average of thickness layers 1,2,3,5 and 7 decrease;
2  along age increasing, average of thickness layers 4,6,and 8 increase;
3  This is one of reason that using retina thickness to predict age has a high accuracy;




Experiment: expOCT_thicknessAnalyzeAge_AllGroups_20201231_9x31x25

=============================================================
======================All patients============================
AgeRange:	50-55,	55-60,	60-65,	65-70,	70-80,	80-95,
All:	    1155,	1099,	867,	791,	1352,	295,
=============================================================
================End of anlayzing thickness===============







# Dec 30th, Wednesday, 2020:
expOCT_thickness2HyT_20201228_2Layers_A: input 9x31x25
    channels:     [16, 8]
    dropoutRates: [0.5,0.5]  # 2 dropout layers.
    Sum = 1.54, majority prediction.

expOCT_thickness2HyT_20201228_2Layers_B: input 9x15x12
    channels:     [16, 8]
    dropoutRates: [0.5,0.5]  # 2 dropout layers.
    Sum = 1.601.

=========================================
Generate 5th thickness channel and 6th texture enface map:
1  use 9x31x25 as input;
2  5th thickness as channle 0, and 6th texure as channel 1; save original save;
3  in the dataload class, use channel-dimension normalization;
4  in conv network, then use 2 head branches to process thickness and texture.
t test for features choose: https://www.quora.com/How-can-I-use-students-T-test-for-feature-selection



expOCT_thickTexture2HyT_20201230_ResNet_A: for input 2x31x25
    network: "ThickTexture2HyTension_ResNet"
    channels:     [18, 18, 18, 18, 18] # the final channel is for FC layer
    dropoutRate: 0.5  # the dropout rate at final fully connected layer.
    without validation augmentation.
    Sum= 1.737 at epoch 116.  Overfitting. while training accuracy stuck at 67%.
    TPR: 0.52, TNR: 0.63, ACC: 0.57


expOCT_thickTexture2HyT_20201230_ResNet_B: for input 2x31x25  (almost best)
    network: "ThickTexture2HyTension_ResNet"
    channels:     [18, 18, 18, 18, 18] # the final channel is for FC layer
    dropoutRate: 0.5  # the dropout rate at final fully connected layer.
    with validation augmentation.
    Sum = 1.814 at epoch 105. at epoch 16, it start to overfitting. training accuracy stuck at 69%.
    TPR: 0.51, TNR: 0.71; ACC: 0.60;






# Dec 29th, Tuesday, 2020
Use t-test to judge the statistics significane of average value of each layer each with corresponding target class:
We choose the layer with all p-values <0.05 crossing training, valdiation and test data.
Here all layer index start from zero.
For hypertension: for 9x31x25 image
      thickness map: 5th layer
      texture enface map: 6th layer

For gender:  for 9x31x25 image
      thickness map: 0th, 5th, 6th, 7th layer.
      texture enface map: 1th, 2th layer.

For hypertension: for 9x15x12 image
      thickness map: 5th layer
      texture enface map: 6th layer





# Dec 29th, Tuesday, 2020
Meeting with Shafkat on Thickness2Hypertension prediction:
Attendee: Shafkat, Hui.
Time: 2:00 pm - 02:50 pm, Dec 29th, Tuesday, 2020
Minutes:
1  The difference of 2 disease prediction projeccts:
   Shafkat's Optic Disk swelling prediction:
   A. Doctors used OCT enface folds and wrinkles image information to get the ground truth labels;
      so these known folds and wrinkles in OCT are helpful features;
   B  It has 200 slices each patients, so its blood vessel information is continuous;

   Hui's hypertension prediction:
   A. Doctors used another blood pressure measurement to get the ground truth labels;
      so there is no currently known pattern in OCT relating to hypertension;
   B. It has 31 slices each patients, so its blood vessel information in not continuous.

2  Possible improvements on OCT2Hypertension projects:
   A  RPE layer has richer blood vessel information;
   B  Using pretrained ResNext network in Shafkat's experience improved accuracy about 10%;
      B1. copy the weight of pretrained network 3 channels to 9 channels;
      B2. scale up the input image to 224x224  to fit the pretrained network;
      B3. Merge 9 layer thickness into 3 layers by choosing important, or more differentiating layers;
   C  analyze activation map to find more important pattern to choose more important layer;

3  input to Shafkat's network:
Let me summarize your input to disease prediction:
1  retinal blood segmentation information;
2  inner retina en-face image (Surface_1_4) ;
3  total retina en-face image (Surface_1_7);
4  RPE en-face image (surface_5_7);
5  total retinal thickness,
6  ONH shape features,


Shafkat, if this minutes is not complete, welcome to add your notes.  Thank you very much.



# Dec 29th, Tuesday, 2020
Meeting conclusions with professor
1  visualize thickness prediction result R with ground truth;
2  analyze the relationship between age and raw thickness map, use 9 layer averages;
3  analyze the pattern dominant in the input for predicting hypertension in Deep learning network and SVM;
4  refer the nature medical paper about the loss design and regulization;
5  add x,y coordinates into input tensor for the surface prediction;
6  use JHU method to prediction thickness Rift;


# Dec 28th, Monday, 2020
Answer professor Wu's questions:
Traditional machine learning:
1) It seems thickness maps are not powerful enough and texture features help. But simply averaging the intensity of the enface image may not be good enough. You may also need to use radiomic features.
A:  OK. I need to research some literature on how to design the radiomic features.  If you have further detailed ideas on this radiomic features, please share with me.

2) Should also try other method, like random forest?
A:  OK. I will try random forest method this week.

Deep learning:
1) Why 2-path independent prediction, in stead of using multiple channels to fuse the features?
A:  These 2 methods both are worth trying.  I worry that using 18 channels (9 thickness + 9 texture) will further increase the number of input features which may lead to further overfitting. But it is worth to try.

2) What is the activation function?
A:  ReLU in each Conv layer.   The final loss uses binary cross-entropy.

3) What is the number of latent features in our segmentation network? This is for our next step - using similar method as Yusen's for prognostication prediction.
A: The first layer has 24 filters, double the number of filters along each deeper layer, and the network has total 7 layers, so at the bottom we have 1536 filters with size 7x8 as the latent vector.
     In other words, the bottom latent vector has a size 1536x7x8 for each slice. If we consider 31 slices together each patient, each patient has 31x1536x7x8 input features, which is 1476 times of training samples(1806), which is highly probable to overfitting.


Data Statistics:
1  1806 training patients, 481 validation patients, and 501 test patients for this data.
2  Age for training data:
    values for Age$ have 1806 records
    min=50.0; mean=63.38538205980066; max=93.0
3  original thickness map;:9x15x12
   add age: 10x15x12  age as channel 15x12 of 60;
   add age as element: 9x15x12 +1
   normalization: range 50-93, thickness: 0-1, 1-10, -1 to 1
   add age, gender etc.
4  Analyze relation of Age and layer average thickness of each layer:
   in different data set:




# Dec 25th, Friday, 2020
expOCT_thickness2HyT_20201224_ResNet_A: with AddSample augmentation:
    at epoch 297, training acc got 97%, while validation acc got 53%;
    at epoch 10, validation loss > training loss, and validation loss continue to increase, while training loss continue to reduce.
    TPR+TNR+ACC= Sum=1.66.

expOCT_thickness2HyT_20201225_ResNet_A: with AddSample augmentation + 18 filters in each layer, and 2 conv in each layer.
    at epoch 406, training acc got 95%, while validation acc got 53%;
    at epoch 3, validation loss > training loss, and validation loss continue to increase, while training loss continue to reduce.
    TPR+TNR+ACC= Sum=1.653.

expOCT_thickness2HyT_20201225_ResNet_B:   with AddSample augmentation + 9 filters in each layer, and 2 conv in each layer. dropout 0.5
    Sum= 1.69.
    at stable, training acc = 77%, while validaiton accc =54%;
    at epoch 0, validation loss > training loss, and validation loss continue to increase, while training loss continue to reduce.

expOCT_thickness2HyT_20201225_ResNet_C:   with AddSample augmentation + 9 filters in each layer, and 2 conv in each layer. dropout 0.2
    Sum= 1.67.
    at stable, training acc = 84%, while validaiton accc =54%;
    at epoch 0, validation loss > training loss, and validation loss continue to increase, while training loss continue to reduce.


expOCT_thickness2HyT_20201225_ResNet_D:  with AddSample augmentation + 6 filters in each layer, and 2 conv in each layer. dropout 0.2
    Sum= 1.60.
    at stable, training acc = 80%, while validaiton accc =51%;
    at epoch 0, validation loss > training loss, and validation loss continue to increase, while training loss continue to reduce.



SVM test result:
Note: SVM use default parameters;

Summary:
1  We did total 8 combination experiments using different input size(9x31x25, 9x15x12), textureEnface or thickness map, and prediction of hypertension or gender;

2  For hypertension prediction:
   A. SVM with polynomial kernel and thickness 9x15x12 input got the best result of average accuracy of validation and test set: 0.575;
   B. Comparing with our deep learning network, our fine-tune deep learning network can get the current best validation accuracy: 0.62;

3  For gender prediction:
   A. SVM with linear kernel and thickness 9x15x12 input got the best result of average accuracy of validation and test set: 0.71;
   B. Comparing with our deep learning network, our hypertension network (not fine-tune for gender) can get the current best validation accuracy for gender: 0.72;

4  Both hypertension and gender prediction with SVM showed that good training accuracy does not mean a good validation and test accuracy;

5  These SVM experiments and deep learning experiments both show that for the same input sizes and forms, gender prediction always gets explicit better result than hypertension prediction;

6  These SVM experiments fit traditional expectation:
   Deep learning generally gets a better performance than traditional ML methods, because of the automatic feature extracting capability of DL.

7  Suggestions on further work:
   A  Further improve the accuracy on deep learning:
     A1. Combine thickness and texture enface map for 2-path independent predictions, and then assemble result;
     A2. Current thickness map is an approximate circle-symmetric map around fovea, can we futher extract one average thickness along same radius or four averages of 4 quadrants along same radius?
         This method will further reduce the size of input features for reducing overfitting, and it keeps core thickness information because of circle symmetric property.
         Maybe we need to ask professor Wang's suggestion on this idea, as this is a medical feature design problem.
   B Report current deep learning and SVM result to professor Wang, and ask her suggestions on further improvement idea;
   C From this SVM result, we may not have a unrealistic expectation that our accuracy must exceed 70%;

=== Accuracies of the 5thThickness and 6thTexture to hypertension_bp_plus_history$ Prediction with different SVM kernels ====
Experiment: expOCT_thickTexture2HyT_20210101_SVM_A
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/5thThickness_6thTexture_2x15x12
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 0.6605555555555556,    0.6669444444444445,     0.6588888888888889,     0.5263888888888889
Validation,	 0.5245046923879041,    0.5453597497393118,     0.5453597497393118,     0.5307612095933264
Test,      	 0.507,                 0.559,                  0.567,                  0.512
========================================================================================================


============ Accuracies of Thickness to hypertension_bp_plus_history$ Prediction with different SVM kernels ====================
Experiment: expOCT_thickness2HyT_20201225_SVM_A
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x15x12
=======================================================================================================
SVM_kernel,  linear,                poly,                   rbf,                    sigmoid
Training,  	 0.8202777777777778,    0.6036111111111111,     0.5986111111111111,     0.5425
Validation,	 0.5234619395203337,    0.5954118873826904,     0.5860271115745568,     0.5119916579770595
Test,      	 0.537,                 0.555,                  0.559,                  0.543
========================================================================================================

============ Accuracies of Thickness to hypertension_bp_plus_history$ Prediction with different SVM kernels ====================
Experiment: expOCT_thickness2HyT_20201225_SVM_B
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x31x25
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 1.0,                   0.6097222222222223,     0.6075,                 0.5452777777777778
Validation,	 0.5140771637122002,    0.5828988529718456,     0.5912408759124088,     0.5130344108446299
Test,      	 0.519,                 0.551,                  0.558,                  0.543
========================================================================================================

============ Accuracies of TextureEnface to hypertension_bp_plus_history$ Prediction with different SVM kernels ====================
Experiment: expOCT_texture2HyT_20201226_SVM_A
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x15x12
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 0.8736111111111111,    0.7502777777777778,     0.7388888888888889,     0.5094444444444445
Validation,	 0.5537017726798749,    0.5537017726798749,     0.5610010427528676,     0.5265901981230449
Test,      	 0.533,                 0.549,                  0.559,                  0.53
========================================================================================================

============ Accuracies of TextureEnface to hypertension_bp_plus_history$ Prediction with different SVM kernels ====================
Experiment: expOCT_texture2HyT_20201226_SVM_B
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x31x25
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 1.0,                   0.8319444444444445,     0.8091666666666667,     0.5386111111111112
Validation,	 0.5516162669447341,    0.5547445255474452,     0.5672575599582899,     0.529718456725756
Test,      	 0.501,                 0.565,                  0.567,                  0.508
=======================================================================================================

============ Accuracies of TextureEnface to gender Prediction with different SVM kernels ====================
Experiment: expOCT_texture2Gender_20201226_SVM_A
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x15x12
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 0.9613888888888888,    0.7658333333333334,     0.8161111111111111,     0.5566666666666666
Validation,	 0.656934306569343,     0.602711157455683,      0.6579770594369134,     0.5537017726798749
Test,      	 0.69,                  0.628,                  0.691,                  0.563
========================================================================================================

============ Accuracies of TextureEnface to gender Prediction with different SVM kernels ====================
Experiment: expOCT_texture2Gender_20201226_SVM_B
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x31x25
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 1.0,                   0.8077777777777778,     0.865,                  0.5741666666666667
Validation,	 0.670490093847758,     0.5985401459854015,     0.6579770594369134,     0.5651720542231491
Test,      	 0.697,                 0.618,                  0.696,                  0.582
========================================================================================================

============ Accuracies of Thickness to gender Prediction with different SVM kernels ====================
Experiment: expOCT_thickness2Gender_20201226_SVM_C
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x15x12
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 0.9102777777777777,    0.735,                  0.7311111111111112,     0.6152777777777778
Validation,	 0.7038581856100105,    0.6923879040667362,     0.6923879040667362,     0.5651720542231491
Test,      	 0.72,                  0.699,                  0.692,                  0.599
========================================================================================================

============ Accuracies of Thickness to gender Prediction with different SVM kernels ====================
Experiment: expOCT_thickness2Gender_20201226_SVM_D
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x31x25
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 1.0,                   0.7458333333333333,     0.74,                   0.6194444444444445
Validation,	 0.6746611053180396,    0.6871741397288843,     0.6882168925964547,     0.5693430656934306
Test,      	 0.711,                 0.701,                  0.695,                  0.596
========================================================================================================


# Dec 24th, Thursday, 2020
Use SVM on Thickness map to hypertension,please review.

Assumption: our thickness to hypertension prediction is not a linear separable.
Solution:
1  use svc function, which support classification error and 4 kernal functions;
2  4 kernal functions: linear, polynomial, rbf, sigmoid tanh;
   one by one try to see which kernal give us best result;
3  use svc.score to get it accuracy;

Input:
1  thickness map of size 9x15x12 flat into a vector;
2  label [0,1] converts into [-1,1];

Possible results:
1  high prediction result: wonderful;
2  low prediction result, which is similar overfitting in deep learning:
   then further possible improvement:
   A  further consider to use feature engineering (SIFT etc0.) to design features;
   B  use a separate deep learning network to search features;
   C  reduce input features;

Plan:
1  This Friday, code;
2  This Saturday, test different kernal and parameter config;
3  Next Monday, report result;








# Dec 23rd, Wednesday, 2020
Let's us try 9x15x12 input size, which keeps 9 layers feature, and preserver X and Z same pixel resolution:
original size: 9x31*512 in CxZxX direction.
resulution: Z:240.555 um/pixel,  X: 11.29 um/pixel;
(240.555*2)/11.29 = 42.614 which means 2 pixels in Z direction has same resolution with 42.6 pixels in X direciton.
512/43 = 12, 31/2 = 15.5
new image size: 9x15x12 = 1620 features.

expOCT_thickness2HyT_20201223_ResNet_A:
        channels:     [4, 8, 16, 32] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        TPR+TNR+ACC= Sum = 1.61;
        at epoch 7, validation Loss > training loss.

expOCT_thickness2HyT_20201223_ResNet_B:
        channels:     [16, 16, 16, 16] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        Sum = 1.63, overfitting.

expOCT_thickness2HyT_20201223_ResNet_C:
        channels:     [32, 32, 32, 32] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        Sum = 1.63, overfitting.



expOCT_thickness2HyT_20201223_ResNet_D:
        channels:     [64, 64, 64, 64] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        Sum = 1.63, overfitting.

===============Use 1Layer network==============
expOCT_thickness2HyT_20201223_1Layer_A: 96 filters
    Sum= 1.659
    at epoch 3, validation loss > training loss
    at stable: training acc 65%, while validation acc 50%;

expOCT_thickness2HyT_20201223_1Layer_B: 64 filters
    Sum= 1.646
    at epoch 7, validation loss > training loss
    at stable: training acc 64%, while validation acc 53%;

expOCT_thickness2HyT_20201223_1Layer_C: 32 filters
    Sum= 1.653
    at epoch 3, validation loss > training loss
    at stable: training acc 61%, while validation acc 52%;

expOCT_thickness2HyT_20201223_1Layer_D: 16 filters
    Sum= 1.661
    at epoch 7, validation loss > training loss
    at stable: training acc 58%, while validation acc 54%;

expOCT_thickness2HyT_20201223_1Layer_E: 8 filters
    Sum= 1.621
    at epoch 0, validation loss > training loss
    at stable: training acc 56%, while validation acc 51%;

expOCT_thickness2HyT_20201223_1Layer_F: 4 filters
    Sum= 1.643
    at epoch 7, validation loss > training loss
    at stable: training acc 57%, while validation acc 51%;

Conclusion: single layer network is not good.


================================================
Use sample sum as data augmentation:  --done, training.
1  get one load index i1 from __getitem__ method;
2  random choose other 2 indexes: i2,i3;
3  if these 3 samples have same labels, average the 3 samples;
   elif i1 = i2, average i1 and i2;
   elif i1 = i3, average i1 and i3;
   else  average i2 and i3;
4  while using this method, validation data do not augmentation;
5  this method can generate sample: int(1806*0.45)*(int(1806*0.45)-1)/2+ int(1806*0.55)*(int(1806*0.55)-1)/2 = 821794
6  while  9*31*25 = 6975 features.
7  redo 9x31x25 map, cancel smooth.  --done

Exp: expOCT_thickness2HyT_20201224_ResNet_A.yaml for addSamples is training:






# Dec 22nd, Tuesday, 2020
Today, in the process of learning SVM, I found a problem which maybe is the root reason why we always encounter overfitting in both our OCT2HyperTension and
OvarianCancerCT to survival prediction.

The problem is that if the number of features in each sample is much greater than the number of samples, it is easy over-fitting.
A very good explanation of this problem is in link
https://www.quora.com/Is-it-possible-to-train-a-machine-learning-model-if-there-are-more-features-than-samples-in-the-data-set
in which, Alex Gilgur used linear equation system as example to illustrate this problem.

Whatever we use deep learning network or SVM, if the number of features in each sample is much greater than the number of samples, it is easy over-fitting.
In SVM method, avoid over-fitting in choosing Kernel functions and regularization term is crucial.
(please refer link: https://scikit-learn.org/stable/modules/svm.html )

We need first solve the feature number problem, and then go further.

In our thickness2Hypertension, our training data has 1806 samples (patients) with binary label for each,
while our input is 9x31x512 tensor which means input has 142848 features. In other words, our feature number is 79 times bigger than the number of samples.

I am planning to reduce features first, and then do the SVM and deep learning:
A Currently, we have 10 surface segmentation and 9 layers. we can use the sum of thickness of first 5 layers as a thickness, and use the sum of last 3 layers as thickness;
  so, we will get 2 thicknesses values;
B with a principle that that pixel resolutions are same in both Z and X direction, reduce enface map to 31x25 from 31x512 by averaging the neighbour pixels;
C Therefore, we got a input tensor of size 2x31x25 = 1550 features;

After this feature reduction(feature selection), go to SVM and deep learning.

Professor, How do you think?
====================================
In deep learning, methods of overcoming overfitting:
1  add the number of training samples;
2  reduce the number of input features;
3  L2 parameter regulization;
4  dropout;
5  add data augmentation;
6  reduce the layer number and filter number of networks to reduce model complexity;

too many features leads the spare of samples.
https://stackoverflow.com/questions/37776333/why-too-many-features-cause-over-fitting

I am thinking that 9x15x12 is still too big in input feature number.

For MNIST data set, input size is 28x28, and training sample is 60K, so the rate of training samples vs input feature = 78;
For ImageNet data set, input size is 3x224x224, and training sample is 14.2 million, so the rate of training sample vs input feature = 94.
For a common (x,y) 2D data point classification,   general we has 200 points,  so the rate for training sample vs input feature = 100;

For our 1806 training samples, it looks 20 input features is a good choice according to the above rough sense.

I am thinking whether we need to reduce input features to 20, for example, use 9x1x1 input, or some feature engineering like below:
Harris Corner Detection — Uses a Gaussian window function to detect corners. (read more)
Shi-Tomasi Corner Detector — The authors modified the scoring function used in Harris Corner Detection to achieve a better corner detection technique (read more)
Scale-Invariant Feature Transform (SIFT) — This technique is scale invariant unlike the previous two. (read more)
Speeded-Up Robust Features (SURF) — This is a faster version of SIFT as the name says. (read more)
Features from Accelerated Segment Test (FAST) — This is a much more faster corner detection technique compared to SURF. (read more)
Binary Robust Independent Elementary Features (BRIEF) — This is only a feature descriptor that can be used with any other feature detector. This technique reduces the memory usage by converting descriptors in floating point numbers to binary strings. (read more)
Oriented FAST and Rotated BRIEF (ORB) — SIFT and SURF are patented and this algorithm from OpenCV labs is a free alternative to them, that uses FAST keypoint detector and BRIEF descriptor. (read more)



# Dec 22nd, Tuesday, 2020
1  input image changes size from 9x31x512 to 9x31x25, 20 times reducing;
2  so we can increase batch size from 30 to 300;

expOCT_thickness2HyT_20201222_ResNet_A:  for 9x31x25 input
        channels:     [8, 16, 32, 64, 128] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        at stable, training acc gets 84%, while validation accc gets 51%;
        at epoch 5, validation loss increases, while training loss decrease.
        TPR+TNR+ACC= Sum = 1.59, very low.

expOCT_thickness2HyT_20201222_ResNet_B:  for 9x31x25 input
        channels:     [4, 8, 16, 32, 64] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        at stable, training acc gets 81%, while validation accc gets 50%;
        at epoch 21, validation loss increases, while training loss decrease.
        TPR+TNR+ACC= Sum = 1.637, low.





# Dec 18th, Friday, 2020

Professor,

If you have convenient time, please let me know.
I can show visualization training/validation loss, accuracy curves to you for all these experiments, which more more vivid.

=========================
Summary on traditional networks exploration:
Experements A series: Using VGG-16 network model:
     A. Used exactly VGG-16 4 layer (conv-maxPooling2d) +2FC layer model, with filter numbers[64, 128, 256, 512, 256]: Network get prediction of 1 (TPR=1, TNR=0)
        validation loss 0.6326, and then increase, it is explict overfitting;
     B. Added batchNormalization to VGG model with filter numbers [64, 128,256, 512, 256]:
        at epoch 69, training acc gets 1.0, while validation acc gets 0.54; Overfitting.
     C. gradually reduce network filter numbers to  [32, 64, 128, 256, 128], [16, 32, 64, 128, 128],
        [4, 8, 16, 32, 32],and [4, 4, 8, 8, 16]:
         they are still overfitting.  For the final [4,4,8,8,16] network,  at epoch 391, training acc gets 0.81, while validation acc gets 0.52.
         The key information is that all these networks do not reduce validation loss while training loss gradually reduces.

Experiment B series: Using ResNet network model:
     A. Used 4 layers with (Conv+ residualLink + max2dPooling) + 1FC model;
     B  initial channels: [32, 64, 128, 256, 512]: training accuracy quickly get 99% at epoch 74, while validation accuracy at 0.52.
     C  gradually reduce channels size  [8, 16, 32, 64, 128],  [4, 8, 16, 32, 32], [4, 4, 8, 8, 16];
        at final [4,4,8,8,16] model,  at epoch 378, training acc get 97%, while validation acc get 49%; TPR+TNR+ACC=Sum=1.60;

Expereiment C series: Using simple 2-layer model: 2 Conv+2dropout+1FC:
    After a series of network scale adjustments:
    expOCT2SysD_20201211_J: (the best)
    channels:     [16, 8]
    dropoutRates: [0.5,0.5]  # 2 dropout layers.
    at epoch 18, validaLoss > trainingLoss.  at stable, with training loss: 0.5909, validation loss: 0.6218
    threshold 0.44, TPR 0.71, TNR 0.51, Acc 0.62.  TPR+TNR+ACC=Sum=1.836

Experiment D series:  OCT thickness map predicts gender, instead of hypertension:
   A use same network, same input, but different binary ground truth (gender vs hypertension) from experiment C;
     (It just needs ONE line code modification from experiment C)
   B expOCT2Gender_20201218B_B:
        channels:     [16, 8]
        dropoutRates: [0.5,0.375]  # 2 dropout layers.
        at epoch  11, validationLoss > trainingLoss,
        At threshold  0.41, TPR 0.71 , TNR 0.73,    Acc 0.72 ,  TPR+TNR+ACc=Sum=2.151
   C Comparing experiment C and experiment D series, their only difference is different ground truth.
     OCT2Gender got better result than OCT2Hypertension. Different applications and data really matter.







#Dec 17th, Thursday, 2020
1  implemented HalfUnet model;  ResNet Model Architecture
    expOCT2SysD_20201217_HalfUnet_A:
        channels:     [32, 64, 128, 256, 512] # the final channel is for FC layer
        after epoch 15, overfitting;
        training accuracy quickly get 99% at epoch 74, while validation accuracy at 0.52.

    expOCT2SysD_20201217_HalfUnet_C:
        channels:     [8, 16, 32, 64, 128] # the final channel is for FC layer
        at epoch 20, validationLoss > training loss
        at epoch 95, training acc get 99%, while validation acc get 55%;

    expOCT2SysD_20201217_HalfUnet_B:
        channels:     [4, 8, 16, 32, 32] # the final channel is for FC layer
        at epoch 29, validationLoss > training loss
        at epoch 200, training acc get 99%, while validation acc get 52%;
    expOCT2SysD_20201217_HalfUnet_D:
        channels:     [4, 4, 8, 8, 16] # the final channel is for FC layer
        at epoch 13 , validationLoss > training loss
        at epoch 378, training acc get 97%, while validation acc get 49%;
        max TPR+TNR+ACC= sum=  1.60


2   standard VGG model:
    expOCT2SysD_20201216_VGG16_A: (standard VGG_16 model with only reducing one layer)
        channels:     [64, 128, 256, 512, 256]
        validationLoss is always less than trainingLoss;validationLoss = 0.6326; trainingLoss = 0.6331.
        validation always predict 1, majority prediction. TPR =1, TNR =0.

    expOCT2SysD_20201216_VGG16_B:
        channels:     [32, 64, 128, 256, 128]
        validationLoss is always less than trainingLoss;validationLoss = 0.6326; trainingLoss = 0.6331.
        validation always predict 1, majority prediction. TPR =1, TNR =0.

3  Add batchnorm to VGG16 model;
    expOCT2SysD_20201217_VGG16_A:
        channels:     [64, 128, 256, 512, 256]
        at epoch 69, training acc gets 1.0, while validation acc gets 0.54. Overfitting.

    expOCT2SysD_20201217_VGG16_B:
        channels:     [32, 64, 128, 256, 128]
        at epoch 69, training acc gets 1.0, while validation acc gets 0.53. Overfitting.

    expOCT2SysD_20201217_VGG16_C: cancel
        channels:     [16, 32, 64, 128, 128]

    expOCT2SysD_20201217_VGG16_D:  cancel
        channels:     [8, 16, 32, 64, 128]

    expOCT2SysD_20201217_VGG16_E:
        channels:     [4, 8, 16, 32, 32]
        at epoch 9, validationLoss > training loss
        at epoch 202, training acc gets 1.0, while validation acc gets 0.52. Overfitting.
    expOCT2SysD_20201217_VGG16_F:
        channels:     [4, 4, 8, 8, 16]
        at epoch 0, validationLoss > training loss
        at epoch 391, training acc gets 0.81, while validation acc gets 0.52. Overfitting.
        sum= 1.742.


4  prepare 2-layer network:
   expOCT2SysD_20201218E_A: remove norm before FC.
        channels:     [48, 16]
        dropoutRates: [0.5,0.8]  # 2 dropout layers.
        at epoch  181, validationLoss > trainingLoss, validation loss flat since then.
        At threshold 0.46 , TPR  0.76, TNR 0.41,    Acc 0.60,  Sum: 1.78

   expOCT2SysD_20201218E_B:
        channels:     [24, 16]
        dropoutRates: [0.5,0.8]  # 2 dropout layers.
        at epoch  85, validationLoss > trainingLoss, validation loss flat since then.
        At threshold  , TPR  , TNR ,    Acc ,  Sum: 1.751

   expOCT2SysD_20201218E_C:
        channels:     [16, 16]
        dropoutRates: [0.0, 0.8]  # 2 dropout layers.
        at epoch  49, validationLoss > trainingLoss, validation loss increases, overfitting.
        At threshold  , TPR  , TNR ,    Acc ,  Sum: 1.745

   expOCT2SysD_20201218E_D:
        channels:     [16, 8]
        dropoutRates: [0.5,0.625]  # 2 dropout layers.
        at epoch 19 , validationLoss > trainingLoss,
        At threshold  , TPR  , TNR ,    Acc ,  Sum: 1.762

   expOCT2SysD_20201218E_E:
        channels:     [16, 8]
        dropoutRates: [0.5,0.375]  # 2 dropout layers.
        at epoch  57, validationLoss > trainingLoss,
        At threshold  , TPR  , TNR ,    Acc ,  Sum: 1.792

    expOCT2SysD_20201219E_A: same with config of expOCT2SysD_20201211_J,  No norm before FC, (Good, not best)
        batchSize = 60
        channels:     [16, 8]
        dropoutRates: [0.5,0.5]  # 2 dropout layers.
        at stable of training, training acc 62%, while validation acc 60%
        at epoch  63, validationLoss > trainingLoss, and then validation loss reduce slowly, but training loss reduces a lot; No overfitting.
        At threshold  0.48, TPR 0.78 , TNR 0.40,    Acc 0.61  Sum: 1.792

5  OCT2Gender:
   expOCT2Gender_20201218B_A:
        channels:     [16, 8]
        dropoutRates: [0.5,0.625]  # 2 dropout layers.
        at epoch  38, validationLoss > trainingLoss; and the validatioin Loss slightly reduces;
        At threshold  0.49, TPR  0.69, TNR 0.69,  Acc 0.69,  Sum: 2.061


   expOCT2Gender_20201218B_B: (the best)
        channels:     [16, 8]
        dropoutRates: [0.5,0.375]  # 2 dropout layers.
        at epoch  11, validationLoss > trainingLoss,
        At threshold  0.41, TPR 0.71 , TNR 0.73,    Acc 0.72 ,  Sum: 2.151

   expOCT2Gender_20201218_ResNet_A:
        channels:     [8, 16, 32, 64, 128] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        at epoch 310, training acc gets 1.0, while validation acc gets 66%;
        after epoch 99, validation loss increases, while training loss decreases.
        threshold 0.27   TPR 0.78   TNR 0.61    ACC 0.70     Sum 2.091

   expOCT2Gender_20201218_ResNet_B:
        channels:     [4, 8, 16, 32, 32] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        at epoch 454, training acc gets 0.98, while validation acc gets 67%;
        after epoch 96, validation loss increases, while training loss decreases.
        threshold 0.48   TPR 0.65   TNR 0.74    ACC 0.69     Sum 2.079

   expOCT2Gender_20201219B_A:  same with config of expOCT2SysD_20201211_J,  No norm before FC,
        batchSize = 60
        channels:     [16, 8]
        dropoutRates: [0.5,0.5]  # 2 dropout layers.
        at statble stage, training acc 71%, validation acc 68%
        at epoch  5, validationLoss > trainingLoss. And validation slight increases, and flat.
        At threshold  0.46, TPR  0.71, TNR 0.70,    Acc  0.70,  Sum: 2.107



# Dec 16th, Wednesday, 2020
(base) [c-xwu000:dataPrepare]#python3 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv gender 12binary None
total 1806 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv
values for gender have 1806 records
1 rate: 0.41472868217054265; 2 rate: 0.5852713178294574
emptyValueIDList = []

Thickness2Gender is training: nohup python3 ./OCT2SysD_Train.py ./testConfig/expOCT2Gender_20201216_A.yaml &
expOCT2Gender_20201216_A:
        channels:     [48, 24]
        dropoutRates: [0.5,0.8]  # 2 dropout layers.
        at epoch  109, validationLoss > trainingLoss, validation loss flat since then.
        At threshold 0.49 , TPR  0.66, TNR 0.73,    Acc 0.69,  Sum: 2.071



About applying traditional baseline network:
As our thickmap has a size 9x31x512, where 9 is channel, 31 is image height, and 512 is image width.
Below I listed standard traditional baseline network architectures for our OCT to hypertension application:
1  MobileNetv3: Its small model has 11 layers with filter size 3x3 or 5x5. Our image height 31 will reduce to 1 at the 5th layer,
                and following 6 layers with 5x5 convolution on 1 element in height will be meaningless.
2  VGG-16: it has 5 max pooling layer with filter 2x2 with stride 2, following 3 dense layers.
           At the 4th pooling layer, our image height reduces to 1, leading following 3x3 conv and 3 dense layers meaningless.
3  GoogleNet: it has 22 layers with filer size 7x7 and 3x3, after the 3th layer, our image height 31 will reduce to 1. Same conclusion with the above;
4  ResNet:    It has 34 layers with 7x7 and 3x3 convolution. It is too deep for our image height 31.

5  launched 2 variants of VGG16: 4 (Cov+ maxPooling) layers + 2 FC layers:
expOCT2SysD_20201216_VGG16_A: (standard VGG_16 model with only reducing one layer)
channels:     [64, 128, 256, 512, 256]
       validationLoss is always less than trainingLoss;validationLoss = 0.6326; trainingLoss = 0.6331.
       validation always predict 1, majority prediction. TPR =1, TNR =0.

expOCT2SysD_20201216_VGG16_B:
        channels:     [32, 64, 128, 256, 128]
        validationLoss is always less than trainingLoss;validationLoss = 0.6326; trainingLoss = 0.6331.
        validation always predict 1, majority prediction. TPR =1, TNR =0.




# Dec 15th, Tuesday, 2020
Meeting with professor:
1  use traditional baseline models for classification;
2  may use SVM to classification;

Further improve OCT2Hypertension Network:
expOCT2SysD_20201211_M:
    channels:     [48, 16]
    dropoutRates: [0.0,0.8]  # 2 dropout layers.
    at epoch  10, validationLoss > trainingLoss, validation loss increases;
    At threshold 0.45, TPR  0.72, TNR 0.45,    Acc 0.60 ,  Sum: 1.762

expOCT2SysD_20201211_N:
    channels:     [48, 16]
    dropoutRates: [0.2,0.8]  # 2 dropout layers.
    at epoch 52 , validationLoss > trainingLoss, validation loss flats;
    At threshold 0.50 , TPR 0.62 , TNR 0.54 ,    Acc 0.59,  Sum: 1.76

expOCT2SysD_20201211_P:
    channels:     [48, 16]
    dropoutRates: [0.5,0.8]  # 2 dropout layers.   (best)
    at epoch  105, validationLoss > trainingLoss, validation loss slightly increases and flats;
    At threshold  0.46, TPR  0.70, TNR 0.51,    Acc 0.61,  Sum: 1.824

expOCT2SysD_20201211_Q:
    channels:     [48, 16]
    dropoutRates: [0.5,0.5]  # 2 dropout layers.
    at epoch  43 , validationLoss > trainingLoss, validation loss slightly increase, flats;
    At threshold 0.44, TPR 0,65, TNR 0.54,    Acc 0.80,  Sum: 1.8

expOCT2SysD_20201211_R:
    channels:     [48, 24]
    dropoutRates: [0.5,0.8]  # 2 dropout layers.
    at epoch  109, validationLoss > trainingLoss, validation loss flat since then.
    At threshold 0.48 , TPR  0.73, TNR 0.46,    Acc 0.60,  Sum: 1.793


# Dec 14th, 2020
Experiment on Lnx-idea006.ecn.uiowa.edu:
Experiment: expOCT2SysD_20201211_J
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_J
Experiment: expOCT2SysD_20201211_E
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_E
Experiment: expOCT2SysD_20201211_H
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_H
Experiment: expOCT2SysD_20201211_F
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_F
Experiment: expOCT2SysD_20201211_I
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_I
Experiment: expOCT2SysD_20201211_G
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_G

Program in c-xwu000:
(base) [c-xwu000:network]#ps 23367 23346 23269 30671
  PID TTY      STAT   TIME COMMAND
23269 ?        Rl   2826:34 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_C.yaml
23346 ?        Rl   2823:30 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_B.yaml
23367 ?        Rl   2823:33 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_D.yaml
30671 ?        Rl   2110:31 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_J.yaml

program in c-iibi007:
ps 104438 104116 104226 104297 104369
   PID TTY      STAT   TIME COMMAND
104116 ?        Rl   2192:51 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_E_iibi007.yaml
104226 ?        Rl   2190:57 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_F_iibi007.yaml
104297 ?        Rl   2193:27 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_G_iibi007.yaml
104369 ?        Rl   2209:29 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_H_iibi007.yaml
104438 ?        Rl   2210:10 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_I_iibi007.yaml

Analysis:
Best network for 1Conv + 1FC layer:
    expOCT2SysD_20201212_E:  on lnx-idea005 _> iibi007
    channels:     [32]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0.8]  # 1 dropout layers.
    at epoch 57, validaLoss > trainingLoss.  but validation still decrease, with training loss: 0.6149, validation loss: 0.6223
    threshold 0.46, TPR 0.78, TNR 0.42, Acc 0.61.

Best network for 2Conv + 1Fc layer:
    expOCT2SysD_20201211_I: in lnx-idea006.ecn.uiowa.edu   (worth to research.)
    channels:     [32, 16]
    dropoutRates: [0.8,0.8]  # 2 dropout layers.
    at epoch 700, validaLoss = trainingLoss.  No explict overfitting, with training loss: 0.6261, validation loss: 0.6248
    threshold 0.47, TPR 0.84, TNR 0.35, Acc 0.62.

    expOCT2SysD_20201211_J: in lnx-idea006.ecn.uiowa.edu  (the best)
    channels:     [16, 8]
    dropoutRates: [0.5,0.5]  # 2 dropout layers.
    at epoch 18, validaLoss > trainingLoss.  overfitting. But sum is 1.823, with training loss: 0.5909, validation loss: 0.6218
    threshold 0.44, TPR 0.71, TNR 0.51, Acc 0.62.  sum: 1.836

Further improvement, and reduce batchSize:
expOCT2SysD_20201211_K:
    channels:     [16, 8]
    dropoutRates: [0.8,0.8]  # 2 dropout layers.
    No overfitting. It looks underfitting.
    threshold  0.49, TPR 0.84 , TNR 0.28,   Acc 0.59, sum 1.719

expOCT2SysD_20201211_L:
    channels:     [48, 16]
    dropoutRates: [0.8,0.8]  # 2 dropout layers.  (best)
    No overfitting, validation loss lock at 0.6244.  validation loss has same trend with training loss.
    threshold  0.48, TPR 0.79 , TNR 0.39,   Acc 0.61.  Sum: 1.797.

expOCT2SysD_20201212_K:  same with config expOCT2SysD_20201212_E
    channels:     [32]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0.8]  # 1 dropout layers.
    at epoch 71, validationLoss > trainingLoss
    threshold  0.50, TPR  0.63, TNR 0.56 , Acc 0.60

expOCT2SysD_20201212_L:
    channels:     [24]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0.8]  # 1 dropout layers.
    at epoch 71, validationLoss > trainingLoss
    threshold  0.49, TPR 0.65 , TNR 0.55,   Acc 0.60

expOCT2SysD_20201212_M:  on c-iibi007
    channels:     [1]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0]  # 1 dropout layers =0 .
    at stable stage: validation loss is 0.6281, training loss is 0.6002.
    at threhold 0.45, TPR 0.62, TNR 0.55, Acc 0.59, Sum is 1..76

On Dec 14th,2020, 20:00, suspend below program:
python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201211_K.yaml
at Dec 14th, 2020, 20:41, resume the above progam.


# Dec 12th, Saturday,2020
Now 3 training programs are running on lnx-idea006.ecn.uiowa.edu.
Current program:
Gradually reduce network complexity (8 layers, 4 layers, 2 layers), and did experiments to reduce overfitting of thickness2Hypertension
thickness2Hypertension network now uses 2 layer network.
got result:threshold 0.47, TPR 0.71, TNR 0.49, Accuracy 0.61 on validation data with 45.6% of 0s and 54.4% of 1s.
But network still get overfitting at 30 epochs.
use the contrast of validation and training loss, instead of accuracy, to judge the reflection point of over-fitting;
loss directly indicates the error with respect with ground truth, without other factors;
while accuracy needs another threshold to measure accuracy values, and different thresholds will lead different accuracy values.





(base) [lnx-idea006:network]#nvidia-smi
Sat Dec 12 12:31:55 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.45.01    Driver Version: 455.45.01    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     On   | 00000000:01:00.0 Off |                  Off |
| 34%   40C    P8    30W / 260W |     49MiB / 24215MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Quadro RTX 6000     On   | 00000000:4B:00.0 Off |                  Off |
| 34%   49C    P2   175W / 260W |  20969MiB / 24220MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1529      G   /usr/lib/xorg/Xorg                 38MiB |
|    0   N/A  N/A      1916      G   /usr/bin/gnome-shell                6MiB |
|    0   N/A  N/A     17007      C   python3                             0MiB |
|    0   N/A  N/A     17055      C   python3                             0MiB |
|    0   N/A  N/A     17090      C   python3                             0MiB |
|    1   N/A  N/A      1529      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A      1916      G   /usr/bin/gnome-shell                0MiB |
|    1   N/A  N/A     17007      C   python3                          6987MiB |
|    1   N/A  N/A     17055      C   python3                          6987MiB |
|    1   N/A  N/A     17090      C   python3                          6987MiB |
+-----------------------------------------------------------------------------+
(base) [lnx-idea006:network]#ps 17007 17055 17090
    PID TTY      STAT   TIME COMMAND
  17007 pts/0    Rl     2:22 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201211_E.yaml
  17055 pts/0    Rl     1:46 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201211_F.yaml
  17090 pts/0    Rl     1:24 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201211_G.yaml
(base) [lnx-idea006:network]#^C
(base) [lnx-idea006:network]#


#Dec 11th, Friday, 2020
lessons:
1  use the contrast of validation and training loss, instead of accuracy, to judge the reflection point of over-fitting;
   loss directly indicates the error with respect with ground truth, without other factors;
   while accuracy needs another threshold to measure accuracy values, and different thresholds will lead different accuracy values,
2  Training accuracy stuck at some point(e.g. 67%) means network that network stucks at a local minimum;

current best result: 20201210_D;




# Dec 10th, Thursday, 2020
Current the best result: expOCT2SysD_20201205_D:




# Dec 8th, 2020
"Overfitting is also caused by a deep model over training data. In that case, you'll observe divergence in loss between val and train very early."
--https://datascience.stackexchange.com/questions/43191/validation-loss-is-not-decreasing

# Dec 4th, Friday, 2020
The memory footprint of full loading all data into memory:
For Tongren data:
42*31*496*512*4 = 1.32 GB
For BES_3K thickness data:
2288*9*31*512*4 = 1.307 GB
1.307 GB x2   = 2.614 GB  for OD/OS eyes together.
Therefore all BES_3K all training and validation data can load into memory at dataset initialization.  --done

Observe the mean and std of thickness map:
(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsThicknessMap.py /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/33089_OS_7812_Volume_thickness_enface.npy
thicknessMap: C=9, H=31, W=512 for all below files:

/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/33089_OS_7812_Volume_thickness_enface.npy:
 mean= 30.530215236283237, std=15.603827787207281
/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/979_OD_8857_Volume_thickness_enface.npy:
 mean= 29.698770283127836, std=21.908612855917635
/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/1955_OS_14474_Volume_thickness_enface.npy:
 mean= 32.7970074596143, std=17.958001387144986
/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/1858_OD_13526_Volume_thickness_enface.npy:
 mean= 34.320023420447065, std=21.11553166304982

 Therefore, our Guassian noise to the thickness is N(0, 3) , which is about 20% of std of original thickness map.  --done;

 # delete ID for no xml file
 ID: 574,  from trianID

Todo:
1  all training data do a normalization and save its mean and std for validation and test data to use; --done
2  change gaussian noise std to 0.1 after the input data has normalization;   --done.

Experiment:
expOCT2SysD_20201204_A:  channels: [30, 30, 30, 60, 60, 60, 60, 60],
                         Result: Overfitting.
                         at epoch 100, training loss = 0.00164, and validation loss = 2.706
                         at stable status, validation acc = 54%
expOCT2SysD_20201204_B:  channels: [15, 15, 15, 30, 30, 30, 30, 30],
                         Result: Overfitting.
                         at epoch 100, training loss = 0.0117, and validation loss = 2.56
                         at stable status, validation acc = 53%

expOCT2SysD_20201205_A:  channels: [9, 9, 9, 15, 15, 15, 15, 15]
                         Result: Overfitting. Stop training at 40 epochs.

expOCT2SysD_20201205_B:  channels: [9, 9, 9, 9, 9, 9, 9, 9]
                         Result: Overfitting. at 300 epochs, traiing accruacy get 93% while validation get 50%;


expOCT2SysD_20201205_C: channels: [9, 8, 7, 6, 5, 4, 3, 3]
                        Result: overfitting.  at 300 epochs, traiing accruacy get 85% while validation get 55%;
                        at epoch 8. validation start exceed and deviate from training loss.



expOCT2SysD_20201205_D: channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 56%, and training accuracy is 58%.
                        at epoch 42, validation loss > training loss.
                        at threshold 0.45,  TPR 70%, TNR 0.47, Acc 60.0%


expOCT2SysD_20201205_E: channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # # 7 dropout layers.
                        validation accuray is 55%, and training accuracy is 58%.
                        at epoch 34, validation loss > training loss.
                        at threshold 0.4333,  TPR 74%, TNR 0.43, Acc 60.0%


expOCT2SysD_20201205_F: channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                        dropoutRates: [0.5,0.5,0.5,0.5, 0.5, 0.5, 0.0]  # # 7 dropout layers.
                        validation accuray is 45%, and training accuracy is 47%.
                        at epoch 159, validation loss > training loss.
                        at threshold 0.497,  TPR 1.0, TNR 0, Acc 54%

expOCT2SysD_20201205_G: channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                        dropoutRates: [0.5,0.4,0.3,0.3, 0.5, 0.25, 0.0]  # # 7 dropout layers.
                        validation accuray is 55%, and training accuracy is 58%.
                        at epoch 45, validation loss > training loss.
                        at threshold 0.485,  TPR 0.685, TNR 0.474, Acc 59.5%

# add network capacities, and validation data without augmentation.
expOCT2SysD_20201206_D: channels:     [90, 80, 70, 60, 50, 40, 30, 30]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 56%, and training accuracy is 69% at stable phase.
                        at epoch 5, validation loss > training loss.
                        at threshold 0.50,  TPR 53%, TNR 0.62, Acc 57.0%


expOCT2SysD_20201206_E: channels:     [60, 60, 60, 60, 60, 60, 60, 60]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 55%, and training accuracy is 67%.
                        at epoch 10, validation loss > training loss.
                        at threshold 0.4333,  TPR 66%, TNR 0.47, Acc 58.0%


expOCT2SysD_20201206_F: channels:     [60, 60, 60, 60, 60, 60, 60, 60]
                        dropoutRates: [0.5,0.5,0.5,0.5, 0.5, 0.5, 0.0]  # 7 dropout layers.
                        validation accuray is 58%, and training accuracy is 60%.
                        at epoch 9, validation loss > training loss.
                        at threshold 0.48  TPR 62%, TNR 55%, Acc 59%

expOCT2SysD_20201206_G: channels:     [90, 80, 70, 60, 50, 40, 30, 30]
                        dropoutRates: [0.5,0.4,0.3,0.3, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 57%, and training accuracy is 64%.
                        at epoch 10, validation loss > training loss.
                        at threshold 0.485,  TPR 0.56, TNR 0.59, Acc 58%

# cancel dropout at beginning of network layers.
expOCT2SysD_20201206_D:  channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                         dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                         validation accuray is 55%, and training accuracy is 76%.
                        at epoch 1, validation loss > training loss.
                        at threshold 0.31,  TPR 0.69, TNR 0.42, Acc 57%

expOCT2SysD_20201207_E:  channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                         dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                         validation accuray is 54%, and training accuracy is 71%.
                        at epoch 12, validation loss > training loss.
                        at threshold 0.31,  TPR 0.76, TNR 0.33, Acc 57%

expOCT2SysD_20201207_F:  channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                         dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.5, 0.0]  # 7 dropout layers.
                         validation accuray is 54%, and training accuracy is 74%.
                        at epoch 6, validation loss > training loss.
                        at threshold 0.39,  TPR 0.70, TNR 0.40, Acc 56%

expOCT2SysD_20201207_G: channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                        dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.0, 0.0]  # 7 dropout layers.
                        validation accuray is 54%, and training accuracy is 77%.
                        at epoch 5, validation loss > training loss.
                        at threshold 0.72,  TPR 0.33, TNR 0.77 Acc 53%

# Dec 10th, 2020: change 4 FC layers into a AvgPooling + 1 FC:
# as accuracy depends on threshold, using loss to judge reflection point is better
expOCT2SysD_20201210_A: channels:     [9, 8, 7, 6]
                        dropoutRates: [0.0,0.0,0.0,0.0]  # 4 dropout layers.
                        at stable stage: 100 epochs,  training acc: 77% continue increasing  , validation acc: 54%
                        at epoch 2, validation loss > training loss.
                        at threshold 0.44,  TPR 0.63, TNR 0.55 , Acc 0.55


expOCT2SysD_20201210_B: channels:     [64, 64, 64, 64]
                        dropoutRates: [0.0,0.0,0.0,0.0]  # 4 dropout layers.
                        at stable stage: training acc: 99% , validation acc: 52%
                        at epoch 3, validation loss > training loss.
                        at threshold 0.90,  TPR 0.38, TNR 0.69 , Acc 0.52


expOCT2SysD_20201210_C: channels:     [32, 32, 32, 32]
                        dropoutRates: [0.0,0.0,0.0,0.0]  # 4 dropout layers.
                        at stable stage: training acc: 99% , validation acc: 54%
                        at epoch 0, validation loss > training loss.
                        at threshold 0.55,  TPR 0.57, TNR 0.52 , Acc 0.55

expOCT2SysD_20201210_D: channels:     [64, 64, 64, 64]
                        dropoutRates: [0.0,0.5,0.5,0.5]  # 4 dropout layers.
                        at stable stage: training acc: 69% , validation acc: 55%
                        at epoch 3, validation loss > training loss.
                        at threshold 0.46,  TPR 0.69, TNR 0.47 , Acc 0.59

# use 2 conv layer network with(31,31) filters.
expOCT2SysD_20201211_A:
channels:     [128, 64]
dropoutRates: [0.5,0.5]  # 2 dropout layers.
stable at training 0.77, validation 0.56
at epoch 8, validaLoss > trainingLoss.
threshold 0.48,, TPR 0.73, TNR 0.46, Acc 0.61.

expOCT2SysD_20201211_B:
channels:     [256, 128]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 43, validaLoss > trainingLoss.  overfitting.
threshold 0.47,, TPR 0.67, TNR 0.52, Acc 0.61.

expOCT2SysD_20201211_C:
channels:     [128, 64]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 76, validaLoss > trainingLoss.  overfitting
threshold 0.46,, TPR 0.76, TNR 0.42, Acc 0.61.

expOCT2SysD_20201211_D:
channels:     [64, 64]
dropoutRates: [0.5,0.5]  # 2 dropout layers.
at epoch 13, validaLoss > trainingLoss.
threshold 0.45,, TPR 0.70, TNR 0.50, Acc 0.61.
=======================================================
expOCT2SysD_20201211_E: in lnx-idea006.ecn.uiowa.edu
channels:     [64, 64]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 39, validaLoss > trainingLoss.  overfitting
threshold 0.47, TPR 0.66, TNR 0.53, Acc 0.60.

expOCT2SysD_20201211_F: in lnx-idea006.ecn.uiowa.edu
channels:     [512, 256]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 33, validaLoss > trainingLoss.  overfitting
threshold 0.48, TPR 0.66, TNR 0.52, Acc 0.60.

expOCT2SysD_20201211_G: in lnx-idea006.ecn.uiowa.edu
channels:     [128, 128]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 45, validaLoss > trainingLoss.  overfitting. validation loss didn't increase.
threshold 0.50, TPR 0.64, TNR 0.55, Acc 0.60.

expOCT2SysD_20201211_H: in lnx-idea006.ecn.uiowa.edu  (worth to research.)
channels:     [64, 32]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 625, validaLoss =  trainingLoss.  No explict overfitting
threshold 0.46, TPR 0.79, TNR 0.40, Acc 0.61.

expOCT2SysD_20201211_I: in lnx-idea006.ecn.uiowa.edu   (worth to research.)
channels:     [32, 16]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 700, validaLoss = trainingLoss.  No explict overfitting
threshold 0.47, TPR 0.84, TNR 0.35, Acc 0.62.  Sum= 1.807

expOCT2SysD_20201211_J: in lnx-idea006.ecn.uiowa.edu
channels:     [16, 8]
dropoutRates: [0.5,0.5]  # 2 dropout layers.
at epoch 18, validaLoss > trainingLoss.  overfitting. But sum is 1.823
threshold 0.44, TPR 0.67, TNR 0.55, Acc 0.61.


==============================================
# one layer network  on Dec 12th, 2020
expOCT2SysD_20201212_A:  on c-xwu000
channels:     [512]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 15, validationLoss > trainingLoss.


expOCT2SysD_20201212_B: on c-xwu000
channels:     [256]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 44, validationLoss > trainingLoss.  Validaiton loss increase after inflection point. explict overfitting.
threshold 0.46, TPR 0.7, TNR 0.49, Acc 0.61


expOCT2SysD_20201212_C:  on c-xwu000
channels:     [128]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 44, validationLoss > trainingLoss.
threshold 0.46, TPR 0.73, TNR 0.45, Acc 0.60


expOCT2SysD_20201212_D:  on c-xwu000
channels:     [64]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 54, validationLoss > trainingLoss. overfitting.
threshold 0.49, TPR 0.62, TNR 0.57, Acc 0.60

===========================================

expOCT2SysD_20201212_E:  on lnx-idea005 _> iibi007
channels:     [32]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 57, validaLoss > trainingLoss.  but validation still decrease. (Not bad)
threshold 0.46, TPR 0.78, TNR 0.42, Acc 0.61.

expOCT2SysD_20201212_F:  on lnx-idea005 _> iibi007
channels:     [32]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 13, validaLoss > trainingLoss.  explict overfitting, validation loss increases.
threshold 0.47, TPR 0.64, TNR 0.53, Acc 0.59.

expOCT2SysD_20201212_G:  on lnx-idea005 _> iibi007
channels:     [16]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 69, validaLoss > trainingLoss.   a liitle overfitting.
threshold 0.47, TPR 0.77, TNR 0.40, Acc 0.60.


expOCT2SysD_20201212_H:  on lnx-idea005 _> iibi007
channels:     [16]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 15, validaLoss > trainingLoss.  explicit overfitting.
threshold 0.47, TPR 0.72, TNR 0.47, Acc 0.60.

expOCT2SysD_20201212_I:  on lnx-idea005 _> iibi007
channels:     [8]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 22, validaLoss > trainingLoss.  explicit overfitting.
threshold 0.46, TPR 0.74, TNR 0.43, Acc 0.60.

expOCT2SysD_20201212_J:  on lnx-idea005  _> c-xwu000 with pid: 30671  (too small is also not good.)
channels:     [4]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 20, validaLoss > trainingLoss.  overfitting.
threshold 0.49, TPR 0.69, TNR 0.47, Acc 0.58.


# Dec 3th, Thursday, 2020
generated all thickness enface images with 3x3 smooth filter.
at /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap

statistics age:
python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv Age$ number None
total 1807 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 1807 records
min=50.0; mean=63.38295517432208; max=93.0

python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv Age$ number None
total 481 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 481 records
min=50.0; mean=64.17671517671518; max=88.0

python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv Age$ number None
total 502 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 502 records
min=50.0; mean=63.83864541832669; max=87.0

Age prediction:
Han Peng, Weikang Gong, Christian F. Beckmann, Andrea Vedaldi, Stephen M. Smith.
``Accurate brain age prediction with lightweight deep neural networks"
bioRxiv 2019.12.17.879346; doi: https://doi.org/10.1101/2019.12.17.879346
used KL divergence loss with a gaussian distribution of mu=age, and sigma=1.

Age range: 40-100.

Network design for age:
1  layer as channel, input 2D conv network;
2  basic layer design:
layer name,   ouputSize,    channels,
input         31x512        9
conv_3x3      16x256        30
conv_3x3      8x128         30
conv_3x3      4x64          30
conv_3x3      2x32          60
conv_2x3      1x16          60
conv_1x4      1x8           60
conv_1x4      1x4           60
conv_1x4      1x1           60
conv_1x1      1x1           60
softmax       1x1           60
3  use 2 losses:
   A  KL divergence loss with mu=age, sigma=1;
   B  soft argmax + MSE;

Professor Wu directed first to do hypertension prediction.

Network design for hypertension:
1  layer as channel, input 2D conv network;
2  basic layer design:
layer name,   ouputSize,    channels,
input         31x512        9
conv_3x3      16x256        30
conv_3x3      8x128         30
conv_3x3      4x64          30
conv_3x3      2x32          60
conv_2x3      1x16          60
conv_1x4      1x8           60
conv_1x4      1x4           60
conv_1x4      1x1           60
conv_1x1      1x1           60
FC             1
BCEWithLogitsLoss      1






# Dec 1st, 2020
read a paper:
Yim, J., Chopra, R., Spitz, T. et al.
Predicting conversion to wet age-related macular degeneration using deep learning.
Nat Med 26, 892–899 (2020). https://doi.org/10.1038/s41591-020-0867-7

This paper from DeepMind used 3D one-hot-code tissue segmentation maps and raw 3D OCT image to ensemble to predict
the exAMD conversion of the follow eye after the first eye diagnosed as exAMD. It first segments OCT into 13 tissues and 3 artifacts
including vitreous body, neural retina, RPE, and hyper-reflective foci etc, and then code this 3D segmentation into one-hot
segmentation map as 13 channels to feed a 3D-dense-analog classification network to predict exAMD. And raw 3D OCT also feed a 3D-dense-analog
classification network to predict exAMD. Its ensemble is interesting which includes each fold model of 4-fold cross validation,
and each fold has 4 different initial parameter model, and 2 path(raw 3D OCT and segmentation map), so total 4x3x2 models ensemble with TTA.

This is an excellent paper, but with huge hardware resource. It trained 300K epochs in 16 GPUs for just one model,
which is not achievable in common university labs.

Its one-hot-code tissue segmentation map and reduced-parameter dense block design can be our reference in the future.



# Nov 26th, 2020
some raw images has problems:
1  91002_OD_4330_Volume data has problem. but it is not at hour training,validation, test set;

# Nov 25th, Wednesday, 2020
Meeting minute of OCT2SysDisease on Nov 24th, 2020
Attendants: Prof. Wu, Prof. Wang, Hui
Time: 20:00-21:30(Iowa Time) Nov 24th, 2020
Minutes:
1  It is better to choose big/major diseases:first hypertension, then diabetes;
2  The core of this project is not at prediction self; it is at the backward retina manifestation or retina impairment of systemic diseases;
3  Thickness map is the most important input, which can consider to use an average of 3x3 grid to alleviate segmentation error;
   A  use thickness map to predict age;
   B  use thickness map to predict hypertension;
   C  use thickness map to predict the severity of hypertension (systolic blood level);
4  Further design for next phase:
   A  description of the surface curvature may act as an input;
   B  axial length can be an input to judge its relation with hypertension;
   C  use thickness map plus 3D layer texture as input;
   D  use the OCT volume 5 years before strokes occur to predict stroke;
   E  use retina layer while keeping its layer curvature without flatting;

Professor Wu's comment:
1  It is better to choose big/major diseases:first hypertension, then diabetes;
2  The core of this project is not at prediction self; it is at the backward retina manifestation or retina impairment of systemic diseases;
3  Thickness map is the most important input, which can consider to use an average of 3x3 grid to alleviate segmentation error;
   A  use thickness map to predict age;
It should not be a prediction problem, but study the thickness changes with respect to ages.
   B  use thickness map to predict hypertension;
then to identify the retina impairment by hypertension.
   C  use thickness map to predict the severity of hypertension (systolic blood level);
4  Further design for next phase:
   A  description of the surface curvature may act as an input;
According to Prof. Wang, may NOT consider surface curvatures.
   B  axial length can be an input to judge its relation with hypertension;
   C  use thickness map plus 3D layer texture as input;
Let's see the results from the first experiment first.
   D  use the OCT volume 5 years before strokes occur to predict stroke;
This is a totally different project.
   E  use retina layer while keeping its layer curvature without flatting;
Somehow it's same as C. Let's see the results from the first experiment first.







# Nov 24th, 2020
Statistics on Congnitive$:

Cognitive Tag on Dataset:
                #cases    min  mean     max
training:       1760      5    24.80    30
validaiton:     473       4    26.11    30
test:           490       6    26.46    30

python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv Cognitive$ number 99
total 1807 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv
values for Cognitive$ have 1760 records
min=5.0; mean=24.79659090909091; max=30.0
 emptyValueIDList =
['287', '828', '1527', '1696', '2311', '2596', '3502', '4170', '4188', '4192', '4231', '4239', '4266', '4287', '4290', '4387', '4388', '4417', '4528', '4550', '4627', '4683', '4696', '4714', '4717', '4756', '4794', '4795', '4816', '4819', '4961', '4981', '4995', '5033', '5034', '5175', '5529', '6985', '31066', '34162', '34164', '34165', '34166', '34167', '34169', '34173', '120032']

python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv Cognitive$ number 99
total 481 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv
values for Cognitive$ have 473 records
min=4.0; mean=26.11416490486258; max=30.0
 emptyValueIDList =
['4184', '4253', '4549', '4822', '4969', '5239', '34065', '34170']

python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv Cognitive$ number 99
total 502 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv
values for Cognitive$ have 490 records
min=6.0; mean=26.46734693877551; max=30.0
 emptyValueIDList =
['551', '1186', '4182', '4187', '4191', '4475', '4477', '4682', '4779', '4913', '5021', '5174']





==================================
Hypertension data: 1: 1915; 0: 1535
input: 62-OCT
output: {0,1}

age range: [50,91], total 42 ranges


plan data division:
    training,   validation,    test,    sum
0,    1075  ,        230,     230,    1535
1,    1341  ,        287,     287,    1915
sum,  2416  ,        517,     517,    3450

Real data division according to hypertension:
    training,   validation,    test,    sum
0,    1007  ,        264,     264,    1535
1,    1257  ,        329,     329,    1915
sum,  2264  ,        593,     593,    3450

perAgeRange choice:
0,                    5-6       5-6
1,                    6-7       6-7

==========================================================================
=============Check Volumes and Clinical ID correspondence================
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/testID.csv
total 593 IDs in /home/hxie1/data/BES_3K/GTs/testID.csv
total 3288 OD volumes in /home/hxie1/data/BES_3K/raw
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/563_OD_5953_Volume', '/home/hxie1/data/BES_3K/raw/563_OD_5957_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1426_OD_16481_Volume', '/home/hxie1/data/BES_3K/raw/1426_OD_16511_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6892_OD_22210_Volume', '/home/hxie1/data/BES_3K/raw/6892_OD_27754_Volume']
find 560 corresponding volumes with ID
NonExistIDList: ['294', '365', '526', '528', '651', '1303', '1988', '2242', '2449', '3622', '4087', '4092', '4149', '4943', '5874', '6002', '6304', '6973', '32085', '34030', '34132', '34176', '110016', '110162', '110177', '110186', '110187', '120074', '170079', '170088']
total 30 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/validationID.csv
total 593 IDs in /home/hxie1/data/BES_3K/GTs/validationID.csv
total 3288 OD volumes in /home/hxie1/data/BES_3K/raw
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/82_OD_2614_Volume', '/home/hxie1/data/BES_3K/raw/82_OD_2791_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/179_OD_4915_Volume', '/home/hxie1/data/BES_3K/raw/179_OD_4914_Volume', '/home/hxie1/data/BES_3K/raw/179_OD_4907_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1703_OD_16532_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16571_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16531_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16582_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5191_OD_29751_Volume', '/home/hxie1/data/BES_3K/raw/5191_OD_29755_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34127_OD_24960_Volume', '/home/hxie1/data/BES_3K/raw/34127_OD_26784_Volume']
find 548 corresponding volumes with ID
NonExistIDList: ['88', '92', '203', '284', '1264', '1962', '1989', '2845', '4009', '4016', '4030', '4070', '4079', '4125', '4498', '4783', '4801', '4856', '4937', '4938', '4949', '5146', '5470', '5542', '5745', '6278', '6966', '32153', '33085', '34133', '34168', '34632', '110015', '120037', '120051', '120087', '120174', '170065', '170075', '170222']
total 40 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/trainID.csv
total 2264 IDs in /home/hxie1/data/BES_3K/GTs/trainID.csv
total 3288 OD volumes in /home/hxie1/data/BES_3K/raw
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/123_OD_25375_Volume', '/home/hxie1/data/BES_3K/raw/123_OD_1936_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/378_OD_954_Volume', '/home/hxie1/data/BES_3K/raw/378_OD_958_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/600_OD_4409_Volume', '/home/hxie1/data/BES_3K/raw/600_OD_4480_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/773_OD_5087_Volume', '/home/hxie1/data/BES_3K/raw/773_OD_5100_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1064_OD_8896_Volume', '/home/hxie1/data/BES_3K/raw/1064_OD_8892_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1070_OD_25149_Volume', '/home/hxie1/data/BES_3K/raw/1070_OD_16613_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1296_OD_9602_Volume', '/home/hxie1/data/BES_3K/raw/1296_OD_24884_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1536_OD_11367_Volume', '/home/hxie1/data/BES_3K/raw/1536_OD_11364_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1690_OD_15989_Volume', '/home/hxie1/data/BES_3K/raw/1690_OD_15976_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1947_OD_14086_Volume', '/home/hxie1/data/BES_3K/raw/1947_OD_13585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/2293_OD_10524_Volume', '/home/hxie1/data/BES_3K/raw/2293_OD_10533_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4479_OD_31798_Volume', '/home/hxie1/data/BES_3K/raw/4479_OD_31794_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4973_OD_29833_Volume', '/home/hxie1/data/BES_3K/raw/4973_OD_29837_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5152_OD_25166_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25157_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25171_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25169_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25167_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25168_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5834_OD_16804_Volume', '/home/hxie1/data/BES_3K/raw/5834_OD_16797_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6049_OD_19216_Volume', '/home/hxie1/data/BES_3K/raw/6049_OD_20607_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6253_OD_20370_Volume', '/home/hxie1/data/BES_3K/raw/6253_OD_20367_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6963_OD_22638_Volume', '/home/hxie1/data/BES_3K/raw/6963_OD_22651_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32009_OD_9268_Volume', '/home/hxie1/data/BES_3K/raw/32009_OD_12398_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32132_OD_15813_Volume', '/home/hxie1/data/BES_3K/raw/32132_OD_15817_Volume', '/home/hxie1/data/BES_3K/raw/32132_OD_15812_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/33019_OD_7226_Volume', '/home/hxie1/data/BES_3K/raw/33019_OD_7229_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34174_OD_31686_Volume', '/home/hxie1/data/BES_3K/raw/34174_OD_31683_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34540_OD_27868_Volume', '/home/hxie1/data/BES_3K/raw/34540_OD_27872_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34623_OD_28790_Volume', '/home/hxie1/data/BES_3K/raw/34623_OD_28817_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/120090_OD_3733_Volume', '/home/hxie1/data/BES_3K/raw/120090_OD_8398_Volume']
find 2034 corresponding volumes with ID
NonExistIDList: ['60', '289', '290', '315', '328', '333', '341', '349', '357', '530', '576', '577', '592', '626', '671', '696', '719', '755', '756', '900', '910', '911', '969', '1088', '1213', '1217', '1340', '1342', '1353', '1354', '1461', '1476', '1482', '1513', '1532', '1587', '1616', '1642', '1647', '1675', '1676', '1719', '1720', '1724', '1763', '1794', '1802', '1870', '1940', '1968', '1969', '2011', '2014', '2035', '2036', '2045', '2057', '2061', '2092', '2100', '2101', '2106', '2107', '2112', '2120', '2121', '2122', '2123', '2128', '2150', '2157', '2200', '2207', '2243', '2261', '2392', '2411', '2422', '2426', '2428', '2450', '2455', '2466', '2573', '2574', '2594', '2671', '2681', '2698', '2743', '2753', '2775', '2864', '3603', '3604', '3606', '3609', '3621', '4014', '4039', '4049', '4078', '4082', '4083', '4114', '4117', '4145', '4152', '4174', '4221', '4241', '4262', '4296', '4318', '4372', '4413', '4523', '4811', '4857', '4892', '4895', '4916', '4941', '4942', '4945', '4948', '4994', '5024', '5047', '5110', '5200', '5213', '5546', '5728', '5830', '5835', '5897', '5984', '6093', '6300', '6649', '6679', '6782', '6843', '6869', '6982', '7019', '31026', '31034', '31038', '31143', '32056', '32059', '32102', '32106', '32115', '32123', '32131', '32133', '32148', '32151', '32152', '32154', '32160', '32161', '34045', '34136', '34553', '34613', '34626', '110002', '110009', '110010', '110018', '110062', '110074', '110115', '110128', '120004', '120007', '120008', '120015', '120041', '120059', '120104', '120112', '120116', '120146', '120153', '120155', '120161', '120180', '120198', '120225', '120245', '120253', '120258', '140014', '140015', '170069', '170083', '170084', '170097', '170098', '170117']
total 205 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#

================================Tidy on Oct 2nd 2020===============

About the correspondence between clinical data and OD volume images.

Summary:
1  From the BES clinical excel file, there are 3450 IDs with hypertension ground truth {0,1};
2  5 original IDs use ????.1 float ID, Other use integer ID; (as Notes for future)
3  In above 3450 IDs, there are 275 IDs without corresponding OD volume images;
4  In above 3450 IDs, there are 33 IDs with multiple different OD volume images;
5  I directly do not use 275+33= 308 IDs , which make total data set of 3142 IDs for training, validation and test;
6  In 3142 patients: training 2034; validation 548; test 560;

ID list without OD volume images:
['60', '289', '290', '315', '328', '333', '341', '349', '357', '530', '576', '577', '592', '626', '671', '696', '719',
'755', '756', '900', '910', '911', '969', '1088', '1213', '1217', '1340', '1342', '1353', '1354', '1461', '1476', '1482',
'1513', '1532', '1587', '1616', '1642', '1647', '1675', '1676', '1719', '1720', '1724', '1763', '1794', '1802', '1870',
'1940', '1968', '1969', '2011', '2014', '2035', '2036', '2045', '2057', '2061', '2092', '2100', '2101', '2106', '2107',
'2112', '2120', '2121', '2122', '2123', '2128', '2150', '2157', '2200', '2207', '2243', '2261', '2392', '2411', '2422',
'2426', '2428', '2450', '2455', '2466', '2573', '2574', '2594', '2671', '2681', '2698', '2743', '2753', '2775', '2864',
'3603', '3604', '3606', '3609', '3621', '4014', '4039', '4049', '4078', '4082', '4083', '4114', '4117', '4145', '4152',
'4174', '4221', '4241', '4262', '4296', '4318', '4372', '4413', '4523', '4811', '4857', '4892', '4895', '4916', '4941',
'4942', '4945', '4948', '4994', '5024', '5047', '5110', '5200', '5213', '5546', '5728', '5830', '5835', '5897', '5984',
'6093', '6300', '6649', '6679', '6782', '6843', '6869', '6982', '7019', '31026', '31034', '31038', '31143', '32056',
'32059', '32102', '32106', '32115', '32123', '32131', '32133', '32148', '32151', '32152', '32154', '32160', '32161',
'34045', '34136', '34553', '34613', '34626', '110002', '110009', '110010', '110018', '110062', '110074', '110115',
'110128', '120004', '120007', '120008', '120015', '120041', '120059', '120104', '120112', '120116', '120146', '120153',
'120155', '120161', '120180', '120198', '120225', '120245', '120253', '120258', '140014', '140015', '170069', '170083',
'170084', '170097', '170098', '170117', '88', '92', '203', '284', '1264', '1962', '1989', '2845', '4009', '4016', '4030',
 '4070', '4079', '4125', '4498', '4783', '4801', '4856', '4937', '4938', '4949', '5146', '5470', '5542', '5745', '6278',
 '6966', '32153', '33085', '34133', '34168', '34632', '110015', '120037', '120051', '120087', '120174', '170065', '170075',
 '170222', '294', '365', '526', '528', '651', '1303', '1988', '2242', '2449', '3622', '4087', '4092', '4149', '4943',
 '5874', '6002', '6304', '6973', '32085', '34030', '34132', '34176', '110016', '110162', '110177', '110186', '110187',
 '120074', '170079', '170088']

Same ID has mulitple different OD volume images:
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/123_OD_25375_Volume', '/home/hxie1/data/BES_3K/raw/123_OD_1936_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/378_OD_954_Volume', '/home/hxie1/data/BES_3K/raw/378_OD_958_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/600_OD_4409_Volume', '/home/hxie1/data/BES_3K/raw/600_OD_4480_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/773_OD_5087_Volume', '/home/hxie1/data/BES_3K/raw/773_OD_5100_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1064_OD_8896_Volume', '/home/hxie1/data/BES_3K/raw/1064_OD_8892_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1070_OD_25149_Volume', '/home/hxie1/data/BES_3K/raw/1070_OD_16613_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1296_OD_9602_Volume', '/home/hxie1/data/BES_3K/raw/1296_OD_24884_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1536_OD_11367_Volume', '/home/hxie1/data/BES_3K/raw/1536_OD_11364_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1690_OD_15989_Volume', '/home/hxie1/data/BES_3K/raw/1690_OD_15976_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1947_OD_14086_Volume', '/home/hxie1/data/BES_3K/raw/1947_OD_13585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/2293_OD_10524_Volume', '/home/hxie1/data/BES_3K/raw/2293_OD_10533_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4479_OD_31798_Volume', '/home/hxie1/data/BES_3K/raw/4479_OD_31794_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4973_OD_29833_Volume', '/home/hxie1/data/BES_3K/raw/4973_OD_29837_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5152_OD_25166_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25157_Volume',
                    '/home/hxie1/data/BES_3K/raw/5152_OD_25171_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25169_Volume',
                    '/home/hxie1/data/BES_3K/raw/5152_OD_25167_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25168_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5834_OD_16804_Volume', '/home/hxie1/data/BES_3K/raw/5834_OD_16797_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6049_OD_19216_Volume', '/home/hxie1/data/BES_3K/raw/6049_OD_20607_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6253_OD_20370_Volume', '/home/hxie1/data/BES_3K/raw/6253_OD_20367_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6963_OD_22638_Volume', '/home/hxie1/data/BES_3K/raw/6963_OD_22651_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32009_OD_9268_Volume', '/home/hxie1/data/BES_3K/raw/32009_OD_12398_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32132_OD_15813_Volume', '/home/hxie1/data/BES_3K/raw/32132_OD_15817_Volume',
                    '/home/hxie1/data/BES_3K/raw/32132_OD_15812_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/33019_OD_7226_Volume', '/home/hxie1/data/BES_3K/raw/33019_OD_7229_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34174_OD_31686_Volume', '/home/hxie1/data/BES_3K/raw/34174_OD_31683_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34540_OD_27868_Volume', '/home/hxie1/data/BES_3K/raw/34540_OD_27872_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34623_OD_28790_Volume', '/home/hxie1/data/BES_3K/raw/34623_OD_28817_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/120090_OD_3733_Volume', '/home/hxie1/data/BES_3K/raw/120090_OD_8398_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/82_OD_2614_Volume', '/home/hxie1/data/BES_3K/raw/82_OD_2791_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/179_OD_4915_Volume', '/home/hxie1/data/BES_3K/raw/179_OD_4914_Volume',
                    '/home/hxie1/data/BES_3K/raw/179_OD_4907_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1703_OD_16532_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16571_Volume',
                   '/home/hxie1/data/BES_3K/raw/1703_OD_16531_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16582_Volume',
                   '/home/hxie1/data/BES_3K/raw/1703_OD_16585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5191_OD_29751_Volume', '/home/hxie1/data/BES_3K/raw/5191_OD_29755_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34127_OD_24960_Volume', '/home/hxie1/data/BES_3K/raw/34127_OD_26784_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/563_OD_5953_Volume', '/home/hxie1/data/BES_3K/raw/563_OD_5957_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1426_OD_16481_Volume', '/home/hxie1/data/BES_3K/raw/1426_OD_16511_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6892_OD_22210_Volume', '/home/hxie1/data/BES_3K/raw/6892_OD_27754_Volume']

# ID name strange:
ID: 5320, and 5320.1; 6084 and 6084.1 are different patients

# original raw data contain .1 volume:
ls -ld *.*_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:29 2697.1_OD_7130_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 2697.1_OS_7136_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 4453.1_OD_23184_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:31 4453.1_OS_23187_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:30 4912.1_OD_30008_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:34 4912.1_OS_30012_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:25 5320.1_OD_26315_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 5320.1_OS_26320_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 6084.1_OD_17542_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:33 6084.1_OS_17546_Volume

As voluem image save in integer Id directory, all above *.1 ID change 9*1 ID, eg. 2697.1 -> 926971
modify:
1  modify clinincal data 5 rows in the BESClinicalGT_Analysis.xlsx
2  modify 10 volume names below: eg. 2697.1 -> 926971;
    /home/hxie1/data/BES_3K/raw/2697.1_OD_7130_Volume,
    /home/hxie1/data/BES_3K/raw/2697.1_OS_7136_Volume,
    /home/hxie1/data/BES_3K/raw/4453.1_OD_23184_Volume
    /home/hxie1/data/BES_3K/raw/4453.1_OS_23187_Volume
    /home/hxie1/data/BES_3K/raw/4912.1_OD_30008_Volume
    /home/hxie1/data/BES_3K/raw/4912.1_OS_30012_Volume
    /home/hxie1/data/BES_3K/raw/5320.1_OD_26315_Volume
    /home/hxie1/data/BES_3K/raw/5320.1_OS_26320_Volume
    /home/hxie1/data/BES_3K/raw/6084.1_OD_17542_Volume
    /home/hxie1/data/BES_3K/raw/6084.1_OS_17546_Volume


below volumes are original *.1*_Volume:
[c-xwu000:raw]#ls -ld 9????1_*_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:29 926971_OD_7130_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 926971_OS_7136_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 944531_OD_23184_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:31 944531_OS_23187_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:30 949121_OD_30008_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:34 949121_OS_30012_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:25 953201_OD_26315_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 953201_OS_26320_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 960841_OD_17542_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:33 960841_OS_17546_Volume

Oct 2nd, 2020
Data division and basic statistics before coding:
below bracket() indicates patients number.

                    Training(2034)         Validation(548)     Test(560)
value               0,       1 ,          0,        1,       0,      1
hypertension:       44.4%  55.6%         44.9%     55.1%    44.3%   55.7%

                    1,       2 ,          1,        2,       1,       2
gender:             42.8%,  57.2%,       45.6%    54.4%,    45.4%,  54.6%


                      Training(2034)         Validation(548)            Test(560)
value               min,   avg,    max,      min,  avg,   max,         min, avg, max
age                 50,    64.0,   93,       50,   60.6,  88,          50,  64.5, 87


                       Training(1853)           Validation(547)              Test(560)
value               min,   avg,    max,      min,   avg,   max,         min,   avg,   max
AxialLength         18.96, 23.22, 30.88      19.39, 23.25, 30.69        21.09, 23.25, 26.76


                       Training(2033)           Validation(548)              Test(560)
value               min,   avg,    max,      min,   avg,   max,         min,   avg,   max
BP_Systolic:        78 ,   129 ,   217       74,    130,   216          70,    130,   205


                       Training(2034)           Validation(548)              Test(560)
value               min,   avg,    max,      min,   avg,   max,         min,   avg,   max
BP_Diastolic:       31,    69 ,    117       36,    69,    118          38,    70,   113


# Oct 3rd, 2020:
# check all volumes has 31 slices from the *_DelNonexist.csv list
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
total 2034 IDs in /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
total 3252 OD volumes in /home/hxie1/data/BES_3K/W512NumpyVolumes
find 2031 corresponding volumes with ID
NonExistIDList: ['574', '2750', '120035']
total 3 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
total 548 IDs in /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
total 3252 OD volumes in /home/hxie1/data/BES_3K/W512NumpyVolumes
find 546 corresponding volumes with ID
NonExistIDList: ['358', '1207']
total 2 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
total 560 IDs in /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
total 3252 OD volumes in /home/hxie1/data/BES_3K/W512NumpyVolumes
find 559 corresponding volumes with ID
NonExistIDList: ['367']
total 1 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/testID_delNonExist_final.csv

Final dataset division in the *_final.csv
train: 2031; validation: 546;  Test: 559;

# Oct 5th, 2020
(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final.csv hypertension_bp_plus_history$ binary
total 2031 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final.csv
values for hypertension_bp_plus_history$ have 2031 records
0 rate: 0.4441161989167898; 1 rate: 0.5558838010832102

total 546 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final.csv
values for hypertension_bp_plus_history$ have 546 records
0 rate: 0.45054945054945056; 1 rate: 0.5494505494505495

(base) [c-xwu000:dataPrepare]#python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_final.csv hypertension_bp_plus_history$ binary
total 559 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_final.csv
values for hypertension_bp_plus_history$ have 559 records
0 rate: 0.44364937388193204; 1 rate: 0.556350626118068



# Oct 6th, 2020
tail a small dataset for pretrain
train: 200, validation: 50
which are extracted from the first 200, and first 50 from the final dataset.
(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final_small.csv hypertension_bp_plus_history$ binary
total 200 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final_small.csv
values for hypertension_bp_plus_history$ have 200 records
0 rate: 0.36; 1 rate: 0.64

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final_small.csv hypertension_bp_plus_history$ binary
total 50 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final_small.csv
values for hypertension_bp_plus_history$ have 50 records
0 rate: 0.28; 1 rate: 0.72

# Oct 8th, 2020
delNonExist_final data:
training: 2031;  0: 44.4%;  1: 55.6%;
validation: 546; 0: 45.1%;  1: 54.9%;
test:     559;   0: 44.4%;  1: 55.6%;

A brief:
1 It needs 40 mins training for one epoch with an input of 31 slices per patients; It is unrealistic for training;
2 data set:
  training: 2031;  0: 44.4%;  1: 55.6%;
  validation: 546; 0: 45.1%;  1: 54.9%;
   test:     559;   0: 44.4%;  1: 55.6%;
3 Now I changed input as one middle slice of 31 slices of OD eye,
  it need one minute per epoch for VGG network; and 0.5 min per peoch for mobileNetV3;
4 Using mobileNet V3, it can get training accuracy 100% in about 400 epochs; but validation accuracy get stuck at 60%;
5 It shows nework at training, but overfiting, which is difefrent from Ovarian cancer project;
6 In future 2 days, I will spent time to reduce its overfitting;

If you are available, you may tell me your time when I can show some training result to you.

# Oct 8th, 2020
Experiment Analysis: for center slice as Input=====================================================================================
            Network                 Pooling     InputActivation LR     dropout  weightDecay    FC            OutputC     trainAccGet70%  trainAccGet100%  validation
20201008_A: Conv2DFeatureNet        Avg         True            0.1    0.5      None        [512, 256, 1]   1024        96              166             57% first big oscillaltion, plane
20201008_B: MobileNetV3_OCT2SysD    Avg         True            0.001  0.5      None        [512, 256, 1]   1024        272             418             56% small oscillation
20201008_C: MobileNetV3_OCT2SysD    Avg         False           0.01   0.5      1e-5        [512, 256, 1]   1024        29              160             57% later stable
20201008_D: Conv2DFeatureNet        Avg         False           0.1    0.5      None        [512, 256, 1]   1024        107             176             56% oscillation
20201008_G: MobileNetV3_OCT2SysD    Avg         False           0.01   0.5*2    1e-4        [512, 256, 1]   1024        29              121             55% oscillation ;  this is improved version of _C.
20201008_H: MobileNetV3_OCT2SysD    Avg         False           0.01   0.8      1e-3        [512,1]         1024        18              101             56% later stable;
20201009_A: moibleNetv3_small       Avg         False           0.01   0.5      1e-2        [64,1]          128         8               40              55% oscillation;
20201009_B: mobileNetv3_small       Max         False           0.01   0.8      1e-1        [64,1]          128         INF             INF             55%, (looks underfitting)
20201009_C: mobileNetv3_small       Max         False           0.01   0.5      1e-2        [64,1]          128         18              134             52%
*20201009_D: mobileNetv3_small       Max         False           0.01   0.8      1e-2        [64,1]          128         27              130             57.69% (Good basis)
20201009_E: mobileNetv3_small       Max         False           0.01   0.5      1e-1        [64,1]          128         INF             INF             55%, majority
20201009_F: mobileNetv3_small       Avg         False           0.01   0.5      1e-1        [64,1]          128         17              INF             55%, majority
20201009_G: mobileNetv3_small       Max         False           0.01   0.2      1e-1        [64,1]          128         INF             INF             55%, majority
20201009_H: mobileNetv3_small       Avg         False           0.01   0.8      1e-2        [64,1]          128         10              64              58%
20201009_I: mobileNetv3_small       IQR         False           0.01   0.8      1e-2        [64,1]          128         37              105             58%
20201009_J: mobileNetv3_small       Max         False           0.01   0.8      1e-2        [48,1]          96          29              127             53%
20201009_K: mobileNetv3_small       Avg         False           0.01   0.8      1e-2        [48,1]          96          11              70              57%
20201009_L: mobileNetv3_small       Avg         False           0.01   0.8      1e-2        [24,1]          48          9               135             56%
20201009_M: mobileNetv3_small       Max         False           0.01   0.8      1e-2        [24,1]          48          44              600             56%
20201009_N: mobileNetv3_small       Max         False           0.01   0.2      1e-2        [12,1]          24          26              153             54%
20201009_O: mobileNetv3_small       Avg         False           0.01   0.2      1e-2        [12,1]          24          8               74              57%
20201009_P: mobileNetv3_small       Max         False           0.01   0.2      1e-2        [1]             48          18              100             57%
20201009_Q: mobileNetv3_small       Max         False           0.01   0.2      1e-2        [1]             24          22              182             58% (Good result)
20201009_R: mobileNetv3_small       Avg         False           0.01   0.2      1e-2        [1]             12          5               70%             57%

Comparison:    OCT2SysD                OvarianCancer
data Size:      3136                    168
predict:        judge current status;   Predict future;
Image model:    Similar;                Various, Each patient cancer is unique;
Classification: Binary;                 Binary;
Network:        MobileNetV3;            MobileNetV3;


# Oct 10th, 2020
Use randoom single slice as input to network:

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv hypertension_bp_plus_history$  binary
total 2034 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
values for hypertension_bp_plus_history$ have 2034 records
0 rate: 0.443952802359882; 1 rate: 0.556047197640118

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv hypertension_bp_plus_history$  binary
total 548 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
values for hypertension_bp_plus_history$ have 548 records
0 rate: 0.4489051094890511; 1 rate: 0.551094890510949

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv hypertension_bp_plus_history$  binary
total 560 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
values for hypertension_bp_plus_history$ have 560 records
0 rate: 0.44285714285714284; 1 rate: 0.5571428571428572

delNonExist data:
training: 2034;  0: 44.4%;  1: 55.6%;
validation: 548; 0: 44.9%;  1: 55.1%;
test:     560;   0: 44.3%;  1: 55.7%;

delete W=384 image ID:
(base) [c-xwu000:dataPrepare]#python3.7 ./deleteNonStdID.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
deleted 1 IDs in /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#python3.7 ./deleteNonStdID.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
No ID deleted.
(base) [c-xwu000:dataPrepare]#python3.7 ./deleteNonStdID.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
deleted 1 IDs in /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#

20201010, statistics data distribution, with deleting error width ID
training: 2033;  0: 44.4%;  1: 55.6%;
validation: 548; 0: 44.9%;  1: 55.1%;
test:     559;   0: 44.4%;  1: 55.6%;

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv hypertension_bp_plus_history$ binary
total 2033 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv
values for hypertension_bp_plus_history$ have 2033 records
0 rate: 0.4441711756025578; 1 rate: 0.5558288243974422

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv hypertension_bp_plus_history$ binary
total 548 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv
values for hypertension_bp_plus_history$ have 548 records
0 rate: 0.4489051094890511; 1 rate: 0.551094890510949

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv hypertension_bp_plus_history$ binary
total 559 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv
values for hypertension_bp_plus_history$ have 559 records
0 rate: 0.44364937388193204; 1 rate: 0.556350626118068

=================Use Random Slice as input to Network on Oct 10th, 2020================================================================================================
            Network                 Pooling     InputActivation LR     LRPatience   dropout  weighDecay    FC            OutputC     trainAccGet60%  trainAccGet70%     trainAccGet100%    validation
20201010_A: mobileNetv3_small       Avg         False           0.01   3             0.2     1e-2          [1]           12          150                                                   max60%
20201010_B: mobileNetv3_small       Avg         False           0.01   3             0.8     1e-2          [64,1]        128         161                                                   max60%
20201010_C: mobileNetv3_small       Avg         False           0.01   30            0.2     1e-2          [1]           12          75               1.8K                                 max61.5%
20201010_D: mobileNetv3_small       Avg         False           0.01   30            0.8     1e-2          [64,1]        128         100                                                   max62%

Oct 13th, 2020 13:29
Current running program:
(base) [c-xwu000:network]#ps 941 938 615 642
GPU   PID TTY      STAT   TIME COMMAND
2     615 ?        Rl   9161:56 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201012_A.yaml
3     642 ?        Rl   8672:33 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201012_B.yaml
1     938 ?        Rl   29848:39 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201010_C.yaml
0     941 ?        Rl   29842:02 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201010_D.yaml

=================Use Random Slice as input to Network on Oct 10th, 2020, with batch size 107 ========================================================================
            Network                 Pooling     InputActivation LR     LRPatience LrDecayFactor  dropout  weighDecay    FC            OutputC     trainAccGet60%  trainAccGet80%     trainAccGet100%    validation
20201012_A: mobileNetv3_small       Avg         False           0.1    62         0.826          0.8     1e-2          [512,256,1]    1024        50                                                   max60%
20201012_B: mobileNetv3_small       Avg         False           0.1    62         0.826          0.8     1e-2          [256,128,1]    512         36                                                   max61.68%
20201015_A: mobile_small(pretrain)  Avg         False           0.1    5          0.8            0.5     1e-3          [256,128,1]    512         Inf oscillation at 55%
20201015_B: mobileNetv2_small       Avg         False           0.1    5          0.8            0.5     1e-3          [256,128,1]    512         28              INf                                  58%(max60%)
20201015_C: mobileNetv2_small       Avg         False           0.1    4          0.8            0.2     1e-4          [256,128,1]    512         Inf             INf                                  55%
20201016_A: large                   Avg         False           0.1    5          0.8            0.2     1e-4          [512,256,1]    1024        ===Stop===
20201016_B: large (NoGauss)         Avg         False           0.1    5          0.8            0.3     1e-5          [512,256,1]    1024        40                                                   60%
            Above: when validation ACC gets 60%, its TPR 61.5%, TNR 58.5%, threshold 0.5027

# below expeiment add gaussian and salt pepper noise:
            Network            Notes     Pooling     InputActivation LR     LRPatience LrDecayFactor  dropout  weighDecay    FC            OutputC     trainingAcc  validation
20201017_A: Large                        Avg         False           0.1    6          0.8            0       1e-5          [512,256,1]    1024        63%          ACC61%,TNR45%; TPR75%; Threshold0.44;
20201017_B: Large(No flip aug)           Avg         False           0.1    6          0.8            0       1e-5          [512,256,1]    1024        64%          ACC61%,TNR48%; TPR72%; Threshold0.48;
20201017_C: large                        Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024        63.8%        ACC62%,TNR49%; TPR73%; Threshold0.44; (best)
            batchsize=40
20201017_D: Large                        Avg         False           0.1    6          0.8            0.5     1e-5          [512,256,1]    1024        63%          ACC61%,TNR51%; TPR69%; Threshold0.45;
20201019_A: Conv2DFeatureNet             Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024
            batchsize =20
20201019_B: Conv2DFeatureNet  ValidAug   Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024
            bathsize =20

# Oct 17th, 2020:
for 20201016_B: 4min /epoch

# Oct 20th, 2020:
exclude some patients with disease like below:
1. High myopia (Axiallength_26_ormore_exclude$ =1)
2. Glaucoma (Glaucoma_exclude$ =1)
3. Macula or retinal diseases (Retina_exclude$=1)

tag: excludeMGM (Myopia, Glaucoma, Macula disease)
(base) [c-xwu000:dataPrepare]#python3.7 ./excludeMyopiaGlaucomaMaculaD4.py  /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv
deleted 57 IDs in /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv
(base) [c-xwu000:dataPrepare]#python3.7 ./excludeMyopiaGlaucomaMaculaD4.py  /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv
deleted 67 IDs in /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv
(base) [c-xwu000:dataPrepare]#python3.7 ./excludeMyopiaGlaucomaMaculaD4.py  /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv
deleted 226 IDs in /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv
(base) [c-xwu000:dataPrepare]#

After deleting MGM,  statistic hypertension:

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv  hypertension_bp_plus_history$ binary
total 1807 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv
values for hypertension_bp_plus_history$ have 1807 records
0 rate: 0.4565578306585501; 1 rate: 0.54344216934145

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv  hypertension_bp_plus_history$ binary
total 481 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv
values for hypertension_bp_plus_history$ have 481 records
0 rate: 0.45322245322245325; 1 rate: 0.5467775467775468

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv  hypertension_bp_plus_history$ binary
total 502 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv
values for hypertension_bp_plus_history$ have 502 records
0 rate: 0.4342629482071713; 1 rate: 0.5657370517928287

after delete MGM cases: high myopia, Glaucoma, Macula/Retina disease cases:

    dataset		&number &tag0  	&tag1 \\
	training	&1807  	&45.66\% &54.34\%  \\
	validation	&481  	&45.32\% &54.68\%  \\
	test		&502  	&43.43\% &56.57\%  \\

total: 2790 cases.


            Network            Notes     Pooling     InputActivation LR     LRPatience LrDecayFactor  dropout  weighDecay    FC            OutputC     trainingAcc  validation
20201020_A: large                        Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024         61%(max)    ACC61%,TNR53%; TPR68%; Threshold0.48;
            batchSize=40
            Validation Augment
            GPU=3

20201020_B: Conv2DFeatureNet             Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024        51%          55%(stop)
            bathsize =20
            Validation Augment
            GPU=2
20201020_C: large                        Avg         False           0.5    6          0.8            0.2     1e-5          [512,256,1]    1024        64%(max)     ACC61%,TNR51%; TPR69%; Threshold0.48;
            batchSize=40
            Validation Augment
            GPU=3

20201020_D: Conv2DFeatureNet             Avg         False           0.5    6          0.8            0.2     1e-5          [512,256,1]    1024        61%          57%(stop)
            bathsize =20
            Validation Augment
            GPU=2

20201021_A: large                        Avg         False           1      6          0.8            0.2     1e-5          [512,256,1]    1024       65%(max)      ACC63%,TNR56%; TPR68%; Threshold0.49; (best)
            batchSize=40
            Validation Augment
            GPU=0
            LR=1

20201022_A: large                        Avg         False           2      6           0.8            0.2     1e-5          [512,256,1]    1024      64%(max)      ACC61%,TNR59%; TPR63%; Threshold0.50;
            batchSize=40
            Validation Augment
            GPU=1
            LR=2
            LrSchedular uses sum.

20201022_B: large                        Avg         False           1      6           0.8            0.2     1e-5          [512,256,1]    1024      65(max)       ACC62%,TNR50%; TPR71%; Threshold0.50;             batchSize=40
            Validation Augment
            GPU=2
            LR=1
            LrSchedular uses sum.