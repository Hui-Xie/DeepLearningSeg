# use 31 thickness +10 clinical futures to feed into deep learning.

debug: True
debugOutputPeriod: 50

# train config
device: torch.device('cuda:0')   #GPU ID
batchSize: 97 #  training data 1530, validation data:193, for 10-fold CV
learningRate: 1.0e-3  #
lrPatience: 6   # learning rate decay patience
lrDecayFactor: 0.8   # pow(0.826, 12) = 0.1
lrSchedulerMode: "min"  # "min" for loss, "max" for sum of Acc+TNR+TPR
weightDecay: 1.0e-5
useFixedLearningRate: False

#data source
existGTLabel: True
dataDir:  "/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thickness9Sector_9x9_41Ftrs_10CV"

# _delNonExist: delete ID nonexist, and repeated ID;
# _final: delete the ID whose slice number does not equal to 31.
# _delErrWID: delete W=384 image ID
# _excludeMGM: delete high myopia, Glaucoma, and Macula and retina disease
K_fold: 10
k: 1
trainingDataPath: "/home/hxie1/data/BES_3K/GTs/41Ftrs_10CV/trainID_41Ftrs_10CV_.csv"  # name needs add k
validationDataPath: "/home/hxie1/data/BES_3K/GTs/41Ftrs_10CV/validationID_41Ftrs_10CV_.csv"
testDataPath: "/home/hxie1/data/BES_3K/GTs/41Ftrs_10CV/testID_41Ftrs_10CV_.csv"

GTPath: "/home/hxie1/data/BES_3K/GTs/BESClinicalGT_Analysis.csv"
# ODOS: "OD"  # right(OD) or left(OS) eye

# this file is placed in netPath directory.
trainNormalizationStdMeanFileName: "trainNormalization_Thickness_Texture_layers"

# Network config
network: "ThicknessClinical41Ftrs_FCNet"
imageH: 9
imageW: 1
volumeSuffix: "_thickness9sector_9x9.npy"
nLayers: 3
# numConvEachLayer: 3
# bothEyes: False  # choose all OD eyes
inputChannels: 9 #
gradChannels: 0   # the added gradient channels beside raw image channel
inputWidth: 41 # 31 thickness +10 clinical features = 41
# where,
fcWidths: [40, 20,1] # num of neural in each FC layer # 42*40+41*20+21*1 =  2521 parameters
# dropoutRate: 0.0  # the dropout rate at final fully connected layer.
targetKey: "hypertension_bp_plus_history$"
appKeys: ["hypertension_bp_plus_history$", "gender", "Age$",'IOP$', 'AxialLength$', 'Height$', 'Weight$', 'Waist_Circum$', 'Hip_Circum$', 'SmokePackYears$',
          'Pulse$', 'Drink_quanti_includ0$', 'Glucose$_Corrected2015', 'CRPL$_Corrected2015',  'Choles$_Corrected2015', 'HDL$_Corrected2015', 'LDL$_Correcetd2015',
          'TG$_Corrected2015']
# labelTable head: patientID,                                          (0)
#             "hypertension_bp_plus_history$", "gender", "Age$",'IOP$', 'AxialLength$', 'Height$', 'Weight$', 'Waist_Circum$', 'Hip_Circum$', 'SmokePackYears$',
# columnIndex:         1                           2        3       4          5             6          7             8              9                10
#              'Pulse$', 'Drink_quanti_includ0$', 'Glucose$_Corrected2015', 'CRPL$_Corrected2015',  'Choles$_Corrected2015', 'HDL$_Corrected2015', 'LDL$_Correcetd2015',
# columnIndex:   11            12                           13                      14                       15                       16                  17
#              'TG$_Corrected2015',  BMI,   WaistHipRate,  LDL/HDL
# columnIndex:      18                 19       20         21

# selected clinical features
inputClinicalFeatures: ['Age', 'IOP', 'AxialLength', 'Pulse', 'Drink', 'Glucose', 'Triglyceride', 'BMI', 'WaistHipRate', 'LDLoverHDL']
clinicalFeatureColIndex: [3, 4, 5, 11, 12, 13, 18, 19, 20, 21]   # in label array index
numClinicalFtr: 10

# selected thickness features
inputThicknessFeatures: [ 'L0_S1', 'L0_S3', 'L0_S4', 'L0_S5', 'L1_S1', 'L1_S3', 'L2_S2', 'L2_S3', 'L3_S2', 'L3_S3', 'L3_S7', 'L4_S7', 'L5_S2', 'L5_S3', 'L5_S4', 'L5_S5',
                          'L5_S6', 'L5_S8', 'L6_S1', 'L6_S3', 'L6_S5', 'L6_S6', 'L6_S7', 'L7_S0', 'L7_S1', 'L7_S4', 'L7_S6', 'L7_S8', 'L8_S5', 'L8_S7', 'L8_S8',]
thicknessFeatureColIndex: [1, 3, 4, 5, 10, 12, 20, 21, 29, 30, 34, 43, 47, 48, 49, 50, 51, 53, 55, 57, 59, 60, 61, 63, 64, 67, 69, 71, 77, 79, 80,]  # the volume array index
numThicknessFtr: 31

# input to network, after feature selection.
# selectedFeatureNames: ['L0_S1', 'L0_S3', 'L0_S4', 'L0_S5', 'L1_S1', 'L1_S3', 'L2_S2', 'L2_S3', 'L3_S2', 'L3_S3', 'L3_S7', 'L4_S7', 'L5_S2', 'L5_S3', 'L5_S4', 'L5_S5',
#  'L5_S6', 'L5_S8', 'L6_S1', 'L6_S3', 'L6_S5', 'L6_S6', 'L6_S7', 'L7_S0', 'L7_S1', 'L7_S4', 'L7_S6', 'L7_S8', 'L8_S5', 'L8_S7', 'L8_S8',
# 'Age', 'IOP', 'AxialLength', 'Pulse', 'Drink', 'Glucose', 'Triglyceride', 'BMI', 'WaistHipRate', 'LDLoverHDL']
# selectedFeatureIndexes: [1, 3, 4, 5, 10, 12, 20, 21, 29, 30, 34, 43, 47, 48, 49, 50, 51, 53, 55, 57, 59, 60, 61, 63, 64, 67, 69, 71, 77, 79, 80, 82, 83, 84, 86, 87, 88, 91, 92, 93, 94]
# numSelectedFtr: 10


#dropoutRate: 0.2 # dropout after global average pooling

class01Percent:  [0.4367121848739496,0.5632878151260504]  # for 10-fold CV data
# class01Percent: [ 0.4441711756025578, 0.5558288243974422] # for rainID_delNonExist_delErrWID.csv
#class01Percent: [0.36, 0.64] # for 200 small training set

trainAugmentation: False
validationAugmentation: False
useAddSamplesAugment: False  # when true, do not use other data augmentation.
addSamplesProb: 0.6  #  data augmentation rate
augmentProb: 0.5  # normal augment prob
gaussianNoiseStd: 0.1 # gausssian nosie std with mean =0, after  input data used normalization
# for salt pepper noise
saltPepperRate: 0.1  # rate = (salt+pepper)/allPixels
saltRate: 0.5  # saltRate = salt/(salt+pepper)
flipAugmentation: True


# save network
netPath: "/home/hxie1/data/BES_3K/netParameters"  # net is saved at netpath / network / self_filename
loadNetPath: ""
outputDir: ""
logDir: "/home/hxie1/data/BES_3K/log"  # net is saved at logPath / network / self_filename
threshold: 0.50
