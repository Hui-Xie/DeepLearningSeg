=============training from sratch============
Program ID of Predictive Network training:  28989

Program commands: ['TrainResAttentionNet.py', '/home/hxie1/temp_netParameters/OvarianCancer/STNResNeXt', '1', '/home/hxie1/data/OvarianCancerCT/pixelSize223/numpy', '/home/hxie1/data/OvarianCancerCT/patientResponseDict.json', '0', '2']
Training log is in /home/hxie1/Projects/OvarianCancer/trainLog/log_ResAttention_CV0_20190820_165538.txt
.........
Traceback (most recent call last):
  File "TrainResAttentionNet.py", line 451, in <module>
    main()
  File "TrainResAttentionNet.py", line 297, in main
    loss.backward()
  File "/home/hxie1/anaconda3/lib/python3.7/site-packages/torch/tensor.py", line 107, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/hxie1/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py", line 93, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [3, 4096, 8, 8]], which is output 0 of LeakyReluBackward1, is at version 4; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
