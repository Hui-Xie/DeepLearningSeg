# date: Dec 23th, 2019.
# analyze 84 (=35+49) files corresponding with its response.

python3.7 analyzeLatentVector_LogisticRegression2.py
latent dir: /home/hxie1/data/OvarianCancerCT/primaryROI1_1_3/LatentCrossValidation/rawLatent_20191210_024607
There are total 84 patients.
Each patient has a latent vector of size (1536, 1)
Each feature alone predicts its response through a Logistic regression along patients dimension.
accuracy Threshold = 0.68, for each feature
program is working on 6000 epochs logistic regression, please wait......
best feature indices in training set:
[7, 10, 17, 21, 25, 28, 30, 32, 45, 52, 54, 79, 84, 93, 127, 128, 135, 160, 172, 174, 178, 182, 199, 203, 213, 224, 249, 250, 253, 260, 273, 278, 283, 286, 307, 333, 336, 344, 349, 356, 359, 371, 373, 375, 380, 382, 386, 411, 415, 426, 432, 436, 441, 448, 450, 451, 456, 459, 462, 465, 469, 479, 482, 495, 507, 541, 542, 543, 546, 548, 552, 562, 563, 578, 582, 587, 597, 598, 616, 617, 618, 629, 636, 639, 648, 662, 670, 677, 681, 684, 685, 688, 704, 713, 720, 723, 736, 739, 748, 755, 781, 785, 792, 834, 838, 840, 865, 870, 874, 875, 876, 879, 891, 901, 902, 903, 914, 922, 923, 947, 948, 955, 957, 980, 997, 998, 1018, 1024, 1025, 1026, 1029, 1033, 1044, 1048, 1051, 1066, 1077, 1078, 1092, 1110, 1113, 1119, 1137, 1151, 1169, 1172, 1177, 1191, 1198, 1204, 1206, 1207, 1220, 1226, 1231, 1234, 1243, 1247, 1257, 1267, 1276, 1297, 1308, 1309, 1338, 1342, 1345, 1357, 1364, 1367, 1368, 1370, 1409, 1417, 1418, 1419, 1426, 1429, 1442, 1443, 1454, 1462, 1473, 1480, 1484, 1490, 1499, 1503, 1507, 1518, 1528, 1533]
Its corresponding prediction accuracy:
0.6547619047619048	0.6547619047619048	0.6785714285714286	0.6428571428571429	0.6666666666666666	0.6666666666666666	0.6666666666666666	0.6547619047619048	0.6904761904761905	0.6547619047619048	0.6785714285714286	0.6547619047619048	0.6904761904761905	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6785714285714286	0.6547619047619048	0.6666666666666666	0.6666666666666666	0.6785714285714286	0.6547619047619048	0.6309523809523809	0.6666666666666666	0.6547619047619048	0.6666666666666666	0.6785714285714286	0.6666666666666666	0.6785714285714286	0.6547619047619048	0.6547619047619048	0.6666666666666666	0.6666666666666666	0.6547619047619048	0.6785714285714286	0.6547619047619048	0.6547619047619048	0.6666666666666666	0.6785714285714286	0.6785714285714286	0.6666666666666666	0.6547619047619048	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6666666666666666	0.6547619047619048	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6666666666666666	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6785714285714286	0.6547619047619048	0.6904761904761905	0.6547619047619048	0.6666666666666666	0.6666666666666666	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6666666666666666	0.6547619047619048	0.6666666666666666	0.6904761904761905	0.6428571428571429	0.6547619047619048	0.6547619047619048	0.6785714285714286	0.6666666666666666	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6666666666666666	0.6547619047619048	0.6666666666666666	0.6785714285714286	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6785714285714286	0.6547619047619048	0.6666666666666666	0.6785714285714286	0.6428571428571429	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6785714285714286	0.6904761904761905	0.6547619047619048	0.6547619047619048	0.6428571428571429	0.6547619047619048	0.6666666666666666	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6785714285714286	0.6428571428571429	0.6547619047619048	0.6666666666666666	0.6785714285714286	0.6904761904761905	0.6666666666666666	0.6785714285714286	0.6785714285714286	0.6547619047619048	0.6666666666666666	0.6547619047619048	0.6547619047619048	0.6904761904761905	0.6547619047619048	0.6785714285714286	0.6666666666666666	0.6547619047619048	0.6428571428571429	0.6904761904761905	0.6547619047619048	0.6904761904761905	0.6547619047619048	0.6785714285714286	0.6785714285714286	0.6785714285714286	0.6547619047619048	0.6190476190476191	0.6785714285714286	0.6547619047619048	0.6547619047619048	0.6904761904761905	0.6785714285714286	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6785714285714286	0.6547619047619048	0.6904761904761905	0.6547619047619048	0.6547619047619048	0.6309523809523809	0.6904761904761905	0.6666666666666666	0.6547619047619048	0.6904761904761905	0.6904761904761905	0.6785714285714286	0.6785714285714286	0.6904761904761905	0.6547619047619048	0.6547619047619048	0.6547619047619048	0.6785714285714286	0.6666666666666666	0.6666666666666666	0.6904761904761905	0.6666666666666666	0.6785714285714286	0.6666666666666666
Average prediction accuracy for checked indices: 0.6633804563492053


For  dice threshold: 0.0...
Its top 16 accuracies location:
indices:    [1429  581 1368  446 1251  588   45  986  616  884  791  793 1237  339
   47  130]
accuracies: [0.69047619 0.69047619 0.69047619 0.69047619 0.69047619 0.69047619
 0.69047619 0.70238095 0.69047619 0.69047619 0.70238095 0.70238095
 0.70238095 0.70238095 0.70238095 0.70238095]
There are 49 whose response prediction accuracy >0.68
there are 49 best featuress
best Feature Indices:
 [45, 47, 84, 130, 168, 191, 201, 282, 339, 347, 420, 429, 446, 468, 545, 559, 581, 588, 616, 681, 706, 791, 793, 846, 884, 955, 978, 986, 1038, 1066, 1086, 1151, 1204, 1207, 1224, 1237, 1251, 1275, 1282, 1297, 1368, 1418, 1429, 1442, 1461, 1462, 1496, 1507, 1511]
Logistic Figure: x axis is normalized latent value, y is response
 green x is GroudTruth, red line is prediciton


dice threshold list:    [0.0]
validation patients:    [84]
avgDice of validaiton:  [0.7890998830833686]
Rate of Response 1:     [0.6547619047619048]
minAccuracy:            [0.6190476190476191]
meanAccuracy:           [0.6573273189484129]
medianAccuracy:         [0.6547619047619048]
maxAccuracy:            [0.7023809523809523]
num of Best Features:   [49]
rate of Best Features:  [0.031901041666666664]
====================end of Logistic Regression 2================
(base) [c-xwu000:Tools]#
